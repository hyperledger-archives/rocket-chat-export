{"msg":"User <em>User_1</em> added by <em>rjones</em>.","username":"rjones","ts":"2018-11-19T18:14:58.936Z","type":"au"}
{"msg":"nage","username":"rjones","ts":"2018-11-19T18:15:08.873Z","type":"subscription-role-added"}
{"msg":"User <em>User_2</em> added by <em>rjones</em>.","username":"rjones","ts":"2018-11-19T18:15:38.148Z","type":"au"}
{"msg":"User <em>User_3</em> added by <em>rjones</em>.","username":"rjones","ts":"2018-11-19T18:15:50.698Z","type":"au"}
{"msg":"kenebert","username":"rjones","ts":"2018-11-19T18:16:05.769Z","type":"subscription-role-added"}
{"msg":"pknowles","username":"rjones","ts":"2018-11-19T18:16:09.445Z","type":"subscription-role-added"}
{"msg":"Has joined the channel.","username":"tom_weiss","ts":"2018-11-19T18:22:08.372Z","type":"uj"}
{"msg":"Has joined the channel.","username":"nhelmy","ts":"2018-11-19T18:23:51.511Z","type":"uj"}
{"msg":"Welcome to the new *#indy-semantics* channel, a home for all Hyperledger Indy data capture and semantics discussions!","username":"pknowles","ts":"2018-11-19T18:37:43.260Z"}
{"msg":"Welcome to the new *#indy-semantics* channel, a home for all Hyperledger Indy data capture and semantics discussions including schemas and overlays!","username":"pknowles","ts":"2018-11-19T18:37:43.260Z"}
{"msg":"Welcome to the new *#indy-semantics* channel, a home for all Hyperledger Indy data capture and semantics discussions!","username":"pknowles","ts":"2018-11-19T18:37:43.260Z"}
{"msg":"","username":"rjones","ts":"2018-11-19T18:54:45.163Z","attachments":[{"url":null,"remote":true,"fileId":null,"fileName":null}],"type":"message_pinned"}
{"msg":"*I leave this channel in your capable hands*","username":"rjones","ts":"2018-11-19T18:55:15.517Z"}
{"msg":"Has left the channel.","username":"rjones","ts":"2018-11-19T18:55:18.332Z","type":"ul"}
{"msg":"Thanks @rjones ","username":"nage","ts":"2018-11-19T19:07:09.654Z"}
{"msg":"Has joined the channel.","username":"rjones","ts":"2018-11-19T19:07:09.709Z","type":"uj"}
{"msg":"Home for all Hyperledger Indy data capture and semantics discussions including schemas and overlays","username":"nage","ts":"2018-11-19T19:07:30.901Z","type":"room_changed_topic"}
{"msg":"Has joined the channel.","username":"mtfkremoveme","ts":"2018-11-19T19:10:23.533Z","type":"uj"}
{"msg":"HI all! ","username":"mtfkremoveme","ts":"2018-11-19T19:10:53.888Z"}
{"msg":"Has left the channel.","username":"mtfkremoveme","ts":"2018-11-19T19:20:39.351Z","type":"ul"}
{"msg":"Has joined the channel.","username":"mtfk","ts":"2018-11-19T19:20:51.493Z","type":"uj"}
{"msg":"Has joined the channel.","username":"mtfkremoveme","ts":"2018-11-19T19:23:19.995Z","type":"uj"}
{"msg":"Has left the channel.","username":"mtfkremoveme","ts":"2018-11-19T19:23:42.103Z","type":"ul"}
{"msg":"Has left the channel.","username":"rjones","ts":"2018-11-19T19:37:12.418Z","type":"ul"}
{"msg":"Has joined the channel.","username":"Sean_Bohan","ts":"2018-11-19T20:39:51.444Z","type":"uj"}
{"msg":"Has joined the channel.","username":"darrell.odonnell","ts":"2018-11-19T22:00:08.920Z","type":"uj"}
{"msg":"Last Thursday, @mtfk and I presented *Overlays 1O1* to the *HL Indy WG* call attendees. The video from that call is housed at https://drive.google.com/open?id=1a4ydpu6RDlyrqWX7eLomElR_CTj8hUug","username":"pknowles","ts":"2018-11-19T22:05:44.182Z"}
{"msg":"Last Thursday, @mtfk and I presented *Overlays 1O1* to the *HL Indy WG* attendees. The video from that call is housed at https://drive.google.com/open?id=1a4ydpu6RDlyrqWX7eLomElR_CTj8hUug","username":"pknowles","ts":"2018-11-19T22:05:44.182Z"}
{"msg":"Last Thursday, @mtfk and I presented *Overlays* to the *Indy WG* attendees. The video from that call is housed at https://drive.google.com/open?id=1a4ydpu6RDlyrqWX7eLomElR_CTj8hUu","username":"pknowles","ts":"2018-11-19T22:05:44.182Z"}
{"msg":"Last Thursday, @mtfk and I presented *Overlays* to the *Indy WG* attendees. The video from that call is housed at https://drive.google.com/open?id=1a4ydpu6RDlyrqWX7eLomElR_CTj8hUug","username":"pknowles","ts":"2018-11-19T22:05:44.182Z"}
{"msg":"Last Thursday, @mtfk and I presented *Overlays* to the *Indy WG* attendees. The video from that call is available at https://drive.google.com/open?id=1a4ydpu6RDlyrqWX7eLomElR_CTj8hUug","username":"pknowles","ts":"2018-11-19T22:05:44.182Z"}
{"msg":"Last Thursday, @mtfk and I presented *Overlays* to the *Indy WG* attendees. The video from that call is available for viewing at https://drive.google.com/open?id=1a4ydpu6RDlyrqWX7eLomElR_CTj8hUug","username":"pknowles","ts":"2018-11-19T22:05:44.182Z"}
{"msg":"Last Thursday, @mtfk and I presented *Overlays* to the *Indy WG* attendees. The video from that call can be viewed at https://drive.google.com/open?id=1a4ydpu6RDlyrqWX7eLomElR_CTj8hUug","username":"pknowles","ts":"2018-11-19T22:05:44.182Z"}
{"msg":"User <em>User_4</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T22:12:25.599Z","type":"au"}
{"msg":"User <em>User_5</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T22:12:25.616Z","type":"au"}
{"msg":"User <em>User_6</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T22:12:25.673Z","type":"au"}
{"msg":"User <em>User_7</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T22:13:25.502Z","type":"au"}
{"msg":"User <em>User_8</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T22:13:25.522Z","type":"au"}
{"msg":"User <em>User_9</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T22:29:36.142Z","type":"au"}
{"msg":"User <em>User_10</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T22:30:29.640Z","type":"au"}
{"msg":"User <em>User_11</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T22:31:25.686Z","type":"au"}
{"msg":"User <em>User_12</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T22:38:44.103Z","type":"au"}
{"msg":"User <em>User_13</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T22:38:44.133Z","type":"au"}
{"msg":"User <em>User_14</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T22:38:44.151Z","type":"au"}
{"msg":"User <em>User_15</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T22:40:24.223Z","type":"au"}
{"msg":"User <em>User_16</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:36:39.883Z","type":"au"}
{"msg":"User <em>User_17</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:36:39.923Z","type":"au"}
{"msg":"User <em>User_18</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:36:39.951Z","type":"au"}
{"msg":"User <em>User_19</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:36:39.976Z","type":"au"}
{"msg":"User <em>User_20</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:36:40.013Z","type":"au"}
{"msg":"User <em>User_21</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:36:40.030Z","type":"au"}
{"msg":"User <em>User_22</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:36:40.060Z","type":"au"}
{"msg":"User <em>User_23</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:36:40.077Z","type":"au"}
{"msg":"User <em>User_24</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:36:40.108Z","type":"au"}
{"msg":"User <em>User_25</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:36:40.127Z","type":"au"}
{"msg":"User <em>User_26</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:36:40.582Z","type":"au"}
{"msg":"User <em>User_27</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:36:40.598Z","type":"au"}
{"msg":"User <em>User_28</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:36:40.626Z","type":"au"}
{"msg":"User <em>User_29</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:36:40.654Z","type":"au"}
{"msg":"User <em>User_30</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:36:40.670Z","type":"au"}
{"msg":"User <em>User_31</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:36:40.703Z","type":"au"}
{"msg":"User <em>User_32</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:36:40.720Z","type":"au"}
{"msg":"User <em>User_33</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:36:40.757Z","type":"au"}
{"msg":"User <em>User_34</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:36:40.775Z","type":"au"}
{"msg":"User <em>User_35</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:37:41.755Z","type":"au"}
{"msg":"User <em>User_36</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:39:18.856Z","type":"au"}
{"msg":"User <em>User_37</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:39:18.873Z","type":"au"}
{"msg":"User <em>User_38</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:39:18.889Z","type":"au"}
{"msg":"User <em>User_39</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:41:26.977Z","type":"au"}
{"msg":"User <em>User_40</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-11-19T23:55:41.203Z","type":"au"}
{"msg":"Very nice, @pknowles. I hope your SSI Meetup webinar went well today—my lunch with the University of Washington (who is very seriously looking into Hyperledger Indy and SSI) went long so I wasn't able to attend. But I'll watch the recording on SSI Meetup. ","username":"drummondreed","ts":"2018-11-20T03:13:31.585Z"}
{"msg":"Has joined the channel.","username":"arunwij","ts":"2018-11-20T05:11:19.007Z","type":"uj"}
{"msg":"Has joined the channel.","username":"gudkov","ts":"2018-11-20T10:48:20.819Z","type":"uj"}
{"msg":"Has joined the channel.","username":"mxs1491","ts":"2018-11-20T11:02:18.195Z","type":"uj"}
{"msg":"The video recording and slideshare presentation from yesterday’s *SSIMeetup* are now available for viewing. The title of the presentation was *Overlays 1O1: Establishing Schema Definitions within the Self-Sovereign Identity (SSI) Ecosystem*. Here is the link. Enjoy! http://ssimeetup.org/overlays-1o1-establishing-schema-definitions-self-sovereign-identity-ssi-ecosystem-paul-knowles-webinar-17/","username":"pknowles","ts":"2018-11-20T12:03:41.262Z"}
{"msg":"The video recording and slideshare presentation from yesterday’s *SSIMeetup* are now available for viewing. The title of the presentation: *Overlays 1O1: Establishing Schema Definitions within the Self-Sovereign Identity (SSI) Ecosystem*. Here is the link. Enjoy! http://ssimeetup.org/overlays-1o1-establishing-schema-definitions-self-sovereign-identity-ssi-ecosystem-paul-knowles-webinar-17/","username":"pknowles","ts":"2018-11-20T12:03:41.262Z"}
{"msg":"The video recording and slideshare presentation from yesterday’s *SSIMeetup* are now available for viewing. The title of the presentation: \"*Overlays 1O1: Establishing Schema Definitions within the Self-Sovereign Identity (SSI) Ecosystem*\". Here is the link. Enjoy! http://ssimeetup.org/overlays-1o1-establishing-schema-definitions-self-sovereign-identity-ssi-ecosystem-paul-knowles-webinar-17/","username":"pknowles","ts":"2018-11-20T12:03:41.262Z"}
{"msg":"The video recording and slideshare presentation from yesterday’s *SSIMeetup* are now available for viewing. The title of the presentation: \" *Overlays 1O1: Establishing Schema Definitions within the Self-Sovereign Identity (SSI) Ecosystem* \". Here is the link. Enjoy! http://ssimeetup.org/overlays-1o1-establishing-schema-definitions-self-sovereign-identity-ssi-ecosystem-paul-knowles-webinar-17/","username":"pknowles","ts":"2018-11-20T12:03:41.262Z"}
{"msg":"The video recording and slideshare presentation from yesterday’s *SSIMeetup* are now available for viewing. The title of the presentation: \" *Overlays 1O1: Establishing Schema Definitions within the Self-Sovereign Identity (SSI) Ecosystem* \". Here is the link. http://ssimeetup.org/overlays-1o1-establishing-schema-definitions-self-sovereign-identity-ssi-ecosystem-paul-knowles-webinar-17/","username":"pknowles","ts":"2018-11-20T12:03:41.262Z"}
{"msg":"Has joined the channel.","username":"Silona","ts":"2018-11-20T15:07:32.055Z","type":"uj"}
{"msg":"Has joined the channel.","username":"MattRaffel","ts":"2018-11-20T16:28:56.871Z","type":"uj"}
{"msg":"Awesome. Great job, Paul.","username":"drummondreed","ts":"2018-11-20T17:16:37.236Z"}
{"msg":"Has joined the channel.","username":"kannancet","ts":"2018-11-20T19:34:35.786Z","type":"uj"}
{"msg":"Lovely to be hear ","username":"tom_weiss","ts":"2018-11-20T20:55:48.533Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=wcFcSnpsnC23qtJC8) @tom_weiss Welcome, Old Bean!","username":"pknowles","ts":"2018-11-20T20:56:48.400Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=wcFcSnpsnC23qtJC8","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=wcFcSnpsnC23qtJC8","remote":true,"fileId":null,"fileName":null}]}
{"msg":"welcome!","username":"Sean_Bohan","ts":"2018-11-20T23:10:49.602Z"}
{"msg":"Has joined the channel.","username":"esplinr","ts":"2018-11-20T23:25:05.862Z","type":"uj"}
{"msg":"Due to the amalgamation of all data capture and semantics initiatives being undertaken on Hyperledger Indy, a new *Semantics WG* has been implemented in place of the old *Schemas and Overlays WG*. Our first meeting under the new name will take place on Tuesday, November 27th providing an opportunity for members of the community to discuss any HL Indy semantics initiatives that they've been working on. Here is the agenda and dial-in information for Tuesday's meeting ... \n\nMeeting: Semantics Working Group\nDate: Tuesday, 27th November\n\nTime:\n10am-11am PT\n11am-12pm MT\n12pm-1pm CT\n1pm-2pm ET\n6pm-7pm GMT\n\nAnyone is welcome to join the call.\n\nChair: Paul Knowles\n\nAgenda:\n• Quick round of participant introductions (Open) - 5 mins\n• Schemas/Overlays data capture architecture ( @pknowles / @mtfk ) - 15 mins\n   - Reference - https://github.com/mitfik/overlays-demo/blob/master/SOD.md\n• Sovrin Verifiable Credentials data model ( @brentzundel / @kenebert ) - 15 mins\n• Consent Receipt model ( @JanL 5 ) - 15 mins\n   - Reference - https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt\n• Any other business (Open) - 10 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727#  or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2018-11-26T07:54:26.715Z"}
{"msg":"Due to the amalgamation of all data capture and semantics initiatives being undertaken on Hyperledger Indy, a new *Semantics WG* has been implemented in place of the old *Schemas and Overlays WG*. Our first meeting under the new name will take place on Tuesday, November 27th providing an opportunity for members of the community to discuss any HL Indy semantics initiatives that they've been working on. Here is the agenda and dial-in information for Tuesday's meeting ... \n\nMeeting: Semantics Working Group\nDate: Tuesday, 27th November\n\nTime:\n10am-11am PT\n11am-12pm MT\n12pm-1pm CT\n1pm-2pm ET\n6pm-7pm GMT\n\nAnyone is welcome to join the call.\n\nChair: Paul Knowles\n\nAgenda:\n• Quick round of participant introductions (Open) - 5 mins\n• Schemas/Overlays data capture architecture ( @pknowles / @mtfk ) - 15 mins\n   - Reference - https://github.com/mitfik/overlays-demo/blob/master/SOD.md\n• Sovrin Verifiable Credentials data model ( @brentzundel / @kenebert ) - 15 mins\n• Consent Receipt model ( @JanL 5 ) - 15 mins\n   - Reference - https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt\n• Any other business (Open) - 10 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727#  or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2018-11-26T07:54:26.715Z"}
{"msg":"Due to the amalgamation of all data capture and semantics initiatives being undertaken on Hyperledger Indy, a new *Semantics WG* has been implemented in place of the old *Schemas and Overlays WG*. Our first meeting under the new name will take place on Tuesday, November 27th providing an opportunity for members of the community to discuss any HL Indy semantics initiatives that they've been working on. Here is the agenda and dial-in information for Tuesday's meeting ... \n\nMeeting: Semantics Working Group\nDate: Tuesday, 27th November\n\nTime:\n10am-11am PT\n11am-12pm MT\n12pm-1pm CT\n1pm-2pm ET\n6pm-7pm GMT\n\nAnyone is welcome to join the call.\n\nChair: Paul Knowles\n\nAgenda:\n• Quick round of participant introductions (Open) - 5 mins\n• Schemas/Overlays data capture architecture ( @pknowles / @mtfk ) - 15 mins\n   - Reference - https://github.com/mitfik/overlays-demo/blob/master/SOD.md\n• Sovrin Verifiable Credentials data model ( @brentzundel / @kenebert ) - 15 mins\n• Consent Receipt model ( @JanL 5 ) - 15 mins\n   - Reference - https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt\n• Any other business (Open) - 10 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727#  or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2018-11-26T07:54:26.715Z"}
{"msg":"Due to the amalgamation of all data capture and semantics initiatives being undertaken on Hyperledger Indy, a new *Semantics WG* has been implemented in place of the old *Schemas and Overlays WG*. Our first meeting under the new name will take place on Tuesday, November 27th providing an opportunity for members of the community to discuss any HL Indy semantics initiatives they've been working on. Here is the agenda and dial-in information for Tuesday's meeting ... \n\nMeeting: Semantics Working Group\nDate: Tuesday, 27th November\n\nTime:\n10am-11am PT\n11am-12pm MT\n12pm-1pm CT\n1pm-2pm ET\n6pm-7pm GMT\n\nAnyone is welcome to join the call.\n\nChair: Paul Knowles\n\nAgenda:\n• Quick round of participant introductions (Open) - 5 mins\n• Schemas/Overlays data capture architecture ( @pknowles / @mtfk ) - 15 mins\n   - Reference - https://github.com/mitfik/overlays-demo/blob/master/SOD.md\n• Sovrin Verifiable Credentials data model ( @brentzundel / @kenebert ) - 15 mins\n• Consent Receipt model ( @JanL 5 ) - 15 mins\n   - Reference - https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt\n• Any other business (Open) - 10 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727#  or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2018-11-26T07:54:26.715Z"}
{"msg":"Due to the amalgamation of all data capture and semantics initiatives being undertaken on Hyperledger Indy, a new *Semantics WG* has been implemented in place of the old *Schemas and Overlays WG*. Our first meeting under the new name will take place on Tuesday, November 27th providing an opportunity for members of the community to discuss any HL Indy semantics initiatives they've been working on. Here is the agenda and dial-in information for Tuesday's meeting ... \n\nMeeting: Semantics Working Group\nDate: Tuesday, 27th November\n\nTime:\n10am-11am PT\n11am-12pm MT\n12pm-1pm CT\n1pm-2pm ET\n6pm-7pm GMT\n\nAnyone is welcome to join the call.\n\nChair: Paul Knowles\n\nAgenda:\n• Quick round of participant introductions (Open) - 5 mins\n• Schemas/Overlays data capture architecture ( @pknowles / @mtfk ) - 15 mins\n   - Reference - https://github.com/mitfik/overlays-demo/blob/master/SOD.md\n• Sovrin Verifiable Credentials data model ( @brentzundel / @kenebert ) - 15 mins\n• Consent Receipt model ( @JanL 5  ) - 15 mins\n   - Reference - https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt\n• Any other business (Open) - 10 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727#  or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2018-11-26T07:54:26.715Z"}
{"msg":"Due to the amalgamation of all data capture and semantics initiatives being undertaken on Hyperledger Indy, a new *Semantics WG* has been implemented in place of the old *Schemas and Overlays WG*. Our first meeting under the new name will take place on Tuesday, November 27th providing an opportunity for members of the community to discuss any HL Indy semantics initiatives they've been working on. Here is the agenda and dial-in information for Tuesday's meeting ... \n\nMeeting: Semantics Working Group\nDate: Tuesday, 27th November\n\nTime:\n10am-11am PT\n11am-12pm MT\n12pm-1pm CT\n1pm-2pm ET\n6pm-7pm GMT\n\nAnyone is welcome to join the call.\n\nChair: Paul Knowles\n\nAgenda:\n• Quick round of participant introductions (Open) - 5 mins\n• Schemas/Overlays data capture architecture ( @pknowles / @mtfk ) - 15 mins\n   - Reference - https://github.com/mitfik/overlays-demo/blob/master/SOD.md\n• Sovrin Verifiable Credentials data model ( @brentzundel / @kenebert ) - 15 mins\n• Consent Receipt model ( @JanL 5 ) - 15 mins\n   - Reference - https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt\n• Any other business (Open) - 10 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727#  or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2018-11-26T07:54:26.715Z"}
{"msg":"Has joined the channel.","username":"brycecurtis","ts":"2018-11-27T15:51:57.053Z","type":"uj"}
{"msg":"This week's *Semantics WG* call starts in 15 minutes. Agenda Doc: https://drive.google.com/drive/u/0/folders/1kN-INYUNYB-yA8teZR3EarxcwdMMmKrl?ogsrc=32","username":"pknowles","ts":"2018-11-27T17:43:01.422Z"}
{"msg":"The agenda, video, notes, etc. from today's *Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, December 12th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2018-11-27T23:09:42.626Z"}
{"msg":"Has joined the channel.","username":"jljordan_bcgov","ts":"2018-11-30T04:01:05.362Z","type":"uj"}
{"msg":"Has joined the channel.","username":"olegwb","ts":"2018-11-30T12:20:34.605Z","type":"uj"}
{"msg":"@pknowles consider the following business case - I want to consider providing a Sovrin-backed Verifiable Credential from a credit union. My \"dream state\" would allow a combination of static data (e..g. \"MemberSince\", \"Institution Name\") and some dynamic data (e.g. \"Average Monthly Balance\", \"Good Customer Standing\"). \n\nI recognize that the current Verifiable Creds, particularly with the ZKP support, require totally new credentials when any data change. Does the current Overlay concept allow data augmentation - combining live/dynamic data from other sources with the VerCred static data?","username":"darrell.odonnell","ts":"2018-12-01T15:44:56.662Z"}
{"msg":"if you could point me at the most current docs I would like to include reference to the Overlays (and Schema) work that you've been working on so hard. I am publishing a report with some experts in the Sovrin/Indy space about Digital Wallets and what they need to become. Overlays is a key feature. ","username":"darrell.odonnell","ts":"2018-12-01T15:47:19.139Z"}
{"msg":"@darrell.odonnell In short, yes, the Overlays architecture will allow the capture of static data with dynamic augmentation from a combination of different internal or external sources. I'll DM you for some more specifics so that I can draft a hypothetical Overlays solution for your particular use case. In the meantime, although still in draft, the following two documents are the most current and relevant to your query: (i.) *Schema Overlays* - https://github.com/mitfik/overlays-demo/blob/master/SOD.md and (ii.) *Consent Receipt* - https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt","username":"pknowles","ts":"2018-12-01T16:47:04.603Z"}
{"msg":"@darrell.odonnell In short, yes, the Overlays architecture will allow the capture of static data with dynamic augmentation from a combination of different internal or external sources. I'll DM you for some more specifics so that I can draft a hypothetical Overlays solution for your particular use case. In the meantime, although still in draft, the following two documents are the most current and relevant to your query: (i.) *Schema Overlays* - https://github.com/mitfik/overlays-demo/blob/master/SOD.md and (ii.) *Consent Receipt* - https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt [Cc: @mtfk @JanL 5]","username":"pknowles","ts":"2018-12-01T16:47:04.603Z"}
{"msg":"@darrell.odonnell In short, yes, the Overlays architecture will allow the capture of static data with dynamic augmentation from a combination of different internal or external sources. I'll DM you for some more specifics so that I can draft a hypothetical Overlays solution for your particular use case. In the meantime, although still in draft, the following two documents are the most current and relevant to your query: (i.) *Schema Overlays* - https://github.com/mitfik/overlays-demo/blob/master/SOD.md and (ii.) *Consent Receipt* - https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt [Cc: @mtfk @JanL]","username":"pknowles","ts":"2018-12-01T16:47:04.603Z"}
{"msg":"@swcurran There are new pieces being added all the time. The data capture architecture has evolved beyond the 101 sessions. In terms of Darrell's query, I see dynamic data being closely aligned with the consent definitions on those particular attributes which we can capture via a combination of consent attributes in the schema definition, a consent overlay and a proof schema.","username":"pknowles","ts":"2018-12-01T16:47:04.603Z"}
{"msg":"@darrell.odonnell In short, yes, the Overlays architecture should allow the capture of static data with augmentation from a combination of different internal or external sources. I’ll DM for some more specifics so that I can draft a hypothetical Overlays solution for your particular use case. In the meantime, although still in draft, the following two documents are the most current and potentially relevant to your query: (i.) *Schema Overlays - https://github.com/mitfik/overlays-demo/blob/master/SOD.md and (ii.) *Consent Receipt* - https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt [Cc: @mtfk @JanL ]","username":"pknowles","ts":"2018-12-01T16:47:04.603Z"}
{"msg":"@darrell.odonnell In short, yes, the Overlays architecture should allow the capture of static data with augmentation from a combination of different internal or external sources. I’ll DM for some more specifics so that I can draft a hypothetical Overlays solution for your particular use case. In the meantime, although still in draft, the following two documents are the most current and potentially relevant to your query: (i.) *Schema Overlays* - https://github.com/mitfik/overlays-demo/blob/master/SOD.md and (ii.) *Consent Receipt* - https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt [Cc: @mtfk @JanL ]","username":"pknowles","ts":"2018-12-01T16:47:04.603Z"}
{"msg":"@mtfk @JanL 5 ^^","username":"pknowles","ts":"2018-12-01T17:40:18.246Z"}
{"msg":"@pknowles is that new since the 101 sessions you've been doing? I can't see how the type of dynamic data @darrell.odonnell is talking about is possible with the overlays model I have seen. He wants dynamic data per credential, not per schema.","username":"swcurran","ts":"2018-12-01T21:14:17.740Z"}
{"msg":"@swcurran The 101 sessions have since evolved and we're adding pieces that should be able to deal with Darrell's use case. I see the handling of dynamic data being closely aligned with the consent definitions on those particular attributes which we can capture via a combination of consent attributes in the schema definition, a consent overlay and a proof schema.","username":"pknowles","ts":"2018-12-01T21:25:00.450Z"}
{"msg":"","username":"pknowles","ts":"2018-12-01T21:25:15.126Z","attachments":[{"type":"file","title":"Screen Shot 2018-12-01 at 20.41.28.png","title_link":"/file-upload/peg2B9LQ9kpSoECP3/Screen%20Shot%202018-12-01%20at%2020.41.28.png","image_url":"/file-upload/peg2B9LQ9kpSoECP3/Screen%20Shot%202018-12-01%20at%2020.41.28.png","image_type":"image/png","image_size":38041,"url":"/file-upload/peg2B9LQ9kpSoECP3/Screen%20Shot%202018-12-01%20at%2020.41.28.png","remote":false,"fileId":"peg2B9LQ9kpSoECP3","fileName":"Screen Shot 2018-12-01 at 20.41.28.png"}]}
{"msg":"From my side, if the Issuer has the ability to dictate the conditions defining the consent window, an automated tool could be built to pull in dynamic data at regular intervals without breaking the overlay terms.","username":"pknowles","ts":"2018-12-01T21:26:06.088Z"}
{"msg":"@brentzundel also added his thoughts from a *Credential Definition* perspective: \"To enable the presentation of dynamic data, the prover could possibly issue the verifier a credential that allows it to access an endpoint which would resolve as the source of dynamic data. The encoding of this end point could be static, signed by the issuer, and revealed to the verifier as part of the proof. This would only be okay if the issuer controls the data provided at the endpoint, but the prover controls access to the endpoint.\"","username":"pknowles","ts":"2018-12-01T21:29:17.712Z"}
{"msg":"But it still relies on the issuance of a credential so that it can be proven. Regardless of the automation around the event, it still means using a verifiable credential - I can't see getting around that.","username":"swcurran","ts":"2018-12-01T21:29:35.978Z"}
{"msg":"Your last point is interesting - seems technically challenging, especially with the desire for a Holder to prove claims independent of the issuer. Seems that might need to be given up?","username":"swcurran","ts":"2018-12-01T21:32:56.705Z"}
{"msg":"Perhaps the benefit of the dynamic data would be worth the trade off?","username":"swcurran","ts":"2018-12-01T21:33:36.776Z"}
{"msg":"It's definitely an interesting use case and an important one at that. Our next *Semantics WG* meeting is on *Tuesday, December 11th* ( *10am-11am PT* ). I'm going to add this as an agenda item. It'll be good to get this one aired for sure.","username":"pknowles","ts":"2018-12-01T21:36:05.562Z"}
{"msg":"Is there a reference to the dynamic data as described above? I think I get the idea, except how the dynamic data can be handled in a proof. Harri from (I think) Tieto did something like that to grant access to data, but it was just a feed of raw data, but encapsulated as a proof.","username":"swcurran","ts":"2018-12-01T21:49:37.340Z"}
{"msg":"Is there a reference to the dynamic data as described above? I think I get the idea, except how the dynamic data can be handled in a proof. Harri from (I think) Tieto did something like that to grant access to data, bu t it was just a feed of raw data, not encapsulated as a proof.","username":"swcurran","ts":"2018-12-01T21:49:37.340Z"}
{"msg":"Is there a reference to the dynamic data as described above? I think I get the idea, except how the dynamic data can be handled in a proof. Harri from (I think) Tieto did something like that to grant access to data, but it was just a feed of raw data, not encapsulated as a proof.","username":"swcurran","ts":"2018-12-01T21:49:37.340Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=3c6e3681-0017-4ea7-8f80-4cab9ef05763) @swcurran @brentzundel Is there a reference to your point re dynamic data? \"To enable the presentation of dynamic data, the prover could possibly issue the verifier a credential that allows it to access an endpoint which would resolve as the source of dynamic data. The encoding of this end point could be static, signed by the issuer, and revealed to the verifier as part of the proof. This would only be okay if the issuer controls the data provided at the endpoint, but the prover controls access to the endpoint.\"","username":"swcurran","ts":"2018-12-01T21:49:37.340Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=3c6e3681-0017-4ea7-8f80-4cab9ef05763","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=3c6e3681-0017-4ea7-8f80-4cab9ef05763","remote":true,"fileId":null,"fileName":null}]}
{"msg":"@brentzundel Is there a reference to your point re dynamic data? \"To enable the presentation of dynamic data, the prover could possibly issue the verifier a credential that allows it to access an endpoint which would resolve as the source of dynamic data. The encoding of this end point could be static, signed by the issuer, and revealed to the verifier as part of the proof. This would only be okay if the issuer controls the data provided at the endpoint, but the prover controls access to the endpoint.","username":"swcurran","ts":"2018-12-01T21:49:37.340Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=3c6e3681-0017-4ea7-8f80-4cab9ef05763","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=3c6e3681-0017-4ea7-8f80-4cab9ef05763","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Is there a reference to the dynamic data as described above? I think I get the idea, except how the dynamic data can be handled in a proof. Harri from (I think) Tieto did something like that to grant access to data, but it was just a feed of raw data, not encapsulated as a proof.","username":"swcurran","ts":"2018-12-01T21:49:37.340Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=3c6e3681-0017-4ea7-8f80-4cab9ef05763","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=3c6e3681-0017-4ea7-8f80-4cab9ef05763","remote":true,"fileId":null,"fileName":null}]}
{"msg":"@brentzundel Is there a reference to the dynamic data idea that you described above? \"To enable the presentation of dynamic data, the prover could possibly issue the verifier a credential that allows it to access an endpoint which would resolve as the source of dynamic data. The encoding of this end point could be static, signed by the issuer, and revealed to the verifier as part of the proof. This would only be okay if the issuer controls the data provided at the endpoint, but the prover controls access to the endpoint.\" [Cc: @swcurran ]","username":"swcurran","ts":"2018-12-01T21:49:37.340Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=3c6e3681-0017-4ea7-8f80-4cab9ef05763","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=3c6e3681-0017-4ea7-8f80-4cab9ef05763","remote":true,"fileId":null,"fileName":null}]}
{"msg":"@brentzundel Is there a reference to the dynamic data idea that you described above? \"To enable the presentation of dynamic data, the prover could possibly issue the verifier a credential that allows it to access an endpoint which would resolve as the source of dynamic data. The encoding of this end point could be static, signed by the issuer, and revealed to the verifier as part of the proof. This would only be okay if the issuer controls the data provided at the endpoint, but the prover controls access to the endpoint.\"","username":"swcurran","ts":"2018-12-01T21:49:37.340Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=3c6e3681-0017-4ea7-8f80-4cab9ef05763","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=3c6e3681-0017-4ea7-8f80-4cab9ef05763","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Which may be just fine. \n\nDon't quite see the connection to overlays, but I'm interested in reading/hearing more.","username":"swcurran","ts":"2018-12-01T21:50:37.718Z"}
{"msg":"All of the consent definitions are bound by entries in a Consent Overlay. If those terms are not dictated by the Issuer, in this case, then they wouldn't necessarily have the legal right to collect dynamic data over a predefined period. I guess until we nut this out, we may be over thinking it but I see dynamic data collection as a combination of verifiable credential and consent terms.","username":"pknowles","ts":"2018-12-01T21:58:05.865Z"}
{"msg":"All of the consent definitions are bound by entries in a Consent Overlay. If those terms are not dictated by the Issuer in this particular case then they wouldn't necessarily have the legal right to collect dynamic data over a predefined period. I guess until we nut this out, we may be over thinking it but I see dynamic data collection as a combination of verifiable credential and consent terms.","username":"pknowles","ts":"2018-12-01T21:58:05.865Z"}
{"msg":"All of the consent definitions are bound by entries in a Consent Overlay. If those terms are not dictated by the Issuer in this particular case then they wouldn't necessarily have the legal right to collect dynamic data over a predefined period. I guess until we nut this out, we may be over thinking it but I see dynamic data collection as a combination of verifiable credential remit and consent terms.","username":"pknowles","ts":"2018-12-01T21:58:05.865Z"}
{"msg":"All of the consent definitions are bound by entries in a Consent Overlay. If those terms are not dictated by the Issuer in this particular case then they wouldn't necessarily have the legal right to collect dynamic data over a predefined period of time. I guess until we nut this out, we may be over complicating it but I ultimately see dynamic data collection as a combination of \"verifiable credential\" remit and consent terms defined by a Consent Overlay.","username":"pknowles","ts":"2018-12-01T21:58:05.865Z"}
{"msg":"All of the consent definitions are bound by entries in a Consent Overlay. If those terms are not dictated by the Issuer (in this particular example) then they wouldn't necessarily have the legal right to collect dynamic data over a predefined period of time. I guess until we nut this out, we may be over complicating it but I ultimately see dynamic data collection as a combination of \"verifiable credential\" remit and consent terms defined by a Consent Overlay.","username":"pknowles","ts":"2018-12-01T21:58:05.865Z"}
{"msg":"All of the consent definitions are bound by entries in a Consent Overlay. If those terms are not dictated by the Issuer (in this particular example) then they wouldn't necessarily have the legal right to collect dynamic data over a predefined period of time. I guess until we nut this out, we may be over complicating it but I ultimately see dynamic data collection as a combination of consent terms defined by a Consent Overlay and information held in the credential.","username":"pknowles","ts":"2018-12-01T21:58:05.865Z"}
{"msg":"All of the consent definitions are bound by entries in a Consent Overlay. If those terms are not dictated by the Issuer (in this particular example) then they wouldn't necessarily have the legal right to collect dynamic data over a predefined period of time. I guess until we nut this out, we may be over complicating it but I ultimately see dynamic data collection as a combination of consent terms defined by a Consent Overlay and data held in the credential.","username":"pknowles","ts":"2018-12-01T21:58:05.865Z"}
{"msg":"All of the consent definitions are bound by entries in a Consent Overlay. If those terms are not dictated by the Issuer (in this particular example) then they wouldn't necessarily have the legal right to collect dynamic data over a predefined period of time. I guess until we nut this out, we may be over complicating it but I ultimately see dynamic data collection as a combination of consent terms defined by a Consent Overlay with some of that data held in the credential.","username":"pknowles","ts":"2018-12-01T21:58:05.865Z"}
{"msg":"All of the consent definitions are bound by entries in a Consent Overlay. If those terms are not dictated by the Issuer (in this particular example) then they wouldn't necessarily have the legal right to collect dynamic data over a predefined period of time. I guess until we nut this out, we may be over complicating it but I ultimately see dynamic data collection as a combination of consent terms defined by a Consent Overlay with some of the timestamp information held in the credential.","username":"pknowles","ts":"2018-12-01T21:58:05.865Z"}
{"msg":"All of the consent definitions are bound by entries in a Consent Overlay. If those terms are not dictated by the Issuer (in this particular example) then they wouldn't necessarily have the legal right to collect dynamic data over a predefined period of time. I guess until we nut this out, we may be over complicating it but I ultimately see dynamic data collection as a combination of Verifiable Credential with consent terms defined by a Consent Overlay with some of the timestamp information held in the credential.","username":"pknowles","ts":"2018-12-01T21:58:05.865Z"}
{"msg":"All of the consent definitions are bound by entries in a Consent Overlay. If those terms are not dictated by the Issuer (in this particular example) then they wouldn't necessarily have the legal right to collect dynamic data over a predefined period of time. I guess until we nut this out, we may be over complicating it but I ultimately see dynamic data collection as a credential with consent terms defined by a Consent Overlay with some of the timestamp information being retained within the credential.","username":"pknowles","ts":"2018-12-01T21:58:05.865Z"}
{"msg":"All of the consent definitions are bound by entries in a Consent Overlay. If those terms are not dictated by the Issuer (in this particular example) then they wouldn't necessarily have the legal right to collect dynamic data over a predefined period of time. I guess until we nut this out, I may be over complicating it but I ultimately see dynamic data collection as a credential with consent terms defined by a Consent Overlay with some of the timestamp information being retained within the credential.","username":"pknowles","ts":"2018-12-01T21:58:05.865Z"}
{"msg":"All of the consent definitions are bound by entries in a Consent Overlay. If those terms are not dictated by the Issuer (in this particular example) then they wouldn't necessarily have the legal right to collect dynamic data over a predefined period of time. I guess until we nut this out, I may be overcomplicating it but I ultimately see dynamic data collection as a credential with consent terms defined by a Consent Overlay with some of the timestamp information being retained within the credential.","username":"pknowles","ts":"2018-12-01T21:58:05.865Z"}
{"msg":"All of the consent definitions are bound by entries in a Consent Overlay. If those terms are not dictated by the Issuer (in this particular example) then they wouldn't necessarily have the legal right to collect dynamic data over a predefined period of time. I guess until we nut this out, I may be overcomplicating it but I ultimately see dynamic data collection as a credential with consent terms being defined by a Consent Overlay with some of that timestamp information being retained within the credential.","username":"pknowles","ts":"2018-12-01T21:58:05.865Z"}
{"msg":"All of the consent definitions are bound by entries in a Consent Overlay. If those terms are not dictated by the Issuer (in this particular example) then they wouldn't necessarily have the legal right to collect dynamic data over a predefined period of time. I guess until we nut this out, I may be overcomplicating it but I ultimately see dynamic data collection as a credential with consent terms being defined by a Consent Overlay with countdown information being retained within the credential.","username":"pknowles","ts":"2018-12-01T21:58:05.865Z"}
{"msg":"All of the consent definitions are bound by entries in a Consent Overlay. In this particular example, if those terms are not dictated by the Issuer then they wouldn't necessarily have the legal right to collect dynamic data over a predefined period of time. I guess until we nut this out, I may be overcomplicating it but I ultimately see dynamic data collection as a credential with consent terms being defined by a Consent Overlay with countdown information being retained within the credential.","username":"pknowles","ts":"2018-12-01T21:58:05.865Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=3c6e3681-0017-4ea7-8f80-4cab9ef05763) @swcurran ^^ @brentzundel ","username":"pknowles","ts":"2018-12-01T21:59:29.469Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=3c6e3681-0017-4ea7-8f80-4cab9ef05763","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=3c6e3681-0017-4ea7-8f80-4cab9ef05763","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=3c6e3681-0017-4ea7-8f80-4cab9ef05763) ^^ @brentzundel ","username":"pknowles","ts":"2018-12-01T21:59:29.469Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=3c6e3681-0017-4ea7-8f80-4cab9ef05763","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=3c6e3681-0017-4ea7-8f80-4cab9ef05763","remote":true,"fileId":null,"fileName":null}]}
{"msg":"User <em>User_41</em> added by <em>pknowles</em>.","username":"pknowles","ts":"2018-12-01T22:11:39.713Z","type":"au"}
{"msg":"@harrihoo I've added you to this channel so that we can get your thoughts on dynamic data collection. See conversation above which @darrell.odonnell kicked off. @swcurran suggested that in the recent past you have managed to grant access to dynamic data via a raw data feed, not encapsulated as a proof. Are you able to explain that piece or point us to a reference document?","username":"pknowles","ts":"2018-12-01T22:16:48.041Z"}
{"msg":"@swcurran From @harrihoo - \"It’s a special marriage of OAuth2 and Indy agents :slightly_smiling_face: - for the initial messaging diagrams you can have a look at this: https://docs.google.com/presentation/d/1KqB7clTef6aMXISCW34MgX6ycfhmRGQrgE2vYuCmB08/edit?usp=sharing \"","username":"pknowles","ts":"2018-12-02T21:18:43.988Z"}
{"msg":"@swcurran From @harrihoo : \"It’s a special marriage of OAuth2 and Indy agents :slightly_smiling_face: - for the initial messaging diagrams you can have a look at this: https://docs.google.com/presentation/d/1KqB7clTef6aMXISCW34MgX6ycfhmRGQrgE2vYuCmB08/edit?usp=sharing \"","username":"pknowles","ts":"2018-12-02T21:18:43.988Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=7RjLgFDesYJM8jXHz) @darrell.odonnell @darrell.odonnell Base on my understanding one of possible way to make it work could be like this: you use schema + overlays to describe verifiable credential structure. Let say your verifiable credential is issued by Credit Union and could look like this:\n```\n   SCHEMA = {\n    did: \"did:sov:abcdefg123455\",\n    name: 'Dream state',\n    description: \"Created by Darrell\",\n    version: '1.0',\n    attr_names: {\n      MemberSince: Date,\n      InstitutionName: String\n      AverageMonthlyBalance: Double,\n      GoodCustomerStanding: Integer\n    },\n    consent: \"did:schema:27312381238123\", # reference to consent schema\n    # Attributes flagged according to the Blinding Identity Taxonomy\n    # by the issuer of the schema\n    bit_attributes: [\"MemberSince\"],\n}\n```\nNext when you create verifiable credentials according to the schema you bind static variables same way as you do it now (including ZKP) and for dynamic attributes likes `AverageMonthlyBalance` you bind it to the did source. Let say that overlay could look like this:\n```\nDYNAMIC_OVERLAY = {\n  did: \"did:sov:57ass8abcd\",\n  type: \"spec/overlay/1.0/dynamic\",\n  name: \"Dynamic Overlay for Dream State\",\n  dynamic_attributes: {\n      AverageMonthlyBalance: \"did:sov:0987poiu\",\n      GoodCustomerStanding: \"did:sov:0987poiu\",\n  }\n}\n```\nWhich basically mean that you bind attribute `AverageMonthlyBalance` and `GoodCustomerStanding` to specific source from where they can come. Which could mean that each time when you would fetch the dynamic attributes they have to be signed by those specific DID's defined in that overlay. \n\nWould that work/make sens? ","username":"mtfk","ts":"2018-12-03T07:46:28.220Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=7RjLgFDesYJM8jXHz","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=7RjLgFDesYJM8jXHz","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=7RjLgFDesYJM8jXHz) @darrell.odonnell Base on my understanding one of possible way to make it work could be like this: you use schema + overlays to describe verifiable credential structure. Let say your verifiable credential is issued by Credit Union and could look like this:\n```\n   SCHEMA = {\n    did: \"did:sov:abcdefg123455\",\n    name: 'Dream state',\n    description: \"Created by Darrell\",\n    version: '1.0',\n    attr_names: {\n      MemberSince: Date,\n      InstitutionName: String\n      AverageMonthlyBalance: Double,\n      GoodCustomerStanding: Integer\n    },\n    consent: \"did:schema:27312381238123\", # reference to consent schema\n    # Attributes flagged according to the Blinding Identity Taxonomy\n    # by the issuer of the schema\n    bit_attributes: [\"MemberSince\"],\n}\n```\nNext when you create verifiable credentials according to the schema you bind static variables same way as you do it now (including ZKP) and for dynamic attributes likes `AverageMonthlyBalance` you bind it to the did source. Let say that overlay could look like this:\n```\nDYNAMIC_OVERLAY = {\n  did: \"did:sov:57ass8abcd\",\n  type: \"spec/overlay/1.0/dynamic\",\n  name: \"Dynamic Overlay for Dream State\",\n  dynamic_attributes: {\n      AverageMonthlyBalance: \"did:sov:0987poiu\",\n      GoodCustomerStanding: \"did:sov:0987poiu\",\n  }\n}\n```\nWhich basically mean that you bind attribute `AverageMonthlyBalance` and `GoodCustomerStanding` to specific source from where they can come. Which could mean that each time when you would fetch the dynamic attributes they have to be signed by those specific DID's defined in that overlay. \n\nWould that work/make sens? ","username":"mtfk","ts":"2018-12-03T07:46:28.220Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=7RjLgFDesYJM8jXHz","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=7RjLgFDesYJM8jXHz","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=7RjLgFDesYJM8jXHz) @darrell.odonnell Base on my understanding one of possible way to make it work for dynamic/static attributes could be like this: you use schema + overlays to describe verifiable credential structure. Let say your verifiable credential is issued by Credit Union and could look like this:\n```\n   SCHEMA = {\n    did: \"did:sov:abcdefg123455\",\n    name: 'Dream state',\n    description: \"Created by Darrell\",\n    version: '1.0',\n    attr_names: {\n      MemberSince: Date,\n      InstitutionName: String\n      AverageMonthlyBalance: Double,\n      GoodCustomerStanding: Integer\n    },\n    consent: \"did:schema:27312381238123\", # reference to consent schema\n    # Attributes flagged according to the Blinding Identity Taxonomy\n    # by the issuer of the schema\n    bit_attributes: [\"MemberSince\"],\n}\n```\nNext when you create verifiable credentials according to the schema you bind static variables same way as you do it now (including ZKP) and for dynamic attributes likes `AverageMonthlyBalance` you bind it to the did source. Let say that overlay could look like this:\n```\nDYNAMIC_OVERLAY = {\n  did: \"did:sov:57ass8abcd\",\n  type: \"spec/overlay/1.0/dynamic\",\n  name: \"Dynamic Overlay for Dream State\",\n  dynamic_attributes: {\n      AverageMonthlyBalance: \"did:sov:0987poiu\",\n      GoodCustomerStanding: \"did:sov:0987poiu\",\n  }\n}\n```\nWhich basically mean that you bind attribute `AverageMonthlyBalance` and `GoodCustomerStanding` to specific source from where they can come. Which could mean that each time when you would fetch the dynamic attributes they have to be signed by those specific DID's defined in that overlay. \n\nWould that work/make sens? ","username":"mtfk","ts":"2018-12-03T07:46:28.220Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=7RjLgFDesYJM8jXHz","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=7RjLgFDesYJM8jXHz","remote":true,"fileId":null,"fileName":null}]}
{"msg":"@darrell.odonnell Base on my understanding one of possible way to make it work for dynamic/static attributes could be like this: you use schema + overlays to describe verifiable credential structure. Let say your verifiable credential is issued by Credit Union and could look like this:\n```\n   SCHEMA = {\n    did: \"did:sov:abcdefg123455\",\n    name: 'Dream state',\n    description: \"Created by Darrell\",\n    version: '1.0',\n    attr_names: {\n      MemberSince: Date,\n      InstitutionName: String\n      AverageMonthlyBalance: Double,\n      GoodCustomerStanding: Integer\n    },\n    consent: \"did:schema:27312381238123\", # reference to consent schema\n    # Attributes flagged according to the Blinding Identity Taxonomy\n    # by the issuer of the schema\n    bit_attributes: [\"MemberSince\",\"InstitutionName\"],\n}\n```\nNext when you create verifiable credentials according to the schema you bind static variables same way as you do it now (including ZKP) and for dynamic attributes likes `AverageMonthlyBalance` you bind it to the did source. Let say that overlay could look like this:\n```\nDYNAMIC_OVERLAY = {\n  did: \"did:sov:57ass8abcd\",\n  type: \"spec/overlay/1.0/dynamic\",\n  name: \"Dynamic Overlay for Dream State\",\n  dynamic_attributes: {\n      AverageMonthlyBalance: \"did:sov:0987poiu\",\n      GoodCustomerStanding: \"did:sov:0987poiu\",\n  }\n}\n```\nWhich basically mean that you bind attribute `AverageMonthlyBalance` and `GoodCustomerStanding` to specific source from where they can come. Which could mean that each time when you would fetch the dynamic attributes they have to be signed by those specific DID's defined in that overlay. \n\nWould that work/make sens?","username":"mtfk","ts":"2018-12-03T07:46:28.220Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=7RjLgFDesYJM8jXHz","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=7RjLgFDesYJM8jXHz","remote":true,"fileId":null,"fileName":null}]}
{"msg":"So even when you agree on something by creating verifiable credentials you agree on the specific static fields right away and on some dynamic attributes just agree who in the future would deliver those attributes (so you create trusted binding between attribute and some entity (his did) which commit to provide it/update it in the future) ","username":"mtfk","ts":"2018-12-03T07:49:52.689Z"}
{"msg":"So by creating verifiable credentials you agree on the specific static fields right away and on some dynamic attributes just agree who in the future would deliver those attributes (so you create trusted binding between attribute and some entity (his did) which commit to provide it/update it in the future) ","username":"mtfk","ts":"2018-12-03T07:49:52.689Z"}
{"msg":"So by creating verifiable credentials you agree on the specific data for static fields right away and for dynamic attributes you agree who in the future would deliver the data for them (so you create trusted binding between attribute and some entity (it's/his did) which commit to provide it/update it in the future) ","username":"mtfk","ts":"2018-12-03T07:49:52.689Z"}
{"msg":"@mtfk - who do you see fetching the dynamic data - the Holder/Prover or the Verifier?  I think it would have to be the Holder/Prover, and that the data would be signed by the Issuer using the DID associated with the Credential Definition.  I don't think the Verifier could get it directly, since there would not be a way to prevent the Verifier from sharing (without consent) the endpoint. If the Holder/Prover, why not just get an updated Credential with the latest info?\n\nAlternatively does it make sense to just have this handled at the Agent-to-Agent message level vs. in the proof process?  E.g. do overlays bring value to this?  Alternatively, specifically add this to the proof process a\n\nSeparate observation: It seems like the concept here is tightly tied to the Issuer and hence the Credential Definition vs an Overlay. Perhaps a Credential Definition should have an optional Overlay included with it for handling these situations that are clearly Issuer-specific.  Non-Issuer specific Overlays would be used for more cross-cutting concerns - e.g. language translations, conditional handling, etc.","username":"swcurran","ts":"2018-12-03T11:40:51.365Z"}
{"msg":"@mtfk - who do you see fetching the dynamic data - the Holder/Prover or the Verifier?  I think it would have to be the Holder/Prover, and that the data would be signed by the Issuer using the DID associated with the Credential Definition.  I don't think the Verifier could get it directly, since there would not be a way to prevent the Verifier from sharing (without consent) the endpoint. If the Holder/Prover, why not just get an updated Credential with the latest info?\n\nAlternatively does it make sense to just have this handled at the Agent-to-Agent message level vs. in the proof process?  E.g. do overlays bring value to this?  Alternatively, specifically add this to the proof process claims that are \"signed but not provable\", that can be filled in at proof time.\n\nSeparate observation: It seems like the concept here is tightly tied to the Issuer and hence the Credential Definition vs an Overlay. Perhaps a Credential Definition should have an optional Overlay included with it for handling these situations that are clearly Issuer-specific.  Non-Issuer specific Overlays would be used for more cross-cutting concerns - e.g. language translations, conditional handling, etc.","username":"swcurran","ts":"2018-12-03T11:40:51.365Z"}
{"msg":"One way for the Verifier to get the data directly from the Issuer without risk of them sharing endpoint access would be for the Holder/Prover (e.g. the Customer of the Credit Union in Darrell's case) to issue a Verifiable Credential to the 3rd party to authorize them to get data from the Issuer.  This is a form of the Delegation of Authority pattern that we think will be very common in the future.","username":"swcurran","ts":"2018-12-03T11:45:41.559Z"}
{"msg":"@darrell.odonnell If you think about this more broadly (i.e. any NFE), some (a few) might evolve over time or need to be corrected, I suggested you look at a generalized approach to created time-sequenced or versioned NFEs on Indy-Sovrin ...essentially think of Indy-Sovrin as a write-only database ...how do you represent changes/updates on a write-only database?","username":"mwherman2000","ts":"2018-12-03T12:00:45.521Z"}
{"msg":"@darrell.odonnell If you think about this more broadly (i.e. any NFE), some (a few) might evolve over time or need to be corrected, I suggested you look at a generalized approach to created time-sequenced or versioned NFEs on Indy-Sovrin ...essentially think of Indy-Sovrin as a write-only database ...how do you represent changes/updates on a write-only database? e.g. Ethereum or NEO.","username":"mwherman2000","ts":"2018-12-03T12:00:45.521Z"}
{"msg":"@darrell.odonnell If you think about this more broadly (i.e. any NFE), the values of some attributes for some entity types (only a few by definition) might evolve over time or need to be corrected, I suggest you look at a generalized approach to created time-sequenced or versioned NFEs on Indy-Sovrin ...essentially think of Indy-Sovrin as a write-only database ...how do you represent entity changes/updates on a write-only database? e.g. Ethereum or NEO.","username":"mwherman2000","ts":"2018-12-03T12:00:45.521Z"}
{"msg":"@darrell.odonnell If you think about this more broadly (i.e. any NFE), the values of some attributes for some entity types (only a few by definition) might evolve over time or need to be corrected, I suggest you look at a generalized approach to created time-sequenced or versioned NFEs on Indy-Sovrin ...essentially think of Indy-Sovrin as a write-only database ...how do you represent entity changes/updates on a write-only database? e.g. Ethereum or NEO or the Stratis Platform","username":"mwherman2000","ts":"2018-12-03T12:00:45.521Z"}
{"msg":"Reference 1: https://medium.com/@mwherman2000/best-way-to-store-secure-immutable-auditable-historized-permanent-data-stored-on-the-69a874ee17cd","username":"mwherman2000","ts":"2018-12-03T12:02:16.870Z"}
{"msg":"Reference 1: https://github.com/mwherman2000/serentitydapps/blob/master/SerentityDapp.Perfmon/README.md\nReference 2: https://medium.com/@mwherman2000/best-way-to-store-secure-immutable-auditable-historized-permanent-data-stored-on-the-69a874ee17cd","username":"mwherman2000","ts":"2018-12-03T12:02:16.870Z"}
{"msg":"Reference 2: https://github.com/mwherman2000/serentitydapps/blob/master/SerentityDapp.Perfmon/README.md","username":"mwherman2000","ts":"2018-12-03T12:03:21.149Z"}
{"msg":"Reference 2: https://github.com/mwherman2000/serentitydapps/blob/master/SerentityDapp.Perfmon/README.mdReference 2: https://github.com/mwherman2000/serentitydapps/blob/master/SerentityDapp.Perfmon/README.md","username":"mwherman2000","ts":"2018-12-03T12:03:21.149Z"}
{"msg":"@darrell.odonnell Another approach is to created an aggregated entity that aggregated separate entities of two classes: static and dynamic.","username":"mwherman2000","ts":"2018-12-03T12:08:20.270Z"}
{"msg":"@darrell.odonnell Another approach is to create an aggregated entity that aggregates (by reference) separate entities of two classes: static and dynamic.","username":"mwherman2000","ts":"2018-12-03T12:08:20.270Z"}
{"msg":"@darrell.odonnell Another approach is to create an aggregated entity that aggregates (by reference) separate entities of two classes: static and dynamic. This diagram...","username":"mwherman2000","ts":"2018-12-03T12:08:20.270Z"}
{"msg":"@darrell.odonnell Another approach is to create an aggregated entity that aggregates (by reference) separate entities of two classes: static and dynamic. Something like this diagram...","username":"mwherman2000","ts":"2018-12-03T12:08:20.270Z"}
{"msg":"","username":"mwherman2000","ts":"2018-12-03T12:10:08.478Z","attachments":[{"type":"file","title":"HBB-Gumball Protocol-Indy-Sovrin-Mapping v0.4-Small.png","title_link":"/file-upload/SBBpRiFHoGALudTwo/HBB-Gumball%20Protocol-Indy-Sovrin-Mapping%20v0.4-Small.png","image_url":"/file-upload/SBBpRiFHoGALudTwo/HBB-Gumball%20Protocol-Indy-Sovrin-Mapping%20v0.4-Small.png","image_type":"image/png","image_size":83084,"url":"/file-upload/SBBpRiFHoGALudTwo/HBB-Gumball%20Protocol-Indy-Sovrin-Mapping%20v0.4-Small.png","remote":false,"fileId":"SBBpRiFHoGALudTwo","fileName":"HBB-Gumball Protocol-Indy-Sovrin-Mapping v0.4-Small.png"}]}
{"msg":"@swcurran I haven't thought about it in any great detail but there might also be a case of using Overlays on top of Credential Definitions [Cc: @kenebert @brentzundel ]. This new data architecture allows maximum flexibility so we might be able to utilise Overlays on top of other data structures, not just Schemas.","username":"pknowles","ts":"2018-12-03T13:18:35.642Z"}
{"msg":"@swcurran I haven't thought about it in any great detail but there might also be a case of using Overlays on top of Credential Definitions, etc. [Cc: @kenebert @brentzundel ]. This new data architecture allows maximum flexibility so we might be able to utilise Overlays on top of other data structures, not just Schemas.","username":"pknowles","ts":"2018-12-03T13:18:35.642Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=pSjrk2pgMiH4M25td) @swcurran Gotcha","username":"pknowles","ts":"2018-12-03T13:18:35.642Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=pSjrk2pgMiH4M25td","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=pSjrk2pgMiH4M25td","remote":true,"fileId":null,"fileName":null}]}
{"msg":"I don't mean an Overlay on top of Cred Def - rather that an Issuer could specify a Schema Overlay as part of a Cred Def where there was a desire for the Issuer to be able to count on the use of an Overlay, vs. it being up to the Prover/Holder or Verifier to use Overlays.","username":"swcurran","ts":"2018-12-03T13:21:35.604Z"}
{"msg":"I don't mean an Overlay on top of Cred Def - rather that an Issuer could specify a Schema Overlay as part of a Cred Def where there was a desire for the Issuer to be able to count on the use of that Overlay, vs. it being up to the Prover/Holder or Verifier to use Overlays.","username":"swcurran","ts":"2018-12-03T13:21:35.604Z"}
{"msg":"@swcurran - so a Driver Licence could come with a couple of overlays: full, age_of_majority","username":"darrell.odonnell","ts":"2018-12-03T13:41:15.749Z"}
{"msg":"I don't think so - those are proof request formats.  There is talk of standardizing them as well - making them available somewhere.","username":"swcurran","ts":"2018-12-03T13:42:56.441Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=rZiPxEHqzE3b4c6mr) @swcurran @swcurran I think that Holder of the data/issuer of verifiable credential or holder of it (it could be an agent, data vault, smart contract with access to the data or authorize entity which keeps my data or myself). Of course your argument is valid that the credential could be updated and new credential could be issued. If that is the case then schema&overlays probably won't play any role here (maybe except being use to prepare claim in first place). But for data which changes regularly like bank account balance, heartbeat or any continues stream of information sounds like overkill. I am not sure if my way of thinking about those stuff is correct but this how I would see it:\n* User need to share information about his bank account to Third party company. He request from the bank that he would like to receive verifiable credential that he is their customer (MemberSince, InstitutionName - static fields) and that his AvarageBalance (dynamic fields) over months is always positive. \n* Bank pull out schema (did:sov:1234) representing that verifiable credentials (here schema&overlays could come handy since they could have one schema with multiple overlays for different customers)\n* Bank issue verifiable credential \n* Now user login to Third Party company  from where he received request to prove that his DID holds credential for schema (did:sov:1234) which is backed by bank. My understanding that the verifiable credential could be stored in agent or in bank directly where each time could be amended/updated for dynamic data, but it could be also stored within my Digital Wallet where can not be updated. But if we would use schema&overlays I could receive the request in my digital wallet where claim is stored and prove that without looking up anywhere. For example with ZKP I could prove that I own claim that I am a member of a bank longer then one year, with AvarageBalance - positive for last few months. Since everything would be tied to schema each piece of information can be proven (even those dynamic one - as we can trust the source of the data and by whom it would be signed)  \n \nNot sure if I am not over engineering anything here but putting schema&overlays as a universal language to talk about structure of data seems very handy when  schema&overlays are identify via DID and stored in immutable storage. This gives possibility to make sure that the communication is easier and much secure within decentralize ecosystem. ","username":"mtfk","ts":"2018-12-03T22:37:24.093Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=rZiPxEHqzE3b4c6mr","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=rZiPxEHqzE3b4c6mr","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=rZiPxEHqzE3b4c6mr) @swcurran @swcurran I think that Holder of the data/issuer of verifiable credential or holder of it (it could be an agent, data vault, smart contract with access to the data or authorize entity which keeps my data or myself). Of course your argument is valid that the credential could be updated and new credential could be issued. If that is the case then schema&overlays probably won't play any role here (maybe except being use to prepare claim in first place). But for data which changes regularly like bank account balance, heartbeat or any continues stream of information sounds like overkill. I am not sure if my way of thinking about those stuff is correct but this how I would see it:\n* User need to share information about his bank account to Third party company. He request from the bank that he would like to receive verifiable credential that he is their customer (MemberSince, InstitutionName - static fields) and that his AvarageBalance (dynamic fields) over months is always positive. \n* Bank pull out schema (did:sov:1234) representing that verifiable credentials (here schema&overlays could come handy since they could have one schema with multiple overlays for different customers)\n* Bank issue verifiable credential \n* Now user login to Third Party company  from where he received request to prove that his DID holds credential for schema (did:sov:1234) which is backed by bank. My understanding that the verifiable credential could be stored in agent or in bank directly where each time could be amended/updated for dynamic data, but it could be also stored within my Digital Wallet where can not be updated. But if we would use schema&overlays I could receive the request in my digital wallet where claim is stored and prove that without looking up anywhere. For example with ZKP I could prove that I own claim that I am a member of a bank longer then one year, with AvarageBalance - positive for last few months. Since everything would be tied to schema each piece of information can be proven (even those dynamic one - as we can trust the source of the data and by whom it would be signed)  \n \nNot sure if I am not over engineering anything here but putting schema&overlays as a universal language to talk about structure of data seems very handy when  schema&overlays are identify via DID and stored in immutable storage. This gives possibility to make sure that the communication is easier and much secure within decentralize ecosystem. ","username":"mtfk","ts":"2018-12-03T22:37:24.093Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=rZiPxEHqzE3b4c6mr","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=rZiPxEHqzE3b4c6mr","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=rZiPxEHqzE3b4c6mr) @swcurran I think that Holder of the data/issuer of verifiable credential or holder of it (it could be an agent, data vault, smart contract with access to the data or authorize entity which keeps my data or myself). Of course your argument is valid that the credential could be updated and new credential could be issued. If that is the case then schema&overlays probably won't play any role here (maybe except being use to prepare claim in first place). But for data which changes regularly like bank account balance, heartbeat or any continues stream of information sounds like overkill. I am not sure if my way of thinking about those stuff is correct but this how I would see it:\n* User need to share information about his bank account to Third party company. He request from the bank that he would like to receive verifiable credential that he is their customer (MemberSince, InstitutionName - static fields) and that his AvarageBalance (dynamic fields) over months is always positive. \n* Bank pull out schema (did:sov:1234) representing that verifiable credentials (here schema&overlays could come handy since they could have one schema with multiple overlays for different customers)\n* Bank issue verifiable credential \n* Now user login to Third Party company  from where he received request to prove that his DID holds credential for schema (did:sov:1234) which is backed by bank. My understanding that the verifiable credential could be stored in agent or in bank directly where each time could be amended/updated for dynamic data, but it could be also stored within my Digital Wallet where can not be updated. But if we would use schema&overlays I could receive the request in my digital wallet where claim is stored and prove that without looking up anywhere. For example with ZKP I could prove that I own claim that I am a member of a bank longer then one year, with AvarageBalance - positive for last few months. Since everything would be tied to schema each piece of information can be proven (even those dynamic one - as we can trust the source of the data and by whom it would be signed)  \n \nNot sure if I am not over engineering anything here but putting schema&overlays as a universal language to talk about structure of data seems very handy when  schema&overlays are identify via DID and stored in immutable storage. This gives possibility to make sure that the communication is easier and much secure within decentralize ecosystem. ","username":"mtfk","ts":"2018-12-03T22:37:24.093Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=rZiPxEHqzE3b4c6mr","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=rZiPxEHqzE3b4c6mr","remote":true,"fileId":null,"fileName":null}]}
{"msg":"is there a call today?","username":"brentzundel","ts":"2018-12-04T18:05:11.696Z"}
{"msg":" @brentzundel No. The call takes place bi-weekly, every other Tuesday. The next one is on December 11th.","username":"pknowles","ts":"2018-12-04T20:04:36.383Z"}
{"msg":"I figured it out eventually :)","username":"brentzundel","ts":"2018-12-04T20:06:02.368Z"}
{"msg":"We’re starting to get new use cases from members of the Hyperledger Indy community so, regarding the format of the biweekly *Semantics WG* calls, I thought we could concentrate on (i.) 1 x *advanced model presentation* (15 mins) and (ii.) 1 x *new use case* with input from the Schemas/Overlays team (approx. 10-15 mins) and the Verifiable Credentials team (approx. 10-15 mins). The 2nd of these items would be a 30 minute brainstorming session. When an advanced model presentation is not on the agenda, we may try to tackle two new use cases per call. I also think that we should increase the duration of these calls by 15 minutes (from 1 hour to 1 hour 15 minutes) so that we’re not pressed for time. Any further input regarding the format of these calls is most welcome.","username":"pknowles","ts":"2018-12-05T10:46:52.213Z"}
{"msg":"I'm looking for a dedicated note taker to document discussions from the *Semantics WG* calls. Any takers?","username":"pknowles","ts":"2018-12-05T12:06:06.982Z"}
{"msg":"I'm also looking for a dedicated note taker to document discussions from the *Semantics WG* calls. Any takers?","username":"pknowles","ts":"2018-12-05T12:06:06.982Z"}
{"msg":"After reflecting on the notion of dynamic data, I am very uncomfortable with the idea of a holder granting a verifier access to the issuer. This is a bad idea.\nThe holder would no longer be in control of what data the verifier may receive. This subverts self-sovereign identity.\nLive access is not necessary, if a credential is no longer valid, the issuer should revoke it. \nI've seen descriptions of this where the access token provided by the holder to the verifier contains the holder's DID that is pairwise with the issuer. This completely negates any correlation and issuer-holder collusion protection the pairwise DID is supposed to provide. \nEven the capacity of the holder to revoke the verifier's access to the issuer is a matter of trusting the issuer.\nThis feels like it's going in the opposite direction we want, with the verifier and issuer retaining more control over the holder's data, and the verifier getting even more of the holder's data than was possible before. \nInstead of a holder having control of his data independent of the issuer, and selectively disclosing it to whichever verifiers he wishes, this notion provides more control to the issuer, who will see every verifier that comes along and know exactly what data they've retrieved. The whole idea that the holder has a different \"identity\" with the issuer than he has with the verifier is completely lost here.\nThe worst part is that this new anti-pattern of over sharing comes with the \"consent\" of the holder.","username":"brentzundel","ts":"2018-12-05T22:57:25.107Z"}
{"msg":"@brentzundel I agree with you entirely. See my next post!","username":"pknowles","ts":"2018-12-06T04:48:39.656Z"}
{"msg":"Going back to the credit union use case outlined by @darrell.odonnell , the individual is not an actor in the transaction. We need a verifiable credential that contains four variables, two static (MemberSince, InstitutionName) and two dynamic (AverageMonthlyBalance, GoodCustomerStanding). In this particular case, as these data points have been algorithmically generated by the credit union [CU1], they are the “Holder” and the “Verifier” of that data. The “Issuer” might be another credit union [CU2] who would be requesting verified data from the first credit union [CU1]. \n\nSo …\n\nCU2 issues a schema to CU1 containing … \n\nMemberSince\nInstitutionName\nAverageMonthlyBalance\nGoodCustomerStanding\n\nCU1 (with their “Holder” hat on) determines whether or not they are happy to share that data and, if so, (with their “Verifier” hat on) sends the Verifiable Credential to CU2.\n\nGoing back to the Dynamic Overlay suggestion by @mtfk , the overlay (specifying DID references to the two dynamic variables) would go on top of the credential not the schema.\n\nDoes that seem reasonable?\n\n[Cc: @swcurran , @mtfk , @darrell.odonnell , @brentzundel ]","username":"pknowles","ts":"2018-12-06T04:51:01.133Z"}
{"msg":"@pknowles - I'm really confused. That does not make sense to me at all.  How about we take this to a Google Doc and use that as a forum to make progress.  Among the pieces that don't make sense - the concept of issuing a schema, and that it appears to be two Credit Unions exchanging data about a  customer without the customer involved?   That definitely doesn't see right.","username":"swcurran","ts":"2018-12-06T05:52:11.331Z"}
{"msg":"@brentzundel - I think there may be use cases where the volume and frequency of data precludes the use of all data flowing from the Issuer to the Holder to the Verifier. The @darrell.odonnell example is one that is fine (monthly updates, two aggregate data values - monthly VerCred issuances). However, what about the case of Mint or QuickBooks services getting a feed of all bank account transactions for the client?  I think that is one where the flow would be challenging.  Again - it might be OK, but for a big organization with many transactions - it's tricky.\n","username":"swcurran","ts":"2018-12-06T05:58:50.741Z"}
{"msg":"@brentzundel - I think there may be use cases where varying from the strict - Issuer to Holder to Verifier data flow may be useful. In @darrell.odonnell's case, perhaps not - it's just two values monthly, so a Verifiable Credential is fine. But look at the case of services like Mint and QuickBooks that need near-real time access to all bank account transactions?  The volume increases with IoT devices.  Does the pure Verifiable Creds flow model always work for those?\n\nIn that case (Bank, Client, Service), I had thought a model like this might work (which I think is what @harrihoo did - I haven't reread his paper though).\n\n- the Bank gives the Client a unique token (a capability) in a verifiable credential\n- the Client issues a Verifiable Credential to the Service with that token\n- the Service proves that token to the Bank each time it requests data (including proving non-revocation).\n- Aside - on first use, the Bank might confirm with the Client if there were possibilities of a Verifier sharing the token - not sure on the tech there.\n- the Bank sends non-verifiable credential data (but likely signs the data) to the Service.\n- the Client can revoke the VerfCred sent to the Service at any time.\n\nThe \"pure VC\" alternative is that same setup is done with VerfCreds and automated processing by the SSI Agents from the Bank -> Client -> Service, but the net effect is the same - the Client only gets involved when they want to change the automation - e.g. cut off the Service. The challenge with this approach is that there is a lot more overhead involved - lots of asynch communications.  This might be the way to go, but at this stage, that seems more challenging.","username":"swcurran","ts":"2018-12-06T06:17:19.596Z"}
{"msg":"@swcurran @brentzundel I do think we should figure out a one-size-fits-all model re dynamic data so that we have some solid guidelines to follow. Let me go through @harrihoo 's model in more detail and then we can start a Google Doc. It may be a two stage process to get consent from the customer in the first instance. Once that consent is given, I stand by my logic.","username":"pknowles","ts":"2018-12-06T07:37:05.650Z"}
{"msg":"Guys, FYI, @peacekeeper and the OASIS XDI Technical Committee members ran into this same pattern several years ago, just using different terminology. I think it's fairly common for a Verifier, when offering some service to a Holder, to want to establish a subscription to some data (or a proof of some data) about the Holder from an Issuer (bank balance being an example). At a high level there are two basic patterns:\n\n1) *Direct Connection.* The Holder uses a VC to authorize a new direct connection between the Verifier and the Issuer. Done right, this connection has it's own pairwise pseudonymous DIDs between the Verifier and Issuer that are NOT the same as the pairs the Holder has with the Verifier and Issuer, respectively. So privacy can still be preserved. The Holder continues to control authorization of this connection for as long as the Holder wants the Verifier to have it (and the Issuer supports it). And this direct connection can either pull or push updates to the claim values.\n\n2) *Proxy Connection*. The Holder uses a VC to authorize the Verifier to dynamically request the current claim value (e.g., a bank balance) from the Holder's cloud agent, who in turn proxies that request from the Holder directly back to the Issuer. The Issuer issues the updated claim value to the Holder's cloud agent, who then responds with the proof to the Veriifer. No additional pairwise pseudonymous DIDs need to be issued or shared; all privacy is preserved; and the Verifier now effectively has a pull-based subscription to the claim value. This same scenario can be set up for push as well. But for the proof to flow automatically, the Holder has to trust its cloud agent to produce the proof.","username":"drummondreed","ts":"2018-12-07T06:34:25.975Z"}
{"msg":"Thanks, @drummondreed ! That's super helpful. During our week in Basel, @mtfk and I will hash out a design to deal with dynamic variables using consent and dynamic overlays on credentials and/or schemas. Once we're close, I'll run it by experts like you, @swcurran , etc. for valued opinions.","username":"pknowles","ts":"2018-12-07T07:51:01.312Z"}
{"msg":"That makes sense, @drummondreed - thanks for the overview.  Sounds like we are in sync.  We'll chat in Basel!","username":"swcurran","ts":"2018-12-07T08:06:11.214Z"}
{"msg":"@pknowles & @swcurran et al. I'm also interested in joining this discussion. Our team (Tieto) did the company identity project (aka Mercury) which also did a very quick-n-dirty VC-solution, similar to what @harrihoo did. I also now have few cases on the table where different types of consent models and \"key verification without connection\" -pattern is needed. ","username":"anttikettunen","ts":"2018-12-07T08:09:30.174Z"}
{"msg":"@anttikettunen - if you are going to Basel, we can discuss there. If online (and perhaps as well) - perhaps create a google doc outlining the parameters of the use case?","username":"swcurran","ts":"2018-12-07T08:10:48.973Z"}
{"msg":"Yeah, a doc would be good, as I'm unlikely to be in Basel due to multiple deadlines at work before holiday season... :( ","username":"anttikettunen","ts":"2018-12-07T08:11:31.525Z"}
{"msg":"","username":"anttikettunen","ts":"2018-12-07T08:12:18.086Z","attachments":[{"type":"file","title":"Mercury VC model","title_link":"/file-upload/Z2xadtWiukPXC59R3/Mercury%20VC%20model","image_url":"/file-upload/Z2xadtWiukPXC59R3/Mercury%20VC%20model","image_type":"image/png","image_size":141222,"url":"/file-upload/Z2xadtWiukPXC59R3/Mercury%20VC%20model","remote":false,"fileId":"Z2xadtWiukPXC59R3","fileName":"Mercury VC model"}]}
{"msg":"This is essentially the same on high level as with @harrihoo's design.","username":"anttikettunen","ts":"2018-12-07T08:13:17.554Z"}
{"msg":"I've started a document outlining the Credit Union use case. It has a few holes in it but we're off to the races. @mtfk will add his thoughts and then I'll Google Doc it and post in this channel for review.","username":"pknowles","ts":"2018-12-07T08:13:50.223Z"}
{"msg":"I'm not yet familiar with the overlays and what it enables, so I need to dive deeper there first.","username":"anttikettunen","ts":"2018-12-07T08:14:09.584Z"}
{"msg":"I will also have multiple use cases to add, but I need to flesh them out first with the customers.","username":"anttikettunen","ts":"2018-12-07T08:14:42.913Z"}
{"msg":"@anttikettunen We're still pre-HIPE on Overlays but the best working document is *Overlays* - https://github.com/mitfik/overlays-demo/blob/master/SOD.md","username":"pknowles","ts":"2018-12-07T08:16:02.654Z"}
{"msg":"@anttikettunen We're still pre-HIPE on *Overlays* but the best working document is https://github.com/mitfik/overlays-demo/blob/master/SOD.md","username":"pknowles","ts":"2018-12-07T08:16:02.654Z"}
{"msg":"@anttikettunen We're still pre-HIPE on overlays but the best working document is https://github.com/mitfik/overlays-demo/blob/master/SOD.md","username":"pknowles","ts":"2018-12-07T08:16:02.654Z"}
{"msg":"The next *Semantics WG* meeting will take place  on *Tuesday, December 11th*. These calls provide an opportunity for Hyperledger Indy community members to discuss data capture and semantics initiatives. Anyone is welcome to join the call.\n\nHere is the agenda and dial-in information for next Tuesday's meeting ... \n\nMeeting: Semantics Working Group\nDate: Tuesday, 11th December, 2018\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: Paul Knowles\n\nAgenda:\n• Quick round of participant introductions (Open) - 5 mins\n• *Advanced model presentation*: Consent Receipt model (Presenter: @JanL ) - 15 mins\n- Reference - https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt\n• *Use case*: Working with dynamic variables (Member query: @darrell.odonnell ) - 30 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2018-12-07T08:19:24.111Z"}
{"msg":"The next *Semantics WG* meeting will take place  on *Tuesday, December 11th*. These calls provide an opportunity for Hyperledger Indy community members to discuss data capture and semantics initiatives. Anyone is welcome to join the call.\n\nHere is the agenda and dial-in information for next Tuesday's meeting ... \n\nMeeting: Semantics Working Group\nDate: Tuesday, 11th December, 2018\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: Paul Knowles\n\nAgenda:\n• Quick round of participant introductions (Open) - 5 mins\n• *Advanced model presentation*: Consent Receipt model (Presenter: @janl ) - 15 mins\n- Reference - https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt\n• *Use case*: Working with dynamic variables (Member query: @darrell.odonnell ) - 30 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2018-12-07T08:19:24.111Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=ehFfM6tTZiDGDvtDM) @swcurran In order for the Client to issue the verifiable credential (and have the ability to revoke it) it would need a DID on the ledger, and right now the plan is to not put DIDs on the ledger for pairwise connections. I'm think that requiring a bank account holder to become a public entity in order to enable a service live access to that holder's account is a bad idea. \nBut that is beside the point, allowing a service live access to my personal data is already a bad idea, unless a way can be come up with that gives the holder complete control. Granting live access to my personal data is an anti-pattern. \nNone of the suggested protocols I've seen seem to fit with the stated principles of self-sovereign identity, so from my perspective, the answer to the question, \"can Sovrin support this use case?\" is, \"No\"","username":"brentzundel","ts":"2018-12-07T19:12:04.440Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=ehFfM6tTZiDGDvtDM","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=ehFfM6tTZiDGDvtDM","remote":true,"fileId":null,"fileName":null}]}
{"msg":"@mtfk @JanL 5 ^^^ See @brentzundel 's comment above. This is totally in line with Jan's *Consent* work. Having spoken to Robert yesterday, we'll draft an overlays solution for dynamic data usage in Basel next week which we'll run past the likes of @swcurran and @drummondreed . Data revocation will be key to that proposed solution. Once the Basel attendees are happy, we'll send it over to Jan to ensure that the proposal fits in with Jan's consent piece. Brent - I'm guessing Robert and I will have verifiable credential-related queries as we deep dive this. I'll DM you next week to arrange a call. Onwards!","username":"pknowles","ts":"2018-12-08T04:19:57.572Z"}
{"msg":"@mtfk @JanL 5 ^^^ See @brentzundel 's comment above. This is totally in line with Jan's *consent* work. Having spoken to Robert yesterday, we'll draft an overlays solution for dynamic data usage in Basel next week which we'll run past the likes of @swcurran and @drummondreed . Data revocation will be key to that proposed solution. Once the Basel attendees are happy, we'll send it over to Jan to ensure that the proposal fits in with his consent piece. Brent - I'm guessing Robert and I will have verifiable credential-related queries as we deep dive this. I'll DM you next week to arrange a call. Onwards!","username":"pknowles","ts":"2018-12-08T04:19:57.572Z"}
{"msg":"@mtfk @JanL 5 , see @brentzundel 's comment above ^^^. This is totally in line with Jan's *consent* work. Having spoken to Robert yesterday, we'll draft an overlays solution for dynamic data usage in Basel next week which we'll run past the likes of @swcurran and @drummondreed . Data revocation will be key to that proposed solution. Once the Basel attendees are happy, we'll send it over to Jan to ensure that the proposal fits in with his consent piece. Brent - I'm guessing Robert and I will have verifiable credential-related queries as we deep dive this. I'll DM you next week to arrange a call. Onwards!","username":"pknowles","ts":"2018-12-08T04:19:57.572Z"}
{"msg":"@mtfk @JanL 5 , see @brentzundel 's comment above ^^^. This is totally in line with Jan's *consent* modelling work. Having spoken to Robert yesterday, we'll draft an overlays solution for dynamic data usage in Basel next week which we'll run past the likes of @swcurran and @drummondreed . Data revocation will be key to that proposed solution. Once the Basel attendees are happy, we'll send it over to Jan to ensure that the proposal fits in with his consent piece. Brent - I'm guessing Robert and I will have verifiable credential-related queries as we deep dive this. I'll DM you next week to arrange a call. Onwards!","username":"pknowles","ts":"2018-12-08T04:19:57.572Z"}
{"msg":"@mtfk @JanL 5 , see @brentzundel 's comment above ^^^. This is totally in line with Jan's *consent modelling* work. Having spoken to Robert yesterday, we'll draft an overlays solution for dynamic data usage in Basel next week which we'll run past the likes of @swcurran and @drummondreed . Data revocation will be key to that proposed solution. Once the Basel attendees are happy, we'll send it over to Jan to ensure that the proposal fits in with his consent piece. Brent - I'm guessing Robert and I will have verifiable credential-related queries as we deep dive this. I'll DM you next week to arrange a call. Onwards!","username":"pknowles","ts":"2018-12-08T04:19:57.572Z"}
{"msg":"@mtfk @JanL 5 , see @brentzundel 's comment above ^^^. This is totally in line with Jan's *consent modelling* work. Having spoken to Robert yesterday, we'll draft an overlays solution for dynamic data usage in Basel next week which we'll run past the likes of @nage , @swcurran and @drummondreed . Data revocation will be key to that proposed solution. Once the Basel crew are happy, we'll send it over to Jan to ensure that the proposal fits in with his consent piece. Brent - I'm guessing Robert and I will have verifiable credential-related queries as we deep dive this. I'll DM you next week to arrange a call. Onwards!","username":"pknowles","ts":"2018-12-08T04:19:57.572Z"}
{"msg":"@mtfk @janl , see @brentzundel 's comment above ^^^. This is totally in line with Jan's *consent modelling* work. Having spoken to Robert yesterday, we'll draft an overlays solution for dynamic data usage in Basel next week which we'll run past the likes of @nage , @swcurran and @drummondreed . Data revocation will be key to that proposed solution. Once the Basel crew are happy, we'll send it over to Jan to ensure that the proposal fits in with his consent piece. Brent - I'm guessing Robert and I will have verifiable credential-related queries as we deep dive this. I'll DM you next week to arrange a call. Onwards!","username":"pknowles","ts":"2018-12-08T04:19:57.572Z"}
{"msg":"Has joined the channel.","username":"AndrewHughes3000","ts":"2018-12-09T17:13:07.255Z","type":"uj"}
{"msg":"User <em>User_42</em> added by <em>harrihoo</em>.","username":"harrihoo","ts":"2018-12-10T18:22:32.728Z","type":"au"}
{"msg":"Finally on this tool also (goodbye Sovrin Slack). I (@harrihoo) and @stuorini will be glad to follow this dynamic data access drafting closely also. We've also done our fair deal of consent modeling on our past research. Where's the current Consent Overlay material to be found at?","username":"harrihoo","ts":"2018-12-10T18:26:51.275Z"}
{"msg":"@harrihoo @stuorini Great to have you guys onboard! @JanL 5 's \"consent\" work is in progress. I would suggest that the best link is https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt","username":"pknowles","ts":"2018-12-10T19:42:34.807Z"}
{"msg":"@harrihoo @stuorini Great to have you guys onboard! @JanL 5 's \"consent\" work is still in draft form but would be a good place to start. https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt","username":"pknowles","ts":"2018-12-10T19:42:34.807Z"}
{"msg":"@harrihoo @stuorini Great to have you guys onboard! @JanL 5 's \"consent\" work is still in draft form but would be a good place to start. https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt","username":"pknowles","ts":"2018-12-10T19:42:34.807Z"}
{"msg":"@harrihoo @stuorini Great to have you guys onboard! @janl 's \"consent\" work is still in draft form but would be a good place to start. https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt","username":"pknowles","ts":"2018-12-10T19:42:34.807Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=4F3LRB8vZaYeG6P8M) @harrihoo We will discuss it in tomorrow's call. Looking forward to hear about your research.","username":"janl","ts":"2018-12-10T20:17:27.631Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=4F3LRB8vZaYeG6P8M","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=4F3LRB8vZaYeG6P8M","remote":true,"fileId":null,"fileName":null}]}
{"msg":"This week's *Semantics WG* call starts in 10 minutes. Agenda Doc: https://drive.google.com/drive/u/0/folders/1kN-INYUNYB-yA8teZR3EarxcwdMMmKrl?ogsrc=32","username":"pknowles","ts":"2018-12-11T17:52:32.773Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=H4iPXfbNBEe6Xu4NA) @pknowles darnit... first I was an hour early (7pm EET instead of CET) and now I'm an hour late (due to kids)... maybe next time again...","username":"anttikettunen","ts":"2018-12-11T19:06:23.464Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=H4iPXfbNBEe6Xu4NA","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=H4iPXfbNBEe6Xu4NA","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Btw @pknowles was the meeting link ok, or did you guys finish early? https://zoom.us/j/2157245727 was empty just 15 mins ago.","username":"anttikettunen","ts":"2018-12-11T19:07:01.744Z"}
{"msg":"No problem, @anttikettunen ! We finished a little early this week. We'll be squeezing in another meeting before the Christmas break though. The next call will be next Tuesday, December 18th at the same time. We'll keep the deep dive going on the *Dynamic Variable* piece. The Hyperledger Global Forum in Basel this week will enable the semantics team to flesh it out further still.","username":"pknowles","ts":"2018-12-11T19:13:13.802Z"}
{"msg":"No problem, @anttikettunen ! We finished a little early this week. We'll be squeezing in another meeting before the Christmas break though. The next call will be next *Tuesday, December 18th* at the same time. We'll keep the deep dive going on the *Dynamic Variable* piece. The Hyperledger Global Forum in Basel this week will enable the semantics team to flesh it out further still.","username":"pknowles","ts":"2018-12-11T19:13:13.802Z"}
{"msg":"Has joined the channel.","username":"wombletron","ts":"2018-12-11T20:09:34.802Z","type":"uj"}
{"msg":"The agenda, video, notes, etc. from today's *Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, December 18th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2018-12-11T20:19:55.128Z"}
{"msg":"The agenda, video, notes, etc. from today's *Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, December 18th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2018-12-11T20:19:55.128Z"}
{"msg":"Has joined the channel.","username":"dznz","ts":"2018-12-12T01:40:26.261Z","type":"uj"}
{"msg":"Has joined the channel.","username":"yisheng","ts":"2018-12-12T03:41:28.337Z","type":"uj"}
{"msg":"I was unable to attend the meeting today, and will not be in Basel. Please keep Nathan George @nage in the loop on dynamic variables.","username":"brentzundel","ts":"2018-12-12T16:01:03.983Z"}
{"msg":"@brentzundel - @mtfk and I will be sitting down with @nage , @drummondreed and @swcurran on either Friday or Saturday to discuss dynamic variables. I'll keep you posted.","username":"pknowles","ts":"2018-12-12T22:04:54.563Z"}
{"msg":"Has joined the channel.","username":"Rantwijk","ts":"2018-12-14T09:49:11.346Z","type":"uj"}
{"msg":"I have created a HIPE proposal that explains the theory and conventions associated with A2A decorators. As I was discussing with @pknowles yesterday, decorators have a huge amount in common with the notion of overlays, but I hadn't realized it until yesterday. There is a section of this document that acknowledges that overlap (see \"Rationale and alternatives\" near the end). Would love public comment: https://github.com/hyperledger/indy-hipe/pull/71","username":"danielhardman","ts":"2018-12-15T11:15:34.042Z"}
{"msg":"@janl Keep going on https://github.com/hyperledger/indy-hipe/pull/55 . This becomes hugely important when defining a static *Consent Schema Base*. It's very important work. I'll help where I can.","username":"pknowles","ts":"2018-12-16T10:46:43.391Z"}
{"msg":"@janl Keep going on https://github.com/hyperledger/indy-hipe/pull/55 . This becomes hugely important when defining a static *Consent Schema Base*. If you need to bounce anything off me, just shout.","username":"pknowles","ts":"2018-12-16T10:46:43.391Z"}
{"msg":"@janl Keep going on https://github.com/hyperledger/indy-hipe/pull/55 . This becomes hugely important when defining a static *Consent Schema Base*. If you need to run anything by me, just shout. Otherwise, do as he ( @danielhardman ) say.","username":"pknowles","ts":"2018-12-16T10:46:43.391Z"}
{"msg":"@janl Keep going on https://github.com/hyperledger/indy-hipe/pull/55 . This becomes hugely important when defining a static *Consent Schema Base*. If you need to run anything by me, just shout. Otherwise, do as he ( i.e. @danielhardman ) say!","username":"pknowles","ts":"2018-12-16T10:46:43.391Z"}
{"msg":"@janl Keep going on https://github.com/hyperledger/indy-hipe/pull/55 . This becomes hugely important when defining a static *Consent Schema Base*. If you need to run anything by me, just shout. Otherwise, follow the Technical Ambassador comments. That will steer you in the right direction.","username":"pknowles","ts":"2018-12-16T10:46:43.391Z"}
{"msg":"@darrell.odonnell Re dynamic variables, in our model, there is no such thing as dynamic. As a similar analogy, think of an analog wave form as a non-interpolated stream and a digitised version and an interpolated stream of data. In your use case re dynamic data, you can either tackle it from the Issuer side in a *collectionFrequency* attribute in a linked *Consent Schema* or you can put a *Source Overlay* on that attribute to point to an external dynamic variable. In both cases, we're dealing with interpolation which means you're covered from a \"schemas and data capture\" perspective. I need to better understand your use case in the Issuer, Holder, Verifier model. If I haven't answered your question, I'll look at it from a \"claims and credentials perspective. In any case, it's certainly not going to be an issue.","username":"pknowles","ts":"2018-12-16T11:06:06.583Z"}
{"msg":"@darrell.odonnell Re dynamic variables, in our model, there is no such thing as dynamic. As a similar analogy, think of an analog wave form as a non-interpolated form and a digitised version as an interpolated stream of data. In your use case re dynamic data, you can either tackle it from the Issuer side in a *collectionFrequency* attribute in a linked *Consent Schema* or you can put a *Source Overlay* on that attribute to point to an external dynamic variable. In both cases, we're dealing with interpolation which means you're covered from a \"schemas and data capture\" perspective. I need to better understand your use case in the Issuer, Holder, Verifier model. If I haven't answered your question, I'll look at it from a \"claims and credentials perspective. In any case, it's certainly not going to be an issue.","username":"pknowles","ts":"2018-12-16T11:06:06.583Z"}
{"msg":"@darrell.odonnell Re dynamic variables, in our model, there is no such thing as dynamic. As a similar analogy, think of an analog wave form as non-interpolated and a digitised version as an interpolated stream of data. In your use case re dynamic data, you can either tackle it from the Issuer side by using either (i.) a *collectionFrequency* attribute in a linked *Consent Schema* or (ii.) by using a *Source Overlay* on that attribute to point to an external dynamic variable. In both cases, we're dealing with interpolation which means you're covered from a \"schemas and data capture\" perspective. I need to better understand your use case in the Issuer/Holder/Verifier model. If I haven't answered your question, I'll also look at it from a \"claims and credentials perspective. In any case, it's certainly not going to be an issue.","username":"pknowles","ts":"2018-12-16T11:06:06.583Z"}
{"msg":"@darrell.odonnell Within the Sovrin model there will be no such thing as truly dynamic. As a similar analogy, think of an analog wave form as non-interpolated and a digitised version as interpolated. In your use case re dynamic data, you can either tackle it from the Issuer side by using either (i.) a *collectionFrequency* attribute in a linked *Consent Schema* or (ii.) by using a *Source Overlay* on that attribute to point to an external dynamic variable. In both cases, we're dealing with interpolation which means you're covered from a \"schemas and data capture\" perspective. I need to better understand your use case in the Issuer/Holder/Verifier model. If I haven't answered your question, I'll also look at it from a \"claims and credentials perspective. In any case, it's certainly not going to be an issue.","username":"pknowles","ts":"2018-12-16T11:06:06.583Z"}
{"msg":"@darrell.odonnell Within the Sovrin model there will be no such thing as truly dynamic. As a similar analogy, think of an analog wave form as non-interpolated and a digitised version as interpolated. In your use case re dynamic data, you can either tackle it from the Issuer side by using either (i.) a *collectionFrequency* attribute in a linked *Consent Schema* or (ii.) by using a *Source Overlay* on that attribute to point to an external dynamic variable. In both cases, we're dealing with interpolation which means you're covered from a \"schemas and data capture\" perspective. I need to better understand your use case in the Issuer/Holder/Verifier model. If I haven't answered your question, I'll also look at it from a \"claims and credentials\" perspective. In any case, it's certainly not going to be an issue.","username":"pknowles","ts":"2018-12-16T11:06:06.583Z"}
{"msg":"@darrell.odonnell Within the Sovrin model there will be no such thing as truly dynamic. As a similar analogy, think of an analog wave form as non-interpolated and a digitised version as interpolated. In your use case re dynamic data, you can tackle it from the Issuer side by using either (i.) a *collectionFrequency* attribute in a linked *Consent Schema* or (ii.) by using a *Source Overlay* on that attribute to point to an external dynamic variable. In both cases, we're dealing with interpolation which means you're covered from a \"schemas and data capture\" perspective. I need to better understand your use case in the Issuer/Holder/Verifier model. If I haven't answered your question, I'll also look at it from a \"claims and credentials\" perspective. In any case, it's certainly not going to be an issue.","username":"pknowles","ts":"2018-12-16T11:06:06.583Z"}
{"msg":"@darrell.odonnell Within the Sovrin model there will be no such thing as truly dynamic. As a similar analogy, think of an analog wave form as non-interpolated and a digitised version as interpolated. In your use case re dynamic data, you can tackle it from the Issuer side by using either (i.) a *collectionFrequency* attribute in a linked *Consent Schema* or (ii.) you can use a *Source Overlay* on that attribute to point to an external dynamic variable. In both cases, we're dealing with interpolation which means you're covered from a \"schemas and data capture\" perspective. I need to better understand your use case in the Issuer/Holder/Verifier model. If I haven't answered your question, I'll also look at it from a \"claims and credentials\" perspective. In any case, it's certainly not going to be an issue.","username":"pknowles","ts":"2018-12-16T11:06:06.583Z"}
{"msg":"@darrell.odonnell Within the Sovrin model there will be no such thing as truly dynamic. As a similar analogy, think of an analog wave form as non-interpolated and a digitised version as interpolated. In your use case re dynamic data, you can tackle it from the Issuer side by using either (i.) a *collectionFrequency* attribute in a linked *Consent Schema* or (ii.) you can use a *Source Overlay* on that attribute to point to an external dynamic variable. In both cases, we're dealing with interpolation which means you're covered from a \"schemas and data capture\" perspective. If that doesn't answer your question, I'll need to better understand your use case so that I can describe how that might look from a \"claims and credentials\" perspective. In any case, it's certainly not going to be an issue.","username":"pknowles","ts":"2018-12-16T11:06:06.583Z"}
{"msg":"@darrell.odonnell Within the Sovrin model there is no such thing as truly dynamic. As a similar analogy, think of an analog wave form as non-interpolated and a digitised version as interpolated. In your use case re dynamic data, you can tackle it from the Issuer side by using either (i.) a *collectionFrequency* attribute in a linked *Consent Schema* or (ii.) you can use a *Source Overlay* on that attribute to point to an external dynamic variable. In both cases, we're dealing with interpolation which means you're covered from a \"schemas and data capture\" perspective. If that doesn't answer your question, I'll need to better understand your use case so that I can describe how that might look from a \"claims and credentials\" perspective. In any case, it's certainly not going to be an issue.","username":"pknowles","ts":"2018-12-16T11:06:06.583Z"}
{"msg":"@pknowles - I'm not sure there is any need for either a consent schema or an overlay for @darrell.odonnell's scenario.   The way that I understood we had agreed was that we would just use the normal - issuer/holder/verifier model, but the difference would be the automation of the claim flow to avoid constant manual intervention.  Assuming each party has an configurable, automated (Cloud) Agent, likely flow (but others are possible) is the following:\n\n* The Verifier (Third Party) requests a periodic credential from the Holder (CU Customer)\n* The Holder requests a Proof from the Issuer (CU)\n* The Holder Proves the Claims from the Proof\n\nAll three are automated, and if any of the three want to stop the flow of data - they just stop their Agent from participating.  Of course, any of the three (and in particular - the CU Customer) could choose to not automate the process and get pinged for consent on every iteration.\n\nWith the agent infrastructure in place (which isn't available yet....), I think this can be done without any extra magic.  Frequency would like be handled as part of the Agent Message Family used to setup the automated process.","username":"swcurran","ts":"2018-12-16T21:23:10.964Z"}
{"msg":"@swcurran That's very cool!","username":"pknowles","ts":"2018-12-16T21:32:29.464Z"}
{"msg":"@swcurran That's very cool! ","username":"pknowles","ts":"2018-12-16T21:32:29.464Z"}
{"msg":"BTW, @mtfk and I cracked the Overlays data architecture model early yesterday morning. The HIPE will be going in within the next couple of days for review. A couple of important pieces that we will be subsequently looking at are: (i.) a _pii_attributes_ *schema object* to allow the issuer to flag sensitive data according to the *Blinding Identity Taxonomy (BIT)* as we start to onboard. That is the Issuer's tool for flagging sensitive schema elements. On the Holder side, sensitive data can be screened courtesy of a sensitive overlay which is not tied to a particular schema base but rather to a sensitive data repository held off-ledger. (ii.) The second interesting piece will be determining the exact elements defined in a consent schema which can then be coupled with any schema. The exact elements will be determined according to GDPR requirements along with those necessary for @janl 's consent receipt model to work. [ref. https://github.com/hyperledger/indy-hipe/pull/55 ]. Things are starting to get very interesting. Seeing the pieces align between the \"schemas and data capture\" team and the \"claims and credentials\" team will be awesome to see.","username":"pknowles","ts":"2018-12-16T22:13:28.312Z"}
{"msg":"BTW, @mtfk and I cracked the Overlays data architecture model early yesterday morning. The HIPE will be going in within the next couple of days for review. A couple of important pieces that we will be subsequently looking at are: (i.) a pii_attributes *schema object* to allow the issuer to flag sensitive data according to the *Blinding Identity Taxonomy (BIT)* as we start to onboard. That is the Issuer's tool for flagging sensitive schema elements. On the Holder side, sensitive data can be screened courtesy of a sensitive overlay which is not tied to a particular schema base but rather to a sensitive data repository held off-ledger. (ii.) The second interesting piece will be determining the exact elements defined in a consent schema which can then be coupled with any schema. The exact elements will be determined according to GDPR requirements along with those necessary for @janl 's consent receipt model to work. [ref. https://github.com/hyperledger/indy-hipe/pull/55 ]. Things are starting to get very interesting. Seeing the pieces align between the \"schemas and data capture\" team and the \"claims and credentials\" team will be awesome to see.","username":"pknowles","ts":"2018-12-16T22:13:28.312Z"}
{"msg":"BTW, @mtfk and I cracked the Overlays data architecture model early yesterday morning. The HIPE will be going in within the next couple of days for review. A couple of important pieces that we will subsequently be looking at are: (i.) a pii_attributes *schema object* to allow the issuer to flag sensitive data according to the *Blinding Identity Taxonomy (BIT)* as we start to onboard. That is the Issuer's tool for flagging sensitive schema elements. On the Holder side, sensitive data can be screened courtesy of a sensitive overlay which is not tied to a particular schema base but rather to a sensitive data repository held off-ledger. (ii.) The second interesting piece will be determining the exact elements defined in a consent schema which can then be coupled with any schema. The exact elements will be determined according to GDPR requirements along with those necessary for @janl 's consent receipt model to work. [ref. https://github.com/hyperledger/indy-hipe/pull/55 ]. Things are starting to get very interesting. Seeing the pieces align between the \"schemas and data capture\" team and the \"claims and credentials\" team will be awesome to see.","username":"pknowles","ts":"2018-12-16T22:13:28.312Z"}
{"msg":"BTW, @mtfk and I cracked the Overlays data architecture model early yesterday morning. The HIPE will be going in within the next couple of days for review. A couple of important pieces that we will subsequently be looking at are: (i.) a pii_attributes *schema object* to allow the issuer to flag sensitive data according to the *Blinding Identity Taxonomy (BIT)* as we start to onboard. That is the Issuer's tool for flagging sensitive schema elements. On the Holder side, sensitive data can be screened courtesy of a *sensitive overlay* which is not tied to a particular schema base but rather to a sensitive data repository held off-ledger. (ii.) The second interesting piece will be determining the exact elements defined in a *consent schema base* which can then be coupled with any schema. The exact elements will be determined according to GDPR requirements along with those necessary for @janl 's consent receipt model to work. [ref. https://github.com/hyperledger/indy-hipe/pull/55 ]. Things are starting to get very interesting. Seeing these pieces align between the \"schemas and data capture\" experts and the \"claims and credentials\" experts will be awesome to see.","username":"pknowles","ts":"2018-12-16T22:13:28.312Z"}
{"msg":"BTW, @mtfk and I cracked the Overlays data architecture model early yesterday morning. The HIPE will be going in within the next couple of days for review. A couple of important pieces that we will subsequently be looking at are: (i.) a pii_attributes *schema object* to allow the issuer to flag sensitive data according to the *Blinding Identity Taxonomy (BIT)* as we start to onboard. That is the Issuer's tool for flagging sensitive schema elements. On the Holder side, sensitive data can be screened courtesy of a *sensitive overlay* which is not tied to a particular schema base but rather to a sensitive data repository held off-ledger. (ii.) The second interesting piece will be determining the exact elements defined in a *consent schema base* which can then be coupled with any schema. The exact elements will be determined according to GDPR requirements along with those necessary for @janl 's consent model to work. [ref. https://github.com/hyperledger/indy-hipe/pull/55 ]. Things are starting to get very interesting. Seeing these semantics pieces align will be truly awesome to see.","username":"pknowles","ts":"2018-12-16T22:13:28.312Z"}
{"msg":"BTW, @mtfk and I cracked the Overlays data architecture model early yesterday morning. The HIPE will be going in within the next couple of days for review. A couple of important pieces that we will subsequently be looking at are: (i.) a *pii_attributes schema object* to allow the issuer to flag sensitive data according to the *Blinding Identity Taxonomy (BIT)* as we start to onboard. That is the Issuer's tool for flagging sensitive schema elements. On the Holder side, sensitive data can be screened courtesy of a *sensitive overlay* which is not tied to a particular schema base but rather to a sensitive data repository held off-ledger. (ii.) The second interesting piece will be determining the exact elements defined in a *consent schema base* which can then be coupled with any schema. The exact elements will be determined according to GDPR requirements along with those necessary for @janl 's consent model to work. [ref. https://github.com/hyperledger/indy-hipe/pull/55 ]. Things are starting to get very interesting. Seeing these semantics pieces align will be truly awesome to see.","username":"pknowles","ts":"2018-12-16T22:13:28.312Z"}
{"msg":"BTW, @mtfk and I cracked the Overlays data architecture model early yesterday morning. The HIPE will be going in within the next couple of days for review. A couple of important pieces that we will subsequently be looking at are: (i.) a *pii_attributes schema object* to allow the issuer to flag sensitive data according to the *Blinding Identity Taxonomy (BIT)* as we start to onboard. That is the Issuer's tool for flagging sensitive schema elements. On the Holder side, sensitive data can be screened courtesy of a *sensitive overlay* which is not tied to a particular schema base but rather to a sensitive data repository held off-ledger. (ii.) The second interesting piece will be determining the exact elements defined in a *consent schema base* which can then be coupled with any schema. The exact elements will be determined by legal regulations  along with those necessary for @janl 's consent model to work. [ref. https://github.com/hyperledger/indy-hipe/pull/55 ]. Things are starting to get very interesting. Seeing these semantics pieces align will be truly awesome to see.","username":"pknowles","ts":"2018-12-16T22:13:28.312Z"}
{"msg":"BTW, @mtfk and I cracked the Overlays data architecture model early yesterday morning. The HIPE will be going in within the next couple of days for review. A couple of important pieces that we will subsequently be looking at are: (i.) a *pii_attributes schema object* to allow the issuer to flag sensitive data according to the *Blinding Identity Taxonomy (BIT)* as we start to onboard. That is the Issuer's tool for flagging sensitive schema elements. On the Holder side, sensitive data can be screened courtesy of a *sensitive overlay* which is not tied to a particular schema base but rather to a sensitive data repository held off-ledger. (ii.) The second interesting piece will be determining the exact elements defined in a *consent schema base* which can then be coupled with any schema. The exact elements will be determined by legal/tech requirements and will include capture capability for @janl 's consent model to work. [ref. https://github.com/hyperledger/indy-hipe/pull/55 ]. Things are starting to get very interesting. Seeing these semantics pieces align will be truly awesome to see.","username":"pknowles","ts":"2018-12-16T22:13:28.312Z"}
{"msg":"BTW, @mtfk and I cracked the Overlays data architecture model early yesterday morning. The HIPE will be going in within the next couple of days for review. A couple of important pieces that we will subsequently be looking at are: (i.) a *pii_attributes schema object* to allow the issuer to flag sensitive data according to the *Blinding Identity Taxonomy (BIT)* as we start to onboard. That is the Issuer's tool for flagging sensitive schema elements. On the Holder side, sensitive data can be screened courtesy of a *sensitive overlay* which is not tied to a particular schema base but rather to a sensitive data repository held off-ledger. (ii.) The second interesting piece will be determining the exact elements defined in a *consent schema base* which can then be coupled with any schema. The exact elements will ultimately be determined by legal/tech requirements and will include capture capability for @janl 's consent model to work. [ref. https://github.com/hyperledger/indy-hipe/pull/55 ].","username":"pknowles","ts":"2018-12-16T22:13:28.312Z"}
{"msg":"BTW, @mtfk and I cracked the Overlays data architecture model early yesterday morning. The HIPE will be going in within the next couple of days for review. A couple of important pieces that we will subsequently be looking at are: (i.) a *pii_attributes schema object* to allow the issuer to flag sensitive data according to the *Blinding Identity Taxonomy (BIT)* as we start to onboard. That is the Issuer's tool for flagging sensitive schema elements. On the Holder side, sensitive data can be screened courtesy of a *sensitive overlay* which is not tied to a particular schema base but rather to a sensitive data repository held off-ledger. (ii.) The second interesting piece will be determining the exact elements defined in a *consent schema base* which can then be coupled with any schema. The exact elements will ultimately be determined by legal/tech requirements and will obviously include capture capability for @janl 's consent model to work. [ref. https://github.com/hyperledger/indy-hipe/pull/55 ].","username":"pknowles","ts":"2018-12-16T22:13:28.312Z"}
{"msg":"BTW, @mtfk and I cracked the Overlays data architecture model early yesterday morning. The HIPE will be going in within the next couple of days for review. A couple of important pieces that we will subsequently be looking at are: (i.) a *pii_attributes schema object* to allow the issuer to flag sensitive data according to the *Blinding Identity Taxonomy (BIT)* as we start to onboard. That is the Issuer's tool for flagging sensitive schema elements. On the Holder side, sensitive data can be screened courtesy of a *sensitive overlay* which is not tied to any schema. (ii.) The second interesting piece will be determining the exact elements defined in a *consent schema base* which can then be coupled with any schema. The exact elements will ultimately be determined by legal/tech requirements and will obviously include capture capability for @janl 's consent model to work. [ref. https://github.com/hyperledger/indy-hipe/pull/55 ].","username":"pknowles","ts":"2018-12-16T22:13:28.312Z"}
{"msg":"BTW, @mtfk and I cracked the Overlays data architecture model early yesterday morning. The HIPE will be going in within the next couple of days for review. A couple of important pieces that we will subsequently be looking at are: (i.) a *pii_attributes schema object* to allow the issuer to flag sensitive data according to the *Blinding Identity Taxonomy (BIT)* as we start to onboard. That is the Issuer's tool for flagging sensitive schema elements. On the Holder side, sensitive data can be screened courtesy of a *sensitive overlay* which is not tied to any schema. (ii.) The second interesting piece will be determining the exact elements defined in a *consent schema* which can then become a coupling object. The exact elements will ultimately be determined by legal/tech requirements and will obviously include capture capability for @janl 's consent model to work. [ref. https://github.com/hyperledger/indy-hipe/pull/55 ].","username":"pknowles","ts":"2018-12-16T22:13:28.312Z"}
{"msg":"BTW, @mtfk and I cracked the Overlays data architecture model early yesterday morning. The HIPE will be going in within the next couple of days for review. A couple of important pieces that we will subsequently be looking at are: (i.) a *pii_attributes schema object* to allow the issuer to flag sensitive data according to the *Blinding Identity Taxonomy (BIT)* as we start to onboard. That is the Issuer's tool for flagging sensitive schema elements. On the Holder side, sensitive data can be screened courtesy of a *sensitive overlay* which is not tied to any schema. (ii.) The second interesting piece will be determining elements to be defined in a *consent schema* which can then become a coupling object. The exact elements will ultimately be determined by legal/tech requirements and will obviously include capture capability for @janl 's consent model to work. [ref. https://github.com/hyperledger/indy-hipe/pull/55 ].","username":"pknowles","ts":"2018-12-16T22:13:28.312Z"}
{"msg":"BTW, @mtfk and I cracked the Overlays data architecture model early yesterday morning. The HIPE will be going in within the next couple of days for review. A couple of important pieces that we will subsequently be looking at are: (i.) a *pii_attributes schema object* to allow the issuer to flag sensitive data according to the *Blinding Identity Taxonomy (BIT)* as we start to onboard. That is the Issuer's tool for flagging sensitive schema elements. On the Holder side, sensitive data can be screened courtesy of a *sensitive overlay* which is not tied to any schema. (ii.) The second interesting piece will be determining elements to be defined in a *data consent schema* which can then become a coupling object. The exact elements will ultimately be determined by legal/tech requirements and will obviously include capture capability for @janl 's consent model to work. [ref. https://github.com/hyperledger/indy-hipe/pull/55 ].","username":"pknowles","ts":"2018-12-16T22:13:28.312Z"}
{"msg":"@mtfk and I cracked the Overlays data architecture model early yesterday morning. The HIPE will be going in within the next couple of weeks for review. A couple of important pieces that we will subsequently be looking at are: (i.) a *pii_attributes schema object* to allow the issuer to flag sensitive data according to the *Blinding Identity Taxonomy (BIT)* as we start to onboard. That is the Issuer's tool for flagging sensitive schema elements. On the Holder side, sensitive data can be screened courtesy of a *sensitive overlay* which is not tied to any schema. (ii.) The second interesting piece will be determining elements to be defined in a *data consent schema* which can then become a coupling object. The exact elements will ultimately be determined by legal/tech requirements and will obviously include capture capability for @janl 's consent model to work. [ref. https://github.com/hyperledger/indy-hipe/pull/55 ].","username":"pknowles","ts":"2018-12-16T22:13:28.312Z"}
{"msg":"@mtfk and I cracked the *Overlays* data architecture model early yesterday morning. The HIPE will be going in within the next couple of weeks for review. A couple of important pieces that we will subsequently be looking at are: (i.) a *pii_attributes schema object* to allow the issuer to flag sensitive data according to the *Blinding Identity Taxonomy (BIT)* as we start to onboard. That is the Issuer's tool for flagging sensitive schema elements. On the Holder side, sensitive data can be screened courtesy of a *sensitive overlay* which is not tied to any schema. (ii.) The second interesting piece will be determining elements to be defined in a *data consent schema* which can then become a coupling object. The exact elements will ultimately be determined by legal/tech requirements and will obviously include capture capability for @janl 's consent model to work. [ref. https://github.com/hyperledger/indy-hipe/pull/55 ].","username":"pknowles","ts":"2018-12-16T22:13:28.312Z"}
{"msg":"@mtfk and I cracked the *Overlays* data architecture model early yesterday morning. The HIPE will be going in within the next couple of weeks for review. A couple of important pieces that we will subsequently be looking at are: (i.) a *pii_attributes schema object* to allow the issuer to flag sensitive data according to the *Blinding Identity Taxonomy (BIT)* as we start to onboard. That is the Issuer's tool for flagging sensitive schema elements. On the Holder side, sensitive data can be screened courtesy of a *sensitive overlay* which is not tied to any schema. (ii.) The second interesting piece will be determining attributes to be defined in a *data consent schema* which can then become a coupling object. The exact elements will ultimately be determined by legal/tech requirements and will obviously include capture capability for @janl 's consent model to work. [ref. https://github.com/hyperledger/indy-hipe/pull/55 ].","username":"pknowles","ts":"2018-12-16T22:13:28.312Z"}
{"msg":"@mtfk and I cracked the *Overlays* data architecture model early yesterday morning. The HIPE will be going in within the next couple of weeks for review. A couple of important pieces that we will subsequently be looking at are: (i.) a *pii_attributes schema object* to allow the issuer to flag sensitive data according to the *Blinding Identity Taxonomy (BIT)* as we start to onboard. That is the Issuer's tool for flagging sensitive schema elements. On the Holder side, sensitive data can be screened courtesy of a *sensitive overlay* which is not tied to any schema. (ii.) The second interesting piece will be determining attributes to be defined in a *data consent schema* which can then become a coupling object. The exact attributes will ultimately be determined by legal/tech requirements and will obviously include capture capability for @janl 's consent model to work. [ref. https://github.com/hyperledger/indy-hipe/pull/55 ].","username":"pknowles","ts":"2018-12-16T22:13:28.312Z"}
{"msg":"BTW, that alignment question is happening in the # indy channel right now. Keep your eye on that discussion!","username":"pknowles","ts":"2018-12-16T22:21:47.462Z"}
{"msg":"BTW, that alignment question is happening in the #indy indy channel right now. Keep your eye on that discussion!","username":"pknowles","ts":"2018-12-16T22:21:47.462Z"}
{"msg":"BTW, that alignment question is happening in the #indy channel right now. Keep your eye on that discussion!","username":"pknowles","ts":"2018-12-16T22:21:47.462Z"}
{"msg":"BTW, that alignment discussion is happening in the #indy channel right now. @brentzundel and @kenebert , keep your eye on that one!","username":"pknowles","ts":"2018-12-16T22:21:47.462Z"}
{"msg":"That alignment discussion is happening in the #indy channel right now. @brentzundel and @kenebert , keep your eye on that one!","username":"pknowles","ts":"2018-12-16T22:21:47.462Z"}
{"msg":"The discussion happening in the #indy channel right now is an important handshake. @brentzundel and @kenebert , keep your eye on that one!","username":"pknowles","ts":"2018-12-16T22:21:47.462Z"}
{"msg":"The discussion happening in the #indy channel right now is an important handshake. @brentzundel and @kenebert , keep your eye on that one too!","username":"pknowles","ts":"2018-12-16T22:21:47.462Z"}
{"msg":"The discussion happening in the #indy channel right now is an important handshake. @brentzundel and @kenebert , keep your eye on that discussion too!","username":"pknowles","ts":"2018-12-16T22:21:47.462Z"}
{"msg":"The final *Semantics WG* meeting of the year will take place today, *Tuesday, December 18th*. Anyone is welcome to join the call.\n\nThe call provides an opportunity for Hyperledger Indy community members to discuss data capture and semantics. \n\nHere is the agenda and dial-in information for today's meeting ... \n\nMeeting: Semantics Working Group\nDate: Tuesday, 18th December, 2018\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: Paul Knowles\n\nAgenda:\n• Quick round of participant introductions (Open) - 5 mins\n• Takeaways from Hyperledger Global Forum - 10 mins\n• Possibility of ZK-specific Overlays - 10 mins\n* Tools to capture sensitive data - 10 mins\n* When identity meets semantics - 10 mins\n* Consent Schema Attributes - 10 mins\n- Reference - https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt\n* Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2018-12-18T01:55:13.935Z"}
{"msg":"The final *Semantics WG* meeting of the year will take place today, *Tuesday, December 18th*. \n\nThese calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nHere is the agenda and dial-in information for today's meeting ... \n\nMeeting: Semantics Working Group\nDate: Tuesday, 18th December, 2018\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: Paul Knowles\n\nAgenda:\n• Quick round of participant introductions (Open) - 5 mins\n• Takeaways from Hyperledger Global Forum - 10 mins\n* Overlays architecture - 10 mins\n• Possibility of ZK-specific Overlays - 10 mins\n* Tools to capture sensitive data - 10 mins\n* When identity meets semantics - 10 mins\n* Consent Schema attributes - 10 mins\n- Reference - https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt\n* Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2018-12-18T02:04:52.313Z"}
{"msg":"The agenda, video, notes, etc. from today's *Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, December 18th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2018-12-18T19:56:09.261Z"}
{"msg":"The agenda, video, notes, etc. from today's *Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, January 8th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2018-12-18T19:56:56.040Z"}
{"msg":"Has joined the channel.","username":"josh.hill","ts":"2018-12-19T20:29:56.211Z","type":"uj"}
{"msg":"*Verifiable Credentials* overview deck is now stored in the HL Indy server as a Google Doc - https://drive.google.com/drive/u/0/folders/1UxLLugRQKuV8Mdvv_X9Y6ty4szSi5ZNU?ogsrc=32","username":"pknowles","ts":"2018-12-22T06:45:49.007Z"}
{"msg":"*Verifiable Credentials* overview deck is now stored on the HL Indy server as a Google Doc - https://drive.google.com/drive/u/0/folders/1UxLLugRQKuV8Mdvv_X9Y6ty4szSi5ZNU?ogsrc=32","username":"pknowles","ts":"2018-12-22T06:45:49.007Z"}
{"msg":"Has joined the channel.","username":"infominer33","ts":"2018-12-23T22:14:04.442Z","type":"uj"}
{"msg":"Has joined the channel.","username":"andrewtan","ts":"2018-12-26T01:25:06.964Z","type":"uj"}
{"msg":"Has joined the channel.","username":"mahesh_rao","ts":"2018-12-27T20:41:53.503Z","type":"uj"}
{"msg":"In order to receive *Semantics WG call* calendar invites, please add your contact details to the following distribution list. https://docs.google.com/document/d/1NL36ZIksk4DmquRNvxpyZugWyjqCYa6n20FMzUnf-fY/edit?usp=sharing","username":"pknowles","ts":"2018-12-29T13:57:16.335Z"}
{"msg":"In order to receive *Semantics WG call calendar invites*, please add your contact details to the following distribution list. https://docs.google.com/document/d/1NL36ZIksk4DmquRNvxpyZugWyjqCYa6n20FMzUnf-fY/edit?usp=sharing","username":"pknowles","ts":"2018-12-29T13:57:16.335Z"}
{"msg":"In order to receive *Indy Semantics WG call calendar invites*, please add your contact details to the following distribution list. https://docs.google.com/document/d/1NL36ZIksk4DmquRNvxpyZugWyjqCYa6n20FMzUnf-fY/edit?usp=sharing","username":"pknowles","ts":"2018-12-29T13:59:17.961Z"}
{"msg":"In order to receive *Indy Semantics WG call calendar invites*, please add your contact details to the following distribution list. https://docs.google.com/document/d/1NL36ZIksk4DmquRNvxpyZugWyjqCYa6n20FMzUnf-fY/edit?usp=sharing","username":"pknowles","ts":"2018-12-29T13:59:49.248Z"}
{"msg":"In order to receive *Indy Semantics WG calendar invites*, please add your contact details to the following distribution list. https://docs.google.com/document/d/1NL36ZIksk4DmquRNvxpyZugWyjqCYa6n20FMzUnf-fY/edit?usp=sharing","username":"pknowles","ts":"2018-12-29T13:59:49.248Z"}
{"msg":"I've been heavily researching *industry classification standards* for the past 14 months and have finally settled on a proposed implementation solution to better improve data object indexing and searchability within the Hyperledger Indy ecosystem. My proposal is to utilise two publicly available classification standards for: (i.) *Global Industries* and (ii.) *New Economies*. I've stored the two ontologies, *GICS* (Global Industry Classification Standard) and *NECS* (New Economy Classification Standard) in the following HL Indy shared area. This topic will be further discussed during the Semantics WG call on January 8th. https://drive.google.com/drive/u/0/folders/1uRBKIPT1DA838wTGStYhfj0CKqBKq1rV?ogsrc=32","username":"pknowles","ts":"2018-12-31T11:34:58.609Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=mCrp7aomq36xSLqqa) Perhaps these classifications will be useful classifying Actors and Things (https://hyperonomy.com/2018/12/21/decentralized-identifiers-dids-architecture-reference-model-arm/) for my proposed subledger feature (https://www.cliffsnotes.com/study-guides/accounting/accounting-principles-i/subsidiary-ledgers-and-special-journals/subsidiary-ledgers) in the Trusted Digital Assistant (https://www.linkedin.com/feed/update/urn:li:activity:6479972559323484162).","username":"mwherman2000","ts":"2018-12-31T14:46:18.614Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=mCrp7aomq36xSLqqa","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=mCrp7aomq36xSLqqa","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=mCrp7aomq36xSLqqa) Perhaps these classifications will be useful for classifying Actors and Things (https://hyperonomy.com/2018/12/21/decentralized-identifiers-dids-architecture-reference-model-arm/) for my proposed subledger feature (https://www.cliffsnotes.com/study-guides/accounting/accounting-principles-i/subsidiary-ledgers-and-special-journals/subsidiary-ledgers) in the Trusted Digital Assistant (https://www.linkedin.com/feed/update/urn:li:activity:6479972559323484162).","username":"mwherman2000","ts":"2018-12-31T14:46:18.614Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=mCrp7aomq36xSLqqa","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=mCrp7aomq36xSLqqa","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=mCrp7aomq36xSLqqa) Perhaps these classifications will be useful for classifying Actors and Things (https://hyperonomy.com/2018/12/21/decentralized-identifiers-dids-architecture-reference-model-arm/) for my proposed subledger feature (https://www.cliffsnotes.com/study-guides/accounting/accounting-principles-i/subsidiary-ledgers-and-special-journals/subsidiary-ledgers) in the Trusted Digital Assistant `(https://www.linkedin.com/feed/update/urn:li:activity:6479972559323484162)`.","username":"mwherman2000","ts":"2018-12-31T14:46:18.614Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=mCrp7aomq36xSLqqa","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=mCrp7aomq36xSLqqa","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=mCrp7aomq36xSLqqa) Perhaps these classifications will be useful for classifying Actors and Things (https://hyperonomy.com/2018/12/21/decentralized-identifiers-dids-architecture-reference-model-arm/) for my proposed subledger feature (https://www.cliffsnotes.com/study-guides/accounting/accounting-principles-i/subsidiary-ledgers-and-special-journals/subsidiary-ledgers) in the [Trusted Digital Assistant](https://www.linkedin.com/feed/update/urn:li:activity:6479972559323484162).","username":"mwherman2000","ts":"2018-12-31T14:46:18.614Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=mCrp7aomq36xSLqqa","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=mCrp7aomq36xSLqqa","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=mCrp7aomq36xSLqqa) Perhaps these classifications will be useful for classifying Actors and Things (https://hyperonomy.com/2018/12/21/decentralized-identifiers-dids-architecture-reference-model-arm/) for my proposed subledger feature (https://www.cliffsnotes.com/study-guides/accounting/accounting-principles-i/subsidiary-ledgers-and-special-journals/subsidiary-ledgers) in the [Trusted Digital Assistant](https://www.linkedin.com/feed/update/urn:li:activity:6479972559323484162). ([click](https://www.linkedin.com/feed/update/urn:li:activity:6479972559323484162))","username":"mwherman2000","ts":"2018-12-31T14:46:18.614Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=mCrp7aomq36xSLqqa","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=mCrp7aomq36xSLqqa","remote":true,"fileId":null,"fileName":null}]}
{"msg":"","username":"mwherman2000","ts":"2018-12-31T15:01:32.184Z","attachments":[{"type":"file","title":"DID Logical Architecture v0.11.png","title_link":"/file-upload/LGbimpcdKBgMzhx8Y/DID%20Logical%20Architecture%20v0.11.png","image_url":"/file-upload/LGbimpcdKBgMzhx8Y/DID%20Logical%20Architecture%20v0.11.png","image_type":"image/png","image_size":115665,"url":"/file-upload/LGbimpcdKBgMzhx8Y/DID%20Logical%20Architecture%20v0.11.png","remote":false,"fileId":"LGbimpcdKBgMzhx8Y","fileName":"DID Logical Architecture v0.11.png"}]}
{"msg":"Following valuable input from @danielhardman, I've started early work on a *data consent schema* build proposal detailing the necessary attributes required for data retention/revocation transactions as described in @janl 's _Consent Receipt model_ [https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt] or that a person might rightly impose before they are willing to give consent for the use of requested data. I've stored the early drafts in the following HL Indy shared area. This topic will be further discussed during the Semantics WG call on January 8th. https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb?ogsrc=32","username":"pknowles","ts":"2019-01-01T09:11:20.184Z"}
{"msg":"Following valuable input from @danielhardman, I've started early work on a *data consent schema* build proposal detailing the necessary attributes required for data retention/revocation transactions as described in @janl 's _Consent Receipt model_ [https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt ] or that a person might rightly impose before they are willing to give consent for the use of requested data. I've stored the early drafts in the following HL Indy shared area. This topic will be further discussed during the Semantics WG call on January 8th. https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb?ogsrc=32","username":"pknowles","ts":"2019-01-01T09:11:20.184Z"}
{"msg":"Has joined the channel.","username":"ashokkj","ts":"2019-01-02T02:46:54.261Z","type":"uj"}
{"msg":"Has joined the channel.","username":"xadhoom76","ts":"2019-01-03T11:18:56.574Z","type":"uj"}
{"msg":"Home for all Hyperledger Indy data capture and semantics discussions including schema bases and overlays","username":"pknowles","ts":"2019-01-03T12:17:24.899Z","type":"room_changed_topic"}
{"msg":"As of late last night, a couple of new elements have been added to the *Blinding Identity Taxonomy (BIT)*. Updated version via link. https://drive.google.com/drive/u/0/folders/1gSD1b70OySIUKNOQTSbQ7khq9oy1V8UP?ogsrc=32","username":"pknowles","ts":"2019-01-04T11:22:06.988Z"}
{"msg":"Following initial review from @TomWeiss (Thanks, Tom!), we've added a new compulsory free form text attribute into the *Data Consent schema base* called (for want of a better name) `Use-Case-Description`. The point here is that legally when we share our _PII_ we are only sharing it for specific use cases. _PII_ can't be shared with consent for \"all use cases\", only for specific ones. Under GDPR, consumers have to explicitly opt-in to each use case. It's a key part of consent. If we're clever, we might be able to do some machine learning on that free form text attribute to help categorise use cases in an upgraded version further down the road. For now, it certainly addresses the issue without overcomplicating. Updated version via link. https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb?ogsrc=32","username":"pknowles","ts":"2019-01-04T12:00:12.678Z"}
{"msg":"Following initial review from @TomWeiss (Thanks, Tom!), we've added a new compulsory free form text attribute into the *Data Consent schema base* called (for want of a better name) `Use-Case-Description`. The point here is that legally when we share our _PII_ we are only sharing it for specific use cases. Under GDPR, consumers have to explicitly opt-in to each use case. It's a key part of consent. If we're clever, we might be able to do some machine learning on that free form text attribute to help categorise use cases in an upgraded version further down the road. For now, it certainly addresses the issue without overcomplicating. Updated version via link. https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb?ogsrc=32","username":"pknowles","ts":"2019-01-04T12:00:12.678Z"}
{"msg":"Following initial review from @TomWeiss (Thanks, Tom!), we've added a new compulsory free form text attribute into the *Data Consent schema base* called (for want of a better name) `Use-Case-Description`. The point here is that legally when we share our _PII_ , we are only sharing it for specific use cases. Under GDPR, consumers have to explicitly opt-in to each use case. It's a key part of consent. If we're clever, we might be able to do some machine learning on that free form text attribute to help categorise use cases in an upgraded version further down the road. For now, it certainly addresses the issue without overcomplicating. Updated version via link. https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb?ogsrc=32","username":"pknowles","ts":"2019-01-04T12:00:12.678Z"}
{"msg":"Following initial review from @TomWeiss (Thanks, Tom!), we've added a new compulsory free form text attribute into the *Data Consent* schema base called (for want of a better name) `Use-Case-Description`. The point here is that legally when we share our _PII_ , we are only sharing it for specific use cases. Under GDPR, consumers have to explicitly opt-in to each use case. It's a key part of consent. If we're clever, we might be able to do some machine learning on that free form text attribute to help categorise use cases in an upgraded version further down the road. For now, it certainly addresses the issue without overcomplicating. Updated version via link. https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb?ogsrc=32","username":"pknowles","ts":"2019-01-04T12:00:12.678Z"}
{"msg":"Following initial review from @TomWeiss (Thanks, Tom!), we've added a new compulsory free form text attribute into the *Data Consent* _schema base_ called (for want of a better name) `Use-Case-Description`. The point here is that legally when we share our _PII_ , we are only sharing it for specific use cases. Under GDPR, consumers have to explicitly opt-in to each use case. It's a key part of consent. If we're clever, we might be able to do some machine learning on that free form text attribute to help categorise use cases in an upgraded version further down the road. For now, it certainly addresses the issue without overcomplicating. Updated version via link. https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb?ogsrc=32","username":"pknowles","ts":"2019-01-04T12:00:12.678Z"}
{"msg":"Following initial review from @TomWeiss @tom_weiss (Thanks, Tom!), we've added a new compulsory free form text attribute into the *Data Consent* _schema base_ called (for want of a better name) `Use-Case-Description`. The point here is that legally when we share our _PII_ , we are only sharing it for specific use cases. Under GDPR, consumers have to explicitly opt-in to each use case. It's a key part of consent. If we're clever, we might be able to do some machine learning on that free form text attribute to help categorise use cases in an upgraded version further down the road. For now, it certainly addresses the issue without overcomplicating. Updated version via link. https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb?ogsrc=32","username":"pknowles","ts":"2019-01-04T12:00:12.678Z"}
{"msg":"Following initial review from @tom_weiss (Thanks, Tom!), we've added a new compulsory free form text attribute into the *Data Consent* _schema base_ called (for want of a better name) `Use-Case-Description`. The point here is that legally when we share our _PII_ , we are only sharing it for specific use cases. Under GDPR, consumers have to explicitly opt-in to each use case. It's a key part of consent. If we're clever, we might be able to do some machine learning on that free form text attribute to help categorise use cases in an upgraded version further down the road. For now, it certainly addresses the issue without overcomplicating. Updated version via link. https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb?ogsrc=32","username":"pknowles","ts":"2019-01-04T12:00:12.678Z"}
{"msg":"This is my actually account","username":"tom_weiss","ts":"2019-01-04T12:49:49.628Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=mBt5hlx4LDl6SARJPw) @tom_weiss Cool. I've requested for @TomWeiss to be deleted.","username":"pknowles","ts":"2019-01-04T12:56:32.019Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=mBt5hlx4LDl6SARJPw","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=mBt5hlx4LDl6SARJPw","remote":true,"fileId":null,"fileName":null}]}
{"msg":"The first *Indy Semantics WG* meeting of the year takes place on *Tuesday, January 8th*. \n\nThese calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nHere is the agenda and dial-in information for Tuesday's meeting ... \n\nMeeting: Semantics Working Group\nDate: Tuesday, 8th January, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: Paul Knowles\n\nAgenda:\n• Introductions (Open) - 5 mins\n• Industry classification standards - 35 mins\n• Consent Schema attributes - 20 mins\n- Reference - https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt\n* Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-01-06T08:32:58.001Z"}
{"msg":"The first *Indy Semantics WG* meeting of 2019 takes place on *Tuesday, January 8th*. \n\nThese calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nHere is the agenda and dial-in information for Tuesday's meeting ... \n\nMeeting: Semantics Working Group\nDate: Tuesday, 8th January, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: Paul Knowles\n\nAgenda:\n• Introductions (Open) - 5 mins\n• Industry classification standards / GICS and NECS ontologies - 30 mins\n- Reference - https://drive.google.com/drive/u/0/folders/1uRBKIPT1DA838wTGStYhfj0CKqBKq1rV?ogsrc=32 \n• Consent Schema attributes - 20 mins\n- Reference 1 - https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb?ogsrc=32 \n- Reference 2 - https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-01-06T08:39:16.464Z"}
{"msg":"The first *Indy Semantics WG* meeting of 2019 takes place on *Tuesday, January 8th*. \n\nThese calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nHere is the agenda and dial-in information for Tuesday's meeting ... \n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 8th January, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: Paul Knowles\n\nAgenda:\n• Introductions (Open) - 5 mins\n• Industry classification standards / GICS and NECS ontologies - 30 mins\n- Reference - https://drive.google.com/drive/u/0/folders/1uRBKIPT1DA838wTGStYhfj0CKqBKq1rV?ogsrc=32 \n• Consent Schema attributes - 20 mins\n- Reference 1 - https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb?ogsrc=32 \n- Reference 2 - https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-01-06T08:39:16.464Z"}
{"msg":"The first *Indy Semantics WG* meeting of 2019 takes place on *Tuesday, January 8th*. \n\nThese calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nHere is the agenda and dial-in information for Tuesday's meeting ... \n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 8th January, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: Paul Knowles\n\nAgenda:\n• Introductions (Open) - 5 mins\n• Industry classification standards / GICS and NECS ontologies - 30 mins\n- Reference - https://drive.google.com/drive/u/0/folders/1uRBKIPT1DA838wTGStYhfj0CKqBKq1rV?ogsrc=32 \n• Data Consent schema base attributes - 20 mins\n- Reference 1 - https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb?ogsrc=32 \n- Reference 2 - https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-01-06T08:39:16.464Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=n8Fe2YBZqjmfp62ip) I just received the following message from @apoikola on the MyData Slack channel. Jogi's suggestions are always well thought through so we should consider the following comment during Tuesday's WG meeting … \n\n\"The name of Kantara’s group ”Consent *and* Information Sharing” has two sides. My practical understanding is that consent as *one of the legal bases* for data prosessing under GDPR is not very popular, organisations do everything possible to avoid consent.\n\n*1#* One strategy is: ”let’s make consent so easy and smooth so that it becomes more popular”.\n\n*2#* Other strategy would be to cover all legal bases in wider information sharing framework and hope that transparency and individual’s control over their data can be achieved also in cases when consent is not used.\n\nPersonally I used to be proponent on nr. 1, but lately I have been shifting more towards 2.\n\nTherefore my suggestion would be to make the schema ”legal base agnostic” technical means to capture the attributes and conditions related to data sharing.\"","username":"pknowles","ts":"2019-01-06T11:27:50.280Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=n8Fe2YBZqjmfp62ip","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=n8Fe2YBZqjmfp62ip","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=n8Fe2YBZqjmfp62ip) I just received the following message from @apoikola on the MyData Slack channel. Jogi's suggestions are always well thought through so we should consider the following comment during Tuesday's WG call … \n\n\"The name of Kantara’s group ”Consent *and* Information Sharing” has two sides. My practical understanding is that consent as *one of the legal bases* for data prosessing under GDPR is not very popular, organisations do everything possible to avoid consent.\n\n*1#* One strategy is: ”let’s make consent so easy and smooth so that it becomes more popular”.\n\n*2#* Other strategy would be to cover all legal bases in wider information sharing framework and hope that transparency and individual’s control over their data can be achieved also in cases when consent is not used.\n\nPersonally I used to be proponent on nr. 1, but lately I have been shifting more towards 2.\n\nTherefore my suggestion would be to make the schema ”legal base agnostic” technical means to capture the attributes and conditions related to data sharing.\"","username":"pknowles","ts":"2019-01-06T11:27:50.280Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=n8Fe2YBZqjmfp62ip","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=n8Fe2YBZqjmfp62ip","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=n8Fe2YBZqjmfp62ip) I just received the following message from @apoikola on the MyData Slack channel. Jogi's suggestions are always well conceived so we should consider the following comment during Tuesday's WG call … \n\n\"The name of Kantara’s group ”Consent *and* Information Sharing” has two sides. My practical understanding is that consent as *one of the legal bases* for data prosessing under GDPR is not very popular, organisations do everything possible to avoid consent.\n\n*1#* One strategy is: ”let’s make consent so easy and smooth so that it becomes more popular”.\n\n*2#* Other strategy would be to cover all legal bases in wider information sharing framework and hope that transparency and individual’s control over their data can be achieved also in cases when consent is not used.\n\nPersonally I used to be proponent on nr. 1, but lately I have been shifting more towards 2.\n\nTherefore my suggestion would be to make the schema ”legal base agnostic” technical means to capture the attributes and conditions related to data sharing.\"","username":"pknowles","ts":"2019-01-06T11:27:50.280Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=n8Fe2YBZqjmfp62ip","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=n8Fe2YBZqjmfp62ip","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=n8Fe2YBZqjmfp62ip) I just received the following message from @apoikola on the MyData Slack channel. Jogi's suggestions are always well conceived so we should consider the following comment during Tuesday's WG call … \n\n\"The name of Kantara’s group ”Consent *and* Information Sharing” has two sides. My practical understanding is that consent as *one of the legal bases* for data processing under GDPR is not very popular, organisations do everything possible to avoid consent.\n\n*1#* One strategy is: ”let’s make consent so easy and smooth so that it becomes more popular”.\n\n*2#* Other strategy would be to cover all legal bases in wider information sharing framework and hope that transparency and individual’s control over their data can be achieved also in cases when consent is not used.\n\nPersonally I used to be proponent on nr. 1, but lately I have been shifting more towards 2.\n\nTherefore my suggestion would be to make the schema ”legal base agnostic” technical means to capture the attributes and conditions related to data sharing.\"","username":"pknowles","ts":"2019-01-06T11:27:50.280Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=n8Fe2YBZqjmfp62ip","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=n8Fe2YBZqjmfp62ip","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=n8Fe2YBZqjmfp62ip) I just received the following message from @apoikola on the MyData Slack channel. Jogi's suggestions are always well-conceived so we should consider the following comment during Tuesday's WG call … \n\n\"The name of Kantara’s group ”Consent *and* Information Sharing” has two sides. My practical understanding is that consent as *one of the legal bases* for data processing under GDPR is not very popular, organisations do everything possible to avoid consent.\n\n*1#* One strategy is: ”let’s make consent so easy and smooth so that it becomes more popular”.\n\n*2#* Other strategy would be to cover all legal bases in wider information sharing framework and hope that transparency and individual’s control over their data can be achieved also in cases when consent is not used.\n\nPersonally I used to be proponent on nr. 1, but lately I have been shifting more towards 2.\n\nTherefore my suggestion would be to make the schema ”legal base agnostic” technical means to capture the attributes and conditions related to data sharing.\"","username":"pknowles","ts":"2019-01-06T11:27:50.280Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=n8Fe2YBZqjmfp62ip","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=n8Fe2YBZqjmfp62ip","remote":true,"fileId":null,"fileName":null}]}
{"msg":"In order to receive *Indy Semantics WG calendar invites*, make sure you've added your contact details to the following distribution list. https://docs.google.com/document/d/1NL36ZIksk4DmquRNvxpyZugWyjqCYa6n20FMzUnf-fY/edit?usp=sharing","username":"pknowles","ts":"2019-01-07T02:19:05.095Z"}
{"msg":"Has joined the channel.","username":"jakubkoci","ts":"2019-01-07T17:54:37.779Z","type":"uj"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=gvbAB54ayFjaJsSN4) @pknowles In the Kantara CIS WG our currently-published spec is the \"Consent Receipt\" for a variety historical of reasons. We are making the transition towards a more general \"Receipt for Personal Data Processing\" which captures record-keeping details for the service provider to keep and also for the individual to keep (if they wish) - and will be applicable to any of the GDPR legal basis categories. So we are all lined up to do #2 while already covering #! (or, at least all the 'consent management' product companies are covering  it) ","username":"AndrewHughes3000","ts":"2019-01-07T23:52:45.161Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=gvbAB54ayFjaJsSN4","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=gvbAB54ayFjaJsSN4","remote":true,"fileId":null,"fileName":null}]}
{"msg":"@AndrewHughes3000 I prefer the wording - \"Receipt for Personal Data Processing\". I was just expressing to @mwherman2000 that a number of startups had tended towards data reclusion rather than adopting a more sensible approach to data sharing. \"Consent Receipt\" sounds like one of terms borne out of that reclusive mindset. \"Receipt for Personal Data Processing\" feels much more sociable! On that note, I'd be inclined to change the name of the current *data consent schema* to *PDP schema* (something along those lines anyway). Let's bring this point up in today's Semantics WG. [Cc: @mtfk ]","username":"pknowles","ts":"2019-01-08T02:46:06.538Z"}
{"msg":"@AndrewHughes3000 I definitely prefer the wording of \"Receipt for Personal Data Processing\" to \"Consent Receipt\". I was just expressing to @mwherman2000 that a number of startups had tended towards data reclusion rather than adopting a more sensible approach to data sharing. \"Consent Receipt\" sounds like one of terms borne out of that reclusive mindset. \"Receipt for Personal Data Processing\" feels much more sociable! On that note, I'd be inclined to change the name of the current *data consent schema* to *PDP schema* (something along those lines anyway). Let's bring this point up in today's Semantics WG. [Cc: @mtfk ]","username":"pknowles","ts":"2019-01-08T02:46:06.538Z"}
{"msg":"@AndrewHughes3000 I definitely prefer the wording of \"Receipt for Personal Data Processing\" to \"Consent Receipt\". I was just expressing to @mwherman2000 that a number of startups had tended towards data reclusion rather than adopting a more sensible approach to data sharing. \"Consent Receipt\" sounds like one of the terms borne out of that reclusive mindset. \"Receipt for Personal Data Processing\" feels much more sociable! On that note, I'd be inclined to change the name of the current *data consent schema* to *PDP schema* (something along those lines anyway). Let's bring this point up in today's Semantics WG. [Cc: @mtfk ]","username":"pknowles","ts":"2019-01-08T02:46:06.538Z"}
{"msg":"@AndrewHughes3000 I definitely prefer the wording of \"Receipt for Personal Data Processing\" over \"Consent Receipt\". I was just expressing to @mwherman2000 that a number of startups had tended towards data reclusion rather than adopting a more sensible approach to data sharing. \"Consent Receipt\" sounds like one of the terms borne out of that reclusive mindset. \"Receipt for Personal Data Processing\" feels much more sociable! On that note, I'd be inclined to change the name of the current *data consent schema* to *PDP schema* (something along those lines anyway). Let's bring this point up in today's Semantics WG. [Cc: @mtfk ]","username":"pknowles","ts":"2019-01-08T02:46:06.538Z"}
{"msg":"@AndrewHughes3000 I definitely prefer the wording of \"Receipt for Personal Data Processing\" over \"Consent Receipt\". I was just expressing to @mwherman2000 that a number of startups had tended towards data reclusion rather than adopting a more sensible approach to data sharing. \"Consent Receipt\" sounds like one of those terms borne out of that reclusive mindset. \"Receipt for Personal Data Processing\" feels much more sociable! On that note, I'd be inclined to change the name of the current *data consent schema* to *PDP schema* (something along those lines anyway). Let's bring this point up in today's Semantics WG. [Cc: @mtfk ]","username":"pknowles","ts":"2019-01-08T02:46:06.538Z"}
{"msg":"@AndrewHughes3000 I definitely prefer the wording of \"Receipt for Personal Data Processing\". I was just expressing to @mwherman2000 that a number of startups had tended towards data reclusion rather than adopting a more sensible approach to data sharing. \"Consent Receipt\" sounds like a term borne out of that reclusive mindset. \"Receipt for Personal Data Processing\" feels much more sociable! On that note, I'd be inclined to change the name of the current *data consent schema* to *PDP schema* (something along those lines anyway). Let's bring this point up in today's Semantics WG. [Cc: @mtfk ]","username":"pknowles","ts":"2019-01-08T02:46:06.538Z"}
{"msg":"@AndrewHughes3000 I definitely prefer the wording of \"Receipt for Personal Data Processing\". I was just expressing to @mwherman2000 that a number of startups had tended towards data reclusion rather than adopting a more sensible approach to data sharing. \"Consent Receipt\" sounds like a term borne out of that reclusive mindset. \"Receipt for Personal Data Processing\" feels much more sociable! On that note, I'd be inclined to change the name of the current *data consent schema* to *PDP schema* (or something along those lines). Let's bring this point up in today's Semantics WG [Cc: @mtfk ].","username":"pknowles","ts":"2019-01-08T02:46:06.538Z"}
{"msg":"@AndrewHughes3000 I definitely prefer the wording of \"Receipt for Personal Data Processing\". I was just expressing to @mwherman2000 that a number of startups had tended towards data reclusion rather than adopting a more sensible approach to data sharing. \"Consent Receipt\" sounds like a term borne out of that reclusive mindset. \"Receipt for Personal Data Processing\" feels much more sociable. On that note, I'd be inclined to change the name of the current *data consent schema* to *PDP schema* (or something along those lines). Let's bring this point up in today's Semantics WG [Cc: @mtfk ].","username":"pknowles","ts":"2019-01-08T02:46:06.538Z"}
{"msg":"@AndrewHughes3000 I definitely prefer the wording of \"Receipt for Personal Data Processing\". I was just expressing to @mwherman2000 that a number of startups had tended towards data reclusion rather than adopting a more sensible approach to data sharing. \"Consent Receipt\" sounds like a term borne out of that reclusive mindset. \"Receipt for Personal Data Processing\" feels much more sociable. On that note, I'd be inclined to change the name of the current *data consent schema* to *PDP schema* (or something along those lines). Let's bring this point up in today's Semantics WG call. [Cc: @mtfk @janl ]","username":"pknowles","ts":"2019-01-08T02:46:06.538Z"}
{"msg":"@AndrewHughes3000 I definitely prefer the wording of \"Receipt for Personal Data Processing\". I was just expressing to @mwherman2000 that a number of startups had tended towards data reclusion rather than adopting a more sensible approach to data sharing. \"Consent Receipt\" sounds like a term borne out of that reclusive mindset. \"Receipt for Personal Data Processing\" feels much more sociable. On that note, I'd be inclined to change the name of the current *data consent schema* to *PDP schema* (or something along those lines). Let's bring this point up in today's Semantics call. [Cc: @mtfk @janl ]","username":"pknowles","ts":"2019-01-08T02:46:06.538Z"}
{"msg":"@AndrewHughes3000 I definitely prefer the wording of \"Receipt for Personal Data Processing\". I was just expressing to @mwherman2000 that a number of startups had tended towards data reclusion rather than adopting a more sensible approach to data sharing. \"Consent Receipt\" sounds like a term borne out of that reclusive mindset. \"Receipt for Personal Data Processing\" feels much more sociable. On that note, I'd be inclined to change the name of the current *data consent schema* to *PDP schema* (or something along those lines). Let's bring this point up in today's Semantics call [Cc: @mtfk @janl ]","username":"pknowles","ts":"2019-01-08T02:46:06.538Z"}
{"msg":"@AndrewHughes3000 I definitely prefer the wording of \"Receipt for Personal Data Processing\". I was just expressing to @mwherman2000 that a number of startups had tended towards data reclusion rather than adopting a more sensible approach to data sharing. \"Consent Receipt\" sounds like a term borne out of that reclusive mindset. \"Receipt for Personal Data Processing\" feels much more socially inviting. On that note, I'd be inclined to change the name of the current *data consent schema* to *PDP schema* (or something along those lines). Let's bring this point up in today's Semantics call [Cc: @mtfk @janl ]","username":"pknowles","ts":"2019-01-08T02:46:06.538Z"}
{"msg":"@AndrewHughes3000 I definitely prefer the wording of \"Receipt for Personal Data Processing\". I was just expressing to @mwherman2000 that, since the Facebook/Cambridge Analytica fiasco, a number of startups had tended towards data reclusion rather than adopting a more sensible approach to data sharing. \"Consent Receipt\" sounds like a term borne out of that reclusive mindset. \"Receipt for Personal Data Processing\" feels much more socially inviting. On that note, I'd be inclined to change the name of the current *data consent schema* to *PDP schema* (or something along those lines). Let's bring this point up in today's Semantics call [Cc: @mtfk @janl ]","username":"pknowles","ts":"2019-01-08T02:46:06.538Z"}
{"msg":"@AndrewHughes3000 I definitely prefer the wording of \"Receipt for Personal Data Processing\". I was just expressing to @mwherman2000 that, since the Facebook/Cambridge Analytica fiasco, a number of startups had tended towards data reclusion rather than adopting a more sensible approach to data sharing. \"Consent Receipt\" sounds like a term borne out of that reclusive mindset. \"Receipt for Personal Data Processing\" feels much more socially inviting. On that note, I'd be inclined to change the name of the current *data consent schema* to *PDP schema* (or something along those lines). Let's discuss this point in today's Semantics call [Cc: @mtfk @janl ]","username":"pknowles","ts":"2019-01-08T02:46:06.538Z"}
{"msg":"@AndrewHughes3000 I definitely prefer the wording of \"Receipt for Personal Data Processing\". I was just expressing to @mwherman2000 that, since the Facebook/Cambridge Analytica fiasco, a number of startups had tended towards data reclusion rather than adopting a more sensible approach to data sharing. \"Consent Receipt\" sounds like a term borne out of that reclusive mindset. \"Receipt for Personal Data Processing\" feels much more socially inviting. On that note, I'd be inclined to change the name of the current *data consent schema* to *PDP schema* (or something along those lines). Let's discuss this in today's Semantics call [Cc: @mtfk @janl ]","username":"pknowles","ts":"2019-01-08T02:46:06.538Z"}
{"msg":"This week's *Indy Semantics WG* call starts in 10 minutes. Zoom link: https://zoom.us/j/2157245727","username":"pknowles","ts":"2019-01-08T17:48:48.540Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, January 8th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-01-08T21:48:25.398Z"}
{"msg":"The agenda, video, notes, etc. from today's *Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, January 22nd. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-01-08T21:49:48.076Z"}
{"msg":"Has joined the channel.","username":"tuckerg","ts":"2019-01-10T16:25:42.703Z","type":"uj"}
{"msg":"Following a brief discussion during Tuesday's *Semantics WG* call regarding the original *data consent schema* proposal to capture legally required attributes related to _data consent_ and the subsequent *PDP*  _[Personal Data Processing]_ *schema* to capture attributes used to define a window of access for the intended data share, we're going to prioritise the latter. The data capture provided by the *PDP schema* will allow algorithmic processes to be constructed so that data can be automatically revoked once the defined access window has been closed. It is not intended to be a construct for legal consent terms. We'll deep dive this topic on Tuesday, January 22nd during the next Semantics call.","username":"pknowles","ts":"2019-01-11T07:56:38.372Z"}
{"msg":"Following a brief discussion during Tuesday's *Semantics WG* call regarding the original *data consent schema* proposal to capture legally required attributes related to _data consent_ and the subsequent *PDP*  _[Personal Data Processing]_ *schema* to capture attributes used to define a window of access for the intended data share, we're going to prioritise the latter. The data capture provided by the *PDP schema* will allow algorithmic processes to be constructed so that data can be automatically revoked once the defined access window has been closed. It is not intended to be a construct for legal consent terms. The difference lies in the subtlety of the wording. \"Consent\" has a connotation of ownership. \"Processing\" has a connotation of mechanics. We'll deep dive this topic on Tuesday, January 22nd during the next Semantics call.","username":"pknowles","ts":"2019-01-11T07:56:38.372Z"}
{"msg":"Following a brief discussion in the _Hyperledger Indy Semantics WG_ call last week regarding the original *data consent schema* proposal to capture legally required attributes related to _data consent_ and the subsequent *PDP* _[Personal Data Processing]_ *schema* to capture attributes used to define an _access window_ for the intended data share, we've decided to prioritise the latter. The data capture provided by the *PDP schema* will allow algorithmic processes to be constructed so that data can be automatically revoked once the defined access window has been closed. It is not intended to be a construct for legal consent terms. The difference lies in the subtlety of the wording. \"Consent\" has a connotation of _ownership_ (dictated by the _Holder_). \"Processing\" has a connotation of mechanics (dictated by the _Issuer_). Thanks to @apoikola and @AndrewHughes3000 for your valuable input on this topic. We might rename it further still but, at least for now, we've isolated the piece that we wish to construct. We'll deep dive this topic on Tuesday, January 22nd during the next Semantics call.","username":"pknowles","ts":"2019-01-11T07:56:38.372Z"}
{"msg":"Following a brief discussion in the *Semantics WG* call last week regarding the original *data consent schema* proposal to capture legally required attributes related to _data consent_ and the subsequent *PDP* _[Personal Data Processing]_ *schema* to capture attributes used to define an _access window_ for the intended data share, we've decided to prioritise the latter. The data capture provided by the *PDP schema* will allow algorithmic processes to be constructed so that data can be automatically revoked once the defined access window has been closed. It is not intended to be a construct for legal consent terms. The difference lies in the subtlety of the wording. \"Consent\" has a connotation of _ownership_ (dictated by the _Holder_). \"Processing\" has a connotation of mechanics (dictated by the _Issuer_). Thanks to @apoikola and @AndrewHughes3000 for your valuable input on this topic. We might rename it further still but, at least for now, we've isolated the piece that we wish to construct. We'll deep dive this topic on Tuesday, January 22nd during the next Semantics call.","username":"pknowles","ts":"2019-01-11T07:56:38.372Z"}
{"msg":"Following a brief discussion in the *Semantics WG* call last week regarding the original *data consent schema* proposal to capture legally required attributes related to _data consent_ and the subsequent *PDP* _[Personal Data Processing]_ *schema* to capture attributes used to define an _access window_ for the intended data share, we've decided to prioritise the latter. The data capture provided by the *PDP schema* will allow algorithmic processes to be constructed so that data can be automatically revoked once the defined access window has been closed. It is not intended to be a construct for legal consent terms. The difference lies in the subtlety of the wording. \"Consent\" has a connotation of _ownership_ (dictated by the _Holder_). \"Processing\" has a connotation of mechanics (dictated by the _Issuer_). Thanks to @apoikola and @AndrewHughes3000 for your valuable input on this topic. We might rename it further still but, at least for now, we've isolated the piece that we wish to construct. We'll deep dive this topic on Tuesday, January 22nd during the next Semantics call. [Cc: @janl ]","username":"pknowles","ts":"2019-01-11T07:56:38.372Z"}
{"msg":"Following a brief discussion in the *Semantics WG* call last week regarding the original *data consent schema* proposal to capture legally required attributes related to _data consent_ and the subsequent *PDP* _[Personal Data Processing]_ *schema* to capture attributes used to define an _access window_ for the intended data share, we've decided to prioritise the latter. The data capture provided by the *PDP schema* will allow algorithmic processes to be constructed so that data can be automatically revoked once the defined access window has been closed. It is not intended to be a construct for legal consent terms. The difference lies in the subtlety of the wording. \"Consent\" has a connotation of _ownership_ (dictated by the _Holder_). \"Processing\" has a connotation of mechanics (dictated by the _Issuer_). Thanks to @apoikola and @AndrewHughes3000 for your valuable input on this topic. We might rename it further still but, at least for now, we've isolated the piece that we wish to construct. We'll deep dive this topic on Tuesday, January 22nd during the next Semantics call. [Cc: @janl @harrihoo ]","username":"pknowles","ts":"2019-01-11T07:56:38.372Z"}
{"msg":"Following a brief discussion in the *Semantics WG* call last week regarding the original *data consent schema* proposal to capture legally required attributes related to _data consent_ and the subsequent *PDP* _[Personal Data Processing]_ *schema* to capture attributes used to define an _access window_ for the intended data share, we've decided to prioritise the latter. The data capture provided by the *PDP schema* will allow algorithmic processes to be constructed so that data can be automatically revoked once the defined access window has been closed. It is not intended to be a construct for legal consent terms. The difference lies in the subtlety of the wording. \"Consent\" has a connotation of _ownership_ (dictated by the _Holder_). \"Processing\" has a connotation of _mechanics_ (dictated by the _Issuer_). Thanks to @apoikola and @AndrewHughes3000 for your valuable input on this topic. We might rename it further still but, at least for now, we've isolated the piece that we wish to construct. We'll deep dive this topic on Tuesday, January 22nd during the next Semantics call. [Cc: @janl @harrihoo ]","username":"pknowles","ts":"2019-01-11T07:56:38.372Z"}
{"msg":"Re *industry classification codes*, CSV versions of the *GICS* _[Global Industry Classification Standard]_ and *NECS* *[New Economy Classification Standard]* ontologies have been uploaded to the following HL Indy shared area. https://drive.google.com/drive/u/0/folders/1uRBKIPT1DA838wTGStYhfj0CKqBKq1rV?ogsrc=32 ","username":"pknowles","ts":"2019-01-12T04:06:51.378Z"}
{"msg":"Re *industry classification codes*, CSV versions of the *GICS* _[Global Industry Classification Standard]_ and *NECS* _[New Economy Classification Standard]_ ontologies have been uploaded to the following HL Indy shared area. https://drive.google.com/drive/u/0/folders/1uRBKIPT1DA838wTGStYhfj0CKqBKq1rV?ogsrc=32 ","username":"pknowles","ts":"2019-01-12T04:06:51.378Z"}
{"msg":"Has joined the channel.","username":"ardagumusalan","ts":"2019-01-15T21:20:55.613Z","type":"uj"}
{"msg":"Hi everyone. Are the community meetings held fixed times every week? If so when will be the next one?","username":"ardagumusalan","ts":"2019-01-15T21:24:20.214Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=y2GQ67SBy54YtqZa9) @ardagumusalan The *Indy Semantics WG* calls take place bi-weekly on Tuesdays at 6.00pm - 7.15pm GMT. The next one is on Tuesday, January 22nd. In order to receive *Semantics WG calendar invites*, please add your contact details to the following distribution list. https://docs.google.com/document/d/1NL36ZIksk4DmquRNvxpyZugWyjqCYa6n20FMzUnf-fY/edit?usp=sharing","username":"pknowles","ts":"2019-01-15T22:07:46.475Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=y2GQ67SBy54YtqZa9","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=y2GQ67SBy54YtqZa9","remote":true,"fileId":null,"fileName":null}]}
{"msg":"The *Indy Semantics WG* calls have now been added to the *Hyperledger community calendar* (Thanks, @Sean_Bohan !!!). Here is the :calendar: link. https://calendar.google.com/calendar/embed?mode=AGENDA&src=linuxfoundation.org_nf9u64g9k9rvd9f8vp4vur23b0%40group.calendar.google.com&ctz=UTC","username":"pknowles","ts":"2019-01-16T22:56:16.756Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* meeting. \n\nThese calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 22nd January, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: Paul Knowles\n\nAgenda:\n• Introductions (Open) - 5 mins\n• Industry classification standards / GICS and NECS ontologies - 10 mins\n- Reference - https://drive.google.com/drive/u/0/folders/1uRBKIPT1DA838wTGStYhfj0CKqBKq1rV?ogsrc=32 \n• Data Consent schema base attributes - 20 mins\n- Reference 1 - https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb?ogsrc=32 \n- Reference 2 - https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-01-22T05:19:57.364Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 22nd January, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: Paul Knowles\n\nAgenda:\n• Introductions (Open) - 5 mins\n• @janl ’s “Consent Receipt” model (incl. data revocation) - 15 mins\n• How PDP (Personal Data Processing) schema base attributes relate to that model - 20 mins\n- Reference - https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb\n• Overlays required for data extraction (@wip-abramson ) - 15 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-01-22T05:32:13.635Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 22nd January, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: Paul Knowles\n\nAgenda:\n• Introductions (Open) - 5 mins\n• @janl ’s “Consent Receipt” model (incl. data revocation) - 15 mins\n• How PDP (Personal Data Processing) schema base attributes relate to that model - 20 mins\n- Reference - https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb\n• Overlays required for data extraction ( @wip-abramson ) - 15 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-01-22T05:32:13.635Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 22nd January, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles \n\nAgenda:\n• Introductions (Open) - 5 mins\n• @janl ’s “Consent Receipt” model (incl. data revocation) - 15 mins\n• How PDP (Personal Data Processing) schema base attributes relate to that model - 20 mins\n- Reference - https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb\n• Overlays required for data extraction ( @wip-abramson ) - 15 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-01-22T05:32:13.635Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 22nd January, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles \n\nAgenda:\n• Introductions (Open) - 5 mins\n• @janl ’s “Consent Receipt” model (incl. data revocation) - 15 mins\n- Reference - https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt (Note: Not the latest update)\n• How PDP (Personal Data Processing) schema base attributes relate to that model - 20 mins\n- Reference - https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb\n• Overlays required for data extraction ( @wip-abramson ) - 15 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-01-22T10:41:08.098Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 22nd January, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles \n\nAgenda:\n• Introductions (Open) - 5 mins\n• @janl ’s data revocation (“Consent Receipt”) model - 15 mins\n- Reference - https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt (Note: Not the latest update)\n• How PDP (Personal Data Processing) schema base attributes relate to that model - 20 mins\n- Reference - https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb\n• Overlays required for data extraction ( @wip-abramson ) - 15 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-01-22T10:41:08.098Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 22nd January, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles \n\nAgenda:\n• Introductions (Open) - 5 mins\n• @janl ’s data revocation / consent receipt model - 15 mins\n- Reference - https://github.com/JanLin/indy-hipe/tree/master/text/consent_receipt (Note: Not the latest update)\n• How PDP (Personal Data Processing) schema base attributes relate to that model - 20 mins\n- Reference - https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb\n• Overlays required for data extraction ( @wip-abramson ) - 15 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-01-22T10:41:08.098Z"}
{"msg":"This week's *Indy Semantics WG* call starts in 1 hour. Zoom link: https://zoom.us/j/2157245727","username":"pknowles","ts":"2019-01-22T17:00:19.228Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, February 5th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-01-22T21:55:44.702Z"}
{"msg":"The *Indy Semantics WG* is mentioned in this month's '_Keeping up with the Kantarians_', *Kantara Initiative*'s monthly newsletter, as we plan to align consent schemas to produce a generic Kantara-compliant \"Consent Receipt\" that can be deployed in both Distributed Ledger and traditional networks. https://t.e2ma.net/message/ziw27/nhnlvj","username":"pknowles","ts":"2019-01-22T22:18:37.039Z"}
{"msg":"The *Indy Semantics WG* is mentioned in this month's \" _Keeping up with the Kantarians_ \", *Kantara Initiative*'s monthly newsletter, as we plan to align consent schemas to produce a generic Kantara-compliant \"Consent Receipt\" that can be deployed in both Distributed Ledger and traditional networks. https://t.e2ma.net/message/ziw27/nhnlvj","username":"pknowles","ts":"2019-01-22T22:18:37.039Z"}
{"msg":"@pknowles You are relentless! Keep going!!","username":"drummondreed","ts":"2019-01-23T13:20:55.444Z"}
{"msg":"At the end of this meeting: https://www.youtube.com/watch?time_continue=67&v=0Fga1_Fz7MI schema.org is mentioned. Does it mean, support for json-ld is also part of this effort?","username":"ardagumusalan","ts":"2019-01-25T21:47:28.492Z"}
{"msg":"At the end of this meeting: https://www.youtube.com/watch?time_continue=67&v=0Fga1_Fz7MI schema.org is mentioned. Does it mean support for json-ld is also part of this effort","username":"ardagumusalan","ts":"2019-01-25T21:47:28.492Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=FdocpRhRqYe824Di6) @ardagumusalan Yes, we'll be supporting JSON-LD for the development of all Schema bases and Overlays.","username":"pknowles","ts":"2019-01-25T22:20:31.070Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=FdocpRhRqYe824Di6","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=FdocpRhRqYe824Di6","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Has joined the channel.","username":"peter.danko","ts":"2019-01-28T11:57:34.280Z","type":"uj"}
{"msg":"Has joined the channel.","username":"kdenhartog","ts":"2019-01-31T17:02:32.600Z","type":"uj"}
{"msg":"An updated version of the *Overlays Data Capture Architecture* deck has been uploaded to the following HL Indy shared area. Feel free to touch base on this channel to discuss. https://drive.google.com/drive/u/0/folders/1-Q3CBSYXlRNEvTu7XQfGo-6W5H_yyOA3","username":"pknowles","ts":"2019-01-31T19:04:20.692Z"}
{"msg":"An updated version of the *Overlays data capture architecture* deck has been uploaded to the following HL Indy shared area. Feel free to touch base on this channel to discuss contents of the document. https://drive.google.com/drive/u/0/folders/1-Q3CBSYXlRNEvTu7XQfGo-6W5H_yyOA3","username":"pknowles","ts":"2019-01-31T19:04:20.692Z"}
{"msg":"An updated version of the *Overlays data capture architecture* deck has been uploaded to the following HL Indy shared area. Feel free to touch base on this channel to discuss any contents of the document. https://drive.google.com/drive/u/0/folders/1-Q3CBSYXlRNEvTu7XQfGo-6W5H_yyOA3","username":"pknowles","ts":"2019-01-31T19:04:20.692Z"}
{"msg":"An updated version of the *Overlays data capture architecture* deck has been uploaded to the following HL Indy shared area. Feel free to touch base on this channel to discuss contents of the document. https://drive.google.com/drive/u/0/folders/1-Q3CBSYXlRNEvTu7XQfGo-6W5H_yyOA3","username":"pknowles","ts":"2019-01-31T19:04:20.692Z"}
{"msg":"An updated version of the *Overlays data capture architecture* deck has been uploaded to the following HL Indy shared area. Feel free to touch base on this channel to discuss document contents. https://drive.google.com/drive/u/0/folders/1-Q3CBSYXlRNEvTu7XQfGo-6W5H_yyOA3","username":"pknowles","ts":"2019-01-31T19:04:20.692Z"}
{"msg":"An updated version of the *Overlays data capture architecture* deck has been uploaded to the following HL Indy shared area. Feel free to touch base on this channel to discuss it's contents. https://drive.google.com/drive/u/0/folders/1-Q3CBSYXlRNEvTu7XQfGo-6W5H_yyOA3","username":"pknowles","ts":"2019-01-31T19:04:20.692Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 5th February, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Latest _Verifiable Credentials_ presentation ( @brentzundel / @kenebert ) - 15 mins\n- Reference - https://drive.google.com/drive/u/0/folders/1WDIP8t829XhBX2hq-9xBN8u2IG5k5TCO\n• How multi-layered schema constructs can enhance interoperability of Credential Definitions and ZKP requirements (Open) - 45 mins\n- Reference - https://drive.google.com/drive/u/0/folders/1Y4-YOVJW65qVg9NJZaiwBmuTEUNMY6pp\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-02-05T04:47:59.520Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 5th February, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Latest _Verifiable Credentials Schemas_ presentation ( @brentzundel / @kenebert ) - 15 mins\n- Reference - https://drive.google.com/drive/u/0/folders/1WDIP8t829XhBX2hq-9xBN8u2IG5k5TCO\n• How multi-layered schema constructs can enhance interoperability of Credential Definitions and ZKP requirements (Open) - 45 mins\n- Reference - https://drive.google.com/drive/u/0/folders/1Y4-YOVJW65qVg9NJZaiwBmuTEUNMY6pp\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-02-05T04:47:59.520Z"}
{"msg":"This week's *Indy Semantics WG* call starts in 1 hour. Zoom link: https://zoom.us/j/2157245727","username":"pknowles","ts":"2019-02-05T17:52:01.612Z"}
{"msg":"This week's *Indy Semantics WG* call starts in 10 minutes. Zoom link: https://zoom.us/j/2157245727","username":"pknowles","ts":"2019-02-05T17:52:21.281Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, February 5th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-02-05T20:24:53.164Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, February 19th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-02-05T20:25:06.778Z"}
{"msg":"Has joined the channel.","username":"jleders","ts":"2019-02-13T05:34:25.122Z","type":"uj"}
{"msg":"Has joined the channel.","username":"xaviervila","ts":"2019-02-13T09:42:54.039Z","type":"uj"}
{"msg":"Has joined the channel.","username":"dklesev","ts":"2019-02-14T11:34:53.395Z","type":"uj"}
{"msg":"The next *Indy Semantics WG* call is this coming Tuesday, February 19th @ 11am-12.15pm MT / 7pm-8.15pm CET\n\nIf you're planning to join the call, there is a bit of homework/research to be done beforehand ...  \n\nFollowing a number of calls with the technical team at *digi.me*, they're keen to investigate the possibility of integrating some of their core functionality with Hyperledger Indy. I have an integration review call with their tech team later this month and a Blockchain interoperability feasibility study site meeting in early March. For those of you in the *MyData* space, you’ll know that this could be a potentially powerful collaboration of technologies and mindsets. I’m keen to help facilitate these discussions. For an initial soft integration, I propose to approach this from a semantics perspective and then, if deemed appropriate, to delve deeper into the stack on an _as needed_ basis.\n\nFor any Indy community members planning to dial into next week’s semantics call, check out the following two links beforehand to better understand digi.me's backend services ...   \n\n(i.) A four part series ending with how digi.me do consent - https://www.youtube.com/playlist?list=PLsg6XlZAq3AJVp_439UzcMkg7Pdakzw-9\n(ii.) A further drill down at developers.digi.me \n\nDuring Tuesday night's semantics call, we’ll be discussing …\n\n1.  Taking a code fragment that would allow digi.me backend to support 3 primary functions …\n\n     *   Init connection (with appropriate credentials)\n     *   Write block of data representing a Consent Access Receipt (according to some base CAR schema, topic, identity model)\n     *   Read a block of Clinical Trial data according to the base Schema + (chosen) Overlay\n  \n2.  Discussion on lowering the bar for digi.me team to perform integration\n\n     *   They seek a fast track to demo implementation to release funding\n\n3.  Share digi.me view of how multiple overlays work and how they could normalise to a master ontology to support N x N interoperability\n\n     *   Concepts\n     *   Toolchain example\n\n4.  Constructing a mini Hyperledger Indy development team for potential interwork including a public demo\n\nHave a fabulous weekend!!!","username":"pknowles","ts":"2019-02-15T15:59:22.443Z"}
{"msg":"@all The next *Indy Semantics WG* call is this coming Tuesday, February 19th @ 11am-12.15pm MT / 7pm-8.15pm CET\n\nIf you're planning to join the call, there is a bit of homework/research to be done beforehand ...  \n\nFollowing a number of calls with the technical team at *digi.me*, they're keen to investigate the possibility of integrating some of their core functionality with Hyperledger Indy. I have an integration review call with their tech team later this month and a Blockchain interoperability feasibility study site meeting in early March. For those of you in the *MyData* space, you’ll know that this could be a potentially powerful collaboration of technologies and mindsets. I’m keen to help facilitate these discussions. For an initial soft integration, I propose to approach this from a semantics perspective and then, if deemed appropriate, to delve deeper into the stack on an _as needed_ basis.\n\nFor any Indy community members planning to dial into next week’s semantics call, check out the following two links beforehand to better understand digi.me's backend services ...   \n\n(i.) A four part series ending with how digi.me do consent - https://www.youtube.com/playlist?list=PLsg6XlZAq3AJVp_439UzcMkg7Pdakzw-9\n(ii.) A further drill down at developers.digi.me \n\nDuring Tuesday night's semantics call, we’ll be discussing …\n\n1.  Taking a code fragment that would allow digi.me backend to support 3 primary functions …\n\n     *   Init connection (with appropriate credentials)\n     *   Write block of data representing a Consent Access Receipt (according to some base CAR schema, topic, identity model)\n     *   Read a block of Clinical Trial data according to the base Schema + (chosen) Overlay\n  \n2.  Discussion on lowering the bar for digi.me team to perform integration\n\n     *   They seek a fast track to demo implementation to release funding\n\n3.  Share digi.me view of how multiple overlays work and how they could normalise to a master ontology to support N x N interoperability\n\n     *   Concepts\n     *   Toolchain example\n\n4.  Constructing a mini Hyperledger Indy development team for potential interwork including a public demo\n\nHave a fabulous weekend!!!","username":"pknowles","ts":"2019-02-15T15:59:22.443Z"}
{"msg":"@all The next *Indy Semantics WG* call is this coming Tuesday, February 19th @ 11am-12.15pm MT / 7pm-8.15pm CET\n\nIf you're planning to join the call, there is a bit of homework/research to be done beforehand ...  \n\nFollowing a number of calls with the technical team at *digi.me*, they're keen to investigate the possibility of integrating some of their core functionality with Hyperledger Indy. I have an integration review call with their tech team later this month and a Blockchain interoperability feasibility study site meeting in early March. For those of you in the *MyData* space [https://mydata.org ], you’ll know that this could be a potentially powerful collaboration of technologies and mindsets. I’m keen to help facilitate these discussions. For an initial soft integration, I propose to approach this from a semantics perspective and then, if deemed appropriate, to delve deeper into the stack on an _as needed_ basis.\n\nFor any Indy community members planning to dial into next week’s semantics call, check out the following two links beforehand to better understand digi.me's backend services ...   \n\n(i.) A four part series ending with how digi.me do consent - https://www.youtube.com/playlist?list=PLsg6XlZAq3AJVp_439UzcMkg7Pdakzw-9\n(ii.) A further drill down at developers.digi.me \n\nDuring Tuesday night's semantics call, we’ll be discussing …\n\n1.  Taking a code fragment that would allow digi.me backend to support 3 primary functions …\n\n     *   Init connection (with appropriate credentials)\n     *   Write block of data representing a Consent Access Receipt (according to some base CAR schema, topic, identity model)\n     *   Read a block of Clinical Trial data according to the base Schema + (chosen) Overlay\n  \n2.  Discussion on lowering the bar for digi.me team to perform integration\n\n     *   They seek a fast track to demo implementation to release funding\n\n3.  Share digi.me view of how multiple overlays work and how they could normalise to a master ontology to support N x N interoperability\n\n     *   Concepts\n     *   Toolchain example\n\n4.  Constructing a mini Hyperledger Indy development team for potential interwork including a public demo\n\nHave a fabulous weekend!!!","username":"pknowles","ts":"2019-02-15T15:59:22.443Z"}
{"msg":"@all The next *Indy Semantics WG* call is this coming Tuesday, February 19th @ 11am-12.15pm MT / 7pm-8.15pm CET\n\nIf you're planning to join the call, there is a bit of homework/research to be done beforehand ...  \n\nFollowing a number of calls with the technical team at *digi.me*, they're keen to investigate the possibility of integrating some of their core functionality with Hyperledger Indy. I have an integration review call with their tech team later this month and a Blockchain interoperability feasibility study site meeting in early March. For those of you in the *MyData* space [https://mydata.org ], you’ll know that this could be a potentially powerful collaboration of technologies and minds. I’m keen to help facilitate these discussions. For an initial soft integration, I propose to approach this from a semantics perspective and then, if deemed appropriate, to delve deeper into the stack on an _as needed_ basis.\n\nFor any Indy community members planning to dial into next week’s semantics call, check out the following two links beforehand to better understand digi.me's backend services ...   \n\n(i.) A four part series ending with how digi.me do consent - https://www.youtube.com/playlist?list=PLsg6XlZAq3AJVp_439UzcMkg7Pdakzw-9\n(ii.) A further drill down at developers.digi.me \n\nDuring Tuesday night's semantics call, we’ll be discussing …\n\n1.  Taking a code fragment that would allow digi.me backend to support 3 primary functions …\n\n     *   Init connection (with appropriate credentials)\n     *   Write block of data representing a Consent Access Receipt (according to some base CAR schema, topic, identity model)\n     *   Read a block of Clinical Trial data according to the base Schema + (chosen) Overlay\n  \n2.  Discussion on lowering the bar for digi.me team to perform integration\n\n     *   They seek a fast track to demo implementation to release funding\n\n3.  Share digi.me view of how multiple overlays work and how they could normalise to a master ontology to support N x N interoperability\n\n     *   Concepts\n     *   Toolchain example\n\n4.  Constructing a mini Hyperledger Indy development team for potential interwork including a public demo\n\nHave a fabulous weekend!!!","username":"pknowles","ts":"2019-02-15T15:59:22.443Z"}
{"msg":"@all The next *Indy Semantics WG* call is this coming Tuesday, February 19th @ 11am-12.15pm MT / 7pm-8.15pm CET\n\nIf you're planning to join the call, there is a bit of homework/research to be done beforehand ...  \n\nFollowing a number of calls with the technical team at *digi.me*, they're keen to investigate the possibility of integrating some of their core functionality with Hyperledger Indy. I have an integration review call with their tech team later this month and a Blockchain interoperability feasibility study site meeting in early March. For those of you in the *MyData* space [https://mydata.org ], you’ll know that this could be a potentially powerful collaboration of technologies and minds. I’m keen to help facilitate these discussions. For an initial soft integration, I propose to approach this from a semantics perspective and then, if deemed appropriate, to delve deeper into the stack on an _as needed_ basis.\n\nFor any Indy community members planning to dial into next week’s semantics call, check out the following two links beforehand to better understand digi.me's backend services ...   \n\n(i.) A four part series ending with how digi.me do consent - https://www.youtube.com/playlist?list=PLsg6XlZAq3AJVp_439UzcMkg7Pdakzw-9\n(ii.) A further drill down at developers.digi.me \n\nDuring the call, we’ll be discussing …\n\n1.  Taking a code fragment that would allow digi.me backend to support 3 primary functions …\n\n     *   Init connection (with appropriate credentials)\n     *   Write block of data representing a Consent Access Receipt (according to some base CAR schema, topic, identity model)\n     *   Read a block of Clinical Trial data according to the base Schema + (chosen) Overlay\n  \n2.  Discussion on lowering the bar for digi.me team to perform integration\n\n     *   They seek a fast track to demo implementation to release funding\n\n3.  Share digi.me view of how multiple overlays work and how they could normalise to a master ontology to support N x N interoperability\n\n     *   Concepts\n     *   Toolchain example\n\n4.  Constructing a mini Hyperledger Indy development team for potential interwork including a public demo\n\nHave a fabulous weekend!!!","username":"pknowles","ts":"2019-02-15T15:59:22.443Z"}
{"msg":"@all The next *Indy Semantics WG* call is this coming Tuesday, February 19th @ 11am-12.15pm MT / 7pm-8.15pm CET\n\nIf you're planning to join the call, there is a bit of homework/research to be done beforehand ...  \n\nFollowing a number of calls with the technical team at *digi.me*, they're keen to investigate the possibility of integrating some of their core functionality with Hyperledger Indy. I have an integration review call with their tech team later this month and a Blockchain interoperability feasibility study site meeting in early March. For those of you in the *MyData* space [https://mydata.org ], you’ll know that this could be a potentially powerful collaboration of technologies and minds. I’m keen to help facilitate these discussions. For an initial soft integration, I propose to approach this from a semantics perspective and then, if deemed appropriate, to delve deeper into the stack on an _as needed_ basis.\n\nFor any Indy community members planning to dial into next week’s semantics call, check out the following two links beforehand to better understand digi.me's backend services ...   \n\n(i.) A four part series ending with how digi.me do consent - https://www.youtube.com/playlist?list=PLsg6XlZAq3AJVp_439UzcMkg7Pdakzw-9\n(ii.) A further drill down at developers.digi.me \n\nDuring the call, we’ll be discussing …\n\n1.  Taking a code fragment that would allow digi.me backend to support 3 primary functions …\n\n     *   Init connection (with appropriate credentials)\n     *   Write block of data representing a Consent Access Receipt (according to some base CAR schema, topic, identity model)\n     *   Read a block of Clinical Trial data according to the base Schema + (chosen) Overlay\n  \n2.  Discussion on lowering the bar for digi.me team to perform integration\n\n     *   They seek a fast track to demo implementation to release funding\n\n3.  Share digi.me view of how multiple overlays work and how they could normalise to a master ontology to support N x N interoperability\n\n     *   Concepts\n     *   Toolchain example\n\n4.  Constructing a mini Hyperledger Indy development team for potential interwork including a public demo\n\nHappy reading. Have a fabulous weekend!!!","username":"pknowles","ts":"2019-02-15T15:59:22.443Z"}
{"msg":"@kdenhartog @swcurran @danielhardman @mtfk @janl @tom_weiss @nage @drummondreed @kenebert @brentzundel ^^^","username":"pknowles","ts":"2019-02-15T16:39:13.445Z"}
{"msg":"@pknowles we will have some attendance difficulties, with so many folks participating in the connect-a-thon","username":"nage","ts":"2019-02-18T18:08:30.559Z"}
{"msg":"I look forward to seeing what the group discovers","username":"nage","ts":"2019-02-18T18:09:01.728Z"}
{"msg":"Has joined the channel.","username":"aronvanammers","ts":"2019-02-18T21:06:47.853Z","type":"uj"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 19th February, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles   \n\nAgenda:\n• Introductions (Open) - 5 mins\n• How multi-layered schema constructs can enhance interoperability of Credential Definitions and ZKP requirements ( @mtfk ) - 20 mins\n- Reference - https://drive.google.com/drive/u/0/folders/1Y4-YOVJW65qVg9NJZaiwBmuTEUNMY6pp\n• Investigating the possibility of integrating some of digi.me's core functionality with Hyperledger Indy ( @pknowles ) - 30 mins\n- Reference - https://www.youtube.com/playlist?list=PLsg6XlZAq3AJVp_439UzcMkg7Pdakzw-9\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-02-19T16:49:23.798Z"}
{"msg":"This week's *Indy Semantics WG* call starts in 30 minutes. Zoom link: https://zoom.us/j/2157245727","username":"pknowles","ts":"2019-02-19T17:33:08.938Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. I've scheduled in an ad hoc *Indy Semantics WG* call for next Tuesday, February 26th so that we can slot in a missed agenda item: _How multi-layered schema constructs can enhance interoperability of Credential Definitions and ZKP requirements_ ( @mtfk ). https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-02-19T23:41:51.099Z"}
{"msg":"Has joined the channel.","username":"runiner","ts":"2019-02-22T17:37:28.323Z","type":"uj"}
{"msg":"In order to receive *Indy Semantics WG calendar invites*, make sure you've added your contact details to the following distribution list. https://docs.google.com/document/d/1NL36ZIksk4DmquRNvxpyZugWyjqCYa6n20FMzUnf-fY/edit?usp=sharing","username":"pknowles","ts":"2019-02-24T10:33:26.460Z"}
{"msg":"This week's ad hoc *Indy Semantics WG* call starts in 30 minutes. Zoom link: https://zoom.us/j/2157245727","username":"pknowles","ts":"2019-02-26T17:30:00.989Z"}
{"msg":"Repo with tool which we are working on: https://github.com/THCLab/tool\nAny contribution and feedback welcome. Open an issue directly on github if you have any concern/ideas or wishes. PR welcome :) ","username":"mtfk","ts":"2019-02-26T21:14:02.686Z"}
{"msg":"Follow-up from this mornings Semantics WG call ....what do people think of this visualization...  p.s. I had to guess where a few of the layers belong ...also did some rewording....","username":"mwherman2000","ts":"2019-02-26T21:25:59.339Z"}
{"msg":"","username":"mwherman2000","ts":"2019-02-26T21:26:11.158Z","attachments":[{"type":"file","title":"Clipboard - February 26, 2019 2:26 PM","title_link":"/file-upload/NKje8dYQ5GGj86Ftv/Clipboard%20-%20February%2026,%202019%202:26%20PM","image_url":"/file-upload/NKje8dYQ5GGj86Ftv/Clipboard%20-%20February%2026,%202019%202:26%20PM","image_type":"image/png","image_size":282517,"url":"/file-upload/NKje8dYQ5GGj86Ftv/Clipboard%20-%20February%2026,%202019%202:26%20PM","remote":false,"fileId":"NKje8dYQ5GGj86Ftv","fileName":"Clipboard - February 26, 2019 2:26 PM"}]}
{"msg":"Here's a linkable version: https://github.com/mwherman2000/indy-arm/blob/master/README.md#appendix-f---indy-overlays-architecture-reference-model-overlays-arm-","username":"mwherman2000","ts":"2019-02-26T21:38:45.491Z"}
{"msg":"The PowerPoint source can be found here: https://github.com/mwherman2000/indy-arm/tree/master/src","username":"mwherman2000","ts":"2019-02-26T21:39:48.442Z"}
{"msg":"@mwherman2000 - I'll colour-coordinate the images in the latest *Overlays data capture architecture* deck to align with the Tech / App / Bus layers as defined. I envisage those images being used in various future HIPEs so it makes sense to get the colours to line up with the layers in the rest of your ARM work. Thanks, Michael.","username":"pknowles","ts":"2019-02-26T22:06:24.517Z"}
{"msg":"@pknowles Checkout some of the wording suggestions as well ...especially the smaller text on the right side of each card.","username":"mwherman2000","ts":"2019-02-26T22:08:01.695Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=ZxeYCPamJbHY3MhZu) @mwherman2000 I certainly will. There are a few tweaks to be made. I'll take a look with fresh eyes tomorrow morning. :sleeping:","username":"pknowles","ts":"2019-02-26T22:10:57.465Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=ZxeYCPamJbHY3MhZu","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=ZxeYCPamJbHY3MhZu","remote":true,"fileId":null,"fileName":null}]}
{"msg":"The order of the cards (from bottom to top) within each color range (architectural layer) is also important.  The higher cards build or have a dependency on the ones below/","username":"mwherman2000","ts":"2019-02-26T22:12:35.078Z"}
{"msg":"The agenda, video, notes, etc. from today's ad hoc *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be next Tuesday, March 5th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32 ","username":"pknowles","ts":"2019-02-26T22:25:06.993Z"}
{"msg":"I documented the Principles I used to guide the creation of the Overlays ARM diagram: https://github.com/mwherman2000/indy-arm/blob/master/README.md#principles","username":"mwherman2000","ts":"2019-02-26T23:55:05.881Z"}
{"msg":"@mwherman2000 - The following 7 overlays have been defined for \"Issuer” use ...\n\n*Source Overlay* => to point to an external source of predefined Schema attribute definitions (e.g. HL7 FHIR, Schema 2.0, etc.);\n\n*Encode Overlay* => to define character encoding (e.g. UTF-8, ISO-8859-1, Windows-1251, Base58Check, etc.);\n\n*Entry Overlay* => to add predefined field values to Schema attributes;\n\n*Label Overlay* => to add labels to Schema attributes (incl. category labels);\n\n*Format Overlay* => to add formats (incl. field lengths) to Schema attributes;\n\n*Conditional Overlay* => to add simple conditional programming within a Schema;\n\n*Subset Overlay* => to create a Schema subset","username":"pknowles","ts":"2019-02-27T04:49:09.015Z"}
{"msg":"The only overlay defined for “Holder” use is ...\n\n*Sensitive Overlay* => to enable a Holder to flag user-defined sensitive attributes","username":"pknowles","ts":"2019-02-27T04:51:54.577Z"}
{"msg":"[Note that the _Sensitive Overlay_ is the only one not linked to a specific _Schema Base_ but rather to a _Data Vault_ within the Holder's personal device.]","username":"pknowles","ts":"2019-02-27T04:54:52.379Z"}
{"msg":"@mwherman2000 - In @mtfk 's  _Schema Base & Overlays_ tooling demo, a couple of redundant overlays made their way back in but they can be disregarded, namely the _Informational Overly_ and _Consent Overlay_","username":"pknowles","ts":"2019-02-27T05:21:58.637Z"}
{"msg":"@mwherman2000 - In @mtfk 's  _Schema Base & Overlays_ tooling demo, a couple of redundant overlays made their way back in but they can be disregarded, namely the _Informational Overly_ and _Consent Overlay_","username":"pknowles","ts":"2019-02-27T05:21:58.637Z"}
{"msg":"@mwherman2000 - In @mtfk 's  _Schema Base & Overlays_ tooling demo, a couple of redundant overlays made their way back in but they can be disregarded, namely the _Information Overly_ and _Consent Overlay_","username":"pknowles","ts":"2019-02-27T05:21:58.637Z"}
{"msg":"@mwherman2000 - In @mtfk 's  _Schema Base & Overlays_ tooling demo, a couple of redundant overlays made their way back in but they can be disregarded, namely the _Information Overlay_ and _Consent Overlay_","username":"pknowles","ts":"2019-02-27T05:21:58.637Z"}
{"msg":"@mwherman2000 - In @mtfk 's  _Schema Base & Overlays_ tooling demo, a couple of redundant overlays made their way back into the fray but they can be disregarded, namely the _Information Overlay_ and _Consent Overlay_","username":"pknowles","ts":"2019-02-27T05:21:58.637Z"}
{"msg":"@mwherman2000 - In @mtfk 's  _Schema Base & Overlays_ tooling demo, a couple of redundant overlays made their way back into the fray but they can be disregarded, namely the _Information Overlay_ and the _Consent Overlay_","username":"pknowles","ts":"2019-02-27T05:21:58.637Z"}
{"msg":"@mtfk - Can you double-check the written definition of the _Source Overlay_ , I'm not sure if that is the correct purpose. If I've got that wrong, please suggest a new definition.","username":"pknowles","ts":"2019-02-27T05:23:21.403Z"}
{"msg":"@mtfk - Can you double-check the written definition of the _Source Overlay_ ? I'm not sure if that is the correct purpose. If I've got that wrong, please suggest a new definition.","username":"pknowles","ts":"2019-02-27T05:23:21.403Z"}
{"msg":"@mtfk - Can you double-check the written definition of the *Source Overlay* ? I'm not sure if that is the correct purpose. If I've got that wrong, please suggest a new definition.","username":"pknowles","ts":"2019-02-27T05:23:21.403Z"}
{"msg":"While building the tool didn't thought much about semantics yet just copy pasted what had around but as soo  as from feature point of view will have correct flow we can review one by one and kick out those which are  ot needed.","username":"mtfk","ts":"2019-02-27T06:22:39.964Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=a08a324e-8d4a-4611-89be-aed60a0b7dc9) @mtfk I think we've done that already.","username":"pknowles","ts":"2019-02-27T07:21:09.245Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=a08a324e-8d4a-4611-89be-aed60a0b7dc9","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=a08a324e-8d4a-4611-89be-aed60a0b7dc9","remote":true,"fileId":null,"fileName":null}]}
{"msg":"@mwherman2000 @mtfk - Looking at the Overlays ARM schematic, we may be able to remove the Business Layer from the card stack. Perhaps a description of the flow might shed some light on my thinking here. As I see it, the process of using Robert's middleware tool from an Ïssuer's point of view would go something like ... \n\n(i.) According to the GICS / NECS ontologies [ https://drive.google.com/drive/u/0/folders/1uRBKIPT1DA838wTGStYhfj0CKqBKq1rV ], the Issuer would tag the current Schema building process with the lowest level GICS and/or NECS industry codes. These tags can be used for searchability purposes further downstream.; \n\n(ii.) The Issuer then builds a plethora of pre-publish schema(s) incl. _Technology Layer_ and _Application Layer_ overlays.; \n\n(iii.) The Issuer then hits a \"Publish\" button but, before the schemas are published, the build process for the _Business_ schemas (i.e. consent-related schemas) is triggered. The Schema build process for these Business schemas will allow the same level of overlay flexibility but I envisage the Schema Bases to already be locked in courtesy of an Issuer such as Kantara Initiative. The 3 consent-related schema constructs that we are/will be working on are a *PDP* (Personal Data Processing) schema, a *Generic Consent* schema and a *Specialized Consent* schema. Elements from each of these 3 constructs will ultimately be used to populate a standardized Consent Receipt (Kantara Initiative). Once the Issuer has defined these consent-related constructs, the entire suite of completed Schemas (i.e.  the \"plethora of pre-publish schema(s)\" mentioned in point (i.)) can be published. \n\nMore information on the _PDP schema_ ... https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb\n\nThese _Business Layer_ constructs would basically act as a wrapper encompassing the suite of Schemas to be published. Think of these constructs as containing metadata to define consent for all schemas contained in a .ZIP file.","username":"pknowles","ts":"2019-02-27T08:17:13.305Z"}
{"msg":"RE: Format Overlay* => to add formats (incl. field lengths) to Schema attributes;\nIs this purpose of this overlay to:\na. control presentation the values of an attribute in the user experience? (Application layer)\nb. storage/persistence of the values of an attribute? (Technology layer)\nThese are (usually) different.","username":"mwherman2000","ts":"2019-02-27T13:46:34.692Z"}
{"msg":"@pknowles RE: Perhaps a description of the flow might shed some light on my thinking here. As I see it, the process of using Robert's middleware tool from an Ïssuer's point of view would go something like ... \nWe need to separate the \"how\" from the \"what\".  The process you described is the \"how\" but the card stack diagram is intended to be a description of the \"what\" ...the architecture of the Overlay card stack.  There is an interplay between the two but they are different.","username":"mwherman2000","ts":"2019-02-27T13:51:33.332Z"}
{"msg":"@pknowles RE: Perhaps a description of the flow might shed some light on my thinking here. As I see it, the process of using Robert's middleware tool from an Ïssuer's point of view would go something like ... \nWe need to separate the \"how\" from the \"what\".  The process you described is the \"how\" but the card stack diagram is intended to be a description of the \"what\" ...the architecture of the Overlays card stack.  There is an interplay between the two but they are different.s","username":"mwherman2000","ts":"2019-02-27T13:51:33.332Z"}
{"msg":"@pknowles RE: These _Business Layer_ constructs would basically act as a wrapper encompassing the suite of Schemas to be published. Think of these constructs as containing metadata to define consent for all schemas contained in a .ZIP file.\nThis is consistent with the card stack model - the Application Layer is supposed to support needs of the Business layer.  ...or alternatively, the business layer is an overarching concept for what appears in the Application and Technology layers.","username":"mwherman2000","ts":"2019-02-27T13:54:18.371Z"}
{"msg":"Here's a cleanup up v0.2: https://github.com/mwherman2000/indy-arm/blob/master/README.md#appendix-f---indy-overlays-architecture-reference-model-overlays-arm-","username":"mwherman2000","ts":"2019-02-27T14:21:34.532Z"}
{"msg":"Here's a cleaned up v0.2: https://github.com/mwherman2000/indy-arm/blob/master/README.md#appendix-f---indy-overlays-architecture-reference-model-overlays-arm-","username":"mwherman2000","ts":"2019-02-27T14:21:34.532Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=egRnmhThtwEbX3Crz) @mwherman2000 That definitely looks better. I'm still waiting to hear back from @mtfk re the correct definition for the *Source Transfer*. The only other tiny tweak is \"Schema Base\" rather than \"Base Schema\".","username":"pknowles","ts":"2019-02-27T18:40:05.285Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=egRnmhThtwEbX3Crz","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=egRnmhThtwEbX3Crz","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=egRnmhThtwEbX3Crz) @mwherman2000 That definitely looks better. I'm still waiting to hear back from @mtfk re the correct definition for *Source Overlay*. The only other tiny tweak is \"Schema Base\" rather than \"Base Schema\".","username":"pknowles","ts":"2019-02-27T18:40:05.285Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=egRnmhThtwEbX3Crz","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=egRnmhThtwEbX3Crz","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=egRnmhThtwEbX3Crz) @mwherman2000 That definitely looks better. I'm still waiting to hear back from @mtfk re correct definition of *Source Overlay*. The only other tiny tweak is \"Schema Base\" rather than \"Base Schema\".","username":"pknowles","ts":"2019-02-27T18:40:05.285Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=egRnmhThtwEbX3Crz","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=egRnmhThtwEbX3Crz","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=7YMrHCi3dZRDBtkAD) @mwherman2000 Application layer ... is the correct one.","username":"pknowles","ts":"2019-02-27T18:48:16.889Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=7YMrHCi3dZRDBtkAD","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=7YMrHCi3dZRDBtkAD","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=dzBXf8ARhfjvMohJ3) @pknowles Fixed","username":"mwherman2000","ts":"2019-02-27T19:04:37.902Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=dzBXf8ARhfjvMohJ3","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=dzBXf8ARhfjvMohJ3","remote":true,"fileId":null,"fileName":null}]}
{"msg":"This week's *Indy Semantics WG* call starts in 20 minutes. Zoom link: https://zoom.us/j/2157245727","username":"pknowles","ts":"2019-03-05T17:40:18.294Z"}
{"msg":"Here is the agenda and dial-in information for the *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 5th March, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Including issuer-specified personal data processing and consent information to a schema set prior to publishing ( @pknowles / @mtfk / @janl ) - 45 mins\n- Reference - https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-03-05T17:48:08.779Z"}
{"msg":"Here is the agenda and dial-in information for the *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 5th March, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Including issuer-specified personal data processing and consent information to a schema set prior to publishing ( @pknowles / @mtfk ) - 45 mins\n- Reference - https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-03-05T17:48:08.779Z"}
{"msg":"Here is the agenda and dial-in information for the *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 5th March, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Including issuer-specified personal data processing and consent information to a schema set prior to publishing - 45 mins\n- Reference - https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-03-05T17:48:08.779Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, March 19th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-03-05T20:07:32.193Z"}
{"msg":"The Overlays data capture architecture is making great headway within both Roche and Novartis. I'll give a brief update during the next Semantics WG call but I believe that Pharma will get behind it. HL Indy rides in on the coattails too. An added bonus!","username":"pknowles","ts":"2019-03-07T17:19:37.250Z"}
{"msg":"The Overlays data capture architecture is making great headway within both Roche and Novartis. I'll give a brief update during the next Semantics WG call but I have great confidence that Pharma will get behind it. HL Indy rides in on the coattails too. An added bonus!","username":"pknowles","ts":"2019-03-07T17:19:37.250Z"}
{"msg":"The Overlays data capture architecture is making great headway within both Roche and Novartis. I'll give a brief update during the next Semantics WG call but I have great confidence that Pharma will get behind it. HL Indy rides in on the coattails of course!","username":"pknowles","ts":"2019-03-07T17:19:37.250Z"}
{"msg":"The Overlays data capture architecture is making great headway within both Roche and Novartis. I'll give a brief update during the next Semantics WG call but I now have great confidence that we'll get Pharma buy-in. HL Indy rides in on the coattails of course!","username":"pknowles","ts":"2019-03-07T17:19:37.250Z"}
{"msg":"The Overlays data capture architecture is making great headway within both Roche and Novartis. I'll give a brief update during the next Semantics WG call but I now have great confidence re Pharma buy-in. HL Indy rides in on the coattails of course!","username":"pknowles","ts":"2019-03-07T17:19:37.250Z"}
{"msg":"The Overlays data capture architecture is making great headway within both Roche and Novartis. I'll give a brief update during the next Semantics WG call but I now have great confidence that Pharma will adopt. HL Indy rides in on the coattails of course!","username":"pknowles","ts":"2019-03-07T17:19:37.250Z"}
{"msg":"The Overlays data capture architecture is making great headway within both Roche and Novartis. I'll give a brief update during the next Semantics WG call but I now have a strong inkling that Pharma will adopt. HL Indy is a strong part of the pitch!","username":"pknowles","ts":"2019-03-07T17:19:37.250Z"}
{"msg":"The Overlays data capture architecture is making great headway within both Roche and Novartis. I'll give a brief update during the next Semantics WG call but I now have a strong inkling that Pharma will adopt. HL Indy surfs the 🌊!","username":"pknowles","ts":"2019-03-07T17:19:37.250Z"}
{"msg":"The Overlays data capture architecture is making great headway within both Roche and Novartis. I'll give a brief update during the next Semantics WG call but I now have a strong inkling that Pharma will adopt. HL Indy surfs the 🌊","username":"pknowles","ts":"2019-03-07T17:19:37.250Z"}
{"msg":"The Overlays data capture architecture is making great headway within both Roche and Novartis. I'll give a brief update during the next Semantics WG call but I now have a strong inkling that Pharma will adopt. HL Indy is carried on that 🌊","username":"pknowles","ts":"2019-03-07T17:19:37.250Z"}
{"msg":"The Overlays data capture architecture is making great headway within both Roche and Novartis. I'll give a brief update during the next Semantics WG call but I now have a strong inkling that Pharma will adopt. HL Indy obviously be carried on that 🌊","username":"pknowles","ts":"2019-03-07T17:19:37.250Z"}
{"msg":"The Overlays data capture architecture is making great headway within both Roche and Novartis. I'll give a brief update during the next Semantics WG call but I now have a strong inkling that Pharma will adopt. HL Indy will obviously be carried on that 🌊","username":"pknowles","ts":"2019-03-07T17:19:37.250Z"}
{"msg":"The *Overlays data capture architecture* is making great headway within both Roche and Novartis. I'll give a brief update during the next Semantics WG call but I now have a strong inkling that Pharma will adopt. HL Indy will obviously be carried on that 🌊","username":"pknowles","ts":"2019-03-07T17:19:37.250Z"}
{"msg":"Published article on the *Overlays data capture architecture* - https://www.dativa.com/introducing-overlays-data-capture-architecture/","username":"pknowles","ts":"2019-03-17T19:26:17.376Z"}
{"msg":"","username":"pknowles","ts":"2019-03-18T21:17:30.839Z","attachments":[{"type":"file","title":"Image-5.png","title_link":"/file-upload/KaC6rw3Xig3hmGzKy/Image-5.png","image_url":"/file-upload/KaC6rw3Xig3hmGzKy/Image-5.png","image_type":"image/png","image_size":855864,"url":"/file-upload/KaC6rw3Xig3hmGzKy/Image-5.png","remote":false,"fileId":"KaC6rw3Xig3hmGzKy","fileName":"Image-5.png"}]}
{"msg":"","username":"pknowles","ts":"2019-03-18T21:17:48.869Z","attachments":[{"type":"file","title":"Image-6.png","title_link":"/file-upload/BhBTxxYJ92r3vRCTF/Image-6.png","image_url":"/file-upload/BhBTxxYJ92r3vRCTF/Image-6.png","image_type":"image/png","image_size":1406452,"url":"/file-upload/BhBTxxYJ92r3vRCTF/Image-6.png","remote":false,"fileId":"BhBTxxYJ92r3vRCTF","fileName":"Image-6.png"}]}
{"msg":"","username":"pknowles","ts":"2019-03-18T21:24:10.843Z","attachments":[{"type":"file","title":"Image-5.png","title_link":"/file-upload/fxMvnYBYWBkero9N9/Image-5.png","image_url":"/file-upload/fxMvnYBYWBkero9N9/Image-5.png","image_type":"image/png","image_size":855864,"url":"/file-upload/fxMvnYBYWBkero9N9/Image-5.png","remote":false,"fileId":"fxMvnYBYWBkero9N9","fileName":"Image-5.png"}]}
{"msg":"","username":"pknowles","ts":"2019-03-18T21:24:22.482Z","attachments":[{"type":"file","title":"Image-6.png","title_link":"/file-upload/K9rm3YBwTcx2dgfDb/Image-6.png","image_url":"/file-upload/K9rm3YBwTcx2dgfDb/Image-6.png","image_type":"image/png","image_size":1406452,"url":"/file-upload/K9rm3YBwTcx2dgfDb/Image-6.png","remote":false,"fileId":"K9rm3YBwTcx2dgfDb","fileName":"Image-6.png"}]}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 19th March, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n5pm-6.15pm GMT *\n6pm-7.15pm CET *\n\n* Note: Due to clock changes, the call time remains the same for US participants but is an hour earlier than usual for European participants!\n\nChair: @pknowles   \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Agent Framework for .NET - Web and Mobile demo ( @tomislav ) - 20 mins\n- Reference - https://agent-framework.readthedocs.io/en/latest/index.html\n• Learnings from Helsinki: Sitra's IHAN Technical Workshop on Consent ( @mtfk / @janl ) - 10 mins\n- Reference - https://www.sitra.fi/en/events/consent-management-workshop/\n• Consent Management assigned to a Schema Family incl. ODCA middleware demo ( @mtfk ) - 20 mins\n- Reference - https://github.com/THCLab/tool\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-03-19T06:29:53.935Z"}
{"msg":"Has joined the channel.","username":"tomislav","ts":"2019-03-19T06:30:01.808Z","type":"uj"}
{"msg":"Has joined the channel.","username":"pieterp","ts":"2019-03-19T08:49:47.964Z","type":"uj"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, March 19th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-03-19T19:36:38.991Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, April 2nd. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-03-19T19:37:12.325Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=nGb4hMpMaTR69DPLD) @pknowles Paul, what's the difference between the 2 video files? ...just the format? ...are they both video files?","username":"mwherman2000","ts":"2019-03-19T22:09:07.673Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=nGb4hMpMaTR69DPLD","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=nGb4hMpMaTR69DPLD","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=yMLWjj24N3P7bG2jf) @mwherman2000 The .mp4 file is a video file. The .m4a file is an audio file. Zoom provides both formats by default. ","username":"pknowles","ts":"2019-03-20T00:41:04.670Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=yMLWjj24N3P7bG2jf","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=yMLWjj24N3P7bG2jf","remote":true,"fileId":null,"fileName":null}]}
{"msg":"@mtfk @brentzundel @kenebert @jan With the *Rich Schema* efforts gaining some focus now, I believe that it'll be hugely valuable for Ken and Brent to see the _under-the-hood_ code being dynamically constructed by the *ODCA middleware tool*. Although Robert and I have been concentrating on the initial schema creation process up until this point, it's fairly obvious to me that a few minor additions to the tool will also enable credential schema issuance. Some of the HL Indy stack processes will be difficult to digest for people less technically minded and new to the community and I strongly believe that we can create this great piece of middleware tooling to help organisations and individuals better adopt. The ODCA tool will always be open source, free to use and without IP. Robert can you suggest a good time for a closed demo/discussion with Ken and Brent so that we can ensure that everyone is pulling in the same direction? [Cc: @nage ]","username":"pknowles","ts":"2019-03-21T05:52:32.166Z"}
{"msg":"@mtfk @brentzundel @kenebert @janl  With the *Rich Schema* efforts gaining some focus now, I believe that it'll be hugely valuable for Ken and Brent to see the _under-the-hood_ code being dynamically constructed by the *ODCA middleware tool*. Although Robert and I have been concentrating on the initial schema creation process up until this point, it's fairly obvious to me that a few minor additions to the tool will also enable credential schema issuance. Some of the HL Indy stack processes will be difficult to digest for people less technically minded and new to the community and I strongly believe that we can create this great piece of middleware tooling to help organisations and individuals better adopt. The ODCA tool will always be open source, free to use and without IP. Robert can you suggest a good time for a closed demo/discussion with Ken and Brent so that we can ensure that everyone is pulling in the same direction? [Cc: @nage ]","username":"pknowles","ts":"2019-03-21T05:52:32.166Z"}
{"msg":"@mtfk @brentzundel @kenebert @janl  With the *Rich Schema* efforts gaining some focus now, I believe that it'll be hugely valuable for Ken and Brent to see the _under-the-hood_ code being dynamically constructed by the *ODCA middleware tool*. Although Robert and I have been concentrating on the initial schema creation process up until this point, it's fairly obvious to me that, with a few minor additions to the tool, we'll also be able to handle credential schema issuance. Some of the HL Indy stack processes will be difficult to digest for people less technically minded and new to the community and I strongly believe that we can create this great piece of middleware tooling to help organisations and individuals better adopt. The ODCA tool will always be open source, free to use and without IP. Robert can you suggest a good time for a closed demo/discussion with Ken and Brent so that we can ensure that everyone is pulling in the same direction? [Cc: @nage ]","username":"pknowles","ts":"2019-03-21T05:52:32.166Z"}
{"msg":"@mtfk @brentzundel @kenebert @janl  With the *Rich Schema* efforts gaining some focus now, I believe that it'll be hugely valuable for Ken and Brent to see the _under-the-hood_ code being dynamically constructed by the *ODCA middleware tool*. Although Robert and I have been concentrating on the initial schema creation process up until this point, it's fairly obvious to me that, with a few minor additions to the tool, we'll also be able to handle credential schema issuance. Some of the HL Indy stack processes will be difficult to digest for people new to the community and less technically minded and, as such, strongly believe that we can create this great piece of middleware tooling to help organisations and individuals better adopt. The ODCA tool will always be open source, free to use and without IP. Robert can you suggest a good time for a closed demo/discussion with Ken and Brent so that we can ensure that everyone is pulling in the same direction? [Cc: @nage ]","username":"pknowles","ts":"2019-03-21T05:52:32.166Z"}
{"msg":"@mtfk @brentzundel @kenebert @janl  With the *Rich Schema* efforts gaining some focus now, I believe that it'll be hugely valuable for Ken and Brent to see the _under-the-hood_ code being dynamically constructed by the *ODCA middleware tool*. Although Robert and I have been concentrating on the initial schema creation process up until this point, it's fairly obvious to me that with a few minor additions to the tool we'll also be able to handle credential schema issuance. Some of the HL Indy stack processes will be difficult to digest for people new to the community and less technically minded and, as such, strongly believe that we can create this great piece of middleware tooling to help organisations and individuals better adopt. The ODCA tool will always be open source, free to use and without IP. Robert can you suggest a good time for a closed demo/discussion with Ken and Brent so that we can ensure that everyone is pulling in the same direction? [Cc: @nage ]","username":"pknowles","ts":"2019-03-21T05:52:32.166Z"}
{"msg":"@mtfk @brentzundel @kenebert @janl  With the *Rich Schema* efforts gaining some focus now, I believe it'll be hugely valuable for Ken and Brent to see the _under-the-hood_ code being dynamically constructed by the *ODCA middleware tool*. Although Robert and I have been concentrating on the initial schema creation process up until this point, it's fairly obvious to me that with a few minor additions to the tool we'll also be able to handle credential schema issuance. Some of the HL Indy stack processes will be difficult to digest for people new to the community and less technically minded and, as such, strongly believe that we can create this great piece of middleware tooling to help organisations and individuals better adopt. The ODCA tool will always be open source, free to use and without IP. Robert can you suggest a good time for a closed demo/discussion with Ken and Brent so that we can ensure that everyone is pulling in the same direction? [Cc: @nage ]","username":"pknowles","ts":"2019-03-21T05:52:32.166Z"}
{"msg":"@mtfk @brentzundel @kenebert @janl  With the *Rich Schema* efforts gaining some focus now, I believe it'll be hugely valuable for Ken and Brent to see the _under-the-hood_ code being dynamically constructed by the *ODCA middleware tool*. Although Robert and I have been concentrating on the initial schema creation process up until this point, it's fairly obvious to me that with a few minor additions to the tool we'll also be able to handle credential schema issuance. Some of the HL Indy stack processes will be difficult to digest for those new to the community or less technically minded and, as such, I strongly believe that we can create this great piece of middleware tooling to help organisations and individuals better adopt. The ODCA tool will always be open source, free to use and without IP. Robert can you suggest a good time for a closed demo/discussion with Ken and Brent so that we can ensure that everyone is pulling in the same direction? [Cc: @nage ]","username":"pknowles","ts":"2019-03-21T05:52:32.166Z"}
{"msg":"@mtfk @brentzundel @kenebert @janl  With the *Rich Schema* efforts gaining some focus now, I believe it'll be hugely valuable for Ken and Brent to see the _under-the-hood_ code being dynamically constructed by the *ODCA middleware tool*. Although Robert and I have been concentrating on the initial schema creation process up until this point, it's fairly obvious to me that with a few minor additions to the tool we'll also be able to handle credential schema issuance. Some of the HL Indy stack processes will be difficult to digest for those new to the community or less technically minded and, as such, I strongly believe that we can create this great piece of middleware tooling to help organisations and individuals better adopt. The ODCA tool will always be open source, free to use and without IP. Robert can you suggest a good time for a closed demo/discussion with Ken and Brent so that we can ensure that everyone is pulling in the same direction? Note: _ODCA = Overlays data capture architecture_ [Cc: @nage ]","username":"pknowles","ts":"2019-03-21T05:52:32.166Z"}
{"msg":"@mtfk @brentzundel @kenebert @janl  With the *Rich Schema* efforts gaining some focus now, I believe it'll be hugely valuable for Ken and Brent to see the _under-the-hood_ code being dynamically constructed by the *ODCA middleware tool*. Although Robert and I have been concentrating on the initial schema creation process up until this point, it's fairly obvious to me that with a few minor additions to the tool we'll also be able to handle credential schema issuance. Some of the HL Indy stack processes will be difficult to digest for those new to the community or less technically minded and, as such, I strongly believe that we can create this great piece of middleware tooling to help organisations and individuals better adopt. The ODCA tool will always be open source, free to use and without IP. Robert can you suggest a good time for a closed demo/discussion with Ken and Brent so that we can ensure that everyone is pulling in the same direction? Note: _ODCA = Overlays data capture architecture_ [Cc: @nage ]","username":"pknowles","ts":"2019-03-21T05:52:32.166Z"}
{"msg":"@mtfk @brentzundel @kenebert @janl  With the *Rich Schema* efforts gaining some focus now, I believe it'll be hugely valuable for Ken and Brent to see the _under-the-hood_ code being dynamically constructed by the *ODCA middleware tool*. Although Robert and I have been concentrating on the initial schema creation process up until this point, it's fairly obvious to me that with a few minor additions to the tool we'll also be able to handle credential schema issuance. Some of the HL Indy stack processes will be difficult to digest for those new to the community or less technically minded and, as such, I strongly believe that we can create this great piece of middleware tooling to help organisations and individuals better adopt. The ODCA tool will always be open source, free to use and without IP. Robert can you suggest a good time for a closed demo/discussion with Ken and Brent so that we can ensure that everyone is pulling in the same direction? Perhaps next Tuesday at 11am MT on the usual Zoom link. Note: _ODCA = Overlays data capture architecture_ [Cc: @nage ]","username":"pknowles","ts":"2019-03-21T05:52:32.166Z"}
{"msg":"@mtfk @brentzundel @kenebert @janl  With the *Rich Schema* efforts gaining some focus now, I believe it'll be hugely valuable for Ken and Brent to see the _under-the-hood_ code being dynamically constructed by the *ODCA middleware tool*. Although Robert and I have been concentrating on the initial schema creation process up until this point, it's fairly obvious to me that with a few minor additions to the tool we'll also be able to handle credential schema issuance. Some of the HL Indy stack processes will be difficult to digest for those new to the community or less technically minded and, as such, I strongly believe that we can create this great piece of middleware tooling to help organisations and individuals better adopt. The ODCA tool will always be open source, free to use and without IP. May I suggest that we all hop on a Zoom call next Tuesday at 11am MT for a closed demo/discussion to ensure that everyone is pulling in the same direction? I'll send out the calendar invite. Note: _ODCA = Overlays data capture architecture_ [Cc: @nage ]","username":"pknowles","ts":"2019-03-21T05:52:32.166Z"}
{"msg":"The _Global Access_ team at *Roche Diagnostics* will be putting together a use case proposal and white paper for the implementation of the *Overlays data capture architecture* which will then be pitched to all global function heads this summer. https://diagnostics.roche.com/global/en/article-listing/global-access-program.html","username":"pknowles","ts":"2019-03-22T11:17:07.341Z"}
{"msg":"Newsflash: The _Global Access_ team at *Roche Diagnostics* will be putting together a use case proposal and white paper for the implementation of the *Overlays data capture architecture* which will then be pitched to all global function heads this summer. https://diagnostics.roche.com/global/en/article-listing/global-access-program.html","username":"pknowles","ts":"2019-03-22T11:17:07.341Z"}
{"msg":"Newsflash: The _Global Access_ team at *Roche Diagnostics* will be putting together a use case proposal and white paper for the implementation of the *Overlays data capture architecture* which will then be pitched to all global function heads this summer. https://diagnostics.roche.com/global/en/article-listing/global-access-program.html ","username":"pknowles","ts":"2019-03-22T11:17:07.341Z"}
{"msg":"The _Global Access_ team at *Roche Diagnostics* will be putting together a use case proposal and white paper for the implementation of the *Overlays data capture architecture* which will then be pitched to all global function heads this summer. https://diagnostics.roche.com/global/en/article-listing/global-access-program.html ","username":"pknowles","ts":"2019-03-22T11:17:07.341Z"}
{"msg":"Has joined the channel.","username":"phoniks","ts":"2019-03-22T19:51:21.644Z","type":"uj"}
{"msg":"@pknowles: I'm a fellow at the Insight Decentralized Consensus program here in San Francisco.  I caught the SSI bug last year at IIW and even though I was new to the concept of DIDs I caught your (or someone else's) session on Overlays.  The idea behind the Insight program is that we spend ~4 weeks working on a project and then demo it to potential employers at the end of the program.  I'm really interested in carving out SSI as my niche in this space, and it feels like overlays could be a really big deal, so I was hoping that you might be able to point me to some aspect of the problem that I might be able to contribute something to.  What would be the first step towards implementing overlays on a different blockchain - like Ethereum for instance.  Or, following from your March 20th post, is there some way that I could help create some high level tools to make ODCA accessible to the less technically minded? ","username":"phoniks","ts":"2019-03-22T22:39:44.606Z"}
{"msg":"@pknowles I think such a review would be useful. Please arrange a meeting.","username":"kenebert","ts":"2019-03-22T22:41:11.184Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C) @phoniks Thanks for reaching out. Although the initial implementation for the *ODCA middleware tool* is closely affiliated to _Hyperledger Indy_, the architecture is platform agnostic. In this new user-centric data economy that we are all striving to build, the OCDA architecture encourages both interoperability and reusability of data objects [_schema bases_ (base objects) and _overlays_] in an open economy. As all overlays contain their own ID, a link ID to a base object and industry sector tags, they become searchable either in a repository or on a ledger. By tracking the number times that the data objects are being utilised, the community of schema issuers effectively drive standardisation. We've started building the ODCA middleware tool in Dativa's innovation hub [https://www.dativa.com/innovation-hub/ ]. This is ultimately the project tool that I hope I can persuade you to work on in collaboration with us with a view to demoing it to potential employers. The code is totally open source. Nobody has any IP on it. Github repository - https://github.com/THCLab/tool . Further reading: https://www.dativa.com/introducing-overlays-data-capture-architecture/ . Let's continue this discussion on a Zoom call. I'll set that up with you directly. [Cc: @mtfk ]","username":"pknowles","ts":"2019-03-23T01:28:56.588Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C) @phoniks Thanks for reaching out. Although the initial implementation for the *ODCA middleware tool* is closely affiliated to _Hyperledger Indy_, the architecture is platform agnostic. In this new user-centric data economy that we are all striving to build, the architecture encourages both interoperability and reusability of data objects [_schema bases_ (base objects) and _overlays_] in an open economy. As all overlays contain their own ID, a link ID to a base object and industry sector tags, they become searchable either in a repository or on a ledger. By tracking the number times that the data objects are being utilised, the community of schema issuers effectively drive standardisation. We've started building the ODCA middleware tool in Dativa's innovation hub [https://www.dativa.com/innovation-hub/ ]. This is ultimately the project tool that I hope I can persuade you to work on in collaboration with us with a view to demoing it to potential employers. The code is totally open source. Nobody has any IP on it. Github repository - https://github.com/THCLab/tool . Further reading: https://www.dativa.com/introducing-overlays-data-capture-architecture/ . Let's continue this discussion on a Zoom call. I'll set that up with you directly. [Cc: @mtfk ]","username":"pknowles","ts":"2019-03-23T01:28:56.588Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C) @phoniks Thanks for reaching out. Although the initial implementation for the *ODCA middleware tool* is closely affiliated to _Hyperledger Indy_, the architecture is indeed platform agnostic. In this new user-centric data economy that we are all striving to build, the architecture encourages both interoperability and reusability of data objects [_schema bases_ (base objects) and _overlays_] in an open economy. As all overlays contain their own ID, a link ID to a base object and industry sector tags, they become searchable either in a repository or on a ledger. By tracking the number times that the data objects are being utilised, the community of schema issuers effectively drive standardisation. We've started building the ODCA middleware tool in Dativa's innovation hub [https://www.dativa.com/innovation-hub/ ]. This is ultimately the project tool that I hope I can persuade you to work on in collaboration with us with a view to demoing it to potential employers. The code is totally open source. Nobody has any IP on it. Github repository - https://github.com/THCLab/tool . Further reading: https://www.dativa.com/introducing-overlays-data-capture-architecture/ . Let's continue this discussion on a Zoom call. I'll set that up with you directly. [Cc: @mtfk ]","username":"pknowles","ts":"2019-03-23T01:28:56.588Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C) @phoniks Thanks for reaching out. Although the initial implementation for the *ODCA middleware tool* is closely affiliated to _Hyperledger Indy_, the architecture is indeed platform agnostic. In this new user-centric data economy that we are all striving to build, the architecture encourages both interoperability and reusability of data objects [ _schema bases_ (base objects) and _overlays_ ] in an open economy. As all overlays contain their own ID, a link ID to a base object and industry sector tags, they become searchable either in a repository or on a ledger. By tracking the number times that the data objects are being utilised, the community of schema issuers effectively drive standardisation. We've started building the ODCA middleware tool in Dativa's innovation hub [https://www.dativa.com/innovation-hub/ ]. This is ultimately the project tool that I hope I can persuade you to work on in collaboration with us with a view to demoing it to potential employers. The code is totally open source. Nobody has any IP on it. Github repository - https://github.com/THCLab/tool . Further reading: https://www.dativa.com/introducing-overlays-data-capture-architecture/ . Let's continue this discussion on a Zoom call. I'll set that up with you directly. [Cc: @mtfk ]","username":"pknowles","ts":"2019-03-23T01:28:56.588Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C) @phoniks Thanks for reaching out. Although the initial implementation for the *ODCA middleware tool* is closely affiliated to _Hyperledger Indy_, the architecture is indeed platform agnostic. In this new user-centric data economy that we are all striving to build, the architecture encourages both interoperability and reusability of data objects [ _schema bases_ (base objects) and _overlays_ ] in an open economy. As all overlays contain their own ID, a link ID to a base object and industry sector tags, they become searchable either in a repository or on a ledger. By tracking the number of times that the data objects are being utilised, the community of schema issuers effectively drive standardisation. We've started building the ODCA middleware tool in Dativa's innovation hub [https://www.dativa.com/innovation-hub/ ]. This is ultimately the project tool that I hope I can persuade you to work on in collaboration with us with a view to demoing it to potential employers. The code is totally open source. Nobody has any IP on it. Github repository - https://github.com/THCLab/tool . Further reading: https://www.dativa.com/introducing-overlays-data-capture-architecture/ . Let's continue this discussion on a Zoom call. I'll set that up with you directly. [Cc: @mtfk ]","username":"pknowles","ts":"2019-03-23T01:28:56.588Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C) @phoniks Thanks for reaching out. Although the initial implementation for the *ODCA middleware tool* is closely affiliated to _Hyperledger Indy_, the architecture is indeed platform agnostic. In this new user-centric data economy that we are all striving to build, the architecture encourages both interoperability and reusability of data objects [ _schema bases_ (base objects) and _overlays_ ] in an open economy. As all overlays contain their own ID, a link ID to a base object and industry sector tags, they become searchable either in a repository or on a ledger. By tracking the number of times that the data objects are being utilised, the community of schema issuers effectively drive standardisation. We've started building the ODCA middleware tool in Dativa's innovation hub [https://www.dativa.com/innovation-hub/ ]. This is ultimately the project tool that I hope we can work on in collaboration with a view to demoing it to potential employers. The code is totally open source. Nobody has any IP on it. Github repository - https://github.com/THCLab/tool . Further reading: https://www.dativa.com/introducing-overlays-data-capture-architecture/ . Let's continue this discussion on a Zoom call. I'll set that up with you directly. [Cc: @mtfk ]","username":"pknowles","ts":"2019-03-23T01:28:56.588Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C) @phoniks Thanks for reaching out. Although the initial implementation for the *ODCA middleware tool* is closely affiliated to _Hyperledger Indy_, the architecture is indeed platform agnostic. In this new user-centric data economy that we are all striving to build, the architecture encourages both interoperability and reusability of data objects [ _schema bases_ (base objects) and _overlays_ ] in an open economy. As all overlays contain their own ID, a link ID to a base object and industry sector tags, they become searchable either in a repository or on a ledger. By tracking the number of times that the data objects are being utilised, the community of schema issuers effectively drive standardisation. We've started building the ODCA middleware tool in Dativa's innovation hub [https://www.dativa.com/innovation-hub/ ]. This is ultimately the project tool that I hope we can work on in collaboration with a view to demoing it to potential employers. The code is totally open source. Nobody has any IP on it. Github repository - https://github.com/THCLab/tool . ODCA blog post: https://www.dativa.com/introducing-overlays-data-capture-architecture/ . Let's continue this discussion on a Zoom call. I'll set that up with you directly. [Cc: @mtfk ]","username":"pknowles","ts":"2019-03-23T01:28:56.588Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C) @phoniks Thanks for reaching out. Although the initial implementation for the *ODCA middleware tool* is closely affiliated to _Hyperledger Indy_, the architecture is indeed platform agnostic. In this new user-centric data economy that we are all striving to build, the architecture encourages both interoperability and reusability of data objects [ _schema bases_ (base objects) and _overlays_ ] in an open economy. As all overlays contain their own ID, a link ID to a base object and industry sector tagging, they become searchable either in a repository or on a ledger. By tracking the number of times that the data objects are being utilised, the community of schema issuers effectively drive standardisation. We've started building the ODCA middleware tool in Dativa's innovation hub [https://www.dativa.com/innovation-hub/ ]. This is ultimately the project tool that I hope we can work on in collaboration with a view to demoing it to potential employers. The code is totally open source. Nobody has any IP on it. Github repository - https://github.com/THCLab/tool . ODCA blog post: https://www.dativa.com/introducing-overlays-data-capture-architecture/ . Let's continue this discussion on a Zoom call. I'll set that up with you directly. [Cc: @mtfk ]","username":"pknowles","ts":"2019-03-23T01:28:56.588Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C) @phoniks Thanks for reaching out. Although the initial implementation for the *ODCA middleware tool* is closely aligned to _Hyperledger Indy_, the architecture is actually platform agnostic. In this new user-centric data economy that we are all striving to build, the architecture encourages both interoperability and reusability of data objects [ _schema bases_ (base objects) and _overlays_ ] in an open economy. As all overlays contain their own ID, a link ID to a base object and industry sector tagging, they become searchable either in a repository or on a ledger. By tracking the number of times that the data objects are being utilised, the community of schema issuers effectively drive standardisation. We've started building the ODCA middleware tool in Dativa's innovation hub [https://www.dativa.com/innovation-hub/ ]. This is ultimately the project tool that I hope we can work on in collaboration with a view to demoing it to potential employers. The code is totally open source. Nobody has any IP on it. Github repository - https://github.com/THCLab/tool . ODCA blog post: https://www.dativa.com/introducing-overlays-data-capture-architecture/ . Let's continue this discussion on a Zoom call. I'll set that up with you directly. [Cc: @mtfk ]","username":"pknowles","ts":"2019-03-23T01:28:56.588Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C) @phoniks Thanks for reaching out. Although the initial implementation for the *ODCA middleware tool* is closely aligned to _Hyperledger Indy_, the architecture is actually platform agnostic. In this new user-centric data economy that we are all striving to build, the architecture encourages both interoperability and reusability of data objects [ _schema bases_ (base objects) and _overlays_ ] in an open economy. As all overlays contain their own ID, a link ID to a base object and industry sector tagging, they become searchable either in a repository or on a ledger. By tracking the number of times that the data objects are being utilised, the community of schema issuers effectively drive standardisation. We've started building the ODCA middleware tool in Dativa's innovation hub [https://www.dativa.com/innovation-hub/ ]. This is ultimately the project tool that I hope we can work on in collaboration with a view to demoing it to potential employers. The code is totally open source. Nobody has any IP on it. Github repository - https://github.com/THCLab/tool . ODCA blog post: https://www.dativa.com/introducing-overlays-data-capture-architecture/ . Let's continue this discussion on a Zoom call. I'll set that up with you directly. [Cc: @mtfk @kenebert ]","username":"pknowles","ts":"2019-03-23T01:28:56.588Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C) @phoniks Thanks for reaching out. Although the initial implementation for the *ODCA middleware tool* is closely aligned with _Hyperledger Indy_, the tool is platform agnostic. In this new user-centric data economy that we are all striving to build, the architecture encourages both interoperability and reusability of data objects [ _schema bases_ (base objects) and _overlays_ ] in an open economy. As all overlays contain their own ID, a link ID to a base object and industry sector tagging, they become searchable either in a repository or on a ledger. By tracking the number of times that the data objects are being utilised, the community of schema issuers effectively drive standardisation. We've started building the ODCA middleware tool in Dativa's innovation hub [https://www.dativa.com/innovation-hub/ ]. This is ultimately the project tool that I hope we can work on in collaboration with a view to demoing it to potential employers. The code is totally open source. Nobody has any IP on it. Github repository - https://github.com/THCLab/tool . ODCA blog post: https://www.dativa.com/introducing-overlays-data-capture-architecture/ . Let's continue this discussion on a Zoom call. I'll set that up with you directly. [Cc: @mtfk @kenebert ]","username":"pknowles","ts":"2019-03-23T01:28:56.588Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C) @phoniks Thanks for reaching out. Although the initial implementation for the *ODCA middleware tool* is closely aligned with _Hyperledger Indy_, the tool is platform agnostic. In this new user-centric data economy that we are all striving to build, the architecture encourages both interoperability and reusability of data objects [ _schema bases_ (base objects) and _overlays_ ] in an open economy. As all overlays contain their own ID, a link ID to a base object and industry sector tagging, they become searchable either in a repository or on a ledger. By tracking the number of times that the data objects are being utilised, the community of schema issuers effectively drive standardisation. We've started building the ODCA middleware tool in Dativa's innovation hub [https://www.dativa.com/innovation-hub/ ]. This is ultimately the project tool that I hope we can work on in collaboration with a view to demoing it to organisations. The code is totally open source. Nobody has any IP on it. Github repository - https://github.com/THCLab/tool . ODCA blog post: https://www.dativa.com/introducing-overlays-data-capture-architecture/ . Let's continue this discussion on a Zoom call. I'll set that up with you directly. [Cc: @mtfk @kenebert ]","username":"pknowles","ts":"2019-03-23T01:28:56.588Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=usxsDbDbT9ZiLfn7C","remote":true,"fileId":null,"fileName":null}]}
{"msg":"The _Global Access_ team at *Roche Diagnostics* will be putting together a use case proposal and white paper for the implementation of the *Overlays data capture architecture* which will then be pitched to all global function heads this summer. https://diagnostics.roche.com/global/en/article-listing/global-access-program.html","username":"pknowles","ts":"2019-03-23T01:57:12.131Z"}
{"msg":"The _Global Access_ team at *Roche Diagnostics* will be putting together a use case proposal and white paper for the implementation of the *Overlays data capture architecture* and middleware tooling which will then be pitched to all global function heads this summer. https://diagnostics.roche.com/global/en/article-listing/global-access-program.html","username":"pknowles","ts":"2019-03-23T01:57:12.131Z"}
{"msg":"Has joined the channel.","username":"pyraman","ts":"2019-03-25T09:41:37.651Z","type":"uj"}
{"msg":"hi all! After 4 months study Hyperledger Fabric - now we win a project require Indy :).\nStick with Indy today I found some awesome tools to make a testnet.\nMy question is! Does Indy offer a public network and smart contract engine so that I can deploy smart contract to the network and call API from client?","username":"pyraman","ts":"2019-03-25T09:44:52.054Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=TLQJGmrFRHw5WTe8T) @pyraman Repost your query to the #indy channel for a quicker response.","username":"pknowles","ts":"2019-03-25T12:36:04.447Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=TLQJGmrFRHw5WTe8T","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=TLQJGmrFRHw5WTe8T","remote":true,"fileId":null,"fileName":null}]}
{"msg":"looks like I've somehow ended up with two semantics group meetings tomorrow. Could anyone tell me which one is right?","username":"brentzundel","ts":"2019-03-25T23:15:49.250Z"}
{"msg":"Has joined the channel.","username":"Ryan2","ts":"2019-03-26T04:49:24.753Z","type":"uj"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 2nd April, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• 2019 Q1 DID Specifications Update ( @mwherman2000 ) - 10-15 mins\n- Reference - https://w3c-ccg.github.io/did-wg-charter/\n• 2019 Q1 Schema 2.0 Update ( @brentzundel / @kenebert ) - 10-15 mins\n- Reference - https://github.com/WebOfTrustInfo/rwot8-barcelona/blob/master/topics-and-advance-readings/Using-Immutable-Data-Objects.md\n• 2019 Q1 ODCA Pipeline Update ( @pknowles / @mtfk ) - 10-15 mins\n- Reference - https://github.com/THCLab/tool\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-04-02T05:45:56.172Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 2nd April, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• 2019 Q1 DID Specifications Update ( @mwherman2000 ) - 10-15 mins\n- Reference - https://w3c-ccg.github.io/did-wg-charter/\n• 2019 Q1 Schema 2.0 Update ( @brentzundel / @kenebert ) - 10-15 mins\n- Reference - https://github.com/WebOfTrustInfo/rwot8-barcelona/blob/master/topics-and-advance-readings/Using-Immutable-Data-Objects.md\n• 2019 Q1 ODCA Pipeline Update ( @pknowles / @mtfk ) - 10-15 mins\n- Reference - https://www.dativa.com/innovation-hub/\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-04-02T05:45:56.172Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, April 16th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-04-02T18:57:03.364Z"}
{"msg":"@mwherman2000 has kindly put together a blog article detailing the *2019 Q1 DID Specifications Update* as presented during yesterday's *Indy Semantics WG* call. Thanks, Michael! https://hyperonomy.com/2019/04/03/2019-q1-update-did-specifications-efforts/","username":"pknowles","ts":"2019-04-03T06:58:33.071Z"}
{"msg":"Thank you to @kenebert for his helping spotting a couple errors in the grammar as well as a lot of general good advice.","username":"mwherman2000","ts":"2019-04-03T09:59:04.672Z"}
{"msg":"Thank you to @kenebert for his helping spotting a couple errors in the grammar examples as well as a lot of general good advice.","username":"mwherman2000","ts":"2019-04-03T09:59:04.672Z"}
{"msg":"I have a clash with today's *Indy WG* call so won't be able to dial in. If @Sean_Bohan asks for a quick summary about the workings of the *Indy Semantics WG*, would perhaps @mwherman2000 or @kenebert be able to step up to the mic?","username":"pknowles","ts":"2019-04-04T04:14:06.347Z"}
{"msg":"I have a clash with today's *Indy WG* call so won't be able to attend. If @Sean_Bohan asks for a quick summary about the workings of the *Indy Semantics WG*, would perhaps @mwherman2000 or @kenebert be able to step in?","username":"pknowles","ts":"2019-04-04T04:14:06.347Z"}
{"msg":"I have a clash with today's *Indy WG* call so won't be able to dial in. If @Sean_Bohan asks for a quick summary about the workings of the *Indy Semantics WG*, would perhaps @mwherman2000 or @kenebert be able to step in?","username":"pknowles","ts":"2019-04-04T04:14:06.347Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=726PzsMZMqEHgSzn2) @mtfk Michael's blog article may help shed some light on proposed syntax for semantics pointers/identifiers.","username":"pknowles","ts":"2019-04-05T06:33:04.837Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=726PzsMZMqEHgSzn2","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=726PzsMZMqEHgSzn2","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=726PzsMZMqEHgSzn2) @mtfk Michael's blog article may help shed some light on proposed syntax for semantics pointers/identifiers. \"Figure 1. DID Specifications Ecosystem\" will be of particular interest.","username":"pknowles","ts":"2019-04-05T06:33:04.837Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=726PzsMZMqEHgSzn2","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=726PzsMZMqEHgSzn2","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=726PzsMZMqEHgSzn2) @mtfk Michael's blog article may help shed some light on proposed syntax for semantics pointers/identifiers. \"_Figure 1. DID Specifications Ecosystem_\" will be of particular interest.","username":"pknowles","ts":"2019-04-05T06:33:04.837Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=726PzsMZMqEHgSzn2","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=726PzsMZMqEHgSzn2","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=726PzsMZMqEHgSzn2) @mtfk Michael's blog article may help shed some light on proposed syntax for semantics pointers/identifiers. _Figure 1. DID Specifications Ecosystem_ will be of particular interest.","username":"pknowles","ts":"2019-04-05T06:33:04.837Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=726PzsMZMqEHgSzn2","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=726PzsMZMqEHgSzn2","remote":true,"fileId":null,"fileName":null}]}
{"msg":"From @drummondreed : Paul, on this whole subject of addressing immutable content objects (like schema definitions) with DIDs, see the current state-of-play about how this will be done in the DID spec in these two Google docs. The first one describes the matrix parameters proposal: https://docs.google.com/document/d/1TctFY8euBH2wq7Z8c9KccICDZUGZplvhoqlHlFMahGk/edit?usp=sharing\n\nThe second one is for contributors to write up their own use cases for DID URLs in the 3 syntaxes under consideration. Should only take any W3C Credentials Community Group member 5 mins to write up your own examples: https://docs.google.com/document/d/1VpYPvUw2o-01e727bCy2V-0MUEe0_NB-EqX677scQbI/edit?usp=sharing","username":"pknowles","ts":"2019-04-07T06:32:40.507Z"}
{"msg":"From @drummondreed : \"Paul, on this whole subject of addressing immutable content objects (like schema definitions) with DIDs, see the current state-of-play about how this will be done in the DID spec in these two Google docs. The first one describes the matrix parameters proposal: https://docs.google.com/document/d/1TctFY8euBH2wq7Z8c9KccICDZUGZplvhoqlHlFMahGk/edit?usp=sharing \"\n\nThe second one is for contributors to write up their own use cases for DID URLs in the 3 syntaxes under consideration. Should only take any W3C Credentials Community Group member 5 mins to write up your own examples: https://docs.google.com/document/d/1VpYPvUw2o-01e727bCy2V-0MUEe0_NB-EqX677scQbI/edit?usp=sharing","username":"pknowles","ts":"2019-04-07T06:32:40.507Z"}
{"msg":"From @drummondreed : \"Paul, on this whole subject of addressing immutable content objects (like schema definitions) with DIDs, see the current state-of-play about how this will be done in the DID spec in these two Google docs. The first one describes the matrix parameters proposal: https://docs.google.com/document/d/1TctFY8euBH2wq7Z8c9KccICDZUGZplvhoqlHlFMahGk/edit?usp=sharing\n\nThe second one is for contributors to write up their own use cases for DID URLs in the 3 syntaxes under consideration. Should only take any W3C Credentials Community Group member 5 mins to write up your own examples: https://docs.google.com/document/d/1VpYPvUw2o-01e727bCy2V-0MUEe0_NB-EqX677scQbI/edit?usp=sharing \"","username":"pknowles","ts":"2019-04-07T06:32:40.507Z"}
{"msg":"I'll add this as an agenda item for the next #indy-semantics WG call.","username":"pknowles","ts":"2019-04-07T06:34:38.733Z"}
{"msg":"I'll add this as an agenda item for the next *Indy Semantics WG* call on April 16th.","username":"pknowles","ts":"2019-04-07T06:34:38.733Z"}
{"msg":"Paul, what time is the call on the 16th? I'll try to attend.","username":"drummondreed","ts":"2019-04-07T19:24:28.377Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=rRPTWhYPZHnRNdGwn) @drummondreed 10am-11.15am PT","username":"pknowles","ts":"2019-04-07T20:38:48.461Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=rRPTWhYPZHnRNdGwn","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=rRPTWhYPZHnRNdGwn","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Excellent—on the calendar now.","username":"drummondreed","ts":"2019-04-07T20:43:36.538Z"}
{"msg":"Has joined the channel.","username":"hamidm","ts":"2019-04-10T11:20:04.648Z","type":"uj"}
{"msg":"A bit off topic but does anyone have a schema definition for a DID Document? ...that is, a meta description/definition outlining the overall structure of a DID Document, the mandatory elements, provisions for optional elements, ...that sort of thing.Effectively, the spec text for a DID Document from the DID Spec (https://w3c-ccg.github.io/did-spec/#did-documents) expressing in some sort of schema definition language (e.g. JSON schema?)\n","username":"mwherman2000","ts":"2019-04-13T14:58:33.936Z"}
{"msg":"A bit off topic but does anyone have a schema definition for a DID Document? ...that is, a meta description/definition outlining the overall structure of a DID Document, the mandatory elements, provisions for optional elements, ...that sort of thing. Effectively, the spec text for a DID Document from the DID Spec (https://w3c-ccg.github.io/did-spec/#did-documents) expressing in some sort of schema definition language (e.g. JSON schema?)\n","username":"mwherman2000","ts":"2019-04-13T14:58:33.936Z"}
{"msg":"A bit off topic but does anyone have a schema definition for a DID Document? ...that is, a meta description/definition outlining the overall structure of a DID Document, the mandatory elements, provisions for optional elements, ...that sort of thing. Effectively, the spec text for a DID Document from the DID Spec (https://w3c-ccg.github.io/did-spec/#did-documents) expressed in some sort of schema definition language (e.g. JSON schema?)\n","username":"mwherman2000","ts":"2019-04-13T14:58:33.936Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=QNNfch4PA3ZEkrjJH) @mwherman2000 https://w3c-ccg.github.io/did-spec/contexts/did-v1.jsonld\nlike this? ","username":"mtfk","ts":"2019-04-15T20:01:41.933Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=QNNfch4PA3ZEkrjJH","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=QNNfch4PA3ZEkrjJH","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 16th April, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles   \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Decentralized Resource Identifier (DRI) - What is it and why do we need it? ( @mtfk ) - 40 mins\n- Reference - https://docs.google.com/document/d/1VpYPvUw2o-01e727bCy2V-0MUEe0_NB-EqX677scQbI/edit#heading=h.lmn1hanjyyns\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-04-16T16:12:12.333Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 16th April, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles   \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Decentralized Resource Identifier (DRI) - What is it and why do we need it? ( @mtfk ) - 40 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-04-16T16:12:12.333Z"}
{"msg":"@peacekeeper @mwherman2000 @drummondreed @danielhardman  :top:","username":"pknowles","ts":"2019-04-16T16:30:24.510Z"}
{"msg":"@pknowles I'm going to pass on this morning's call.  I don't see the Hyperonomy Universal DID URI Specification (did-uri-spec) represented in any of the options listed in the Google doc.  Let's arrange a specific Universal DID URI Specification (did-uri-spec) conversation for the next call.","username":"mwherman2000","ts":"2019-04-16T16:39:37.090Z"}
{"msg":"Has joined the channel.","username":"helengarneau","ts":"2019-04-16T16:52:54.226Z","type":"uj"}
{"msg":"@mtfk I'm looking forward to your talk.  The primary goal of the Hyperonomy Universal Decentralized Identifier URI Specification, its reason for being, is specifically to support every possible application of DIDs on the planet ...quite literally and demonstrably.  A key feature is the concept of Domain-Specific DID Grammar (DSDG).\nThe overview webcast can be found here: https://www.youtube.com/watch?v=e3V5oRB5lYA&list=PLU-rWqHm5p45c9jFftlYcr4XIWcZb0yCv&index=2","username":"mwherman2000","ts":"2019-04-16T16:53:32.071Z"}
{"msg":"@mtfk I'm looking forward to your talk.  The primary goal of the Hyperonomy *Universal *Decentralized Identifier URI Specification, its reason for being, is specifically to support every possible application of DIDs on the planet ...quite literally and demonstrably.  A key feature is the concept of Domain-Specific DID Grammar (DSDG).\nThe overview webcast can be found here: https://www.youtube.com/watch?v=e3V5oRB5lYA&list=PLU-rWqHm5p45c9jFftlYcr4XIWcZb0yCv&index=2","username":"mwherman2000","ts":"2019-04-16T16:53:32.071Z"}
{"msg":"@mtfk I'm looking forward to your talk.  The primary goal of the Hyperonomy *Universal *Decentralized Identifier URI Specification, its reason for being, is specifically to support every possible application of DIDs on the planet ...every possible application ...quite literally and demonstrably.  A key feature is the concept of Domain-Specific DID Grammar (DSDG).\nThe overview webcast can be found here: https://www.youtube.com/watch?v=e3V5oRB5lYA&list=PLU-rWqHm5p45c9jFftlYcr4XIWcZb0yCv&index=2","username":"mwherman2000","ts":"2019-04-16T16:53:32.071Z"}
{"msg":"The DSDG webcast can be found here: https://www.youtube.com/watch?v=IdLm2jHuADg&list=PLU-rWqHm5p45c9jFftlYcr4XIWcZb0yCv&index=6&t=0s","username":"mwherman2000","ts":"2019-04-16T16:54:33.341Z"}
{"msg":"Please review the Rich Schema PR: https://github.com/hyperledger/indy-hipe/pull/119","username":"brentzundel","ts":"2019-04-16T17:56:04.595Z"}
{"msg":"Here is the link to the Google doc that I showed on the call today that consolidates the DID spec syntax and matrix parameters proposal discussions into proposed text for the DID spec. Please do add comments/suggestions/questions so we can refine this into final proposed language that we will turn into a PR. https://mit.webex.com/mit/j.php?MTID=m4d2a5f07fd6efee504f1752a8a2a3965","username":"drummondreed","ts":"2019-04-16T18:07:45.865Z"}
{"msg":"Here is the link to the Google doc that I showed on the call today that consolidates the DID spec syntax and matrix parameters proposal discussions into proposed text for the DID spec. Please do add comments/suggestions/questions so we can refine this into final proposed language that we will turn into a PR. https://docs.google.com/document/d/1qnDExIVjU5bYc601qUdLZIi9UAs1ojlHyKnVoz2zlLM/edit?usp=sharing","username":"drummondreed","ts":"2019-04-16T18:07:45.865Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=bm9FjzMABGaAvqxig) @brentzundel @all - We are scheduling an ad-hoc *Indy Semantics WG* call next Tuesday, April 23rd at 11am-12.15pm MT (7pm-8.15pm CET) to discuss this important hipe. Please review and add your comments to the document before the call.","username":"pknowles","ts":"2019-04-16T18:43:07.918Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=bm9FjzMABGaAvqxig","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=bm9FjzMABGaAvqxig","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=bm9FjzMABGaAvqxig) @brentzundel @all - We are scheduling an ad-hoc *Indy Semantics WG* call next Tuesday, April 23rd at 11am-12.15pm MT (7pm-8.15pm CET) to discuss this important hipe. Please review and add your comments to the document before then.","username":"pknowles","ts":"2019-04-16T18:43:07.918Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=bm9FjzMABGaAvqxig","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=bm9FjzMABGaAvqxig","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=bm9FjzMABGaAvqxig) @brentzundel @all - We are scheduling an ad-hoc *Indy Semantics WG* call for next Tuesday, April 23rd at 11am-12.15pm MT (7pm-8.15pm CET) to discuss this important hipe. Please review and add your comments to the document before then.","username":"pknowles","ts":"2019-04-16T18:43:07.918Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=bm9FjzMABGaAvqxig","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=bm9FjzMABGaAvqxig","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=bm9FjzMABGaAvqxig) @brentzundel @all - We are scheduling an ad-hoc *Indy Semantics WG* call for next Tuesday, April 23rd at 11am-12.15pm MT (7pm-8.15pm CET) to discuss this important HIPE. Please review and add your comments to the document before then.","username":"pknowles","ts":"2019-04-16T18:43:07.918Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=bm9FjzMABGaAvqxig","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=bm9FjzMABGaAvqxig","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Note that I posted the wrong link to the DID spec syntax and matrix parameters proposal in my last message above. I have fixed it. Again, the correct link is: https://docs.google.com/document/d/1qnDExIVjU5bYc601qUdLZIi9UAs1ojlHyKnVoz2zlLM/edit?usp=sharing","username":"drummondreed","ts":"2019-04-16T19:03:43.378Z"}
{"msg":"Noted. Thanks, @drummondreed ","username":"pknowles","ts":"2019-04-16T19:04:34.886Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, April 23td. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-04-16T20:02:36.200Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, April 23rd. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-04-16T20:02:36.200Z"}
{"msg":"Has joined the channel.","username":"rangak","ts":"2019-04-18T23:09:34.449Z","type":"uj"}
{"msg":"There is an ad hoc *Indy Semantics WG* call tomorrow to discuss the new *Rich Schema* PR prior to the HIPE being submitted. Please review prior to the call. Anyone is welcome to join.\n\nRich Schema PR :\nhttps://github.com/hyperledger/indy-hipe/pull/119\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 23rd April, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Review and discuss Rich Schema PR prior to HIPE submission ( @brentzundel ) - 45 mins\n- Reference - https://github.com/hyperledger/indy-hipe/pull/119\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-04-22T10:22:35.787Z"}
{"msg":"There is an ad hoc *Indy Semantics WG* call tomorrow to discuss the new *Rich Schema* PR prior to the HIPE being submitted. Please review prior to the call. Anyone is welcome to join.\n\nRich Schema PR :\nhttps://github.com/hyperledger/indy-hipe/blob/2c3a264963183237e5dfa962fbfd97c8d8da780f/text/rich-schemas/README.md\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 23rd April, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Review and discuss Rich Schema PR prior to HIPE submission ( @brentzundel ) - 45 mins\n- Reference - https://github.com/hyperledger/indy-hipe/pull/119\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-04-22T10:22:35.787Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, April 30th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-04-23T20:34:32.241Z"}
{"msg":"Has joined the channel.","username":"SethiSaab","ts":"2019-04-24T15:53:30.077Z","type":"uj"}
{"msg":"We moved tool presenting ODCA concept from github into bitbucket where we would continue work. We already created tickets there to let others contribute and follow the progress. if you have any wishes or ideas for features or issues please feel free to create new ticket or drop us message here.\n\nThe bitbucket would allow us to connect repo to pipelines and soon the tool should be available under domain where people can take a look on the tool without need to fetch the code. \n\nStay tuned! \nhttps://bitbucket.org/dativa4data/odcatool/ ","username":"mtfk","ts":"2019-04-25T20:48:27.274Z"}
{"msg":"@mtfk  I'm super excited to tackle the IPFS integration!  Can you explain a bit more this concept of the DRI being used to access different layers? I think example would be particularly helpful for me.","username":"phoniks","ts":"2019-04-25T22:37:02.168Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=9sLHA3TuSizAKXWMp) @phoniks I would suggest to start here: https://drive.google.com/drive/folders/1VslH6Wy4WQbGzZ1uAcWFWE1mpkq03drP \nI talked about that concept on one of our calls. Basically DRI could be implement in different ways for example magnet link is pretty good one. CID and multihash is as well quite good. The idea of DRI to have it cross network and not only IPFS or swarm. ","username":"mtfk","ts":"2019-04-26T04:14:47.784Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=9sLHA3TuSizAKXWMp","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=9sLHA3TuSizAKXWMp","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Another approach would be to use DID and latest spec with content id. the spec is still in progress but sound like it could fit into our vision of DRI ","username":"mtfk","ts":"2019-04-26T04:15:57.602Z"}
{"msg":"For know to keep it simple IPFS sounds like a good shoot to try it out. ","username":"mtfk","ts":"2019-04-26T04:16:25.630Z"}
{"msg":"so we need simple JS API which allow us to publish and fetch JSON-LD files ( and structures) to/from IPFS","username":"mtfk","ts":"2019-04-26T04:16:58.079Z"}
{"msg":"Here you would find some materials: https://github.com/THCLab/DRI/ ","username":"mtfk","ts":"2019-04-26T04:25:55.967Z"}
{"msg":"Awesome.  Thanks Robert!","username":"phoniks","ts":"2019-04-26T04:39:44.412Z"}
{"msg":"I'll take a deep dive into this material over the weekend and see if I can take some first steps...","username":"phoniks","ts":"2019-04-26T04:40:49.911Z"}
{"msg":"@phoniks @mtfk I've just uploaded the latest ODCA paper and deck to the following shared area. https://drive.google.com/drive/u/0/folders/1-Q3CBSYXlRNEvTu7XQfGo-6W5H_yyOA3","username":"pknowles","ts":"2019-04-26T11:18:36.687Z"}
{"msg":"First draft of paper: \"Overlays Data Capture Architecture (ODCA): Providing a standardized global solution for data capture and exchange\". Constructive feedback welcome. https://drive.google.com/drive/u/0/folders/1-Q3CBSYXlRNEvTu7XQfGo-6W5H_yyOA3 ","username":"pknowles","ts":"2019-04-26T15:43:32.267Z"}
{"msg":"Has joined the channel.","username":"VipinB","ts":"2019-04-26T20:57:24.919Z","type":"uj"}
{"msg":"Has joined the channel.","username":"troyronda","ts":"2019-04-27T17:52:09.866Z","type":"uj"}
{"msg":"@VipinB [cont. from #indy channel] A schema base provides a standard base from which to decentralize data and, as such, all PII attributes have to be flagged in that base object. If, for example, an issuer were to publish a schema base having failed to flag a PII attribute, a new version would have to be created in order to flag that attribute as sensitive and that new version would inevitably become the standard. In other words, that refinement would not be done via an overlay. Other than that, you're spot on. Attribute names and types from a referenced source such as schema.org can be embedded into a schema base. I'd love to see schema.org flagging PII attributes at their end but that might be a tough sell. In any case, the PII schema object will remain an integral part of schema base functionality. There are also some neat catches that we can provide to a schema issuer. For instance, you'll notice that \"Free-Form Text Fields / Unstructured Data\" is a BIT element. That allows us to apply some deep logic in the foundational code to warn the issuer of any attributes that will be treated as unstructured data fields prior to publishing. Here, if an attribute has a data type of \"Text\" defined in the schema base and a linked entry overlay has not been used to add predefined field values to that attribute, it would be treated as a \"Free-Form Text Field\" and subsequently flagged as a PII attribute. If we were to let that slide, there would be a privacy risk as an end user would be able to potentially enter PII information into that text field (I reckon a \"Ban all free-form text fields!\" working group would be oversubscribed! 🙂). Although there is nothing stopping a schema issuer from publishing a schema base as a stand alone object, I would strongly advocate that, at the very least, an entry overlay be constructed to accompany that object at the time of initial publish. [Cc: @mtfk ]","username":"pknowles","ts":"2019-04-28T04:31:10.625Z"}
{"msg":"@VipinB [cont. from #indy channel] A schema base provides a standard base from which to decentralize data and, as such, all PII attributes have to be flagged in that base object. If, for example, an issuer were to publish a schema base having failed to flag a PII attribute, a new version would have to be created in order to flag that attribute as sensitive and that new version would inevitably become the standard. In other words, that refinement would not be done via an overlay. Other than that, you're spot on. Attribute names and types from a referenced source such as schema.org can be embedded into a schema base. I'd love to see schema.org flagging PII attributes at their end but that might be a tough sell. In any case, the PII schema object will remain an integral part of schema base functionality. There are also some neat catches that we can provide to a schema issuer. For instance, you'll notice that \"Free-Form Text Fields / Unstructured Data\" is a BIT element. That allows us to apply some deep logic in the foundational code to warn the issuer of any attributes that will be treated as unstructured data fields prior to publishing. Here, if an attribute has a data type of \"Text\" defined in the schema base and a linked entry overlay has not been used to add predefined field values to that attribute, it would be treated as a \"Free-Form Text Field\" and subsequently flagged as a PII attribute. If we were to let that slide, there would be a privacy risk as an end user would be able to potentially enter PII information into that text field. Although there is nothing stopping a schema issuer from publishing a schema base as a stand alone object, I would strongly advocate that, at the very least, an entry overlay be constructed to accompany that object at the time of initial publish. [Cc: @mtfk ]","username":"pknowles","ts":"2019-04-28T04:31:10.625Z"}
{"msg":"Has joined the channel.","username":"stone-ch","ts":"2019-04-28T06:00:33.386Z","type":"uj"}
{"msg":"@pknowles are there any implementations of this? Or is it just a proposal? The BIT comes from the Kanatara Initiative? Are there known schemas currently used in the Enterprise for Identity capture, Authentication, Authorization other than what comes from Schema.org (Person) that refer to those PII-Attributes?  Do you have any references for these? Thanks for moving discussion here.","username":"VipinB","ts":"2019-04-28T10:38:53.140Z"}
{"msg":"@pknowles are there any implementations of this? Or is it just a proposal? The BIT comes from the Kanatara Initiative. Do they have schemas for Identity, Identity scoring etc.  Are there known schemas currently used in the Enterprise for Identity capture, Authentication, Authorization other than what comes from Schema.org (Person) that we could qualify using pii-attributes?  Do you have any references for these? Thanks for moving discussion here.","username":"VipinB","ts":"2019-04-28T10:38:53.140Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=zPDg4Fi3YGBG5vfYa) @VipinB We performed a command line \"Overlays\" demo at IIW back in May 2018 to some great feedback. Following detailed input from the Hyperledger Indy Semantics WG and the Hyperledger Technical Ambassadors, we are now in the process of developing the ODCA middleware tooling in the Dativa Innovation Hub [ https://www.dativa.com/innovation-hub/ ]. The final tool will be white labelled, open source, free to use with no IP. It looks like we'll be working with Roche Pharmaceuticals and Roche Diagnostics for the the first two pilots. We're also applying for grants to help fund the ODCA initiative. It feels like we're beyond the conceptual phase now and into the early pilot phase although there is still a lot of coding to be done. I spearheaded the BIT initiative following lengthy discussions with Elizabeth Renieris at the same edition of IIW. The first version of the BIT was published in early September [ https://www.dativa.com/blinding-identity-taxonomy/ ] and, soon after, I donated it to Kantara Initiative. The latest version of the BIT is housed with the Consent & Information Sharing WG at Kantara Initiative as a work in progress. The BIT has remained stable for the past 3 months but it is not an official standard yet. Regarding Kantara, I'll check with @AndrewHughes3000 to see if they have (or know of any) schemas for Identity, Identity scoring, Identity capture, Authentication or Authorization that we could qualify using pii-attributes. I'll get back to you once I have an answer. In the meantime, here is a nice quote from Colin Wallis, Kantara's Executive Director, regarding the BIT: \" _The BIT is one of those critical pieces of behind-the-scenes plumbing that is expected to fundamentally improve data protection of personal data as deployment rates in both traditional and distributed ledger technology (DLT) domains rise._ \"","username":"pknowles","ts":"2019-04-28T12:51:50.290Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=zPDg4Fi3YGBG5vfYa","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=zPDg4Fi3YGBG5vfYa","remote":true,"fileId":null,"fileName":null}]}
{"msg":"@pknowles thanks for the detailed answer. I am poking around  https://bitbucket.org/dativa4data/odcatool/. Elizabeth Reneiris is a friend (at least I like to think so), and I have appreciated her clear thinking around privacy topics. I have also written on medium (https://medium.com/@vipinsun/security-privacy-in-the-age-of-surveillance-6a0fbeae97d4) on the subject of Privacy, more from a 4th Amendment point of view, but I look at some remedies (Combination Therapy) and appropriate technology is definitely one of the tools needed in Combination Therapy. I think BIT is very important- I assume you are going to be at this year's IIW.  I wont be there, but will be hosting Drummond and possibly Nathan on May 1st at the Hyperledger Identity Working Group call for a recap. #identity-wg ...  Looking forward to hearing from you. I  am reading some of the docs from Kantara Initiative on the topic as well. Any pointers on commonly used schemas (not just from kanatara) for Identity related work will be appreciated. We are writing a paper in HL IDWG on Identity and the Blockchain with specific reference to DLTs. As a cross-platform initiative, this is more like a survey of the field with references for a deeper dive targeted to generalists who are interested in Identity. ","username":"VipinB","ts":"2019-04-28T13:07:57.293Z"}
{"msg":"Has joined the channel.","username":"atomeel","ts":"2019-04-29T01:53:48.174Z","type":"uj"}
{"msg":"Has joined the channel.","username":"Unni_1994","ts":"2019-04-29T10:23:46.713Z","type":"uj"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 30th April, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles   \n\nAgenda:\n• Introductions (Open) - 5 mins\n• ID Proofing ( @mtfk ) - 40 mins\n• ODCA update ( @pknowles ) - 10 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-04-30T16:12:05.354Z"}
{"msg":"@mtfk  Are you suggesting that during Authorization, we do this decentralized surety (i.e. Authentication) every time we get granted. To be practical, we need some way to expose this to the relying party","username":"VipinB","ts":"2019-04-30T17:31:53.424Z"}
{"msg":"@mtfk  for mobile, you use the different phone only to contact the bad guy from a random address. The phone will be turned off with no battery during other times. ","username":"VipinB","ts":"2019-04-30T17:33:37.925Z"}
{"msg":"@mtfk  fascinating thought experiment","username":"VipinB","ts":"2019-04-30T17:41:48.524Z"}
{"msg":"@mtfk accumulators. ZKP of that private data etc. can be used instead of granular","username":"VipinB","ts":"2019-04-30T17:48:05.385Z"}
{"msg":"Accumulators like you mentioned .... ","username":"VipinB","ts":"2019-04-30T17:48:51.714Z"}
{"msg":"Negative is already happening like @mtfk ","username":"VipinB","ts":"2019-04-30T17:49:14.641Z"}
{"msg":"said","username":"VipinB","ts":"2019-04-30T17:49:18.832Z"}
{"msg":"Multifactor taken to polyfactor... great job @mfk","username":"VipinB","ts":"2019-04-30T17:51:00.420Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=vAh5p2i7uqAmXh6ug) There is no need to do the whole process each time. You can imagine that you have to provide proofs (randomly choose by versifier) from yesterday, last week and 5 months ago. You digital wallet could store those proofs in a form of verifiable credentials of some sort. So it would be quite simple and fast process. ","username":"mtfk","ts":"2019-04-30T18:49:47.730Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=vAh5p2i7uqAmXh6ug","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=vAh5p2i7uqAmXh6ug","remote":true,"fileId":null,"fileName":null}]}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, May 14th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-04-30T18:49:49.496Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=d3TQMRpRuawGuaNK2) @VipinB of course in that case would be hard to track it as there won't be correlation but if you calling to same guy all the time they can find out who is this guy (if he does not do as you do) if he does you have a problem of exchanging phone numbers anyway). But yes there are some cases where you could hide if you know how. ","username":"mtfk","ts":"2019-04-30T18:51:22.749Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=d3TQMRpRuawGuaNK2","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=d3TQMRpRuawGuaNK2","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=ZsXB7yH9Zuoi6EsTT) The point here is that more signals you have stronger identity you posses. - more trustworthy you are. That is where this decentralized identity comes handy as the artifacts are distributed quite well and you can be quite secure. ","username":"mtfk","ts":"2019-04-30T18:56:17.530Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=ZsXB7yH9Zuoi6EsTT","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=ZsXB7yH9Zuoi6EsTT","remote":true,"fileId":null,"fileName":null}]}
{"msg":"For any *Indy Semantics WG* folks out at *IIW* this week ... Please reach out to @phoniks who will be presenting the ODCA tomorrow. [My much older brother, @darrell.odonnell is definitely out there!]","username":"pknowles","ts":"2019-04-30T19:42:49.656Z"}
{"msg":"For any *Indy Semantics WG* folks out at *IIW* this week, please reach out to @phoniks who will be presenting the ODCA tomorrow. [My much older brother, @darrell.odonnell is definitely out there!]","username":"pknowles","ts":"2019-04-30T19:42:49.656Z"}
{"msg":"For any *Indy Semantics WG* folks out at *IIW* this week, please reach out to @phoniks who will be presenting the *ODCA* tomorrow. [My much older brother, @darrell.odonnell is definitely out there!]","username":"pknowles","ts":"2019-04-30T19:42:49.656Z"}
{"msg":"For any *Indy Semantics WG* folks out at *IIW* this week, please reach out to @phoniks who will be presenting *ODCA* tomorrow. [My much older brother, @darrell.odonnell is definitely out there!]","username":"pknowles","ts":"2019-04-30T19:42:49.656Z"}
{"msg":"For any *Indy Semantics WG* folks out at *IIW* this week, please reach out to @phoniks who will be presenting *ODCA* tomorrow. [My much older brother @darrell.odonnell is definitely out there!]","username":"pknowles","ts":"2019-04-30T19:42:49.656Z"}
{"msg":"Has joined the channel.","username":"richzhao","ts":"2019-04-30T22:07:47.849Z","type":"uj"}
{"msg":"There's discussion going on here at IIW about using DIDs in git, which feels like it has an application in storing overlays in a secure. Also, @darrell.odonnell come find me! I'm wearing a dark side of the moon t-shirt.","username":"phoniks","ts":"2019-05-01T19:00:36.238Z"}
{"msg":"There's discussion going on here at IIW about using DIDs in git, which feels like it has an application in storing overlays in a secure and audit-able manner. Also, @darrell.odonnell come find me! I'm wearing a dark side of the moon t-shirt.","username":"phoniks","ts":"2019-05-01T19:00:36.238Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=sjFFK9sH7afwwywb7) @phoniks Thanks for the update. If you can find out as much information as possible regarding that application, that would be great. Perhaps you can then give a short presentation during an upcoming *Indy Semantics WG*. You're my eyes and ears at IIW this year!","username":"pknowles","ts":"2019-05-01T19:29:42.064Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=sjFFK9sH7afwwywb7","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=sjFFK9sH7afwwywb7","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=sjFFK9sH7afwwywb7) @phoniks Thanks for the update. If you can find out as much information as you can regarding that proposed application, that would be great. Perhaps you can give a short presentation during an upcoming *Indy Semantics WG*. You're my eyes and ears at IIW this year!","username":"pknowles","ts":"2019-05-01T19:29:42.064Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=sjFFK9sH7afwwywb7","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=sjFFK9sH7afwwywb7","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=sjFFK9sH7afwwywb7) @phoniks Thanks for the update. If you can find out as much information as you can regarding that proposed application, that would be great. Perhaps you can give a short presentation during an upcoming *Indy Semantics WG*. You're my eyes and ears at *IIW* this year!","username":"pknowles","ts":"2019-05-01T19:29:42.064Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=sjFFK9sH7afwwywb7","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=sjFFK9sH7afwwywb7","remote":true,"fileId":null,"fileName":null}]}
{"msg":"@pknowles There's a board up for people to post info on working groups.  When are the Indy Semantics WG calls held (both so I can post it on the board, and also so I can jump on them).","username":"phoniks","ts":"2019-05-01T21:22:25.730Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=SnkM4LFPrPESMXer9) @phoniks Every other Tuesday at 10am-11.15am PT / 1pm-2.15pm ET / 6pm-7.15pm GMT. The next one is on Tuesday, May 14th.","username":"pknowles","ts":"2019-05-01T21:41:26.377Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=SnkM4LFPrPESMXer9","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=SnkM4LFPrPESMXer9","remote":true,"fileId":null,"fileName":null}]}
{"msg":"A note about the Hyperledger Aries launch, since this group spans ledger and protocol you may be wondering which project will host this effort.  Because Aries is ledger agnostic, it can support alternative data models, meaning this effort will stay inside Indy with effort in Aries for protocol support.  I expect it will stay an Indy effort and coordinate with Aries.","username":"nage","ts":"2019-05-03T01:42:30.149Z"}
{"msg":"So, one of the most exciting things to come out of IIW this year was the 1st draft spec for a did:git method. The idea is basically to use the git repository as a source of truth about its contents, and its contributors. Interestingly, it also includes support for a governance file that would define the rules for how maintainers could be added, and how releases were issued (with multi sig).  Now, maybe I'm getting a bit ahead of myself - I'll admit to not fully understanding either overlays, or this DID method completely yet - but I wonder if anyone else sees this as an ideal way to manage overlays.  My thinking is that if a consortium of businesses wishes to maintain a common set of overlays they could decide on a governance scheme and then collectively manage a git repo using this method.  So I'm curious, do people see value in this application of the did:git method?  Is it the sort of thing that the ODCA tool should include? @mtfk - I'm particularly interested in your take.","username":"phoniks","ts":"2019-05-08T15:19:11.501Z"}
{"msg":"here's a link to the repo: https://github.com/dhuseby/did-git-spec","username":"phoniks","ts":"2019-05-08T15:24:29.929Z"}
{"msg":"@dhuseby","username":"Silona","ts":"2019-05-08T15:50:15.857Z"}
{"msg":"Has joined the channel.","username":"dhuseby","ts":"2019-05-08T15:50:15.989Z","type":"uj"}
{"msg":"So @dhuseby is on vacation so no internet but he'll love this when he gets back for now @nage ?","username":"Silona","ts":"2019-05-08T15:51:02.226Z"}
{"msg":"@silona @dhuseby Thanks for joining the #indy-semantics channel. If you both DM your email addresses to me, I'll add you to the *Indy Semantics WG* calendar invites. We would love David to talk about the /did:git/ method on a WG call soon. In the meantime, I've stored the *ODCA paper* in the following HL shared area. I'm excited to see what sort of traction there is here. https://drive.google.com/drive/u/0/folders/1-Q3CBSYXlRNEvTu7XQfGo-6W5H_yyOA3","username":"pknowles","ts":"2019-05-08T16:20:04.613Z"}
{"msg":"@Silona @dhuseby Thanks for joining the #indy-semantics channel. If you both DM your email addresses to me, I'll add you to the *Indy Semantics WG* calendar invites. We would love David to talk about the /did:git/ method on a WG call soon. In the meantime, I've stored the *ODCA paper* in the following HL shared area. I'm excited to see what sort of traction there is here. https://drive.google.com/drive/u/0/folders/1-Q3CBSYXlRNEvTu7XQfGo-6W5H_yyOA3","username":"pknowles","ts":"2019-05-08T16:20:04.613Z"}
{"msg":"@Silona @dhuseby Thanks for joining the #indy-semantics channel. If you both DM your email addresses to me, I'll add you to the *Indy Semantics WG* calendar invites. We would love David to talk about the `did:git` method on a WG call soon. In the meantime, I've stored the *ODCA paper* in the following HL shared area. I'm excited to see what sort of traction there is here. https://drive.google.com/drive/u/0/folders/1-Q3CBSYXlRNEvTu7XQfGo-6W5H_yyOA3","username":"pknowles","ts":"2019-05-08T16:20:04.613Z"}
{"msg":"@Silona @dhuseby Thanks for joining the #indy-semantics channel. If you both DM your email addresses to me, I'll add you to the *Indy Semantics WG* calendar invites. We would love David to talk about the `did:git` method on an upcoming semantics call. In the meantime, I've stored the *ODCA paper* in the following HL shared area. I'm excited to see what sort of traction there is here. https://drive.google.com/drive/u/0/folders/1-Q3CBSYXlRNEvTu7XQfGo-6W5H_yyOA3","username":"pknowles","ts":"2019-05-08T16:20:04.613Z"}
{"msg":"@Silona @dhuseby Thanks for joining the #indy-semantics channel. If you both DM your email addresses to me, I'll add you to the *Indy Semantics WG* calendar invites. We would love David to talk about the `did:git` method during an upcoming semantics call. In the meantime, I've stored the *ODCA paper* in the following HL shared area. I'm excited to see what sort of traction there is here. https://drive.google.com/drive/u/0/folders/1-Q3CBSYXlRNEvTu7XQfGo-6W5H_yyOA3","username":"pknowles","ts":"2019-05-08T16:20:04.613Z"}
{"msg":"@Silona & @dhuseby I'm prepping a PR against the `did:git` spec right now adding this as a possible motivation.","username":"phoniks","ts":"2019-05-08T19:05:34.386Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=BcE35DgAYbWG4nv5F) How are you planning to resolve DID on git? ","username":"mtfk","ts":"2019-05-08T19:32:58.488Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=BcE35DgAYbWG4nv5F","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=BcE35DgAYbWG4nv5F","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Another issue which could be problematical is that actually git is not immutable. You can easily override the history of the git and then you depend how many honest copies are on the network. Or you go \"centralized\" path and say that github account holding this repo is the only place of truth.  ","username":"mtfk","ts":"2019-05-08T19:37:06.750Z"}
{"msg":"Of course the commit ID is immutable (almost impossible to get collision) but it means that if someone (even accidentally override the git history) you won't be able to resolve that specific commit anymore.  ","username":"mtfk","ts":"2019-05-08T19:38:13.336Z"}
{"msg":"Because of above I would prefer solutions like IPFS and IPID for ODCA where you can create local swarm and connect everyone from consortium or just use public network to give access to anyone. ","username":"mtfk","ts":"2019-05-08T19:40:37.853Z"}
{"msg":"Has joined the channel.","username":"george.aristy","ts":"2019-05-08T19:41:19.486Z","type":"uj"}
{"msg":"The only missing part of the IPID is the connection with verified identity which is publishing that bit of content. ","username":"mtfk","ts":"2019-05-08T19:42:01.436Z"}
{"msg":"This what for example sovrin offering or in git spec  --signoff feature. ","username":"mtfk","ts":"2019-05-08T19:44:09.512Z"}
{"msg":"There is interesting work done on DID spec where actually you could combine any did compatible method with CID like ipfs hash or magnet link ","username":"mtfk","ts":"2019-05-08T19:44:58.714Z"}
{"msg":"Of course my favorite is DRI - decentralize resource identifier :) but not sure yet how this would be connected to verified identity. ","username":"mtfk","ts":"2019-05-08T19:45:58.456Z"}
{"msg":"I've just published the *ODCA paper* on medium.com for public consumption - https://medium.com/@paul.knowles_52509/overlays-data-capture-architecture-odca-providing-a-standardized-global-solution-for-data-caeb1679137a","username":"pknowles","ts":"2019-05-08T20:04:30.301Z"}
{"msg":"So the identity info is stored in-band. Essentially you'd have a `/repo/.git/dids` where you would store the DID docs.","username":"phoniks","ts":"2019-05-09T18:57:16.684Z"}
{"msg":"but where is the repo? Is it on github? Is it on my private server? How people can find this repo if they do not have it? ","username":"mtfk","ts":"2019-05-09T18:58:37.555Z"}
{"msg":"Currently if you want to share git with someone you need to give him access to the machine where it is (by hosting it or just give the access to the file system) ","username":"mtfk","ts":"2019-05-09T18:59:10.025Z"}
{"msg":"I think it's good to be flexible. so maybe you have a private git server or maybe you host it on IPFS, or maybe you do host it on github.  ","username":"phoniks","ts":"2019-05-09T19:03:48.719Z"}
{"msg":"I think the tool could pretty easily accommodate any of  those options","username":"phoniks","ts":"2019-05-09T19:05:28.039Z"}
{"msg":"Yes but how the did would resolve to specific DID doc if you do not know my address but just commit ID ? ","username":"mtfk","ts":"2019-05-09T19:07:02.822Z"}
{"msg":"ahhh, I see.  they're mapped in the dids directory","username":"phoniks","ts":"2019-05-09T19:08:08.932Z"}
{"msg":"so you have a genesis commit","username":"phoniks","ts":"2019-05-09T19:08:28.439Z"}
{"msg":"after which you treat the repo as immutable","username":"phoniks","ts":"2019-05-09T19:08:40.318Z"}
{"msg":"and sign the commits according to your governance plan","username":"phoniks","ts":"2019-05-09T19:08:51.521Z"}
{"msg":"where this did directory is stored? ","username":"mtfk","ts":"2019-05-09T19:08:54.257Z"}
{"msg":"where this did directory is stored/hosted? ","username":"mtfk","ts":"2019-05-09T19:08:54.257Z"}
{"msg":"it's part of the repo itself.  So where ever you host your repo.","username":"phoniks","ts":"2019-05-09T19:10:12.632Z"}
{"msg":"and the files are named as the PK of the DID","username":"phoniks","ts":"2019-05-09T19:11:15.003Z"}
{"msg":"ok another way here is example of the DID:\n`did:git:abcde12345` Which I shared with you ","username":"mtfk","ts":"2019-05-09T19:12:45.727Z"}
{"msg":"how you would get did document?","username":"mtfk","ts":"2019-05-09T19:12:50.501Z"}
{"msg":"\"The git did read operation will \"resolve\" the \"id\" by looking up the SHA1 hash of the commit that added the DID document to the repo and dynamically add the \"id\" member to what is rendered to the user.\"","username":"phoniks","ts":"2019-05-09T19:18:14.565Z"}
{"msg":"from the spec","username":"phoniks","ts":"2019-05-09T19:18:20.218Z"}
{"msg":"Yes but how you would look up the SHA1 hash if you do not know where repo is?","username":"mtfk","ts":"2019-05-09T19:19:08.753Z"}
{"msg":"for example if I have did:ipid:asdfgh1234 I know that I have to go to IPFS network and look up hash on the IPFS network \nif I have did:git:sha1 I have no idea where to check right? Or am I missing something?","username":"mtfk","ts":"2019-05-09T19:20:22.590Z"}
{"msg":"No I'm sure I'm the one that's missing something haha","username":"phoniks","ts":"2019-05-09T19:21:51.493Z"}
{"msg":"","username":"phoniks","ts":"2019-05-09T19:23:28.560Z","attachments":[{"type":"file","title":"Screen Shot 2019-05-09 at 12.22.54 PM 1.png","title_link":"/file-upload/4kPNRfrdgk65qm6gM/Screen%20Shot%202019-05-09%20at%2012.22.54%20PM%201.png","image_url":"/file-upload/4kPNRfrdgk65qm6gM/Screen%20Shot%202019-05-09%20at%2012.22.54%20PM%201.png","image_type":"image/png","image_size":247174,"url":"/file-upload/4kPNRfrdgk65qm6gM/Screen%20Shot%202019-05-09%20at%2012.22.54%20PM%201.png","remote":false,"fileId":"4kPNRfrdgk65qm6gM","fileName":"Screen Shot 2019-05-09 at 12.22.54 PM 1.png"}]}
{"msg":"The idea of the DID spec is that when you adding new method it explain how the did can be resolved. So where to look it up to get the did document. \nSome methods basically points you to specific network on which you can resolve the hash form did to a did document. For `sov` is sovrin network for `ipid` is IPFS for uport is the string it self. \n\nThe question is where I should look for this commit ID from `did:git` in order to get the did document ","username":"mtfk","ts":"2019-05-09T19:24:07.857Z"}
{"msg":"In many cases I could create my own repository and host it but then only myself is able to resolve it as I know where the git is stored.","username":"mtfk","ts":"2019-05-09T19:24:54.817Z"}
{"msg":"If I would like to share that repo with others I would need to share with them DID and the location of the repository ","username":"mtfk","ts":"2019-05-09T19:25:13.971Z"}
{"msg":"which makes it quite centralized solution and error prone ","username":"mtfk","ts":"2019-05-09T19:25:29.761Z"}
{"msg":"of course you could always choose github which is public repository which anybody can use to resolve it ","username":"mtfk","ts":"2019-05-09T19:25:47.368Z"}
{"msg":"but then it should not be called `did:git` but `did:github` ","username":"mtfk","ts":"2019-05-09T19:26:00.098Z"}
{"msg":"`did:github` exists I believe","username":"phoniks","ts":"2019-05-09T19:26:37.563Z"}
{"msg":"https://w3c-ccg.github.io/did-method-registry/","username":"mtfk","ts":"2019-05-09T19:27:45.670Z"}
{"msg":"for sure not here ","username":"mtfk","ts":"2019-05-09T19:27:50.304Z"}
{"msg":"of course git spec would make sens for some specific use cases like  company base did repository or something ","username":"mtfk","ts":"2019-05-09T19:28:31.596Z"}
{"msg":"but this needs to be clear from the beginning how and where it is hosted ","username":"mtfk","ts":"2019-05-09T19:28:43.073Z"}
{"msg":"because that way it won't be much different from DNS base one as you would always need to use some domains to point to the server ","username":"mtfk","ts":"2019-05-09T19:29:13.035Z"}
{"msg":"you would just get extra features of git how to actually store and track did document ","username":"mtfk","ts":"2019-05-09T19:29:39.126Z"}
{"msg":"Right, so the usecase I'm thinking of is a consortium where presumably you do agree on that in advance","username":"phoniks","ts":"2019-05-09T19:31:18.189Z"}
{"msg":"and the benefit I think is the ability to add a lightweight governance mechanism to the management of shared overlays","username":"phoniks","ts":"2019-05-09T19:31:55.859Z"}
{"msg":"@dhuseby will be able to highlight this approach better when he's back from vacation. I believe the intent is to operate in a p2p fashion and would therefore not define a discovery mechanisms like other DID methods. This is similar to how the DID:peer method is working. A DID method is not required to be discoverable. As an example, a 10.0.* IP address is not globally resolvable. I can only discover it when I'm on a local network. Another example is if I host a local intranet domain and let my local DNS server handle the resolving I can discover it (which would likely resolve to a local IP). However, if I operate on a different network outside the local network, I cannot resolve the domain, and therefore cannot find the IP.","username":"kdenhartog","ts":"2019-05-09T19:38:07.208Z"}
{"msg":"thanks.  I was just about to mention did peer, but that explanation is very illuminating, for me at least.","username":"phoniks","ts":"2019-05-09T19:41:33.550Z"}
{"msg":"Even if you operate with p2p fashion you still need to define how to resolve it. If you assume that it is local repository or local ip, dns what ever it would be need to be part of the spec. The good example of resolution process is this what the guys from uport did with their DID. You can compose did document directly from the string within DID so you don't have to reach any server, place, location. Just build it from there. Of course it is very limiting but it shows how flexible did spec is. \n\nHere in case of p2p communication fashion you could do similar things all depends how you would like to design it.  If you assume that it is always localhost, would be fine as well. \n\nBut this part needs to be clearly specify in the spec. Because if you assume that anyone can define their own location then it should be part of the DID (e.g. encoded within the string SHA1(SHA1+location) or something like that. Does that make any sense? ","username":"mtfk","ts":"2019-05-09T19:58:26.468Z"}
{"msg":"And back to the main question if this would make sens for ODCA, it could if there is close repository of ODCA and nobody from outside can use it. ","username":"mtfk","ts":"2019-05-09T19:59:45.241Z"}
{"msg":"I always try to think about ODCA objects in a way that they have two properties:\n- immutable (like ipfs hash)\n- source verifiable (verify who issued it if I can trust it - like DID)  ","username":"mtfk","ts":"2019-05-09T20:01:25.687Z"}
{"msg":"In the method spec it says \"The git did read operation will \"resolve\" the \"id\" by looking up the SHA1 hash of the commit that added the DID document to the repo and dynamically add the \"id\" member to what is rendered to the user.\"","username":"kdenhartog","ts":"2019-05-09T20:01:27.840Z"}
{"msg":"Yep, how I could know where the repo is? Is it part of the spec somewhere? ","username":"mtfk","ts":"2019-05-09T20:02:34.349Z"}
{"msg":"For example I could have multiple repositories (each for department) ","username":"mtfk","ts":"2019-05-09T20:03:06.803Z"}
{"msg":"No knowing the location is relevant to discovery. Knowing how to resolve is orthogonal. I do think resolution will require better detail though.","username":"kdenhartog","ts":"2019-05-09T20:03:16.817Z"}
{"msg":"By that I mean, I can go through the resolution algorithm, but because I don't have access to the location of the DID Doc I cannot discover it.","username":"kdenhartog","ts":"2019-05-09T20:04:42.057Z"}
{"msg":"Similar to how I can know the domain of the intranet domain, but not able to access the server.","username":"kdenhartog","ts":"2019-05-09T20:05:00.687Z"}
{"msg":"You are right the resolution process is clearly defined. The question is how base on this description someone could implement it e.g. in Digital Wallet. ","username":"mtfk","ts":"2019-05-09T20:06:21.123Z"}
{"msg":"There would be good to have clear specification about the discovery process and how to transport information about it together with DID ","username":"mtfk","ts":"2019-05-09T20:07:00.826Z"}
{"msg":"It would be good to have clear specification about the discovery process and how to transport information about it together with DID ","username":"mtfk","ts":"2019-05-09T20:07:00.826Z"}
{"msg":"It would be good to have clear specification about the discovery process and how to transport information about where to look for it together with DID ","username":"mtfk","ts":"2019-05-09T20:07:00.826Z"}
{"msg":"I'm not sure discovery is relevant. Similar to how the peer did method spec doesn't specify how to cache, and lookup in cache to resolve a DID Doc.","username":"kdenhartog","ts":"2019-05-09T20:08:56.268Z"}
{"msg":"It's up to the implementers to define these aspects I believe. @dhuseb","username":"kdenhartog","ts":"2019-05-09T20:09:27.065Z"}
{"msg":"It's up to the implementers to define these aspects I believe. @dhuseby may have other ideas though.","username":"kdenhartog","ts":"2019-05-09T20:09:27.065Z"}
{"msg":"The closest the peer DID method spec comes to defining this is \"by sending a state_request message from one peer to another\"","username":"kdenhartog","ts":"2019-05-09T20:11:05.068Z"}
{"msg":"However this doesn't mean that if I send this message to a random server that they must send me back a DID Doc. The resolution would fail instead.","username":"kdenhartog","ts":"2019-05-09T20:11:40.776Z"}
{"msg":"Similar to if I send a DNS request to a random web server, I shouldn't expect it to send a proper reply back.","username":"kdenhartog","ts":"2019-05-09T20:12:04.753Z"}
{"msg":"Don't you think that leaving that part to the implementer won't introduce any problems? \n\nWith my understanding is similar to the example where I could take `did:sov` and implement it in a way that it always resolve against my own test sovrin network. Means that if someone would take it would not be able to resolve it unless they use my implementation.","username":"mtfk","ts":"2019-05-09T20:13:27.982Z"}
{"msg":"yeah that's how it works right now. This is with good intention, it allows for extensibility.","username":"kdenhartog","ts":"2019-05-09T20:14:19.360Z"}
{"msg":"For example in a network of networks design, I may want to support many networks that have different DSTF. In this case, I would likely resolve to the genesis_txn_file I have on hand a gensis txn file for a specific network (defined as did:sov:network:id) and then I would resolve the ID from that specific network.","username":"kdenhartog","ts":"2019-05-09T20:17:05.909Z"}
{"msg":"The only network I've heard that specifies to a specific ledger is the sidetree did method for BTC and that's so that it can specify to a certain fork. If another fork occurs, they plan to update which fork the method should resolve to.","username":"kdenhartog","ts":"2019-05-09T20:18:45.141Z"}
{"msg":"So following that lead it could be something like \ndid:git:SHA1?location=localhost\nor \ndid:git:SHA1?location=github.com/did/repo","username":"mtfk","ts":"2019-05-09T20:20:04.099Z"}
{"msg":"just skip the syntax as it is not correct probably with that what is so far used in the did spec","username":"mtfk","ts":"2019-05-09T20:20:24.751Z"}
{"msg":"the point is that did through params could help you out to find out where to look on it ","username":"mtfk","ts":"2019-05-09T20:20:52.602Z"}
{"msg":"I don't think specifying location is necessary. Rather I need to know which resolver to ask so that I can discover it.","username":"kdenhartog","ts":"2019-05-09T20:21:16.267Z"}
{"msg":"By specifying to a specific location how do I know which localhost you're referring to?","username":"kdenhartog","ts":"2019-05-09T20:21:36.638Z"}
{"msg":"as it my localhost or yours?","username":"kdenhartog","ts":"2019-05-09T20:21:43.271Z"}
{"msg":"the point is that params helping you out to find it if that would be through resolver or direct path that could be open to the debate ","username":"mtfk","ts":"2019-05-09T20:22:47.978Z"}
{"msg":"but you are right context is quite important as location does not work if you loose the location ","username":"mtfk","ts":"2019-05-09T20:23:15.783Z"}
{"msg":"but you are right context is quite important as location does not work if you loose the context","username":"mtfk","ts":"2019-05-09T20:23:15.783Z"}
{"msg":"having just relative path should work as soon as you are aware of that you should have that git repo with you","username":"mtfk","ts":"2019-05-09T20:23:46.276Z"}
{"msg":"So you could imagine that within the company each digital wallet by default fetch did directory ","username":"mtfk","ts":"2019-05-09T20:24:02.077Z"}
{"msg":"We may store the exact same git repo locally, but that doesn't mean that my version is the same as your version. Just that they once were based on the same probabilistically. (I say that because sha1 isn't believe to be perfectly collision resistant anymore.)","username":"kdenhartog","ts":"2019-05-09T20:24:11.204Z"}
{"msg":"and then in p2p manner everyone can resolve each did within the company ","username":"mtfk","ts":"2019-05-09T20:24:13.668Z"}
{"msg":"yup, this is in line with what I'm thinking.","username":"kdenhartog","ts":"2019-05-09T20:24:34.317Z"}
{"msg":"However it's not the location that's relevant. It's which resolver that you ask that is.","username":"kdenhartog","ts":"2019-05-09T20:24:59.528Z"}
{"msg":"Similarly, if I live in China and type in a banned website it doesn't resolve.","username":"kdenhartog","ts":"2019-05-09T20:25:23.363Z"}
{"msg":"That resolvablility isn","username":"kdenhartog","ts":"2019-05-09T20:25:41.355Z"}
{"msg":"That resolvability isn't because the domain doesn't exist, but rather because the dns doesn't have a record to resolve to an IP.","username":"kdenhartog","ts":"2019-05-09T20:25:41.355Z"}
{"msg":"China may not be the best example because I think they ban on IP rather than dns lookup, but they may do both.","username":"kdenhartog","ts":"2019-05-09T20:26:57.594Z"}
{"msg":"yep, you are right, for me right now in my mind location = place where I can get what I need (in that case did doc) if that would be done through resolver mechanism or just pointing it directly either way should be fine. ","username":"mtfk","ts":"2019-05-09T20:27:46.395Z"}
{"msg":"For example you could host your git on IPFS :) and point to the ipfs://asd910jd912jd91jd192 d which would be ipns ","username":"mtfk","ts":"2019-05-09T20:28:23.477Z"}
{"msg":"Yeah, that nuance took me awhile to discover. Again Dave may have other thoughts about it, but this is how I've thought about it because it's how the peer method spec works.","username":"kdenhartog","ts":"2019-05-09T20:28:41.259Z"}
{"msg":"yup, I actually like the idea of hosting git repos on ipfs too.","username":"kdenhartog","ts":"2019-05-09T20:29:08.157Z"}
{"msg":"I think that's a pretty exciting possibility as well","username":"phoniks","ts":"2019-05-09T20:31:26.140Z"}
{"msg":"again instead of IPFS I would love to use something like DRI :) Which could support any decentralized storage but that another long discussion :) ","username":"mtfk","ts":"2019-05-09T20:33:24.276Z"}
{"msg":"Guys in did spec WG discussion about content_id parameter which actually could server that purpose so maybe DID would have that build in automatically ","username":"mtfk","ts":"2019-05-09T20:33:49.404Z"}
{"msg":"I haven't heard of DRI. do you have a link to more details about this?","username":"kdenhartog","ts":"2019-05-09T20:34:07.043Z"}
{"msg":"actually I'm curious about that. would you consider a DRI a type of multiaddress?","username":"phoniks","ts":"2019-05-09T20:34:13.059Z"}
{"msg":"DRI is a Decentralized Resource Identifier - it is my attempt to address need to be able to use content identifiers across different decentralize networks (like swarm, ipfs, torrent etc..) similar what magnet link is doing with mutlihashes ","username":"mtfk","ts":"2019-05-09T20:36:14.296Z"}
{"msg":"Got a spec I can read?","username":"kdenhartog","ts":"2019-05-09T20:36:39.153Z"}
{"msg":"There is presentation which I did recently on semantic call, let me fetch the link ","username":"mtfk","ts":"2019-05-09T20:37:17.545Z"}
{"msg":"Here some materials with the deck which I used for presentation: https://github.com/THCLab/DRI/","username":"mtfk","ts":"2019-05-09T20:38:10.606Z"}
{"msg":"https://drive.google.com/drive/folders/1VslH6Wy4WQbGzZ1uAcWFWE1mpkq03drP","username":"mtfk","ts":"2019-05-09T20:39:24.208Z"}
{"msg":"and here the recording from the call ","username":"mtfk","ts":"2019-05-09T20:39:31.298Z"}
{"msg":"and in the context did p2p I think you could be interested as well into ID proofing - https://drive.google.com/drive/folders/1Deb8JZ0VoMpYqXMEWpRKomWYbADqp86j \n\nwe are trying to work out on the new approach to the identity in truly decentralize manner by monitoring signals and impact within environment instead of looking on specific issued credentials. ","username":"mtfk","ts":"2019-05-09T20:43:43.679Z"}
{"msg":"@mtfk can you draw a distinction between DRIs and multiaddresses?  https://multiformats.io/multiaddr/","username":"phoniks","ts":"2019-05-09T21:31:35.514Z"}
{"msg":"I would say that multiaddress sits layer above DRI, DRI is much more closer to the CID/Multihash from IPFS (if not same thing). basically DRI is just an attempt to trigger discussion how to solve problem of different content addresses formats. And important part here is that we are operating here only within the space of Content Base network. So we are looking for content not the location.  ","username":"mtfk","ts":"2019-05-09T21:43:26.618Z"}
{"msg":"The idea is to have CID for each ODCA object which then can be served on multiple decentralized networks  which is not controlled by anyone. Same like with IPFS object as soon as there is someone willing to host the file it never disappear. It comes to this notion of UNIT of LANGUAGE. Which we discussed couple of times. Nobody should control the language and schema base object and overlays are meta language for data. ","username":"mtfk","ts":"2019-05-09T21:45:12.420Z"}
{"msg":"Okay I think I'm starting to understand.","username":"phoniks","ts":"2019-05-10T01:36:12.570Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 14th May, 2019\n\nNote that there have been some clock changes around the globe. Here are the times for this week:\n\n11am-12.15am PT\n12pm-13.15pm MT\n1pm-2.15pm CT\n2pm-3.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @kenebert  \n\nAgenda:\n• Introductions (Open) - 5 mins\n•  Breaking down an Informed Consent Form (ICF) into ODCA consent schema constructs\n( @janl ) - 35 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/7391019238\n\nOr iPhone one-tap : US: +16465588665,,7391019238# or +14086380986,,7391019238#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 7391019238","username":"pknowles","ts":"2019-05-14T15:44:15.141Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 14th May, 2019\n\nNote that there have been some clock changes around the globe. Here are the times for this week:\n\n11am-12.15am PT\n12pm-13.15pm MT\n1pm-2.15pm CT\n2pm-3.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @kenebert  \n\nAgenda:\n• Introductions (Open) - 5 mins\n•  Breaking down an Informed Consent Form (ICF) into ODCA consent schema constructs ( @janl ) - 35 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/7391019238\n\nOr iPhone one-tap : US: +16465588665,,7391019238# or +14086380986,,7391019238#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 7391019238","username":"pknowles","ts":"2019-05-14T15:44:15.141Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 14th May, 2019\n\nNote that there have been some clock changes around the globe. Here are the times for this week:\n\n11am-12.15pm PT\n12pm-13.15pm MT\n1pm-2.15pm CT\n2pm-3.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @kenebert  \n\nAgenda:\n• Introductions (Open) - 5 mins\n•  Breaking down an Informed Consent Form (ICF) into ODCA consent schema constructs ( @janl ) - 35 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/7391019238\n\nOr iPhone one-tap : US: +16465588665,,7391019238# or +14086380986,,7391019238#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 7391019238","username":"pknowles","ts":"2019-05-14T15:44:15.141Z"}
{"msg":"Wow, I have really fallen behind on this thread.  My idea was that the identifier would be based on the commit hash and that the DID Doc itself could contain the main public location of the repository as the service endpoint.  That way a repo could be self contained and tools could deal with permissioning or \"transaction validation\" locally.  This makes a git repo effectively into a full blockchain system with the main DID doc acting like the genesis or constitution block that can be used to process subsequent transactions","username":"nage","ts":"2019-05-14T19:17:41.412Z"}
{"msg":"New members of this channel would probably benefit from introductory presentations of the two main semantics initiatives currently being worked on by members of the _Indy Semantics WG_ , namely: (i.) the *Rich Schemas* work (Spearheaded by @kenebert / @brentzundel ) and the *Overlays data capture architecture* (ODCA) (Spearheaded by @pknowles / @mtfk ). Hit the :thumbsup: emoji if you agree with that proposal. If it looks like there is substantial interest, I'll schedule in two 1O1 sessions so that newbies can be brought up to speed.","username":"pknowles","ts":"2019-05-18T06:57:06.321Z"}
{"msg":"New members of this channel would probably benefit from introductory presentations of the two main semantics initiatives currently being worked on by members of the _Indy Semantics WG_ , namely: (i.) the *Rich Schemas* work (Spearheaded by @kenebert / @brentzundel ) and (ii.) the *Overlays data capture architecture* (ODCA) (Spearheaded by @pknowles / @mtfk ). Hit the :thumbsup: emoji if you agree with that proposal. If it looks like there is substantial interest, I'll schedule in two 1O1 sessions so that newbies can be brought up to speed.","username":"pknowles","ts":"2019-05-18T06:57:06.321Z"}
{"msg":"New members of this channel may benefit from introductory presentations of the two main semantics initiatives currently being worked on by members of the _Indy Semantics WG_ , namely: (i.) the *Rich Schemas* work (Spearheaded by @kenebert / @brentzundel ) and (ii.) the *Overlays data capture architecture* (ODCA) (Spearheaded by @pknowles / @mtfk ). Hit the :thumbsup: emoji if you agree with that proposal. If it looks like there is substantial interest, I'll schedule in two 1O1 sessions so that newbies can be brought up to speed.","username":"pknowles","ts":"2019-05-18T06:57:06.321Z"}
{"msg":"Has joined the channel.","username":"circlespainter","ts":"2019-05-18T07:36:48.794Z","type":"uj"}
{"msg":"Has joined the channel.","username":"jwow","ts":"2019-05-18T23:03:15.014Z","type":"uj"}
{"msg":"If you mean an interactive zoom session, I’m in Sydney (GMT+10) so time can be an issue.","username":"jwow","ts":"2019-05-18T23:07:39.593Z"}
{"msg":"Thanks for that.  I think I've a good understanding of what you're trying to accomplish but I still believe there are omissions that are critical for this to proceed.  My background comes from XBRL, a framework for exchanging financial or business information (XML based) utilised by many government agencies around the world.  Overall it is very similar to what you've described using the term \"linkbase\" rather than \"overlay\".  E.g. Linkbases for Label, Calculations, Definitions, Presentation.","username":"jwow","ts":"2019-05-19T06:57:06.946Z"}
{"msg":"The critical difference is that XBRL is concerned with the 'facts' or as they refer to them 'concepts' .    Concepts are like object classes, while Items are object instances.  Concepts are typically given a particular code \"","username":"jwow","ts":"2019-05-19T07:24:16.532Z"}
{"msg":"Sorry problems with desktop Rocket.","username":"jwow","ts":"2019-05-19T07:24:44.767Z"}
{"msg":"Concepts are typically given a code, much like passport fields, that avoids the biases of language (to some degree). \nSo a field '5F2B' has a semantic meaning of 'date of birth'.  Using a Label link base this can then be presented as 'Birth Date', 'Date of Birth', 'Date de Naisance', '生日' or whatever while still preserving its meaning.  This provides much greater interoperability across languages.  Of course you could standardise on Romanised Latin alphabet with Arabic numerals but I think that is to much of a western bias.","username":"jwow","ts":"2019-05-19T07:31:10.179Z"}
{"msg":"Similarly acceptable values can be given for one language then overlayed with another, extended for one country's specific use or remapped for another's.  E.g. in Australia gender is typically one of 5 choices: 'Male', 'Female', 'Neither', 'Unknown', 'Declined'.  Each of these values would have an associated identifier, so they could be easily translated to another language.","username":"jwow","ts":"2019-05-19T07:35:39.837Z"}
{"msg":"Finally, in defining the 'facts', we need to acknowledge that some require a specific 'as at' date, while the others require 'period' dates.  For example, a 'Balance' field is useless unless you know the 'as at' date.  While an 'Income' field is pointless if there is not period (FY2019) associated with it.","username":"jwow","ts":"2019-05-19T07:38:56.279Z"}
{"msg":"Lest you think these are traits associated only with finance, consider the 'address' field of a driver's license.  Generally it means an 'as at' but for other credentials (say police criminal check) it may be for a period, i.e. at 10 Xyz Street from 1-Jan-2010 to 31-Dec-2013.","username":"jwow","ts":"2019-05-19T07:44:07.444Z"}
{"msg":"Another omission is that that a concept or collection of concepts may have a 'dimension'.  This may be values over a number of months/years or across a number of places.  ","username":"jwow","ts":"2019-05-19T07:45:20.169Z"}
{"msg":"@jwow Thanks for your input and brief overview of XBRL. I'm tagging in @mtfk , the lead ODCA software architect. He'll be interested in any technical differences between the architectures. As I mentioned previously, the initial published paper doesn't go too deep into some of the more granular parts of the architecture. It was written so that people could better understand the overall concept. We still need to bring all aspects together under one shared roof. If you go to https://github.com/THCLab/schema-cake and read the README.md file, you'll see that, much like \"Concepts\" in XBRL, \"Schema Elements\" (which we should probably rename \"Schema Base Elements\") can also be coded.","username":"pknowles","ts":"2019-05-19T07:59:50.270Z"}
{"msg":"@jwow Thanks for your input and brief overview of XBRL. I'm tagging in @mtfk , the lead ODCA software architect. He'll be interested in any technical differences between the architectures. As I mentioned previously, the initial published paper doesn't go too deep into some of the more granular parts of the architecture. It was written so that people could better understand the overall concept. We still need to bring all aspects together under one shared roof. If you go to https://github.com/THCLab/schema-cake and read the README.md file, you'll see that, much like \"Concepts\" in XBRL, \"Schema Elements\" (which we should probably rename \"Schema Base Elements\") have a DID reference to help drive standardisation.","username":"pknowles","ts":"2019-05-19T07:59:50.270Z"}
{"msg":"@jwow Thanks for your input and brief overview of XBRL. I'm tagging in @mtfk , the lead ODCA software architect. He'll be interested in any technical differences between the architectures. As I mentioned previously, the initial published paper doesn't go too deep into some of the more granular parts of the architecture. It was written so that people could better understand the overall concept. We still need to bring all aspects together under one roof. If you go to https://github.com/THCLab/schema-cake and read the README.md file, you'll see that, much like \"Concepts\" in XBRL, \"Schema Elements\" (which we should probably rename \"Schema Base Elements\") have a DID reference to help drive standardisation.","username":"pknowles","ts":"2019-05-19T07:59:50.270Z"}
{"msg":"@jwow Thanks for your input and brief overview of XBRL. I'm tagging in @mtfk , the lead ODCA software architect. He'll be interested in any technical differences between the architectures. As I mentioned previously, the initial published paper doesn't go too deep into some of the more granular parts of the architecture. It was written so that people could better understand the overall concept. We still need to bring all aspects together under one roof. If you go to https://github.com/THCLab/schema-cake and read the README.md file, you'll see that, much like \"Concepts\" in XBRL, \"Schema Elements\" (which we should probably rename \"Schema Base Elements\") can have a DID reference to help drive standardisation.","username":"pknowles","ts":"2019-05-19T07:59:50.270Z"}
{"msg":"@jwow Thanks for your input and brief overview of XBRL. I'm tagging in @mtfk , the lead ODCA software architect. He'll be interested in any technical differences between the architectures. As I mentioned previously, the initial published paper doesn't go too deep into some of the more granular parts of the architecture. It was written so that people could better understand the overall concept. We still need to bring all aspects together under one roof. If you go to https://github.com/THCLab/schema-cake and read the README.md file, you'll see that, much like \"Concepts\" in XBRL, \"Schema Elements\" (which we should probably rename \"Schema Base Elements\") can have their own unique DID reference to help drive standardisation.","username":"pknowles","ts":"2019-05-19T07:59:50.270Z"}
{"msg":"@jwow Thanks for your input and brief overview of XBRL. I'm tagging in @mtfk , the lead ODCA software architect. He'll be interested in any technical differences between the architectures. As I mentioned previously, the initial published paper doesn't go too deep into some of the more granular aspects of the architecture. It was written so that people could better understand the overall concept. We still need to bring all aspects together under one roof. If you go to https://github.com/THCLab/schema-cake and read the README.md file, you'll see that, much like \"Concepts\" in XBRL, \"Schema Elements\" (which we should probably rename \"Schema Base Elements\") can have their own unique DID reference to help drive standardisation.","username":"pknowles","ts":"2019-05-19T07:59:50.270Z"}
{"msg":"@jwow Thanks for your input and brief overview of XBRL. I'm tagging in @mtfk , the lead ODCA software architect. He'll be interested in any technical differences between the architectures. As I mentioned previously, the initial published paper doesn't go too deep into some of the more granular aspects of the architecture. It was written so that people could better understand the overall concept. We still need to bring all aspects together under one roof. If you go to https://github.com/THCLab/schema-cake and read the README file, you'll see that, much like \"Concepts\" in XBRL, \"Schema Elements\" (which we should probably rename \"Schema Base Elements\") can have their own unique DID reference to help drive standardisation.","username":"pknowles","ts":"2019-05-19T07:59:50.270Z"}
{"msg":"There are a number of aspects of ODCA that address fundamental issues that XBRL doesn't appear to address: (i.) a built in schema object for flagging PII attributes [check BIT - ref. https://drive.google.com/drive/u/0/folders/1gSD1b70OySIUKNOQTSbQ7khq9oy1V8UP ]; (ii.) the separation of personal data processing, generic consent and specialised consent to enable better consent management throughout the data lifecycle [check PDP - ref. https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb ] and (iii.) Industry classification code tagging for data object searchability [check GICS/NECS - ref. https://drive.google.com/drive/u/0/folders/1uRBKIPT1DA838wTGStYhfj0CKqBKq1rV ]","username":"pknowles","ts":"2019-05-19T08:36:00.469Z"}
{"msg":"There are a number of aspects of ODCA that address fundamental issues that XBRL doesn't appear to address: (i.) a built in schema object for flagging PII attributes [check BIT - ref. https://drive.google.com/drive/u/0/folders/1gSD1b70OySIUKNOQTSbQ7khq9oy1V8UP ]; (ii.) the separation of personal data processing, generic consent and specialised consent to enable better consent management throughout the data lifecycle [check PDP - ref. https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb ] and (iii.) Industry classification code tagging for data object searchability [check GICS/NECS - ref. https://drive.google.com/drive/u/0/folders/1uRBKIPT1DA838wTGStYhfj0CKqBKq1rV ]. These are all fundamental for a new decentralised data economy to be actualised.","username":"pknowles","ts":"2019-05-19T08:36:00.469Z"}
{"msg":"@mtfk From the ongoing discussion with @jwow , this is the only aspect that I wanted to double-check with you. I think that this is covered by a combination of a *source overlay* (which deals with dynamic variables) and attributes captured in a linked *PDP schema* (which define parameters for data access). I'd love to hear your thoughts on this point.","username":"pknowles","ts":"2019-05-19T08:51:36.028Z"}
{"msg":"@mtfk From the ongoing discussion with @jwow , this is the only aspect that I wanted to double-check with you is the XBRL concept of 'dimension'. I think that this is covered by a combination of *source overlay* (which deals with dynamic variables) and attributes captured in a linked *PDP schema* (which define parameters for data access and processing). I'd love to hear your thoughts on this.","username":"pknowles","ts":"2019-05-19T08:51:36.028Z"}
{"msg":"@mtfk From the ongoing discussion with @jwow , the only aspect that I wanted to double-check with you is the XBRL concept of 'dimension'. I think this is covered by a combination of *source overlay* (which deals with dynamic variables) and attributes captured in a linked *PDP schema* (which define parameters for data access and processing). I'd love to hear your thoughts on this point.","username":"pknowles","ts":"2019-05-19T08:51:36.028Z"}
{"msg":"@mtfk From the ongoing discussion with @jwow , the only aspect that I wanted to double-check with you is the XBRL concept of 'dimension'. I think this is covered by a combination of *source overlay* (which deals with dynamic variables) and attributes captured in a linked *PDP schema* (which define parameters for data access and processing). I'd love to hear your thoughts on this to ensure that we've got it covered.","username":"pknowles","ts":"2019-05-19T08:51:36.028Z"}
{"msg":"@mtfk From the ongoing discussion with @jwow , the only aspect that I wanted to double-check with you is the XBRL concept of 'dimension'. I think this is covered by a combination of *source overlay* (which deals with dynamic variables) and attributes captured in a linked *PDP schema* (which define parameters for data access and processing). I'd love to hear your thoughts on this though to ensure that we've got it covered.","username":"pknowles","ts":"2019-05-19T08:51:36.028Z"}
{"msg":"@mtfk From the ongoing discussion with @jwow , the only aspect that I wanted to double-check with you is the XBRL concept of 'dimension'. I think this is covered by a combination of *source overlay* (which deals with dynamic variables) and attributes captured in a linked *PDP schema* (which define parameters for data access and processing). I'd love to hear your thoughts on this though to ensure that we've got it covered. [Cc: @janl ]","username":"pknowles","ts":"2019-05-19T08:51:36.028Z"}
{"msg":"I also like the idea of putting a unique DID reference on pre-defined field entries. We haven't gone that granular with ODCA [Cc: @mtfk ]. @jwow - Thanks for bringing that to my attention.","username":"pknowles","ts":"2019-05-19T09:12:54.135Z"}
{"msg":"Missed one. I also like the idea of putting a unique DID reference on pre-defined field entries. We haven't gone that granular with ODCA [Cc: @mtfk ]. @jwow - Thanks for bringing that to my attention.","username":"pknowles","ts":"2019-05-19T09:12:54.135Z"}
{"msg":"@jwow  I am not familiar with XBRL but for OCDA some of the most important properties are:\n- immutable\n- discoverable\n- uniquely identifiable \n- context aware\n For sure you can find some similarities between ODCA and XBRL. ODCA define just the meta language and rules how all stuff should be build. It is not forcing anyone to name field specifically. Standards and most popular schema base objects and overlays would come directly from community and experts from fields. But still it would provide interoperability across different sectors. ","username":"mtfk","ts":"2019-05-19T11:15:38.878Z"}
{"msg":"The problem which ODCA is trying to solve is to provide unify data language across any sectors. E.g. XBRL is suited for business reporting. Probably won't fit very well into health care or ecommerce. The future is all about data. We need to find a away to connect different worlds where data are generated, hold or stored. This would be crucial to get data economy possible. You can imagine that business report which you generated with XBRL someone would like to sell on open market or store in his digital wallet. To make that happen ODCA create set of rules which are level higher then any data language like XBRL.","username":"mtfk","ts":"2019-05-19T11:28:33.945Z","attachments":[]}
{"msg":"XBRL is indeed focussed on business, but the solution itself is a design (IMHO) that is equally applicable to Credentials & Claims.  For example, every concept (fact) has a periodType attribute: typically 'instant' or 'duration' (occasionally 'forever').  This is useful to distinguish the 'fact' from the 'fact attribute' to better understand a claim: is this address, for example, at an instant of time or for a period of time?  Of course, a 'context' is needed to determine these.  The 'context' gives understanding to the facts in which they are being used.  A context 'period' element communicates that period the 'fact' relates to, e.g., the issue date and the expiry date.  So the context can be associated with the credential, while the individual claim 'vehicle class licensed to drive = 5' is bound in that context. ","username":"jwow","ts":"2019-05-20T02:42:10.267Z"}
{"msg":"I'm not proposing that XBRL should be used for Credentials and Claims.  Just that we should adopt the same or similar underlying principles.  These include extensibility, interoperability and multilingual.","username":"jwow","ts":"2019-05-20T03:22:58.401Z"}
{"msg":"What about doing a short presentation about XBRL during our next Semantic Call? I would love to learn a bit more about that topic and see how ODCA could enrich already existing solutions or even just use them. \n@pknowles do we have free slot for such presentation for next call? ","username":"mtfk","ts":"2019-05-23T07:41:55.577Z"}
{"msg":"Timing for East Coast Australia is difficult.  What TZ are you in?","username":"jwow","ts":"2019-05-23T07:48:27.184Z"}
{"msg":"@jwow The bi-weekly Indy Semantics WG calls are every other Tuesday at 3am AEST so we'll forgive you for not attending those calls! I'll reach out to by DM to see if we can arrange an ad-hoc conference call for a XBRL/ODCA discussion. Would you be up for presenting the architecture to me and @mtfk at a date/time that suits you well? Our timezone is CET.","username":"pknowles","ts":"2019-05-23T07:59:04.963Z"}
{"msg":"Sure. Maybe like a 6am here.  At a function at moment.  I'll think about it and outline more later.","username":"jwow","ts":"2019-05-23T08:05:39.465Z"}
{"msg":"Has left the channel.","username":"TelegramSam","ts":"2019-05-27T16:36:24.155Z","type":"ul"}
{"msg":"Sorry for not getting back sooner.  Just started a new job, so pretty snowed under with the induction.  Should be okay for a conference call next week, maybe early Tuesday or Saturday morning (AEST).  Will prepare brief overview of XBRL, an example live site, & JSON XBRL.  Let me know","username":"jwow","ts":"2019-05-28T05:41:51.177Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nNote that there have been some clock changes around the globe. Here are the times for this week:\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 28th May, 2019\n\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles \n\nAgenda:\n• Introductions (Open) - 5 mins\n• DID specification update (Part 2) ( @drummondreed ) - 35 mins\n[Ref.: https://docs.google.com/document/d/1qnDExIVjU5bYc601qUdLZIi9UAs1ojlHyKnVoz2zlLM/edit#heading=h.itkracbrxg7m ]\n• SSI-related Blinding Identity Taxonomy (BIT) elements ( @pknowles ) - 10 mins\n[Ref.: https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy ]\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-05-28T15:57:41.898Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, May 14th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-05-28T18:58:05.236Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, June 11th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-05-28T18:58:05.236Z"}
{"msg":"In regard to the structure of requests from verifier our experience in Australia may be relevant:  the “100 point check” (see Wikipedia) requires holders to submit a wide variety of credentials, each with different values or weighting, until at least 100 points is reached.  This may be passport or birth certificate (70 points) down to drivers license (40 points), mortgage doc (35) or credit card or auto club membership (25).  So the user must submit between 2 and 4 credentials.  \n\nAt APRA, we designed and created or own Domain Specific Language utilising XBRL within a specific Taxonomy.  Using short tokens, say PT304, for “Name”, and ADF603 for the form/credential, we could easily write a rule to assign a weight to a credential and add the weight.  We could also ensure specific claims such as name, address and dob were consistent across all forms/credentials, or suitable change of address/name credentials were also provided.\n\nThe evaluation of the DSL was done on the edge device, so no data strictly needed to be transferred.  \n\nDoes this help?","username":"jwow","ts":"2019-05-29T04:59:02.436Z"}
{"msg":"Sound very interesting, I am evaluating possibility to use signals and artifacts for identification where base on different weight of attributes you can identify a person or a thing. Would love to learn more about this \"100 point check\" and the way how XBRL could actually support such that flow. I was thinking about similar approach for ODCA where you by preserving context and weight you could answer same question using different data and schema. E.g. to prove that you are above 18 years old you could: show passport, driving license, monthly ticket for last 2 years (for adult), diploma from university or simply other data which are some how related with adult person.   ","username":"mtfk","ts":"2019-05-29T15:43:45.116Z"}
{"msg":"The *Blinding Identity Taxonomy* (BIT) aims to provide a needed common standards to help protect the privacy of _personally identifiable information_ (PII) about people, organizations, or things. Note that the current version of the BIT does not identify correlation patterns. That may be considered in future versions as correlation patterns emerge. \n\nThe latest version of the BIT resides with Kantara Initiative’s _Consent & Information Sharing WG_. Here is the BIT link ... https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy\n\nDuring this week’s *Hyperledger Indy Semantics WG* call, I put the spotlight on the two contained elements that are integral to SSI that I had been entered on the list at conception. Namely, …\n\n- _Self-sovereign Key Identifiers_\n- _Decentralised Identifiers (DIDs)_\n\nNow that the SSI technology is more mature, I believe that those elements can be removed and the following two elements should be added …\n\n- _Private keys / master keys_\n- _Public keys / symmetric keys_\n\nI had mentioned various DID types and DID Docs during the call but, on closer revision, I would suggest that only the above keys would actually constitute PII. \n\nI'm keen to hear the thoughts of the community on this matter.","username":"pknowles","ts":"2019-05-30T05:11:00.319Z"}
{"msg":"The *Blinding Identity Taxonomy* (BIT) aims to provide a needed common standards to help protect the privacy of _personally identifiable information_ (PII) about people, organizations, or things. Note that the current version of the BIT does not identify correlation patterns. That may be considered in future versions as correlation patterns emerge. \n\nThe latest version of the BIT resides with Kantara Initiative’s _Consent & Information Sharing WG_. Here is a link to the latest version of the BIT ... https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy\n\nDuring this week’s *Hyperledger Indy Semantics WG* call, I put the spotlight on the two contained elements that are integral to SSI that I had been entered on the list at conception. Namely, …\n\n- _Self-sovereign Key Identifiers_\n- _Decentralised Identifiers (DIDs)_\n\nNow that the SSI technology is more mature, I believe that those elements can be removed and the following two elements should be added …\n\n- _Private keys / master keys_\n- _Public keys / symmetric keys_\n\nI had mentioned various DID types and DID Docs during the call but, on closer revision, I would suggest that only the above keys would actually constitute PII. \n\nI'm keen to hear the thoughts of the community on this matter.","username":"pknowles","ts":"2019-05-30T05:11:00.319Z"}
{"msg":"The *Blinding Identity Taxonomy* (BIT) aims to provide a needed common standards to help protect the privacy of _personally identifiable information_ (PII) about people, organizations, or things. Note that the current version of the BIT does not identify correlation patterns. That may be considered in future versions as correlation patterns emerge. \n\nThe latest version of the BIT resides with Kantara Initiative’s _Consent & Information Sharing WG_. Here is a link to the latest version of the BIT ... https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy\n\nDuring this week’s *Hyperledger Indy Semantics WG* call, I put the spotlight on the two contained elements that are integral to SSI that had been entered at conception. Namely, …\n\n- _Self-sovereign Key Identifiers_\n- _Decentralised Identifiers (DIDs)_\n\nNow that the SSI technology is more mature, I believe that those elements can be removed and the following two elements should be added …\n\n- _Private keys / master keys_\n- _Public keys / symmetric keys_\n\nI had mentioned various DID types and DID Docs during the call but, on closer revision, I would suggest that only the above keys would actually constitute PII. \n\nI'm keen to hear the thoughts of the community on this matter.","username":"pknowles","ts":"2019-05-30T05:11:00.319Z"}
{"msg":"The *Blinding Identity Taxonomy* (BIT) aims to provide a needed common standards to help protect the privacy of _personally identifiable information_ (PII) about people, organizations, or things. Note that the current version of the BIT does not identify correlation patterns. That may be considered in future versions as correlation patterns emerge. \n\nThe latest version of the BIT resides with Kantara Initiative’s _Consent & Information Sharing WG_. Here is a link to the latest version of the BIT ... https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy\n\nDuring this week’s *Hyperledger Indy Semantics WG* call, I put the spotlight on the two contained elements that are integral to SSI that had been entered in the taxonomy at the time of conception. Namely, …\n\n- _Self-sovereign Key Identifiers_\n- _Decentralised Identifiers (DIDs)_\n\nNow that the SSI technology is more mature, I believe that those elements can be removed and the following two elements should be added …\n\n- _Private keys / master keys_\n- _Public keys / symmetric keys_\n\nI had mentioned various DID types and DID Docs during the call but, on closer revision, I would suggest that only the above keys would actually constitute PII. \n\nI'm keen to hear the thoughts of the community on this matter.","username":"pknowles","ts":"2019-05-30T05:11:00.319Z"}
{"msg":"The *Blinding Identity Taxonomy* (BIT) aims to provide a needed common standards to help protect the privacy of _personally identifiable information_ (PII) about people, organizations, or things. Note that the current version of the BIT does not identify correlation patterns. That may be considered in future versions as correlation patterns emerge. \n\nThe latest version of the BIT resides with Kantara Initiative’s _Consent & Information Sharing WG_. Here is a link to the latest version of the BIT ... https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy\n\nDuring this week’s *Hyperledger Indy Semantics WG* call, I put the spotlight on the two contained elements that are integral to SSI that had been entered in the taxonomy at the time of conception. Namely, …\n\n- _Self-sovereign Key Identifiers_\n- _Decentralised Identifiers (DIDs)_\n\nNow that SSI technology is more mature, I believe that those elements can be removed and replaced by following two elements …\n\n- _Private keys / master keys_\n- _Public keys / symmetric keys_\n\nI had mentioned various DID types and DID Docs during the call but, on closer revision, I would suggest that only the above keys would actually constitute PII. \n\nI'm keen to hear the thoughts of the community on this matter.","username":"pknowles","ts":"2019-05-30T05:11:00.319Z"}
{"msg":"The *Blinding Identity Taxonomy* (BIT) aims to provide a needed common standards to help protect the privacy of _personally identifiable information_ (PII) about people, organizations, or things. Note that the current version of the BIT does not identify correlation patterns. That may be considered in future versions as correlation patterns emerge. \n\nThe latest version of the BIT resides with Kantara Initiative’s _Consent & Information Sharing WG_. Here is a link to the latest version of the BIT ... https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy\n\nDuring this week’s *Hyperledger Indy Semantics WG* call, I put the spotlight on the two contained elements that are integral to SSI that had been entered in the taxonomy at the time of conception. Namely, …\n\n- _Self-sovereign Key Identifiers_\n- _Decentralised Identifiers (DIDs)_\n\nNow that SSI technology is more mature, I believe that those elements can be removed and replaced by following two elements …\n\n- _Private keys / master keys_\n- _Public keys / symmetric keys_\n\nI had mentioned various DID types and DID Docs during the call but, on closer revision, I would suggest that only the above keys would actually constitute PII. \n\nI'm keen to hear people's thoughts of this.","username":"pknowles","ts":"2019-05-30T05:11:00.319Z"}
{"msg":"The *Blinding Identity Taxonomy* (BIT) aims to provide a needed common standards to help protect the privacy of _personally identifiable information_ (PII) about people, organizations, or things. Note that the current version of the BIT does not identify correlation patterns. That may be considered in future versions as correlation patterns emerge. \n\nThe latest version of the BIT resides with Kantara Initiative’s _Consent & Information Sharing WG_. Here is a link to the latest version of the BIT ... https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy\n\nDuring this week’s *Hyperledger Indy Semantics WG* call, I put the spotlight on two contained elements that are integral to SSI that had been entered in the taxonomy at the time of conception. Namely, …\n\n- _Self-sovereign Key Identifiers_\n- _Decentralised Identifiers (DIDs)_\n\nNow that SSI technology is more mature, I believe that those elements can be removed and replaced by following two elements …\n\n- _Private keys / master keys_\n- _Public keys / symmetric keys_\n\nI had mentioned various DID types and DID Docs during the call but, on closer revision, I would suggest that only the above keys would actually constitute PII. \n\nI'm keen to hear people's thoughts of this.","username":"pknowles","ts":"2019-05-30T05:11:00.319Z"}
{"msg":"The *Blinding Identity Taxonomy* (BIT) aims to provide a needed common standards to help protect the privacy of _personally identifiable information_ (PII) about people, organizations, or things. Note that the current version of the BIT does not identify correlation patterns. That may be considered in future versions as correlation patterns emerge. \n\nThe latest version of the BIT resides with Kantara Initiative’s _Consent & Information Sharing WG_. Here is a link to the latest version of the BIT ... https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy\n\nDuring this week’s *Hyperledger Indy Semantics WG* call, I put the spotlight on two contained elements that are integral to SSI that had been included in the taxonomy at the time of conception. Namely, …\n\n- _Self-sovereign Key Identifiers_\n- _Decentralised Identifiers (DIDs)_\n\nNow that SSI technology is more mature, I believe that those elements can be removed and replaced by following two elements …\n\n- _Private keys / master keys_\n- _Public keys / symmetric keys_\n\nI had mentioned various DID types and DID Docs during the call but, on closer revision, I would suggest that only the above keys would actually constitute PII. \n\nI'm keen to hear people's thoughts of this.","username":"pknowles","ts":"2019-05-30T05:11:00.319Z"}
{"msg":"The *Blinding Identity Taxonomy* (BIT) aims to provide a needed common standards to help protect the privacy of _personally identifiable information_ (PII) about people, organizations, or things. Note that the current version of the BIT does not identify correlation patterns. That may be considered in future versions as correlation patterns emerge. \n\nThe latest version of the BIT resides with Kantara Initiative’s _Consent & Information Sharing WG_. Here is a link to the latest version of the BIT ... https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy\n\nDuring this week’s *Hyperledger Indy Semantics WG* call, I put the spotlight on two contained elements that are integral to SSI that had been included in the taxonomy at the time of conception. Namely, …\n\n- _Self-sovereign Key Identifiers_\n- _Decentralised Identifiers (DIDs)_\n\nNow that SSI technology is more mature, I believe that those elements can be removed and replaced by the following two elements …\n\n- _Private keys / master keys_\n- _Public keys / symmetric keys_\n\nI had mentioned various DID types and DID Docs during the call but, on closer revision, I would suggest that only the above keys would actually constitute PII. \n\nI'm keen to hear people's thoughts of this.","username":"pknowles","ts":"2019-05-30T05:11:00.319Z"}
{"msg":"The *Blinding Identity Taxonomy* (BIT) aims to provide a needed common standards to help protect the privacy of _personally identifiable information_ (PII) about people, organizations, or things. Note that the current version of the BIT does not identify correlation patterns. That may be considered in future versions as correlation patterns emerge. \n\nThe latest version of the BIT resides with Kantara Initiative’s _Consent & Information Sharing WG_. Here is a link to the latest version of the BIT ... https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy\n\nDuring this week’s *Hyperledger Indy Semantics WG* call, I put the spotlight on two contained elements that are integral to SSI that had been included in the taxonomy at the time of conception. Namely, …\n\n- _Self-sovereign Key Identifiers_\n- _Decentralised Identifiers (DIDs)_\n\nNow that SSI technology is more mature, I believe that those elements can be removed and replaced by the following two elements …\n\n- _Private keys / master keys_\n- _Public keys / symmetric keys_\n\nI had mentioned various DID types and DID Docs as potential BIT elements during the call but, on closer revision, I would suggest that only the above keys would actually constitute PII. \n\nI'm keen to hear people's thoughts of this.","username":"pknowles","ts":"2019-05-30T05:11:00.319Z"}
{"msg":"The *Blinding Identity Taxonomy* (BIT) aims to provide a needed common standards to help protect the privacy of _personally identifiable information_ (PII) about people, organizations, or things. Note that the current version of the BIT does not identify correlation patterns. That may be considered in future versions as correlation patterns emerge. \n\nThe latest version of the BIT resides with Kantara Initiative’s _Consent & Information Sharing WG_. Here is a link to the latest version of the BIT ... https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy\n\nDuring this week’s *Indy Semantics WG* call, I put the spotlight on two contained elements that are integral to SSI that had been included in the taxonomy at the time of conception. Namely, …\n\n- _Self-sovereign Key Identifiers_\n- _Decentralised Identifiers (DIDs)_\n\nNow that SSI technology is more mature, I believe that those elements can be removed and replaced by the following two elements …\n\n- _Private keys / master keys_\n- _Public keys / symmetric keys_\n\nI had mentioned various DID types and DID Docs as potential BIT elements during the call but, on closer revision, I would suggest that only the above keys would actually constitute PII. \n\nI'm keen to hear people's thoughts of this.","username":"pknowles","ts":"2019-05-30T05:11:00.319Z"}
{"msg":"The *Blinding Identity Taxonomy* (BIT) aims to provide a needed common standards to help protect the privacy of _personally identifiable information_ (PII) about people, organizations, or things. Note that the current version of the BIT does not identify correlation patterns. That may be considered in future versions as correlation patterns emerge. \n\nThe latest version of the BIT resides with Kantara Initiative’s _Consent & Information Sharing WG_. Here is a link to the latest version ... https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy\n\nDuring this week’s *Indy Semantics WG* call, I put the spotlight on two contained elements that are integral to SSI that had been included in the taxonomy at the time of conception. Namely, …\n\n- _Self-sovereign Key Identifiers_\n- _Decentralised Identifiers (DIDs)_\n\nNow that SSI technology is more mature, I believe that those elements can be removed and replaced by the following two elements …\n\n- _Private keys / master keys_\n- _Public keys / symmetric keys_\n\nI had mentioned various DID types and DID Docs as potential BIT elements during the call but, on closer revision, I would suggest that only the above keys would actually constitute PII. \n\nI'm keen to hear people's thoughts of this.","username":"pknowles","ts":"2019-05-30T05:11:00.319Z"}
{"msg":"The *Blinding Identity Taxonomy* (BIT) aims to provide a needed common standards to help protect the privacy of _personally identifiable information_ (PII) about people, organizations, or things. Note that the current version of the BIT does not identify correlation patterns. Correlation may be considered in future versions as patterns emerge. \n\nThe latest version of the BIT resides with Kantara Initiative’s _Consent & Information Sharing WG_. Here is a link to the latest version ... https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy\n\nDuring this week’s *Indy Semantics WG* call, I put the spotlight on two contained elements that are integral to SSI that had been included in the taxonomy at the time of conception. Namely, …\n\n- _Self-sovereign Key Identifiers_\n- _Decentralised Identifiers (DIDs)_\n\nNow that SSI technology is more mature, I believe that those elements can be removed and replaced by the following two elements …\n\n- _Private keys / master keys_\n- _Public keys / symmetric keys_\n\nI had mentioned various DID types and DID Docs as potential BIT elements during the call but, on closer revision, I would suggest that only the above keys would actually constitute PII. \n\nI'm keen to hear people's thoughts of this.","username":"pknowles","ts":"2019-05-30T05:11:00.319Z"}
{"msg":"The *Blinding Identity Taxonomy* (BIT) aims to provide a needed common standards to help protect the privacy of _personally identifiable information_ (PII) about people, organizations, or things. Note that the current version of the BIT does not identify correlation patterns. Correlation may be considered in future versions as patterns emerge. \n\nThe latest version of the BIT resides with Kantara Initiative’s _Consent & Information Sharing WG_ ... https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy\n\nDuring this week’s *Indy Semantics WG* call, I put the spotlight on two contained elements that are integral to SSI that had been included in the taxonomy at the time of conception. Namely, …\n\n- _Self-sovereign Key Identifiers_\n- _Decentralised Identifiers (DIDs)_\n\nNow that SSI technology is more mature, I believe that those elements can be removed and replaced by the following two elements …\n\n- _Private keys / master keys_\n- _Public keys / symmetric keys_\n\nI had mentioned various DID types and DID Docs as potential BIT elements during the call but, on closer revision, I would suggest that only the above keys would actually constitute PII. \n\nI'm keen to hear people's thoughts of this.","username":"pknowles","ts":"2019-05-30T05:11:00.319Z"}
{"msg":"The *Blinding Identity Taxonomy* (BIT) aims to provide a needed common standards to help protect the privacy of _personally identifiable information_ (PII) about people, organizations, or things. Note that the current version of the BIT does not identify correlation patterns. Correlation may be considered in future versions as patterns emerge. \n\nThe latest version of the BIT resides with Kantara Initiative’s _Consent & Information Sharing WG_ ... https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy\n\nDuring this week’s *Indy Semantics WG* call, I put the spotlight on two contained elements that are integral to SSI that had been included in the taxonomy at the time of conception. Namely, …\n\n- _Self-sovereign Key Identifiers_\n- _Decentralised Identifiers (DIDs)_\n\nNow that SSI technology is more mature, I believe that those elements can be removed and replaced by the following two elements …\n\n- _Private keys / master keys_\n- _Public keys / symmetric keys_\n\nI had mentioned various DID types and DID Docs as potential BIT elements during the call but, on closer revision, I would suggest that only the above keys would actually constitute PII. \n\nI'm keen to hear people's thoughts on this.","username":"pknowles","ts":"2019-05-30T05:11:00.319Z"}
{"msg":"The *Blinding Identity Taxonomy* (BIT) aims to provide a needed common standards to help protect the privacy of _personally identifiable information_ (PII) about people, organizations, or things. Note that the current version of the BIT does not identify correlation patterns. Correlation may be considered in future versions as patterns emerge. \n\nThe latest version of the BIT resides with Kantara Initiative’s _Consent & Information Sharing WG_ ... https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy\n\nDuring this week’s *Indy Semantics WG* call, I put the spotlight on two contained elements that are integral to SSI that had been included in the taxonomy at the time of conception. Namely, …\n\n- _Self-sovereign Key Identifiers_\n- _Decentralised Identifiers (DIDs)_\n\nNow that SSI technology is more mature, I believe that those elements can be removed and replaced by the following two elements …\n\n- _Private keys / master keys_\n- _Public keys / symmetric keys_\n\nI had mentioned various DID types and DID Docs as potential BIT elements during the call but, on closer revision, I would suggest that only the keys actually constitute PII. \n\nI'm keen to hear people's thoughts on this.","username":"pknowles","ts":"2019-05-30T05:11:00.319Z"}
{"msg":"The *Blinding Identity Taxonomy* (BIT) aims to provide a needed common standards to help protect the privacy of _personally identifiable information_ (PII) about people, organizations, or things. Note that the current version of the BIT does not identify correlation patterns. Correlation may be considered in future versions as patterns emerge. \n\nThe latest version of the BIT resides with Kantara Initiative’s _Consent & Information Sharing WG_ ... https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy\n\nDuring this week’s *Indy Semantics WG* call, I put the spotlight on two contained elements that are integral to SSI that had been included in the taxonomy at the time of conception. Namely, …\n\n- _Self-sovereign Key Identifiers_\n- _Decentralised Identifiers (DIDs)_\n\nNow that SSI technology is more mature, I believe that those elements can be removed and replaced by the following two elements …\n\n- _Private Keys / Master Keys_\n- _Public Keys / Symmetric Keys_\n\nI had mentioned various DID types and DID Docs as potential BIT elements during the call but, on closer revision, I would suggest that only the keys actually constitute PII. \n\nI'm keen to hear people's thoughts on this.","username":"pknowles","ts":"2019-05-30T05:11:00.319Z"}
{"msg":"The *Blinding Identity Taxonomy* (BIT) aims to provide a needed common standards to help protect the privacy of _personally identifiable information_ (PII) about people, organizations, or things. Note that the current version of the BIT does not identify correlation patterns. Correlation may be considered in future versions as patterns emerge. \n\nThe latest version of the BIT resides with Kantara Initiative’s _Consent & Information Sharing WG_ ... https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy\n\nDuring this week’s *Indy Semantics WG* call, I put the spotlight on two contained elements that are integral to SSI that had been included in the taxonomy at the time of conception. Namely, …\n\n- _Self-sovereign Key Identifiers_\n- _Decentralised Identifiers (DIDs)_\n\nNow that SSI technology is more mature, I believe that those elements can be removed and replaced by the following two elements …\n\n- _Private Keys / Master Keys_\n- _Public Keys / Symmetric Keys_\n\nI had mentioned various DID types and DID Docs as potential BIT elements during the call but, on closer revision, I would suggest that only the _keys_ actually constitute PII. \n\nI'm keen to hear people's thoughts on this.","username":"pknowles","ts":"2019-05-30T05:11:00.319Z"}
{"msg":"has Anyone customized universal resolver ? ","username":"SethiSaab","ts":"2019-05-30T11:28:14.059Z"}
{"msg":"Courtesy of some valuable input from @MALodder , a new version of the *BIT* has been submitted and subsequently accepted by Kantara Initiative's _Consent & Information Sharing WG_. The new version has been uploaded to the following HL Indy shared drive: https://drive.google.com/drive/u/0/folders/1gSD1b70OySIUKNOQTSbQ7khq9oy1V8UP","username":"pknowles","ts":"2019-05-30T16:12:19.431Z"}
{"msg":"Courtesy of some valuable input from @MALodder , a new version of the *BIT* has been submitted to (and subsequently accepted by) Kantara Initiative's _Consent & Information Sharing WG_. The new version has been uploaded to the following HL Indy shared drive: https://drive.google.com/drive/u/0/folders/1gSD1b70OySIUKNOQTSbQ7khq9oy1V8UP","username":"pknowles","ts":"2019-05-30T16:12:19.431Z"}
{"msg":"Has joined the channel.","username":"MALodder","ts":"2019-05-30T16:12:19.744Z","type":"uj"}
{"msg":"@peacekeeper :top: ","username":"pknowles","ts":"2019-05-30T17:56:14.031Z"}
{"msg":"For contributing a driver for a new DID method to the Universal Resolver, see this doc: https://github.com/decentralized-identity/universal-resolver/blob/master/docs/driver-development.md, also feel free to msg me or @creatornader ","username":"peacekeeper","ts":"2019-05-30T22:35:21.463Z"}
{"msg":"Thansk  @MALodder   and @pknowles ","username":"SethiSaab","ts":"2019-05-31T04:10:30.163Z"}
{"msg":"Hi everyone. I came across this link https://github.com/sovrin-foundation/protocol/tree/master/themis and wanted to see if this is supported/what is the current status?","username":"ardagumusalan","ts":"2019-06-04T18:10:31.800Z"}
{"msg":"Hi everyone. I came across this link https://github.com/sovrin-foundation/protocol/tree/master/themis and wanted to see if this is supported/what is the current status? Does anyone know?","username":"ardagumusalan","ts":"2019-06-04T18:10:31.800Z"}
{"msg":"@kdenhartog :top: ","username":"pknowles","ts":"2019-06-04T18:53:30.797Z"}
{"msg":"This is the earliest thinking of agent to agent protocol. In it's current form it's pretty stale at this point, but there was excellent thinking that went into that work. ","username":"kdenhartog","ts":"2019-06-04T19:07:47.329Z"}
{"msg":"Got it, thanks","username":"ardagumusalan","ts":"2019-06-04T20:07:02.698Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nNote that there have been some clock changes around the globe. Here are the times for this week:\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 11th June, 2019\n\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm BST\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Open Notice (OPN) Network tool (Mark Lizar from OpenConsent) - 45 mins\n[Ref.: https://openconsent.com ]\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-06-11T15:58:20.707Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, June 25th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-06-11T19:45:36.772Z"}
{"msg":" Hi Team i have question\nplease help me to get more knowledge on this\n\nSuppose a DID document of a device is there\n\nand this device also have verifiable credentials\n\n\nNow questions is ---->\n\nWhat kind of service does a service end point of that device offers\n\nand if a verifier has to check the authneticity of the device using service endpoint\n\nhow will he because the verifiable credentials are already available and it can easily verify those by comparing signatures\nwhat additional information we can get from service end point about authenticity of anything even when we have verifiable credentials available for that\n","username":"SethiSaab","ts":"2019-06-12T06:40:56.802Z"}
{"msg":"Has joined the channel.","username":"rchristman","ts":"2019-06-13T15:15:09.922Z","type":"uj"}
{"msg":"@SethiSaab I believe the short answer is that, if the device has a DID document including an agent service endpoint but the device does not actually host its own agent—rather the agent lives in the cloud—then you could only authenticate the agent for the device, not the device itself.","username":"drummondreed","ts":"2019-06-14T04:23:59.354Z"}
{"msg":"In order to authentication the device itself, it must have its own wallet and agent, however minimal.","username":"drummondreed","ts":"2019-06-14T04:24:21.019Z"}
{"msg":"@drummondreed  Thanks for the explanation","username":"SethiSaab","ts":"2019-06-14T05:10:30.075Z"}
{"msg":"and this will done with the concept of DID -AUTH or something similar to that ","username":"SethiSaab","ts":"2019-06-14T05:11:03.685Z"}
{"msg":"right?","username":"SethiSaab","ts":"2019-06-14T05:11:05.614Z"}
{"msg":"Yes. As the DID Comm protocol is proceeding, the easiest option is simply sending a message using authenticated encryption using the DID Comm protocol.","username":"drummondreed","ts":"2019-06-14T05:12:50.224Z"}
{"msg":"Hi Guys I have a question .\nAs per my knowledge . when we create a DID document it gets saved in parts ... in case of Uport and BItcoin and we get block id and transaction ID . to fetch complete DID Document\nbut I am confused ... like when we search a DID Document using DID... .how will that work\n?","username":"SethiSaab","ts":"2019-06-14T05:14:48.767Z"}
{"msg":"I have seen that in case of DID based on bctr . it actually uses   the 3rd part (xxxx-xxxx-xxxx)  of did   did:bctr:xxxx-xxxx-xxxx  to reach at the correct block and transaction  ","username":"SethiSaab","ts":"2019-06-14T05:19:31.839Z"}
{"msg":"and that is how it gets the complete document","username":"SethiSaab","ts":"2019-06-14T05:19:43.221Z"}
{"msg":"but how does that works in INDY ","username":"SethiSaab","ts":"2019-06-14T05:19:53.292Z"}
{"msg":"Hi Guys ,","username":"SethiSaab","ts":"2019-06-14T12:31:04.506Z"}
{"msg":"I have a question regarding construction of DID documents. I have seen that on some platform did documents are getting generated by extracting data from multiple transactions. like in BTCR did method and in uport did method.  Could someone help to understand that how is this working?","username":"SethiSaab","ts":"2019-06-14T12:32:25.564Z"}
{"msg":"@SethiSaab It is similar on Indy. The NYM transaction stores the actual DID and public key; ATTRIB transactions are used for other  DID document properties like service endpoints. A DID resolver such as the DIF Universal Resolver will request all these transactions from an Indy ledger and then compose them into the DID document (if that is the DID resolution result requested).","username":"drummondreed","ts":"2019-06-15T21:22:03.246Z"}
{"msg":"@drummondreed   so there will be multiple transanactions  and did resolver will combine multipe transactions and extract the data from Attrib transactions merge them and construct a document.  Am i right ?","username":"SethiSaab","ts":"2019-06-16T05:59:39.012Z"}
{"msg":"as of now i have seen that uport and btcr are saving DID document off chain","username":"SethiSaab","ts":"2019-06-16T06:00:00.134Z"}
{"msg":"which is kinda following centralized model","username":"SethiSaab","ts":"2019-06-16T06:00:07.962Z"}
{"msg":"but wouldn't saving data on blockchain affect scalability and performance","username":"SethiSaab","ts":"2019-06-16T06:00:27.532Z"}
{"msg":"@SethiSaab Yes, you are right. uPort and BTCR are using IPFS to save the raw DID document. With Indy, the individual properties of the DID document are stored directly on the ledger. They are small, and Indy ledgers are needed only for public DIDs (the vast majority of DIDs will be peer DIDs that are not stored on a public ledger), so scalability and performance should not be an issue.","username":"drummondreed","ts":"2019-06-16T16:10:46.629Z"}
{"msg":"If you haven't read the Peer DID spec, you should. https://dhh1128.github.io/peer-did-method-spec/index.html ","username":"drummondreed","ts":"2019-06-16T16:11:17.709Z"}
{"msg":"@drummondreed   Thanks , i was not aware of this document . Let me explore this","username":"SethiSaab","ts":"2019-06-17T05:54:18.287Z"}
{"msg":"In January, I wrote a submission to the UK Parliament's Human Rights Committee inquiry on The Right to Privacy ( Article 8 ) and the Digital Revolution. The submission explained how the *Blinding Identity Taxonomy* (BIT) initiative would provide a common standards to help protect the privacy of personally identifiable information (PII) about people, organisations, or things. I've just been informed by the Committee Assistant that the submission has been published. More information on the BIT - https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy","username":"pknowles","ts":"2019-06-19T14:39:50.176Z"}
{"msg":"In January, I wrote a submission to the UK Parliament's Human Rights Committee inquiry on The Right to Privacy ( Article 8 ) and the Digital Revolution. The submission explained how the *Blinding Identity Taxonomy* (BIT) initiative would provide a common standards to help protect the privacy of personally identifiable information (PII) about people, organisations, or things. I've just been informed by the Committee Assistant that the submission has been published. More information on the BIT via the following Kantara link - https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy","username":"pknowles","ts":"2019-06-19T14:39:50.176Z"}
{"msg":"Congrats, Paul! That's awesome news. ","username":"drummondreed","ts":"2019-06-19T18:11:34.408Z"}
{"msg":"Thanks, @drummondreed ... Here is \" _The Right to Privacy ( Article 8 ) and the Digital Revolution inquiry_ \" page [UK Parliament: Joint Committee on Human Rights]. Look for \"Dativa - written evidence\" in the \"Latest evidence\" section. https://www.parliament.uk/business/committees/committees-a-z/joint-select/human-rights-committee/inquiries/parliament-2017/right-to-privacy-digital-revolution-inquiry-17-19/","username":"pknowles","ts":"2019-06-19T23:03:25.747Z"}
{"msg":"Thanks, @drummondreed . Here is \"_The Right to Privacy ( Article 8 ) and the Digital Revolution inquiry_\" page - https://www.parliament.uk/business/committees/committees-a-z/joint-select/human-rights-committee/inquiries/parliament-2017/right-to-privacy-digital-revolution-inquiry-17-19/ ","username":"pknowles","ts":"2019-06-19T23:03:25.747Z"}
{"msg":"Thanks, @drummondreed . Here is _The Right to Privacy ( Article 8 ) and the Digital Revolution inquiry_ page - https://www.parliament.uk/business/committees/committees-a-z/joint-select/human-rights-committee/inquiries/parliament-2017/right-to-privacy-digital-revolution-inquiry-17-19/ ","username":"pknowles","ts":"2019-06-19T23:03:25.747Z"}
{"msg":"Thanks, @drummondreed . Here is \" _The Right to Privacy ( Article 8 ) and the Digital Revolution inquiry_ \" page - https://www.parliament.uk/business/committees/committees-a-z/joint-select/human-rights-committee/inquiries/parliament-2017/right-to-privacy-digital-revolution-inquiry-17-19/ ","username":"pknowles","ts":"2019-06-19T23:03:25.747Z"}
{"msg":"Thanks, @drummondreed . Here is \" _The Right to Privacy ( Article 8 ) and the Digital Revolution inquiry_ \" page [UK Parliament: Joint Committee on Human Rights]. Look for \"Dativa - written evidence\" in the \"Latest evidence\" section  - https://www.parliament.uk/business/committees/committees-a-z/joint-select/human-rights-committee/inquiries/parliament-2017/right-to-privacy-digital-revolution-inquiry-17-19/ ","username":"pknowles","ts":"2019-06-19T23:03:25.747Z"}
{"msg":"Thanks, @drummondreed ... Here is \" _The Right to Privacy ( Article 8 ) and the Digital Revolution inquiry_ \" page [UK Parliament: Joint Committee on Human Rights]. Look for \"Dativa - written evidence\" in the \"Latest evidence\" section  - https://www.parliament.uk/business/committees/committees-a-z/joint-select/human-rights-committee/inquiries/parliament-2017/right-to-privacy-digital-revolution-inquiry-17-19/ ","username":"pknowles","ts":"2019-06-19T23:03:25.747Z"}
{"msg":"... and video link to the parliamentary session. https://parliamentlive.tv/event/index/8e8eaaf7-c6cf-43c8-b1ac-5cc8c0273e62","username":"pknowles","ts":"2019-06-19T23:31:49.880Z"}
{"msg":"Here is \" _The Right to Privacy ( Article 8 ) and the Digital Revolution inquiry_ \" page [UK Parliament: Joint Committee on Human Rights]. Look for \"Dativa - written evidence\" in the \"Latest evidence\" section. https://www.parliament.uk/business/committees/committees-a-z/joint-select/human-rights-committee/inquiries/parliament-2017/right-to-privacy-digital-revolution-inquiry-17-19/","username":"pknowles","ts":"2019-06-19T23:39:49.451Z"}
{"msg":"... and video link to the parliamentary session. https://parliamentlive.tv/event/index/8e8eaaf7-c6cf-43c8-b1ac-5cc8c0273e62","username":"pknowles","ts":"2019-06-19T23:40:14.082Z"}
{"msg":"... and a video link to the parliamentary session. https://parliamentlive.tv/event/index/8e8eaaf7-c6cf-43c8-b1ac-5cc8c0273e62","username":"pknowles","ts":"2019-06-19T23:40:14.082Z"}
{"msg":"A question to put to all active members of this channel. There have been a number of offline discussions regarding the potential migration of the *Indy Semantics WG* over to Aries (i.e. *Aries Semantics WG* ). Regarding the ODCA work, that is a no-brainer as that architecture is platform agnostic. The question is whether the Rich Schema work can follow suit. I think we should but it to a non-formal vote to start with. Either click on the :thumbsup: or :thumbsdown: emojis to show your preference. We can do a more formal vote on a future WG call. For now, click an emoji!","username":"pknowles","ts":"2019-06-20T15:40:43.661Z"}
{"msg":"A question to put to all active members of this channel. There have been a number of offline discussions regarding the potential migration of the *Indy Semantics WG* over to Aries (i.e. *Aries Semantics WG* ). Regarding the ODCA work, that is a no-brainer as that architecture is platform agnostic. The question is whether the Rich Schema work can follow suit. I think we should put it to a non-formal vote to start with. Either click on the :thumbsup: or :thumbsdown: emojis to show your preference. We can do a more formal vote on a future WG call. For now, click an emoji!","username":"pknowles","ts":"2019-06-20T15:40:43.661Z"}
{"msg":"A question to put to all active members of this channel. There have been a number of offline discussions regarding the potential migration of the *Indy Semantics WG* over to Aries (i.e. *Aries Semantics WG* ). Regarding the ODCA work, that is a no-brainer as that architecture is platform agnostic. The question is whether the Rich Schema work can follow suit. I think we should put it to a non-formal vote to start with. Either click on the :thumbsup: or :thumbsdown: emojis to show your preference. We can do a more formal vote on a future WG call. For now, click on your preferred emoji to indicate migrating the WG to Aries!","username":"pknowles","ts":"2019-06-20T15:40:43.661Z"}
{"msg":"A question to put to all active members of this channel. There have been a number of offline discussions regarding the potential migration of the *Indy Semantics WG* over to Aries (i.e. *Aries Semantics WG* ). Regarding the ODCA work, that is a no-brainer as that architecture is platform agnostic. The question is whether the Rich Schema work can follow suit. I think we should put it to a non-formal vote to start with. Either click on the :thumbsup: or :thumbsdown: emojis to show your preference. We can do a more formal vote on a future WG call. For now, click on your preferred emoji to indicate whether or not we should migrate the WG to Aries!","username":"pknowles","ts":"2019-06-20T15:40:43.661Z"}
{"msg":"As the Rich Schema work matures and it becomes ready for integration, it might be a good idea to migrate the work to Aries, in my opinion.","username":"kenebert","ts":"2019-06-20T17:07:06.552Z"}
{"msg":"@all - The next *Indy Semantics WG* call is on Tuesday, June 25th at 11am-12.15pm MT (7pm-8.15pm CET) where we will be discussing a proposed HIPE for the context objects as part of the rich schema work that @kenebert and @brentzundel have been spearheading. The proposed HIPE has just been published. Please review and add your comments to this important document before then so that we can have a valuable discussion during the WG call. Thanks, all. https://github.com/hyperledger/indy-hipe/tree/master/text/0138-rich-schema-context","username":"pknowles","ts":"2019-06-20T17:37:15.373Z"}
{"msg":"Regarding Paul Knowles' rich schema question: The crux of the decision, I think, is whether the rich schema work is broader than Indy. Is it our intention that all Aries people should be exposed to and hopefully adopt the rich schema work? If yes, then appropriate location is Aries. If no, then appropriate location is Indy. Specs for Indy's unique approach to credentials belong in Indy, not Aries--that seems clear. I'm less sure about the rich schema stuff.","username":"danielhardman","ts":"2019-06-20T17:45:39.727Z"}
{"msg":"@danielhardman - As the Indy Semantics WG calls are bi-weekly, there might be an opportunity to alternate between *Indy Semantics * and *Aries Semantics* WG calls on weekly rotation. If we were to do that, I would suggest that @kenebert become the new chair of the Indy Semantics WG and step into a vice role. We could then set up a new Aries Semantics WG which I would happily chair and Ken could step into a vice role for that group. This would enable us to maintain synergy between the two semantics WGs as we progress. That might work.","username":"pknowles","ts":"2019-06-20T18:01:13.675Z"}
{"msg":"@danielhardman - As the Indy Semantics WG calls are bi-weekly, there might be an opportunity to alternate between *Indy Semantics * and *Aries Semantics WG* calls on weekly rotation. If we were to do that, I would suggest that @kenebert become the new chair of the Indy Semantics WG and step into a vice role. We could then set up a new Aries Semantics WG which I would happily chair and Ken could step into a vice role for that group. This would enable us to maintain synergy between the two semantics WGs as we progress. That might work.","username":"pknowles","ts":"2019-06-20T18:01:13.675Z"}
{"msg":"@danielhardman - As the Indy Semantics WG calls are bi-weekly, there might be an opportunity to alternate between *Indy Semantics * and *Aries Semantics WG* calls on weekly rotation. If we were to do that, I would suggest that @kenebert become the new chair of the Indy Semantics WG and I step into a vice role. We could then set up a new Aries Semantics WG which I would happily chair and Ken could step into a vice role for that group. This would enable us to maintain synergy between the two semantics WGs as we progress. That might work.","username":"pknowles","ts":"2019-06-20T18:01:13.675Z"}
{"msg":"@danielhardman - As the Indy Semantics WG calls are bi-weekly, there might be an opportunity to alternate between *Indy Semantics * and *Aries Semantics WG* calls on weekly rotation. If we were to do that, I would suggest that @kenebert become the new chair of the Indy Semantics WG and I step into a vice role. We could then set up a new Aries Semantics WG which I would happily chair and Ken could step into a vice role for that group. This would enable us to maintain synergy between the two semantics WGs as we progress. That might work. Keen to hear your thoughts.","username":"pknowles","ts":"2019-06-20T18:01:13.675Z"}
{"msg":"@danielhardman - As the Indy Semantics WG calls are bi-weekly, there might be an opportunity to alternate between *Indy Semantics * and *Aries Semantics WG* calls on a weekly rotation. If we were to do that, I would suggest that @kenebert become the new chair of the Indy Semantics WG and I step into a vice role. We could then set up a new Aries Semantics WG which I would happily chair and Ken could step into a vice role for that group. This would enable us to maintain synergy between the two semantics WGs as we progress. That might work. Keen to hear your thoughts.","username":"pknowles","ts":"2019-06-20T18:01:13.675Z"}
{"msg":"@danielhardman - As the Indy Semantics WG calls are bi-weekly, there might be an opportunity to alternate between *Indy Semantics WG* and *Aries Semantics WG* calls on a weekly rotation. If we were to do that, I would suggest that @kenebert become the new chair of the Indy Semantics WG and I step into a vice role. We could then set up a new Aries Semantics WG which I would happily chair and Ken could step into a vice role for that group. This would enable us to maintain synergy between the two semantics WGs as we progress. That might work. Keen to hear your thoughts.","username":"pknowles","ts":"2019-06-20T18:01:13.675Z"}
{"msg":"@danielhardman - As the Indy Semantics WG calls are bi-weekly, there might be an opportunity to alternate between *Indy Semantics WG* and *Aries Semantics WG* calls on a weekly rotation. If we were to do that, I would suggest that @kenebert become the new chair of the Indy Semantics WG and I step into a vice role. We could then set up a new Aries Semantics WG which I would happily chair and Ken could step into a vice role for that group. This would enable us to maintain synergy between the two semantics WGs as we progress. That might work. Keen to hear everybody's thoughts.","username":"pknowles","ts":"2019-06-20T18:01:13.675Z"}
{"msg":"@danielhardman - As the Indy Semantics WG calls are bi-weekly, there might be an opportunity to go weekly and alternate between *Indy Semantics WG* and *Aries Semantics WG* calls on a weekly rotation. If we were to do that, I would suggest that @kenebert become the new chair of the Indy Semantics WG and I step into a vice role. We could then set up a new Aries Semantics WG which I would happily chair and Ken could step into a vice role for that group. This would enable us to maintain synergy between the two semantics WGs as we progress. That might work. Keen to hear everybody's thoughts.","username":"pknowles","ts":"2019-06-20T18:01:13.675Z"}
{"msg":"@danielhardman - As the Indy Semantics WG calls are bi-weekly, there might be an opportunity to go weekly and alternate between *Indy Semantics WG* and *Aries Semantics WG* calls on rotation. If we were to do that, I would suggest that @kenebert become the new chair of the Indy Semantics WG and I step into a vice role. We could then set up a new Aries Semantics WG which I would happily chair and Ken could step into a vice role for that group. This would enable us to maintain synergy between the two semantics WGs as we progress. That might work. Keen to hear everybody's thoughts.","username":"pknowles","ts":"2019-06-20T18:01:13.675Z"}
{"msg":"@danielhardman - As the Indy Semantics WG calls are bi-weekly, there might be an opportunity to go weekly and alternate between *Indy Semantics WG* and *Aries Semantics WG* calls on rotation. If we were to do that, I would suggest that @kenebert become the new chair of the Indy Semantics WG and I step into a vice role. We could then set up a new Aries Semantics WG which I would happily chair and Ken could step into a vice role for that group. This would enable us to maintain synergy between the two semantics WGs as we progress. Could that work? Keen to hear everybody's thoughts.","username":"pknowles","ts":"2019-06-20T18:01:13.675Z"}
{"msg":"@danielhardman - As the Indy Semantics WG calls are bi-weekly, there might be an opportunity to go weekly and alternate between *Indy Semantics WG* and *Aries Semantics WG* calls on rotation. If we were to do that, I would suggest that @kenebert become the new chair of the Indy Semantics WG and I step into a vice role. We could then set up a new Aries Semantics WG which I would happily chair and Ken could step into a vice role for that group. This would enable us to maintain synergy between the two semantics WGs as we progress. Could that work? Keen to hear people's thoughts.","username":"pknowles","ts":"2019-06-20T18:01:13.675Z"}
{"msg":"@nage :top: ","username":"pknowles","ts":"2019-06-21T07:27:47.905Z"}
{"msg":"@pknowles That makes sense to me. I look at it this way: Indy architecture currently represents one credential format and exchange protocol, the primitives for which are supported on the Indy ledger. Aries is now separating out the P2P DID connection and credential exchange layers so that they can work with any ledger that wants to support them. So I see \"Indy credential semantics\" slowly converging with \"Aries credential semantics\", and starting with these two calls is a good way to move along that path.","username":"drummondreed","ts":"2019-06-23T22:36:25.326Z"}
{"msg":"@mtfk - @phoniks is keen to create a React (Front-end framework) Form Generator for ODCA. Something along the lines of https://react.rocks/tag/FormGenerator . Can you point him to some overlay examples that he can use to template from?","username":"pknowles","ts":"2019-06-24T16:55:51.206Z"}
{"msg":"@mtfk ... @phoniks is keen to create a React (Front-end framework) Form Generator for ODCA. Something along the lines of https://react.rocks/tag/FormGenerator . Can you point him to some overlay examples that he can use to template from?","username":"pknowles","ts":"2019-06-24T16:55:51.206Z"}
{"msg":"@mtfk ... @phoniks is keen to create a React (Front-end framework) Form Generator for ODCA. Something along the lines of https://react.rocks/tag/FormGenerator . Can you point him to some overlay examples that he can use as templates?","username":"pknowles","ts":"2019-06-24T16:55:51.206Z"}
{"msg":"I'll put this down as an agenda item for tomorrow's Indy Semantics WG call. Thanks for your input.","username":"pknowles","ts":"2019-06-24T17:14:05.288Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=kgppmodjSLyNPtQ22) @phoniks  I will prepare new schema base example + overlays this week and share here. I am planning to use similar approach with vue: https://github.com/vue-generators/vue-form-generator for existing project https://github.com/THCLab/tool . Basically the schema base and overlays would have definition file which you can take an use to validate against newly created ones. If you can't wait to start you can take existing examples from https://github.com/THCLab/schema-cake which gives you  good start. We need to update this repo with some minor changes but overall it should work for you. If you would have any questions just let me know here.","username":"mtfk","ts":"2019-06-25T07:54:52.203Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=kgppmodjSLyNPtQ22","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=kgppmodjSLyNPtQ22","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 25th June, 2019\n\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm BST\n7pm-8.15pm CET\n\nChair: @pknowles \n\nAgenda:\n• Introductions (Open) - 5 mins\n• HIPE review: Contexts for Rich Schema Objects ( @kenebert / @brentzundel ) - 35 mins\n[Ref.: https://github.com/hyperledger/indy-hipe/tree/master/text/0138-rich-schema-context ]\n• Discussion: Indy Semantics WG vs. Aries Semantics WG ( @pknowles ) - 25 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-06-25T15:55:00.053Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, July 9th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-06-25T18:33:56.130Z"}
{"msg":"If anyone has any queries regarding the _Contexts for Rich Schema Objects_ HIPE that @kenebert presented in the WG call, please reach out directly to either Ken or @brentzundel . The link to the HIPE - https://github.com/hyperledger/indy-hipe/tree/master/text/0138-rich-schema-context","username":"pknowles","ts":"2019-06-25T18:37:37.024Z"}
{"msg":"During todays WG call, I mentioned the *DPVCG Vocabulary* specification [W3C: Data Privacy Vocabularies and Controls Community Group] which comes hot off the press. The Dativa Innovation team are looking to use DPV defined attributes in 2 ODCA-constructed schemas, namely: (i.) _Personal Data Processing_ (PDP) schema and (ii.) _Generic Consent_ schema. We're also discussing  _personally identifiable information_ (PII) flags in section 4 of the spec with reference to the _Blinding Identity Taxonomy_ (BIT) [https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy ]. Here is the link to the DPV spec. https://www.w3.org/ns/dpv","username":"pknowles","ts":"2019-06-25T20:21:17.021Z"}
{"msg":"During todays WG call, I mentioned the *DPVCG Vocabulary* specification [W3C: Data Privacy Vocabularies and Controls Community Group] which comes hot off the press. The Dativa Innovation team are looking to use DPV defined attributes in 2 ODCA-constructed schemas, namely: (i.) _Personal Data Processing_ (PDP) schema and (ii.) _Generic Consent_ schema. We're also discussing  _personally identifiable information_ (PII) flags to be implemented into section 4 of the spec with reference to the _Blinding Identity Taxonomy_ (BIT) [https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy ]. Here is the link to the DPV spec. https://www.w3.org/ns/dpv","username":"pknowles","ts":"2019-06-25T20:21:17.021Z"}
{"msg":"During todays WG call, I mentioned the *DPVCG Vocabulary* specification [W3C: Data Privacy Vocabularies and Controls Community Group] which comes hot off the press. The Dativa Innovation team are looking to use DPV defined attributes in 2 ODCA-constructed schemas, namely: (i.) a _Personal Data Processing_ (PDP) schema and (ii.) a _Generic Consent_ schema. We're also discussing  _personally identifiable information_ (PII) flags which would be implemented into section 4 of the specification document with reference to the _Blinding Identity Taxonomy_ (BIT) [https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy ]. Here is the link to the DPVCG Vocabulary spec. https://www.w3.org/ns/dpv","username":"pknowles","ts":"2019-06-25T20:21:17.021Z"}
{"msg":"During todays WG call, I mentioned the *DPVCG Vocabulary* specification [W3C: Data Privacy Vocabularies and Controls Community Group] which comes hot off the press. The Dativa Innovation team are looking to use DPV named attributes in 2 ODCA-constructed schemas, namely: (i.) a _Personal Data Processing_ (PDP) schema and (ii.) a _Generic Consent_ schema. We're also discussing  _personally identifiable information_ (PII) flags which would be implemented into section 4 of the specification document with reference to the _Blinding Identity Taxonomy_ (BIT) [https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy ]. Here is the link to the DPVCG Vocabulary spec. https://www.w3.org/ns/dpv","username":"pknowles","ts":"2019-06-25T20:21:17.021Z"}
{"msg":"During todays WG call, I mentioned the *DPVCG Vocabulary* specification [W3C: Data Privacy Vocabularies and Controls Community Group] which comes hot off the press. The Dativa Innovation team are looking to use DPV named attributes in 2 ODCA-constructed schemas, namely: (i.) a _Personal Data Processing_ (PDP) schema and (ii.) a _Generic Consent_ schema. We're also discussing  _personally identifiable information_ (PII) flags which would be implemented into section 4 of the specification document with reference to the _Blinding Identity Taxonomy_ (BIT) [https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy ]. Here is the link to the DPVCG Vocabulary specification. It is really great work! https://www.w3.org/ns/dpv","username":"pknowles","ts":"2019-06-25T20:21:17.021Z"}
{"msg":"During todays WG call, I mentioned the *DPVCG Vocabulary* specification [W3C: Data Privacy Vocabularies and Controls Community Group] which comes hot off the press. The Dativa Innovation team are looking to use DPV named attributes in 2 ODCA-constructed schemas, namely: (i.) a _Personal Data Processing_ (PDP) schema and (ii.) a _Generic Consent_ schema. We're also discussing  _personally identifiable information_ (PII) flags which would be implemented into section 4 of the specification document with reference to the _Blinding Identity Taxonomy_ (BIT) [https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy ]. Here is the link to the DPVCG Vocabulary specification. It really is marvellous work! https://www.w3.org/ns/dpv","username":"pknowles","ts":"2019-06-25T20:21:17.021Z"}
{"msg":"During todays WG call, I mentioned the *DPVCG Vocabulary* specification [W3C: Data Privacy Vocabularies and Controls Community Group] which comes hot off the press. The Dativa Innovation team are looking to use DPV named attributes in 2 ODCA-constructed schemas, namely: (i.) a _Personal Data Processing_ (PDP) schema [https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb ] and (ii.) a _Generic Consent_ schema. We're also discussing  _personally identifiable information_ (PII) flags which would be implemented into section 4 of the specification document with reference to the _Blinding Identity Taxonomy_ (BIT) [https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy ]. Here is the link to the DPVCG Vocabulary specification. It really is marvellous work! https://www.w3.org/ns/dpv","username":"pknowles","ts":"2019-06-25T20:21:17.021Z"}
{"msg":"During todays WG call, I mentioned the *DPVCG Vocabulary* specification [W3C: Data Privacy Vocabularies and Controls Community Group] which comes hot off the press. The Dativa Innovation team are looking to use DPV named attributes in 2 ODCA-constructed schemas, namely: (i.) a _Personal Data Processing_ (PDP) schema [https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb ] and (ii.) a _Generic Consent_ schema. We're also discussing  _personally identifiable information_ (PII) flags which would be implemented into section 4 of the specification document with reference to the _Blinding Identity Taxonomy_ (BIT) [https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy ]. Here is the link to the DPVCG Vocabulary specification. It really is a marvellous piece of work! https://www.w3.org/ns/dpv","username":"pknowles","ts":"2019-06-25T20:21:17.021Z"}
{"msg":"During todays WG call, I mentioned the *DPVCG Vocabulary* specification [W3C: Data Privacy Vocabularies and Controls Community Group] which comes hot off the press. The Dativa Innovation team are looking to use DPV named attributes in 2 ODCA-constructed schemas, namely: (i.) a _Personal Data Processing_ (PDP) schema [https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb ] and (ii.) a _Generic Consent_ schema. We're also discussing  _personally identifiable information_ (PII) flags which would be implemented into section 4 (Personal Data Categories) of the specification document with reference to the _Blinding Identity Taxonomy_ (BIT) [https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy ]. Here is the link to the DPVCG Vocabulary specification. It really is a marvellous piece of work! https://www.w3.org/ns/dpv","username":"pknowles","ts":"2019-06-25T20:21:17.021Z"}
{"msg":"During todays WG call, I mentioned the *DPVCG Vocabulary* specification [W3C: Data Privacy Vocabularies and Controls Community Group] which comes hot off the press. The Dativa Innovation team are looking to use DPV named attributes in 2 ODCA-constructed schemas, namely: (i.) a _Personal Data Processing_ (PDP) schema [https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb] and (ii.) a _Generic Consent_ schema. We're also discussing  _personally identifiable information_ (PII) flags which would be implemented into section 4 (Personal Data Categories) of the specification document with reference to the _Blinding Identity Taxonomy_ (BIT) [https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy]. Here is the link to the DPVCG Vocabulary specification. It really is a marvellous piece of work! https://www.w3.org/ns/dpv","username":"pknowles","ts":"2019-06-25T20:21:17.021Z"}
{"msg":"During todays WG call, I mentioned the *DPVCG Vocabulary* specification [W3C: Data Privacy Vocabularies and Controls Community Group] which comes hot off the press. The Dativa Innovation team are looking to use DPV named attributes in 2 ODCA-constructed schemas, namely: (i.) a _Personal Data Processing_ (PDP) schema [https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb ] and (ii.) a _Generic Consent_ schema. We're also discussing  _personally identifiable information_ (PII) flags which would be implemented into section 4 (Personal Data Categories) of the specification document with reference to the _Blinding Identity Taxonomy_ (BIT) [https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy ]. Here is the link to the DPVCG Vocabulary specification. It really is a marvellous piece of work! https://www.w3.org/ns/dpv","username":"pknowles","ts":"2019-06-25T20:21:17.021Z"}
{"msg":"Harshvardhan \"Harsh\" Pandit, one of the chief editors of the *DPVCG Vocabulary* specification will be presenting the report to the *Indy Semantics WG* on Tuesday, July 9th.","username":"pknowles","ts":"2019-06-26T13:14:18.786Z"}
{"msg":"Harshvardhan \"Harsh\" Pandit, one of the chief editors of the *DPVCG Vocabulary* specification will be presenting the report during the *Indy Semantics WG* call on Tuesday, July 9th.","username":"pknowles","ts":"2019-06-26T13:14:18.786Z"}
{"msg":"Harshvardhan \"Harsh\" Pandit, chief editor of the *DPVCG Vocabulary* specification, will be presenting the report during the next *Indy Semantics WG* call on Tuesday, July 9th. https://www.w3.org/ns/dpv","username":"pknowles","ts":"2019-06-26T13:14:18.786Z"}
{"msg":"Has anybody come across BigID before? If so, any feedback? https://bigid.com","username":"pknowles","ts":"2019-06-26T15:49:06.465Z"}
{"msg":"Has anybody come across *BigID* before? If so, any feedback? https://bigid.com","username":"pknowles","ts":"2019-06-26T15:49:06.465Z"}
{"msg":"Has joined the channel.","username":"MarcoPasotti","ts":"2019-06-26T16:29:59.573Z","type":"uj"}
{"msg":"Very cool","username":"drummondreed","ts":"2019-06-26T19:18:39.696Z"}
{"msg":"During the next *Indy Semantics WG* call (Tuesday, July 9th), @janl will be presenting a preliminary demo on *consent lifecycle using Hyperledger Indy*. The demo goes through the automated steps of setting up the ledger, exchange of PDP (personal data processing) requirements, creating a consent receipt certificate, performing a proof that a consent was given and taking down the ledger. Alice, Bob, Acme and Faber are our volunteer actors once again!","username":"pknowles","ts":"2019-07-04T04:50:40.331Z"}
{"msg":"During the next *Indy Semantics WG* call (Tuesday, July 9th), @janl will also be presenting a preliminary demo on *consent lifecycle using Hyperledger Indy*. The demo goes through the automated steps of setting up the ledger, exchange of PDP (personal data processing) requirements, creating a consent receipt certificate, performing a proof that a consent was given and taking down the ledger. Alice, Bob, Acme and Faber are our volunteer actors once again!","username":"pknowles","ts":"2019-07-04T04:50:40.331Z"}
{"msg":"@pknowles there was a presentation during Identity Working group call on June 12 of the India consent layer by Ajay Jadhav- details available on the IDWG meeting notes. https://wiki.hyperledger.org/display/IWG/2019-06-12-Notes ","username":"VipinB","ts":"2019-07-07T15:34:23.166Z"}
{"msg":"Thanks, @VipinB . @janl :top: ","username":"pknowles","ts":"2019-07-08T09:53:30.778Z"}
{"msg":"Thanks, @VipinB . @janl :top: check out the link.","username":"pknowles","ts":"2019-07-08T09:53:30.778Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 9th July, 2019\n\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm BST\n7pm-8.15pm CET\n\nChair: @pknowles \n\nAgenda:\n• Introductions (Open) - 5 mins\n• DPVCG Vocabulary specification [Data Privacy Vocabulary] (H. Pandit) - 25 mins\n[Ref.: https://www.w3.org/ns/dpv ]\n• Demo: Consent lifecycle using Hyperledger Indy ( @janl ) - 30 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-07-09T15:54:25.901Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, July 23rd. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-07-09T19:47:49.153Z"}
{"msg":"@pknowles For those of us who were not able to attend, could you post a few bullets of highlights from the calls?","username":"drummondreed","ts":"2019-07-11T06:51:55.045Z"}
{"msg":"Has joined the channel.","username":"iamtxena","ts":"2019-07-12T09:01:41.976Z","type":"uj"}
{"msg":"I was on the call. Will try to summarize what I remember\n1. DPV by Harsh was about  Data Protection Vocabulary developed in a w3C community group: https://docs.google.com/presentation/d/1qQIdIxpkPdldS_RR7x8L2ZAq3plse9yd-WxcFZgBjY0/edit#slide=id.gc6f9e470d_0_126```\n2. It is expressed in RDF, it is a collection of vocabularies covering multiple dimensions and highly focused on GDPR themes (like data controllers and the like)\n3. The dimensions include data subject, purpose (including legal basis), consent, and a host of others (more details in the slides- look at 3,4 etc)\n4.  Follow on by a demo of consent lifecycle \n```","username":"VipinB","ts":"2019-07-12T18:56:34.730Z"}
{"msg":"I was on the call. Will try to summarize what I remember\n1. DPV by Harsh was about  Data Protection Vocabulary developed in a w3C community group: https://docs.google.com/presentation/d/1qQIdIxpkPdldS_RR7x8L2ZAq3plse9yd-WxcFZgBjY0/edit#slide=id.gc6f9e470d_0_126\n2. It is expressed in RDF, it is a collection of vocabularies covering multiple dimensions and highly focused on GDPR themes (like data controllers and the like)\n3. The dimensions include data subject, purpose (including legal basis), consent, and a host of others (more details in the slides- look at 3,4 etc)\n4.  Follow on by a demo of consent lifecycle by janl implemented thru Hyperledger Indy.\n","username":"VipinB","ts":"2019-07-12T18:56:34.730Z"}
{"msg":"I was on the call. Will try to summarize what I remember\n1. DPV by Harshvardhan was about  Data Protection Vocabulary developed in a w3C community group: https://docs.google.com/presentation/d/1qQIdIxpkPdldS_RR7x8L2ZAq3plse9yd-WxcFZgBjY0/edit#slide=id.gc6f9e470d_0_126\n2. It is expressed in RDF, it is a collection of vocabularies covering multiple dimensions and highly focused on GDPR themes (like data controllers and the like)\n3. The dimensions include data subject, purpose (including legal basis), consent, and a host of others (more details in the slides- look at 3,4 etc)\n4.  Follow on by a demo of consent lifecycle by janl implemented thru Hyperledger Indy.\n5. @janl and Harsh Pandit will collaborate, @janl will normalize the vocabulary and types based on the DPV document","username":"VipinB","ts":"2019-07-12T18:56:34.730Z"}
{"msg":"Thanks, @VipinB . Nicely summarised!","username":"pknowles","ts":"2019-07-12T19:31:56.500Z"}
{"msg":"Thanks, @VipinB !","username":"drummondreed","ts":"2019-07-12T23:57:57.221Z"}
{"msg":"@drummondreed - The call was recorded. https://drive.google.com/drive/u/0/folders/159vc1HsnAsgb8hOh-LFtp8u9spP5iL1I . The DPV talk by Harsh Pandit starts at 4mins. The consent lifecycle demo by @janl starts at 40mins 30secs.","username":"pknowles","ts":"2019-07-13T04:01:03.528Z"}
{"msg":"Has joined the channel.","username":"ravip","ts":"2019-07-13T19:40:04.119Z","type":"uj"}
{"msg":"Hello everyone, is there a way to send some data when sending a proof request? \nI mean, let's say a data controller (DC) is asking gov attested address to a data subject (DS) in a proof request and wants to specify the reason for the ask as well. So is it possible to send that data in the form of key value pair in a proof request ","username":"ravip","ts":"2019-07-13T19:40:05.812Z"}
{"msg":"*request?","username":"ravip","ts":"2019-07-13T19:40:10.905Z"}
{"msg":"Also, is there some kind of explorer for microledger between entities wherein a data subject could see what they have consented to and for how long to data controllers?","username":"ravip","ts":"2019-07-13T19:51:31.869Z"}
{"msg":"consent-flow","username":"ravip","ts":"2019-07-14T21:59:04.027Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=RsKdfHe2hRyXvZFZq) The fun answer is perhaps :-).  Technically, yes it can be done.  The challenge is that the Holder must know what that extra data is about - why it is there and what to do with it.  To achieve interoperability, we are building up versioned protocols that define the interactions between agents indepdently implemented.  **There is a current specification for the \"Present Proof\" process that describes protocol here - https://github.com/hyperledger/aries-rfcs/tree/master/features/0037-present-proof\n\nIn theory, you could use the \"comment\" field for that, but again, the Holder is likely to just display that to the Holder/Prover.","username":"swcurran","ts":"2019-07-15T02:12:44.071Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=RsKdfHe2hRyXvZFZq","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=RsKdfHe2hRyXvZFZq","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=onAgSi6k6u6FZDg5k) The implementation of the \"microledger\" has evolved to be more of a set of related records in a data store. There is a connection object (the relationship between the entities that swapped pairwise, private DIDs) and there is data collected about the connection. All of that is stored in secured storage (\"wallet\" in Indy), and can be manipulated by the agent code as necessary.  It is not implemented as ledger in the blockchain sense (distributed data store with consensus, etc.).  You can look at the code in https://github.com/hyperledger/aries-cloudagent-python for an implementation.","username":"swcurran","ts":"2019-07-15T02:17:41.894Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=onAgSi6k6u6FZDg5k","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=onAgSi6k6u6FZDg5k","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Thank you @swcurran for sharing your knowledge and pointers on the topic.","username":"ravip","ts":"2019-07-15T06:37:02.886Z"}
{"msg":"I was trying to build a consent application using hyperledget indy and I was thinking how would one implement the process of 'revoking consent'?\n\nI listened to the recorded call and got an idea that granting consent could be implemented interms of Data controller (DC) issuing a Verifiable Credential (VC) to Data Subject (DS) thereby giving a consent receipt to DS, later on a verifier could request a proof from the DS for the same.\n\nBut lets say, if DS wants to revoke the consent that he has already provided, then how would that work?\n","username":"ravip","ts":"2019-07-15T06:45:44.354Z"}
{"msg":"Will DC keep on continuously checking if DS has revoked the consent or not and if he has, then invalidate the claim? ","username":"ravip","ts":"2019-07-15T06:54:25.280Z"}
{"msg":"Has joined the channel.","username":"jadhavajay","ts":"2019-07-15T13:44:13.339Z","type":"uj"}
{"msg":"@ravip , @janl is the man to chat to re consent lifecycle.","username":"pknowles","ts":"2019-07-15T14:02:34.877Z"}
{"msg":"Hi @ravip - @janl is the man to chat to re consent lifecycle on HL Indy.","username":"pknowles","ts":"2019-07-15T14:02:34.877Z"}
{"msg":"Hi @ravip - @janl is the man to chat to re consent lifecycle using HL Indy.","username":"pknowles","ts":"2019-07-15T14:02:34.877Z"}
{"msg":"Good questions @ravip. You seem to have several, but will answer the revoking consent first. Planned to use the consent receipt certificate revocation. The DS has to inform DC to revoke consent which triggers the revocation by the DC. Due to the fact you cannot trust the DC the DS controls the verification (proof request) from a 3rd party (subDC) and basically make assertions that fail the proof. The verifier may have difficulty to discern a consent revocation since proof is a simple check of assertions. Need to work out how this best can be achieved.","username":"janl","ts":"2019-07-15T14:19:58.562Z"}
{"msg":"Good questions @ravip . You seem to have several, but will answer the revoking consent first. Planned to use the consent receipt certificate revocation. The DS has to inform DC to revoke consent which triggers the revocation by the DC. Due to the fact you cannot trust the DC the DS controls the verification (proof request) from a 3rd party (subDC) and basically make assertions that fail the proof. The verifier may have difficulty to discern a consent revocation since proof is a simple check of assertions. Need to work out how this best can be achieved.","username":"janl","ts":"2019-07-15T14:19:58.562Z"}
{"msg":"@janl do you have plans to create an Aries RFC for consent receipts?","username":"troyronda","ts":"2019-07-16T13:25:21.162Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, August 6th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"troyronda","ts":"2019-07-16T13:25:21.162Z"}
{"msg":"Correct. The old HIPE will become an Aries RFC. What may not be completely clear is in which form will the RFC look like. Goal is to create a best practices and guidance of how to setup consent receipt.","username":"janl","ts":"2019-07-16T13:43:29.678Z"}
{"msg":"Has joined the channel.","username":"smithsamuelm","ts":"2019-07-22T21:35:23.573Z","type":"uj"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 23rd July, 2019\n\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm BST\n7pm-8.15pm CET\n\nChair: @pknowles \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Novartis pilots utilizing ODCA ( @pknowles ) - 15 mins\n• Abbreviated PSCI SAQ & Audit Report Template for Service Providers & General Manufacturers ( @pknowles ) - 15 mins \n[Ref.: https://pscinitiative.org/resource?resource=318 ]\n• Global Decentralized Data Economy ( @mtfk ) - 15 mins\n[Ref.: https://docs.google.com/document/d/19ewSzXM4TUPzj8S9pGMCxBY4CkQxQ1kL1kiOQ6y8ANg/edit?ts=5d322608 ]\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-07-23T16:23:46.304Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, August 6th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-07-23T19:57:48.034Z"}
{"msg":"Due to a meeting clash, today's Indy Semantics WG call will be postponed to next Tuesday, August 13th. Apologies for the inconvenience. Look forward to catching up next week. Best. Paul","username":"pknowles","ts":"2019-08-06T16:11:48.971Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 13th August, 2019\n\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm BST\n7pm-8.15pm CET\n\nChair: @pknowles \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Rich Schema demo ( @kenebert ) - 30 mins\n• Update: TPRM project utilizing ODCA [Novartis] ( @pknowles ) - 20 mins\n[Ref.: https://pscinitiative.org/resource?resource=318 ]\n\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-08-13T16:14:48.142Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 13th August, 2019\n\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm BST\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Rich Schema demo ( @kenebert ) - 30 mins\n• Update: TPRM project utilizing ODCA [Novartis] ( @pknowles ) - 20 mins\n[Ref.: https://pscinitiative.org/resource?resource=318 ]\n• Update: Consent Lifecycle RFC ( @janl ) - 10 mins\n[Ref.: https://github.com/hyperledger/indy-hipe/pull/55 ]\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-08-13T16:17:04.941Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 13th August, 2019\n\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm BST\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Rich Schema demo ( @kenebert ) - 30 mins\n• Update: TPRM project utilizing ODCA [Novartis] ( @pknowles ) - 20 mins\n[Ref.: https://pscinitiative.org/resource?resource=318 ]\n• Update: Consent Lifecycle RFC ( @janl ) - 10 mins\n[Ref.: https://github.com/hyperledger/aries-rfcs/blob/master/concepts/0167-data-consent-lifecycle/README.md ]\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-08-13T16:17:04.941Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 13th August, 2019\n\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm BST\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Rich Schema demo ( @kenebert ) - 30 mins\n• Update: TPRM project utilizing ODCA [Novartis] ( @pknowles ) - 20 mins\n[Ref.: https://pscinitiative.org/resource?resource=318 ]\n• Update: Data Consent Lifecycle RFC ( @janl ) - 10 mins\n[Ref.: https://github.com/hyperledger/aries-rfcs/blob/master/concepts/0167-data-consent-lifecycle/README.md ]\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-08-13T16:17:04.941Z"}
{"msg":"The agenda, video, notes, etc. from last week's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be today at 11am MT / 7pm CET. Agenda to follow. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-08-20T09:04:31.354Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 20th August, 2019\n\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm BST\n7pm-8.15pm CET\n\nChair: @pknowles   \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Semantics-related RFC update: Data Consent Lifecycle RFC ( @janl ) - 10 mins\n[Ref.: https://github.com/hyperledger/aries-rfcs/blob/master/concepts/0167-data-consent-lifecycle/README.md ]\n• Personal Data Processing (PDP) schema in ODCA format ( @pknowles ) - 15 mins\n[Ref.: https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb ]\n• Open discussion on pending/upcoming projects - 25 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-08-20T15:51:07.503Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 20th August, 2019\n\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm BST\n7pm-8.15pm CET\n\nChair: @pknowles   \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Semantics-related RFC updates: Data Consent Lifecycle RFC ( @janl ) - 10 mins\n[Ref.: https://github.com/hyperledger/aries-rfcs/blob/master/concepts/0167-data-consent-lifecycle/README.md ]\n• Personal Data Processing (PDP) schema in ODCA format ( @pknowles ) - 15 mins\n[Ref.: https://drive.google.com/drive/u/0/folders/1FFU47tCTu7XbNnpD2oZlbgglrKiTh5yb ]\n• Open discussion on pending/upcoming projects or events - 25 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-08-20T15:51:07.503Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, September 3rd. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-08-20T18:57:03.657Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 3rd September, 2019\n\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm BST\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Schema Bases, PII flagging and a proposed Masking Overlay ( @janl  / @pknowles ) - 10 mins\n[Ref.: https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy ]\n• ODCA: What has been built so far? ( @mtfk ) - 15 mins\n[Ref.:  https://github.com/THCLab/schema-cake ]\n• Hashlinks for ODCA: A discussion with Manu Sporny ( @mtfk ) - 10 mins\n• Sitra Service WG ( @mtfk ) - 10 mins\n[Ref. https://www.sitra.fi/en/ ]\n• Vienna Identify meetup ( @mtfk ) - 10 mins\n[Ref. https://www.meetup.com/Vienna-Digital-Identity-Meetup/events/262359964/ ]\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-09-03T16:11:02.738Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 3rd September, 2019\n\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm BST\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Schema Bases, PII flagging and a proposed Masking Overlay ( @janl  / @pknowles ) - 10 mins\n[Ref.: https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy ]\n• ODCA: What has been built so far? ( @mtfk ) - 15 mins\n[Ref.:  https://github.com/THCLab/schema-cake ]\n• Hashlinks for ODCA: A discussion with Manu Sporny ( @mtfk ) - 10 mins\n[Ref.: https://tools.ietf.org/html/draft-sporny-hashlink-00 ]\n• Sitra Service WG ( @mtfk ) - 10 mins\n[Ref. https://www.sitra.fi/en/ ]\n• Vienna Digital Identify meetup ( @mtfk ) - 10 mins\n[Ref. https://www.meetup.com/Vienna-Digital-Identity-Meetup/events/262359964/ ]\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-09-03T16:11:02.738Z"}
{"msg":"The agenda, video, notes, etc. from yesterday's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, September 17th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-09-04T05:09:47.787Z"}
{"msg":"There are a number of Hyperledger Indy/Aries community members attending the MyData conference in Helsinki next week. If anyone in this community will be presenting at the conference and would like to do a trial run to a familiar audience, we can accommodate two 15 minute presentations during tomorrow's HL Indy Semantics WG call. DM me if you would like to reserve one of those presentation slots.","username":"pknowles","ts":"2019-09-16T14:36:48.804Z"}
{"msg":"There are a number of Hyperledger Indy/Aries community members attending the MyData conference in Helsinki next week. If anyone in this community will be presenting at the conference and would like to do a trial run to a familiar audience, we can accommodate two 15 minute presentations during tomorrow's HL Indy Semantics WG call. DM me if you would like to reserve one of those slots.","username":"pknowles","ts":"2019-09-16T14:36:48.804Z"}
{"msg":"There are a number of Hyperledger Indy/Aries community members attending the MyData conference in Helsinki next week. If anyone in this community will be presenting at the conference and would like to try it out on a familiar audience, we can accommodate two 15 minute presentations during tomorrow's HL Indy Semantics WG call. DM me if you would like to reserve one of those slots.","username":"pknowles","ts":"2019-09-16T14:36:48.804Z"}
{"msg":"There are a number of Hyperledger Indy/Aries community members attending the MyData conference in Helsinki next week. If anyone in this community will be presenting at the conference and would like to try it out on a familiar audience beforehand, we can accommodate two 15 minute presentations during tomorrow's HL Indy Semantics WG call. DM me if you would like to reserve a slot.","username":"pknowles","ts":"2019-09-16T14:36:48.804Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 17th September, 2019\n\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm BST\n7pm-8.15pm CET\n\nChair: @pknowles \n\nAgenda:\n• Introductions (Open) - 5 mins\n• DNS over HTTPS ( @mtfk ) - 10 mins\n[Ref.: https://www.eff.org/deeplinks/2019/09/encrypted-dns-could-help-close-biggest-privacy-gap-internet-why-are-some-groups ]\n• Machine-readable ODCA specification ( @pknowles ) - 10 mins\n• Overlay metadata attributes: Discuss  ( @mtfk ) - 10 mins\n• MyData 2019 ( @pknowles ) - 10 mins\n[Ref. https://mydata2019.org ]\n• Internet Identity Workshop [IIW] ( @pknowles ) - 10 mins\n[Ref. https://internetidentityworkshop.com ]\n• Any other business (Open) - 5 mins\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-09-17T16:17:02.161Z"}
{"msg":"The agenda, video, notes, etc. from yesterday's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, October 1st. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-09-18T01:30:59.464Z"}
{"msg":"Hi guys, it's purely by accident that I dropped in to watch today recording.  Thank you @pknowles for noting the article on DNS.  My particular interest is that I've built a Universal DID Server based entirely on DNS procotols and structures using the DnsServer open source project as a basis.  It's working and working very well ...still early but it's working.  Here's a screenshot....","username":"mwherman2000","ts":"2019-09-18T02:21:43.624Z"}
{"msg":"Hi guys, it's purely by accident that I dropped in to watch today's recording.  Thank you @pknowles for noting the article on DNS.  My particular interest is that I've built a Universal DID Server based entirely on DNS procotols and structures using the DnsServer open source project as a basis.  It's working and working very well ...still early but it's working.  Here's a screenshot....","username":"mwherman2000","ts":"2019-09-18T02:21:43.624Z"}
{"msg":"","username":"mwherman2000","ts":"2019-09-18T02:22:17.962Z","attachments":[{"type":"file","title":"Clipboard - September 17, 2019 8:22 PM","title_link":"/file-upload/Y73PpiERP8czr9x9t/Clipboard%20-%20September%2017,%202019%208:22%20PM","image_url":"/file-upload/Y73PpiERP8czr9x9t/Clipboard%20-%20September%2017,%202019%208:22%20PM","image_type":"image/png","image_size":108908,"url":"/file-upload/Y73PpiERP8czr9x9t/Clipboard%20-%20September%2017,%202019%208:22%20PM","remote":false,"fileId":"Y73PpiERP8czr9x9t","fileName":"Clipboard - September 17, 2019 8:22 PM"}]}
{"msg":"The `Name` column is the Subject's DID in the `did:neonation` DID method space.","username":"mwherman2000","ts":"2019-09-18T02:24:12.147Z"}
{"msg":"It's very cool.","username":"mwherman2000","ts":"2019-09-18T02:24:43.323Z"}
{"msg":"Here's a sample Universal DID Document ...which leverages the DNS over HTTPS proctocol...","username":"mwherman2000","ts":"2019-09-18T02:27:54.483Z"}
{"msg":"","username":"mwherman2000","ts":"2019-09-18T02:28:01.293Z","attachments":[{"type":"file","title":"Clipboard - September 17, 2019 8:27 PM","title_link":"/file-upload/zhWGBEcAgEAagpcu8/Clipboard%20-%20September%2017,%202019%208:27%20PM","image_url":"/file-upload/zhWGBEcAgEAagpcu8/Clipboard%20-%20September%2017,%202019%208:27%20PM","image_type":"image/png","image_size":97442,"url":"/file-upload/zhWGBEcAgEAagpcu8/Clipboard%20-%20September%2017,%202019%208:27%20PM","remote":false,"fileId":"zhWGBEcAgEAagpcu8","fileName":"Clipboard - September 17, 2019 8:27 PM"}]}
{"msg":"@mwherman2000 Do you fancy running through a Universal DID Server demo during the next HL Indy Semantics call on Oct.1st?","username":"pknowles","ts":"2019-09-18T15:34:21.861Z"}
{"msg":"Oct. 15 or 116th would be better Paul","username":"mwherman2000","ts":"2019-09-18T15:41:04.885Z"}
{"msg":"Oct.15th. Noted.","username":"pknowles","ts":"2019-09-18T15:43:01.732Z"}
{"msg":"Note: https://github.com/TechnitiumSoftware/DnsServer/issues/87","username":"mwherman2000","ts":"2019-09-19T00:13:24.560Z"}
{"msg":"Has joined the channel.","username":"Alexi","ts":"2019-09-24T16:58:00.041Z","type":"uj"}
{"msg":"Guardianship Task Force white paper draft—please review if you are able as we will be using this to hold a session at Internet Identity Workshop next week: https://docs.google.com/document/d/1d1I3f4sBlc9nLt_TAtsXvi-EKSzECaQObKZPL0Zx_9U/edit?usp=sharing","username":"drummondreed","ts":"2019-09-25T12:17:00.485Z"}
{"msg":"Interesting read. Would this be a special form of consent? For example a court may assign guardianship to an individual. This would be down by having the court \"consent\" to a guardian to represent the individual.","username":"janl","ts":"2019-09-29T16:17:53.101Z"}
{"msg":"Hi,\nI have an update to my rfc: 167, data consent lifecycle, which may be of general interest. I have given several demos of how indy-sdk can be used can used for creating consent receipt and performing proof request without revealing any private information. The demo is based on getting-started and is now available as a reference implementation for anybody to check out. Once Aries is ready the plan is to adapt it over. The next step for the reference implementation is to add revocation example which is on the works. Welcome to come with feedback.\n\nhttps://github.com/JanLin/aries-rfcs/tree/master/concepts/0167-data-consent-lifecycle\n\nBest regards,\nJan\n\nNote the new reference implementation is in a Pull Request #238 to hyperledger:master.","username":"janl","ts":"2019-09-30T21:02:32.532Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 19th February, 2019\n\nTime:\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles   \n\nAttendee register:\nhttps://docs.google.com/document/d/1ayXu4JLznvi1-qM0mRRN24EPuAWpAeV4f1f6DqSKG5c/edit\n\nAgenda:\n• Introductions (Open) - 5 mins\n• Aries RFC 0167: Data Consent Lifecycle - Status update with reference implementation ( @janl ) - 10 mins\n   - Reference: https://github.com/hyperledger/aries-rfcs/blob/master/concepts/0167-data-consent-lifecycle/README.md\n• Proposed white paper: “Decentralized Identity for Human Beings” - Creating a blue print for the building blocks of a human-centric data economy ( @pknowles ) - 10 mins\n• New global ontologies required to fulfil the promise of a decentralized data economy ( @pknowles ) - 10 mins\n• Novartis TPRM project update ( @pknowles ) - 10 mins\n• MyData 2019 summary ( @pknowles / @mtfk ) - 10 mins\n   - Reference: https://mydata2019.org\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-10-01T11:28:49.624Z"}
{"msg":"The agenda, video, notes, etc. from yesterday's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, October 15th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-10-01T22:58:25.544Z"}
{"msg":"Has joined the channel.","username":"PaulA","ts":"2019-10-08T16:12:06.501Z","type":"uj"}
{"msg":"The Blinding Identity Taxonomy (BIT) is a list of 47 elements that could potentially unblind the identity of an organisation, a person or a thing. https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy\n\nA 48th element will soon be added to the BIT ... \"Link Secrets\"\n\n*Link Secret*\nAn item of Private Data used by a Prover to link a Credential uniquely to the Prover. A Link Secret is an input to Zero Knowledge Proofs that enables Claims from one or more Credentials to be combined in order to prove that the Credentials have a common Holder (the Prover). A Link Secret should be known only to the Prover.","username":"pknowles","ts":"2019-10-09T21:49:43.306Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 15th October, 2019\n\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm BST\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Demo: Universal DID Server ( @mwherman2000 ) - 30 mins\n[Ref.: https://github.com/TechnitiumSoftware/DnsServer/issues/87 ]\n• Use case: (DMV) Division of Motor Vehicles integration into decentralized identity blockchain ( @wksantiago ) - 15 mins\n• Novartis TPRM update ( @pknowles ) - 10 mins\n• Any other business (Open) - 5 mins\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-10-15T16:27:57.792Z"}
{"msg":"Has joined the channel.","username":"wksantiago","ts":"2019-10-15T16:27:57.854Z","type":"uj"}
{"msg":"The agenda, video, notes, etc. from yesterday's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, October 29th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-10-16T02:22:51.986Z"}
{"msg":"Has joined the channel.","username":"yunho.chung","ts":"2019-10-16T08:03:34.337Z","type":"uj"}
{"msg":"My apologies for missing the call yesterday.  ","username":"mwherman2000","ts":"2019-10-16T11:35:00.433Z"}
{"msg":"@mwherman2000 No stress. Happy to schedule in the demo for October 29th. Let me know if that suits.","username":"pknowles","ts":"2019-10-16T11:38:33.352Z"}
{"msg":"Yes, please","username":"mwherman2000","ts":"2019-10-16T11:40:25.957Z"}
{"msg":"From Identity Working Group presentation by @janl \nNotes have been updated see https://wiki.hyperledger.org/display/IWG/2019-10-16 for details\n\nNotes:\nJan Linquist gave a teaser on the RFC Consent in Hyperledger Aries .\n\nThe paper consists of : \n\nAn ontology - terms that are relevant and objects that are built up from these terms\n\nLegal compliance standards\nHow can DID based systems implement a consent lifecyle\nA reference implementation of a lifecycle\nConsent certificate + proof\nProcess Flow\nJan says the paper should be properly called the enforcement of a Privacy Agreement\nWe spoke briefly of the following hard problems\n\nHierarchy of sharing (what if the original relying party (RP) sells or shares the information to another party) and so on?\nSelective disclosure, granularity and quality of information shared (derived information like age boundary-i.e. older than x, younger than y from birthday)\nMeta data harvesting (IP addresses, location) and creating correlations\nBankruptcy and delegation of control of privacy proof \nForgetting: what sort of regulation should control this\nCommon themes and ideas around sovereign or multi-state regulations (like GDPR, India Consent Layer, CCA, New York state privacy, Chinese regulation on consent) and how to implement them, are there patterns code snippets libraries\nSome techniques proposed on the Semantics call\n\nAdding masking layers for psuedonimisation\nMetadata turns up as machine readable quasi-identifiers- what to do about this\nJan agreed to do a demo of the reference lifecycle in a future meeting- we will publicize this and hopefully we will have greater participation.\n","username":"VipinB","ts":"2019-10-16T20:48:51.351Z"}
{"msg":"Has joined the channel.","username":"ajayjadhav","ts":"2019-10-18T13:36:46.672Z","type":"uj"}
{"msg":"@janl @VipinB : Jan and I continue to work closely with Mark Lizar, CEO at OpenConsent and main seed behind Kantara's Consent Receipt Specification, and Harsh Pandit, the main contributing author of the Data Privacy Vocabulary, on consent development on Hyperledger. \n\nYou can read more about the recent collaboration agreement between Financial Data Exchange (FDX) and Kantara on an Open Banking consent receipt framework. The following interview explains what a \"consent receipt\" is and why is it important? Kantara's Colin Wallis and FDX's Don Cardinal explain. https://financialdataexchange.org/blogs/fdx-blog/interview-fdx-s-don-cardinal-and-kantara-s-colin-wallace-talk-about-recent-collaborating-agreement","username":"pknowles","ts":"2019-10-22T23:33:41.244Z"}
{"msg":"@janl @VipinB : Jan and I continue to work closely with Mark Lizar, CEO at OpenConsent and main seed behind Kantara's Consent Receipt Specification, and Harsh Pandit, the main contributing author of the Data Privacy Vocabulary, on consent development on Hyperledger. \n\nYou can read more about the recent collaboration agreement between Financial Data Exchange (FDX) and Kantara on an Open Banking consent receipt framework via the following link. The interview explains what a \"consent receipt\" is and why is it important. Kantara's Colin Wallis and FDX's Don Cardinal explain. https://financialdataexchange.org/blogs/fdx-blog/interview-fdx-s-don-cardinal-and-kantara-s-colin-wallace-talk-about-recent-collaborating-agreement","username":"pknowles","ts":"2019-10-22T23:33:41.244Z"}
{"msg":"@janl @VipinB Jan and I continue to work closely with Mark Lizar, CEO at OpenConsent and the main contributor of Kantara's Consent Receipt Specification, and Harsh Pandit, the main contributing author of the Data Privacy Vocabulary, on consent development on Hyperledger. \n\nYou can read more about the recent collaboration agreement between Financial Data Exchange (FDX) and Kantara on an Open Banking consent receipt framework via the following link. The interview explains what a \"consent receipt\" is and why is it important. Kantara's Colin Wallis and FDX's Don Cardinal explain. https://financialdataexchange.org/blogs/fdx-blog/interview-fdx-s-don-cardinal-and-kantara-s-colin-wallace-talk-about-recent-collaborating-agreement","username":"pknowles","ts":"2019-10-22T23:33:41.244Z"}
{"msg":"@janl @VipinB Jan and I continue to work closely with Mark Lizar, CEO at OpenConsent and the main contributor of Kantara's Consent Receipt Specification, and Harsh Pandit, the main contributing author of the Data Privacy Vocabulary, on consent development on Hyperledger. Jan is leading that initiative. \n\nYou can read more about the recent collaboration agreement between Financial Data Exchange (FDX) and Kantara on an Open Banking consent receipt framework via the following link. The interview explains what a \"consent receipt\" is and why is it important. Kantara's Colin Wallis and FDX's Don Cardinal explain. https://financialdataexchange.org/blogs/fdx-blog/interview-fdx-s-don-cardinal-and-kantara-s-colin-wallace-talk-about-recent-collaborating-agreement","username":"pknowles","ts":"2019-10-22T23:33:41.244Z"}
{"msg":"@janl @VipinB Jan and I continue to work closely with Mark Lizar, CEO at OpenConsent and seed contributor of Kantara's Consent Receipt Specification, and Harsh Pandit, the main contributing author of the Data Privacy Vocabulary, on consent development on Hyperledger. Jan is leading that initiative. \n\nYou can read more about the recent collaboration agreement between Financial Data Exchange (FDX) and Kantara on an Open Banking consent receipt framework via the following link. The interview explains what a \"consent receipt\" is and why is it important. Kantara's Colin Wallis and FDX's Don Cardinal explain. https://financialdataexchange.org/blogs/fdx-blog/interview-fdx-s-don-cardinal-and-kantara-s-colin-wallace-talk-about-recent-collaborating-agreement","username":"pknowles","ts":"2019-10-22T23:33:41.244Z"}
{"msg":"@janl @VipinB Jan and I continue to work closely with Mark Lizar, CEO at OpenConsent and seed contributor of Kantara's Consent Receipt Specification, and Harsh Pandit, the main contributing author of the Data Privacy Vocabulary, on consent development using Hyperledger. Jan is leading that initiative. \n\nYou can read more about the recent collaboration agreement between Financial Data Exchange (FDX) and Kantara on an Open Banking consent receipt framework via the following link. The interview explains what a \"consent receipt\" is and why is it important. Kantara's Colin Wallis and FDX's Don Cardinal explain. https://financialdataexchange.org/blogs/fdx-blog/interview-fdx-s-don-cardinal-and-kantara-s-colin-wallace-talk-about-recent-collaborating-agreement","username":"pknowles","ts":"2019-10-22T23:33:41.244Z"}
{"msg":"@janl @VipinB Jan and I continue to work closely with Mark Lizar, CEO at OpenConsent and seed contributor of Kantara's Consent Receipt Specification, and Harsh Pandit, the main contributing author of the Data Privacy Vocabulary, on consent development using Hyperledger Aries. Jan is leading that initiative. \n\nYou can read more about the recent collaboration agreement between Financial Data Exchange (FDX) and Kantara on an Open Banking consent receipt framework via the following link. The interview explains what a \"consent receipt\" is and why is it important. Kantara's Colin Wallis and FDX's Don Cardinal explain. https://financialdataexchange.org/blogs/fdx-blog/interview-fdx-s-don-cardinal-and-kantara-s-colin-wallace-talk-about-recent-collaborating-agreement","username":"pknowles","ts":"2019-10-22T23:33:41.244Z"}
{"msg":"@janl @VipinB Jan and I continue to work closely with Mark Lizar, CEO at OpenConsent and seed contributor to Kantara's Consent Receipt Specification, and Harsh Pandit, main contributing author of the Data Privacy Vocabulary, on consent development implementation using Hyperledger Aries. Jan is leading that initiative. \n\nYou can read more about the recent collaboration agreement between Financial Data Exchange (FDX) and Kantara on an Open Banking consent receipt framework via the following link. The interview explains what a \"consent receipt\" is and why is it important. Kantara's Colin Wallis and FDX's Don Cardinal explain. https://financialdataexchange.org/blogs/fdx-blog/interview-fdx-s-don-cardinal-and-kantara-s-colin-wallace-talk-about-recent-collaborating-agreement","username":"pknowles","ts":"2019-10-22T23:33:41.244Z"}
{"msg":"@janl @VipinB Jan and I continue to work closely with Mark Lizar, CEO at OpenConsent and seed contributor to Kantara's Consent Receipt Specification, and Harsh Pandit, main contributing author of the Data Privacy Vocabulary, on consent development implementation using Hyperledger Aries. Jan is leading that initiative. \n\nYou can read more about the recent collaboration agreement between Financial Data Exchange (FDX) and Kantara on an Open Banking consent receipt framework via the following link. The interview explains what a \"consent receipt\" is and why it is important. Kantara's Colin Wallis and FDX's Don Cardinal explain. https://financialdataexchange.org/blogs/fdx-blog/interview-fdx-s-don-cardinal-and-kantara-s-colin-wallace-talk-about-recent-collaborating-agreement","username":"pknowles","ts":"2019-10-22T23:33:41.244Z"}
{"msg":"@janl @VipinB Jan and I continue to work closely with Mark Lizar, CEO at OpenConsent and seed contributor to Kantara's Consent Receipt Specification, and Harsh Pandit, main contributing author of the Data Privacy Vocabulary, on consent development implementation using Hyperledger Aries. Jan is leading that initiative. \n\nYou can read more about the recent collaboration agreement between Financial Data Exchange (FDX) and Kantara on an Open Banking consent receipt framework via the following link. The interview explains what a \"consent receipt\" is and why it is important. Kantara's Colin Wallis and FDX's Don Cardinal explain. https://financialdataexchange.org/blogs/fdx-blog/interview-fdx-s-don-cardinal-and-kantara-s-colin-wallace-talk-about-recent-collaborating-agreement\n\nRelated links ...\n(i.) Kantara's Consent Receipt Specification - \nhttps://kantarainitiative.org/confluence/display/infosharing/Consent+Receipt+Specification\n(ii.) Data Privacy Vocabulary -\nhttps://www.w3.org/ns/dpv/\n(iii.) Data Consent Lifecycle RFC (Hyperledger Aries) - \nhttps://github.com/hyperledger/aries-rfcs/blob/master/concepts/0167-data-consent-lifecycle/README.md","username":"pknowles","ts":"2019-10-22T23:33:41.244Z"}
{"msg":"@janl @VipinB Jan and I continue to work closely with Mark Lizar, CEO at OpenConsent and seed contributor to Kantara's Consent Receipt Specification, and Harsh Pandit, main contributing author of the Data Privacy Vocabulary, on consent development implementation using Hyperledger Aries. Jan is leading that initiative. \n\nYou can read more about a recent collaboration agreement between Financial Data Exchange (FDX) and Kantara on an Open Banking consent receipt framework via the following link. The interview explains what a \"consent receipt\" is and why it is important. Kantara's Colin Wallis and FDX's Don Cardinal explain. https://financialdataexchange.org/blogs/fdx-blog/interview-fdx-s-don-cardinal-and-kantara-s-colin-wallace-talk-about-recent-collaborating-agreement\n\nRelated links ...\n(i.) Kantara's Consent Receipt Specification - \nhttps://kantarainitiative.org/confluence/display/infosharing/Consent+Receipt+Specification\n(ii.) Data Privacy Vocabulary -\nhttps://www.w3.org/ns/dpv/\n(iii.) Data Consent Lifecycle RFC (Hyperledger Aries) - \nhttps://github.com/hyperledger/aries-rfcs/blob/master/concepts/0167-data-consent-lifecycle/README.md","username":"pknowles","ts":"2019-10-22T23:33:41.244Z"}
{"msg":"@janl @VipinB Jan and I continue to work closely with Mark Lizar, CEO at OpenConsent and seed contributor to Kantara's Consent Receipt Specification, and Harsh Pandit, main contributing author of the Data Privacy Vocabulary, on consent development implementation using Hyperledger Aries. Jan is leading that initiative. \n\nCheck out the following press announcement re a collaboration agreement between Financial Data Exchange (FDX) and Kantara on an Open Banking consent receipt framework. The interview explains what a \"consent receipt\" is and why it is important. Kantara's Colin Wallis and FDX's Don Cardinal explain. https://financialdataexchange.org/blogs/fdx-blog/interview-fdx-s-don-cardinal-and-kantara-s-colin-wallace-talk-about-recent-collaborating-agreement\n\nRelated links ...\n(i.) Kantara's Consent Receipt Specification - \nhttps://kantarainitiative.org/confluence/display/infosharing/Consent+Receipt+Specification\n(ii.) Data Privacy Vocabulary -\nhttps://www.w3.org/ns/dpv/\n(iii.) Data Consent Lifecycle RFC (Hyperledger Aries) - \nhttps://github.com/hyperledger/aries-rfcs/blob/master/concepts/0167-data-consent-lifecycle/README.md","username":"pknowles","ts":"2019-10-22T23:33:41.244Z"}
{"msg":"@janl @VipinB Jan and I continue to work closely with Mark Lizar, CEO at OpenConsent and seed contributor to Kantara's Consent Receipt Specification, and Harsh Pandit, main contributing author of the Data Privacy Vocabulary, on consent development implementation using Hyperledger Aries. Jan is leading that initiative. \n\nCheck out the following press announcement regarding the recent collaboration agreement between Financial Data Exchange (FDX) and Kantara on an Open Banking consent receipt framework. The interview explains what a \"consent receipt\" is and why it is important. Kantara's Colin Wallis and FDX's Don Cardinal explain. https://financialdataexchange.org/blogs/fdx-blog/interview-fdx-s-don-cardinal-and-kantara-s-colin-wallace-talk-about-recent-collaborating-agreement\n\nRelated links ...\n(i.) Kantara's Consent Receipt Specification - \nhttps://kantarainitiative.org/confluence/display/infosharing/Consent+Receipt+Specification\n(ii.) Data Privacy Vocabulary -\nhttps://www.w3.org/ns/dpv/\n(iii.) Data Consent Lifecycle RFC (Hyperledger Aries) - \nhttps://github.com/hyperledger/aries-rfcs/blob/master/concepts/0167-data-consent-lifecycle/README.md","username":"pknowles","ts":"2019-10-22T23:33:41.244Z"}
{"msg":"@janl @VipinB Jan and I continue to work closely with Mark Lizar, CEO at OpenConsent and seed contributor to Kantara's Consent Receipt Specification, and Harsh Pandit, main contributing author of the Data Privacy Vocabulary, on consent development implementation using Hyperledger Aries. Jan is leading that initiative. \n\nCheck out the following press announcement regarding a collaboration agreement between Financial Data Exchange (FDX) and Kantara on an Open Banking consent receipt framework. The interview explains what a \"consent receipt\" is and why it is important. Kantara's Colin Wallis and FDX's Don Cardinal explain. https://financialdataexchange.org/blogs/fdx-blog/interview-fdx-s-don-cardinal-and-kantara-s-colin-wallace-talk-about-recent-collaborating-agreement\n\nRelated links ...\n(i.) Kantara's Consent Receipt Specification - \nhttps://kantarainitiative.org/confluence/display/infosharing/Consent+Receipt+Specification\n(ii.) Data Privacy Vocabulary -\nhttps://www.w3.org/ns/dpv/\n(iii.) Data Consent Lifecycle RFC (Hyperledger Aries) - \nhttps://github.com/hyperledger/aries-rfcs/blob/master/concepts/0167-data-consent-lifecycle/README.md","username":"pknowles","ts":"2019-10-22T23:33:41.244Z"}
{"msg":"@janl @VipinB Jan and I continue to work closely with Mark Lizar, CEO at OpenConsent and seed contributor to Kantara's Consent Receipt Specification, and Harsh Pandit, main contributing author of the Data Privacy Vocabulary (DPV), on consent development implementation using Hyperledger Aries. Jan is leading that initiative. \n\nCheck out the following press announcement regarding a collaboration agreement between Financial Data Exchange (FDX) and Kantara on an Open Banking consent receipt framework. The interview explains what a \"consent receipt\" is and why it is important. Kantara's Colin Wallis and FDX's Don Cardinal explain. https://financialdataexchange.org/blogs/fdx-blog/interview-fdx-s-don-cardinal-and-kantara-s-colin-wallace-talk-about-recent-collaborating-agreement\n\nRelated links ...\n(i.) Kantara's Consent Receipt Specification - \nhttps://kantarainitiative.org/confluence/display/infosharing/Consent+Receipt+Specification\n(ii.) Data Privacy Vocabulary (DPV) -\nhttps://www.w3.org/ns/dpv/\n(iii.) Data Consent Lifecycle RFC (Hyperledger Aries) - \nhttps://github.com/hyperledger/aries-rfcs/blob/master/concepts/0167-data-consent-lifecycle/README.md","username":"pknowles","ts":"2019-10-22T23:33:41.244Z"}
{"msg":"@janl @VipinB Jan and I continue to work closely with Mark Lizar, CEO at OpenConsent and seed contributor to Kantara's Consent Receipt Specification, and Harsh Pandit, main contributing author of the Data Privacy Vocabulary (DPV), on consent development using Hyperledger Aries. Jan is leading that initiative. \n\nCheck out the following press announcement regarding a collaboration agreement between Financial Data Exchange (FDX) and Kantara on an Open Banking consent receipt framework. The interview explains what a \"consent receipt\" is and why it is important. Kantara's Colin Wallis and FDX's Don Cardinal explain. https://financialdataexchange.org/blogs/fdx-blog/interview-fdx-s-don-cardinal-and-kantara-s-colin-wallace-talk-about-recent-collaborating-agreement\n\nRelated links ...\n(i.) Kantara's Consent Receipt Specification - \nhttps://kantarainitiative.org/confluence/display/infosharing/Consent+Receipt+Specification\n(ii.) Data Privacy Vocabulary (DPV) -\nhttps://www.w3.org/ns/dpv/\n(iii.) Data Consent Lifecycle RFC (Hyperledger Aries) - \nhttps://github.com/hyperledger/aries-rfcs/blob/master/concepts/0167-data-consent-lifecycle/README.md","username":"pknowles","ts":"2019-10-22T23:33:41.244Z"}
{"msg":"Related links ...\n(i.) Kantara's Consent Receipt Specification - \nhttps://kantarainitiative.org/confluence/display/infosharing/Consent+Receipt+Specification\n(ii.) Data Privacy Vocabulary -\nhttps://www.w3.org/ns/dpv/\n","username":"pknowles","ts":"2019-10-22T23:38:49.891Z"}
{"msg":"Related links ...\n(i.) Kantara's Consent Receipt Specification - \nhttps://kantarainitiative.org/confluence/display/infosharing/Consent+Receipt+Specification\n(ii.) Data Privacy Vocabulary -\nhttps://www.w3.org/ns/dpv/\n(iii.) Data Consent Lifecycle RFC (Hyperledger Aries) - \nhttps://github.com/hyperledger/aries-rfcs/blob/master/concepts/0167-data-consent-lifecycle/README.md","username":"pknowles","ts":"2019-10-22T23:38:49.891Z"}
{"msg":"Has joined the channel.","username":"Rick","ts":"2019-10-24T13:47:26.290Z","type":"uj"}
{"msg":"proof","username":"Rick","ts":"2019-10-24T13:48:48.208Z"}
{"msg":"Great list- we might take up some of this in IDWG (there is a call to name this Identity TSIG (Technical Special Interest Group))","username":"VipinB","ts":"2019-10-24T15:45:38.167Z"}
{"msg":"","username":"pknowles","ts":"2019-10-25T02:44:06.831Z","attachments":[{"type":"file","title":"CredDef-ODCA.pdf","title_link":"/file-upload/BPzF8rqA5RdrDRNXp/CredDef-ODCA.pdf","url":"/file-upload/BPzF8rqA5RdrDRNXp/CredDef-ODCA.pdf","remote":false,"fileId":"BPzF8rqA5RdrDRNXp","fileName":"CredDef-ODCA.pdf"}]}
{"msg":"","username":"pknowles","ts":"2019-10-25T02:44:06.831Z","attachments":[{"type":"file","title":"CredDef-ODCA.pdf","title_link":"/file-upload/BPzF8rqA5RdrDRNXp/CredDef-ODCA.pdf","url":"/file-upload/BPzF8rqA5RdrDRNXp/CredDef-ODCA.pdf","remote":false,"fileId":"BPzF8rqA5RdrDRNXp","fileName":"CredDef-ODCA.pdf"}]}
{"msg":"Credential Definitions (ODCA format) to discuss. @brentzundel @kenebert @mtfk ","username":"pknowles","ts":"2019-10-25T02:47:02.014Z"}
{"msg":"Credential Definitions (ODCA format) to discuss. @brentzundel @kenebert @mtfk @danielhardman ","username":"pknowles","ts":"2019-10-25T02:47:02.014Z"}
{"msg":"Credential Definitions (ODCA format). To discuss on the next *Indy Semantics WG* call . @brentzundel @kenebert @mtfk @danielhardman ","username":"pknowles","ts":"2019-10-25T02:47:02.014Z"}
{"msg":"","username":"pknowles","ts":"2019-10-25T02:47:20.847Z","attachments":[{"type":"file","title":"CredDef-ODCA.pdf","title_link":"/file-upload/epQFbwe4Q72rckbNo/CredDef-ODCA.pdf","url":"/file-upload/epQFbwe4Q72rckbNo/CredDef-ODCA.pdf","remote":false,"fileId":"epQFbwe4Q72rckbNo","fileName":"CredDef-ODCA.pdf"}]}
{"msg":"","username":"pknowles","ts":"2019-10-25T03:02:06.774Z","attachments":[{"type":"file","title":"CredDef-ODCA.pdf","title_link":"/file-upload/oKMqP83FNhNAGtXah/CredDef-ODCA.pdf","url":"/file-upload/oKMqP83FNhNAGtXah/CredDef-ODCA.pdf","remote":false,"fileId":"oKMqP83FNhNAGtXah","fileName":"CredDef-ODCA.pdf"}]}
{"msg":"","username":"pknowles","ts":"2019-10-25T03:04:23.915Z","attachments":[{"type":"file","title":"CredDef-ODCA.pdf","title_link":"/file-upload/hNE2HT22KQQowfLff/CredDef-ODCA.pdf","url":"/file-upload/hNE2HT22KQQowfLff/CredDef-ODCA.pdf","remote":false,"fileId":"hNE2HT22KQQowfLff","fileName":"CredDef-ODCA.pdf"}]}
{"msg":"","username":"pknowles","ts":"2019-10-25T03:49:52.456Z","attachments":[{"type":"file","title":"CredDef-ODCA.pdf","title_link":"/file-upload/W4KqJRmmmwr6JYTaq/CredDef-ODCA.pdf","url":"/file-upload/W4KqJRmmmwr6JYTaq/CredDef-ODCA.pdf","remote":false,"fileId":"W4KqJRmmmwr6JYTaq","fileName":"CredDef-ODCA.pdf"}]}
{"msg":"","username":"pknowles","ts":"2019-10-25T04:35:10.161Z","attachments":[{"type":"file","title":"CredDef-ODCA.pdf","title_link":"/file-upload/FbKwsqCApSSwzsy7m/CredDef-ODCA.pdf","url":"/file-upload/FbKwsqCApSSwzsy7m/CredDef-ODCA.pdf","remote":false,"fileId":"FbKwsqCApSSwzsy7m","fileName":"CredDef-ODCA.pdf"}]}
{"msg":"Can we have links to the current state of the art for credential definition? Maybe @kenebert you could provide some links. So we can take a look. ","username":"mtfk","ts":"2019-10-25T06:33:24.876Z"}
{"msg":"@mtfk I believe this is the best place for the CredDef implementation work. @kenebert can correct me if I'm wrong! https://drive.google.com/drive/u/0/folders/1WDIP8t829XhBX2hq-9xBN8u2IG5k5TCO","username":"pknowles","ts":"2019-10-25T14:07:03.496Z"}
{"msg":"have a look at https://sovrin.org/wp-content/uploads/2019/03/What-if-someone-steals-my-phone-040319.pdf","username":"jonathanreynolds","ts":"2019-10-25T14:41:30.918Z"}
{"msg":"Have a look at https://sovrin.org/wp-content/uploads/2019/03/What-if-someone-steals-my-phone-040319.pdf","username":"jonathanreynolds","ts":"2019-10-25T14:41:58.540Z"}
{"msg":"The definition here is around it being secret in a privacy sense rather than a security sense.","username":"jonathanreynolds","ts":"2019-10-25T14:42:42.541Z"}
{"msg":"Can you identify someone from a Link Secret? If not, it doesn't need to go on the Blinding Identity Taxonomy. If you can, w ","username":"pknowles","ts":"2019-10-25T20:32:31.309Z"}
{"msg":"Can you identify someone from a Link Secret? If not, it doesn't need to go on the Blinding Identity Taxonomy. If it can, we should add it. What do you think? ","username":"pknowles","ts":"2019-10-25T20:32:31.309Z"}
{"msg":"Can you identify someone from a _Link Secret_? If not, it doesn't need to go on the Blinding Identity Taxonomy (BIT). If it can, then we should add it. What do you reckon? ","username":"pknowles","ts":"2019-10-25T20:32:31.309Z"}
{"msg":"that is probably a question for someone from Sovrin/Evernym but from that doc i linked it seems that if it is compromised then you will be at risk of correlation but not of identity theft","username":"jonathanreynolds","ts":"2019-10-26T12:11:33.229Z"}
{"msg":"Thanks, Jonathan. I appreciate your input. I think we should add it to the BIT as it sounds like the element should always be encrypted if it were to fall outside of its intended verification purpose. From a data capture perspective, I would always flag it as sensitive and the BIT is a reference document for safe data capture. @danielhardman @MALodder ","username":"pknowles","ts":"2019-10-26T12:46:25.672Z"}
{"msg":"Thanks, Jonathan. I appreciate your input. I think we should add it to the BIT as it sounds like the element should always be encrypted if it were to fall outside of its intended verification purpose. From a data capture perspective, I'd advocate to flag it as sensitive and the BIT is a reference document for safe data capture. @danielhardman @MALodder ","username":"pknowles","ts":"2019-10-26T12:46:25.672Z"}
{"msg":"Thanks, Jonathan. I appreciate your input. I think we should add it to the BIT as it sounds like the element should always be encrypted if it were to fall outside of its intended verification purpose. The BIT is a reference document for safe data capture. From that perspective, I'd advocate to flag _Link Secrets_ as sensitive and therefore include it in the taxonomy. @danielhardman @MALodder ","username":"pknowles","ts":"2019-10-26T12:46:25.672Z"}
{"msg":"Thanks, Jonathan. I appreciate your input. I think we should add it to the BIT as it sounds like the element should always be encrypted if it were to fall outside of its intended verification purpose. The BIT is a reference document for safe data capture. From that perspective, I'd advocate flagging _Link Secrets_ as sensitive and therefore including that element in the taxonomy. @danielhardman @MALodder ","username":"pknowles","ts":"2019-10-26T12:46:25.672Z"}
{"msg":"Thanks, Jonathan. I appreciate your input. I think we should add it to the BIT as it sounds like the element should always be encrypted if it were to fall outside of its intended verification purpose. The BIT is a reference document for safe data capture. From that perspective, I'd advocate flagging _Link Secrets_ as sensitive and including that element in the taxonomy. @danielhardman @MALodder ","username":"pknowles","ts":"2019-10-26T12:46:25.672Z"}
{"msg":"Thanks, Jonathan. I appreciate your input. I think we should add it to the BIT as it sounds like the element should always be encrypted if it were to fall outside of its intended verification purpose. The BIT is a reference document for safe data capture. From that perspective, I'd advocate flagging _Link Secrets_ as sensitive and including it in the taxonomy. @danielhardman @MALodder ","username":"pknowles","ts":"2019-10-26T12:46:25.672Z"}
{"msg":"seems like a good call","username":"jonathanreynolds","ts":"2019-10-26T13:51:11.421Z"}
{"msg":"Before we get too excited about Tuesday, I'm going to have to push y Universal DID Data Service talk out 2 more weeks ...until after I get back from the Malta Blockchain Summit.","username":"mwherman2000","ts":"2019-10-28T00:02:51.658Z"}
{"msg":"No problem, @mwherman2000 . That actually helps me. The agenda is ge","username":"pknowles","ts":"2019-10-28T07:50:59.886Z"}
{"msg":"No problem, @mwherman2000 . That actually helps me. The agenda is quite full this week.","username":"pknowles","ts":"2019-10-28T07:50:59.886Z"}
{"msg":"No problem, @mwherman2000 . That actually helps me. The agenda is quite full this week already.","username":"pknowles","ts":"2019-10-28T07:50:59.886Z"}
{"msg":"Due to the clocks changing in Europe, please note that today's *HL Indy Semantics WG* call will start at 7pm CET / 12pm MT","username":"pknowles","ts":"2019-10-29T16:38:47.664Z"}
{"msg":"Due to the clocks changing in Europe, please note that today's *Indy Semantics WG* call will start at 7pm CET / 12pm MT","username":"pknowles","ts":"2019-10-29T16:38:47.664Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 29th October, 2019\n\n11am-12.15pm PT\n12pm-1.15pm MT\n1pm-2.15pm CT\n2pm-3.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Presentation: IHAN Blueprint work for facilitating fair data economy (consents) ( C. Ahlin ) - 10 mins\n[Ref.: https://media.sitra.fi/2019/04/09132843/a-roadmap-for-a-fair-data-economy.pdf ]\n• Use case: (DMV) Division of Motor Vehicles integration into decentralized identity blockchain ( @wksantiago ) - 15 mins\n• Discussion: CredDef structures in ODCA format ( @pknowles ) - 20 mins\n• Discussion: Expected content structure within a CredDef ( @mtfk ) - 20 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-10-29T17:08:08.127Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, November 12th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-10-29T20:50:35.751Z"}
{"msg":"@janl There were some questions from the impromptu talk you gave last week from Randy Zhang from cisco which you may not have seen if you are not on the mailing list. I quote the email below...\n\n\"Thanks for sharing Vipin/Jan.\n\nQuestions:\n\n    Are there provisions to perform real-time id attestation (proofing in your chart)?\n    On the expiration of access, is the attribute or id removed from the database or just the access is revoked? I think there should be hierarchical RBAC for every ID attribute attribute with automatic revoking plus user allowed revoking timer. The ID owner has complete control over all the ID attributes that are inherent with the user (internal ID attributes).\n\"\n \n\nRandy","username":"VipinB","ts":"2019-10-30T14:20:53.768Z"}
{"msg":"@pknowles was not able to attend yesterday's  meeting- I will read the agenda notes etc. to get a better idea of what was talked about. I have two points to add:\n1. We need to talk about consent (especially telling is the backtracking of gitlab about the collection of telemetry data)\n2. A reframing of the question of \"data protection\" by Elizabeth Reneiris on medium- I respect Elizabeth's viewpoint- please read and let me know what you think. https://medium.com/berkman-klein-center/distracted-by-data-dbe40033591c Going back to the basics helps sometimes","username":"VipinB","ts":"2019-10-30T14:27:52.257Z"}
{"msg":"@janl :top: ","username":"pknowles","ts":"2019-10-30T14:49:02.718Z"}
{"msg":"Thanks, @VipinB . I respect Elizabeth's opinions so I look forward to reading the article. From my perspective, the link between trusted source and data sharing is vital for a healthy flow of information. The trick is not to become a prisoner of our personal data. Data sharing is absolutely vital so we're looking for the perfect blend of data flagging and subsequent encryption alongside SSI (decentralised identity). If any of those mechanisms are flawed, the model for a secure decentralised data economy breaks. ODCA is hugely powerful from the data capture perspective. SSI is hugely powerful from an identity perspective. We are working on bringing harmony between those two essential cogs.","username":"pknowles","ts":"2019-10-30T14:56:25.525Z"}
{"msg":"@VipinB Let me see if I can answer the question from Randy. Expiration relates to when the service ends. The attribute limitation indicates how long the data will be kept. In case of forget I would say a new consent receipt is created that supersedes the previous consent with limitation set to 0. A technique of pseudynomization is mentioned the association between ID and data is removed when forgetting.\n\nHope this gives some ideas. They are welcome to comment in semantic mailing list or attend one of the WG calls.","username":"janl","ts":"2019-10-30T16:04:53.172Z"}
{"msg":"@janl we talked about consent today at the IDWG call. The India consent layer came up again and @nitin.agarwal will give a presentation on this architecture at a later date. I would like to possibly unify the ideas around this topic and address in a short form in the Identity paper.","username":"VipinB","ts":"2019-10-30T18:26:00.653Z"}
{"msg":"Has joined the channel.","username":"nitin.agarwal","ts":"2019-10-30T18:26:00.706Z","type":"uj"}
{"msg":"In her article, Elizabeth focuses on: \n(i.) data as a distraction from real human engagement; and \n(ii.) an acknowledgement that we are facing data governance challenges. \n\nRe the first point, I agree that society is becoming less engaged on a very human level but I blame _technology_ rather than _data_. I myself am guilty of using technology as a distancing tool! \n\nRe the second point, I totally agree. However, as I've delved deeper into the development of data semantics through my ODCA work, I'm convinced that the large majority of people don't fully understand the power of a well-conceived semantic architecture for data capture. The semantics gurus are now starting to discuss overlays to deal with data watermarking, data quality, masking and data as currency. I'm not saying that all of these concepts will stick but I am saying that ODCA changes the current data landscape and, in particular, data governance possibilities.","username":"pknowles","ts":"2019-10-31T02:55:55.677Z"}
{"msg":"In her article, Elizabeth focuses on: \n(i.) data as a distraction from real human engagement and \n(ii.) an acknowledgement that we are facing data governance challenges. \n\nRe the first point, I agree that society is becoming less engaged on a very human level but I blame _technology_ rather than _data_. I myself am guilty of using technology as a distancing tool! \n\nRe the second point, I totally agree. However, as I've delved deeper into the development of data semantics through my ODCA work, I'm convinced that the large majority of people don't fully understand the power of a well-conceived semantic architecture for data capture. The semantics gurus are now starting to discuss overlays to deal with data watermarking, data quality, masking and data as currency. I'm not saying that all of these concepts will stick but I am saying that ODCA changes the current data landscape and, in particular, data governance possibilities.","username":"pknowles","ts":"2019-10-31T02:55:55.677Z"}
{"msg":"In her article, Elizabeth focuses on: \n(i.) data as a distraction from real human engagement; and \n(ii.) an acknowledgement that we are facing data governance challenges. \n\nRe the first point, I agree that society is becoming less engaged on a very human level but I blame _technology_ rather than _data_. I myself am guilty of using technology as a distancing tool! \n\nRe the second point, I totally agree. However, as I've delved deeper into the development of data semantics through my ODCA work, I'm convinced that the large majority of people don't fully understand the power of a well-conceived semantic architecture for data capture. The semantics gurus are now starting to discuss overlays to deal with data watermarking, data quality, masking and data as currency. I'm not saying that all of these concepts will stick but I am saying that ODCA changes the current data landscape and, in particular, data governance possibilities.","username":"pknowles","ts":"2019-10-31T02:55:55.677Z"}
{"msg":"In her article, Elizabeth focuses on: \n(i.) data as a distraction from real human engagement; and \n(ii.) an acknowledgement that we are facing data governance challenges. \n\nRe the first point, I agree that society is becoming less engaged on a very human level but I blame _technology_ rather than _data_. I myself am guilty of using technology as a distancing tool! \n\nRe the second point, I totally agree. However, as I've delved deeper into the development of data semantics through my ODCA work, I'm convinced that the large majority of people don't fully understand the power of a well-conceived semantics architecture for data capture. The semantics gurus are now starting to discuss overlays to deal with data watermarking, data quality, masking and data as currency. I'm not saying that all of these concepts will stick but I am saying that ODCA changes the current data landscape and, in particular, data governance possibilities.","username":"pknowles","ts":"2019-10-31T02:55:55.677Z"}
{"msg":"In her article, Elizabeth focuses on: \n(i.) data as a distraction from real human engagement; and \n(ii.) an acknowledgement that we are facing data governance challenges. \n\nRe the first point, I agree that society is becoming less engaged on a very human level but I blame _technology_ rather than _data_. I myself am guilty of using technology as a distancing tool! \n\nRe the second point, I totally agree. However, as I've delved deeper into the development of data semantics through my ODCA work, I'm convinced that the large majority of people don't fully understand the power of a well-designed semantics architecture for data capture and exchange. The semantics gurus in the open source community are now starting to discuss overlays to deal with data watermarking, data quality, masking and data as currency. I'm not saying that all of these concepts will stick but I am saying that ODCA changes the current data landscape and, in particular, data governance possibilities.","username":"pknowles","ts":"2019-10-31T02:55:55.677Z"}
{"msg":"In her article, Elizabeth focuses on: \n(i.) data as a distraction from real human engagement; and \n(ii.) an acknowledgement that we are facing data governance challenges. \n\nRe the first point, I agree that society is becoming less engaged on a very human level but I blame _technology_ rather than _data_. I myself am guilty of using technology as a distancing tool! \n\nRe the second point, I totally agree. However, as I've delved deeper into the development of data semantics through my ODCA work, I'm convinced that the large majority of people don't fully understand the power of a well-designed semantics architecture for data capture and exchange. The semantics gurus in the open source community are now starting to discuss overlays to deal with data watermarking, data quality, masking and data as currency. I'm not saying that all of these concepts will stick but I am saying that ODCA changes the current landscape and, in particular, data governance possibilities.","username":"pknowles","ts":"2019-10-31T02:55:55.677Z"}
{"msg":"Another view on this could be that \"privacy\" is the goal and \"data governance\" is the means. Focusing on the goal as an abstraction does not get you anywhere; however getting deep into the data governance aspect may not result in attaining the goal either. Unlike a \"goal\", privacy is a continuing concern as you noted.\n","username":"VipinB","ts":"2019-10-31T15:14:39.909Z"}
{"msg":"Done. https://kantarainitiative.org/confluence/display/infosharing/Blinding+Identity+Taxonomy","username":"pknowles","ts":"2019-11-01T01:32:55.538Z"}
{"msg":"Re the Blinding Identity Taxonomy, it would be good to get some community input on the following potential addition ... \"Product Identifier\". For example, if I come into some rich data re Maxidex, a drug manufactured by Novartis, I might be able to determine the identity of the company who published the data. However, Novartis might wish for 3rd parties to have access to that data without the identity of the company being revealed.\n\nThe BIT is supposed to protect the identity of organisations, people and things.\n\nIn my example, Maxidex is the pharmaceutical \"tradename\". Dexamethasone is the active ingredient. I would suggest that Maxidex is PII, Dexamethasone is not.\n\nMaxidex is really supposed to be covered by ...\n\n\"Names (incl. First Names, Last Names, Full Names, Entity Names)\"\n\n... perhaps we should include \"Product Names\" in that inclusion list.\n\n\"Product Identifier\" would be a new element on the list.\n\nAll thoughts welcome!","username":"pknowles","ts":"2019-11-05T18:12:15.900Z"}
{"msg":"Re the *Blinding Identity Taxonomy*, it would be good to get some community input on the following potential addition ... \"Product Identifier\". For example, if I come into some rich data re Maxidex, a drug manufactured by Novartis, I might be able to determine the identity of the company who published the data. However, Novartis might wish for 3rd parties to have access to that data without the identity of the company being revealed.\n\nThe BIT is supposed to protect the identity of organisations, people and things.\n\nIn my example, Maxidex is the pharmaceutical \"tradename\". Dexamethasone is the active ingredient. I would suggest that Maxidex is PII, Dexamethasone is not.\n\nMaxidex is really supposed to be covered by ...\n\n\"Names (incl. First Names, Last Names, Full Names, Entity Names)\"\n\n... perhaps we should include \"Product Names\" in that inclusion list.\n\n\"Product Identifier\" would be a new element on the list.\n\nAll thoughts welcome!","username":"pknowles","ts":"2019-11-05T18:12:15.900Z"}
{"msg":"Re the *Blinding Identity Taxonomy*, it would be good to get some community input on the following potential addition ... \"Product Identifier\". For example, if I were to come into some rich data re Maxidex, a drug manufactured by Novartis, I might be able to determine the identity of the company who published the data. However, Novartis might wish for 3rd parties to have access to that data without the identity of the company being revealed.\n\nThe BIT is supposed to protect the identity of organisations, people and things.\n\nIn my example, Maxidex is the pharmaceutical \"tradename\". Dexamethasone is the active ingredient. I would suggest that Maxidex is PII, Dexamethasone is not.\n\nMaxidex is really supposed to be covered by ...\n\n\"Names (incl. First Names, Last Names, Full Names, Entity Names)\"\n\n... perhaps we should include \"Product Names\" in that inclusion list.\n\n\"Product Identifier\" would be a new element on the list.\n\nAll thoughts welcome!","username":"pknowles","ts":"2019-11-05T18:12:15.900Z"}
{"msg":"Re the *Blinding Identity Taxonomy*, it would be good to get some community input on the following potential addition ... \"Product Identifier\". For example, if I were to come into some rich data re Maxidex, a drug manufactured by Novartis, I might be able to determine the identity of the company who published the data. However, Novartis might wish for 3rd parties to have access to that data without the identity of the company being revealed.\n\nThe BIT is supposed to protect the identity of organisations, people and things.\n\nIn my example, Maxidex is the pharmaceutical trade name of the drug. Dexamethasone is the active ingredient. I would suggest that Maxidex is PII, Dexamethasone is not.\n\nMaxidex is really supposed to be covered by ...\n\n\"Names (incl. First Names, Last Names, Full Names, Entity Names)\"\n\n... perhaps we should include \"Product Names\" in that inclusion list.\n\n\"Product Identifier\" would be a new element on the list.\n\nAll thoughts welcome!","username":"pknowles","ts":"2019-11-05T18:12:15.900Z"}
{"msg":"Re the *Blinding Identity Taxonomy*, it would be good to get some community input on the following potential addition ... \"Product Identifier\". For example, if I were to come into some rich data re Maxidex, a drug manufactured by Novartis, I might be able to determine the identity of the company who published the data. However, Novartis might wish for 3rd parties to have access to that data without the identity of the company being revealed.\n\nThe BIT is supposed to protect the identity of organisations, people and things.\n\nIn my example, Maxidex is the pharmaceutical trade name of the drug. Dexamethasone is the active ingredient. I would suggest that Maxidex is PII, Dexamethasone is not.\n\nMaxidex is really supposed to be covered by ...\n\n\"Names (incl. First Names, Last Names, Full Names, Entity Names)\"\n\n... perhaps we should include \"Product Names\" in that inclusion list.\n\n\"Product Identifier\" would be a new element on the list.\n\nDoes anyone have a strong opinion on this? All thoughts and deliberations welcome!","username":"pknowles","ts":"2019-11-05T18:12:15.900Z"}
{"msg":"Re the *Blinding Identity Taxonomy*, it would be good to get some community input on the following potential addition ... \"Product Identifier\". \n\nFor example, if I were to come into some rich data re Maxidex, a drug manufactured by Novartis, I might be able to determine the identity of the company who published the data. However, Novartis might wish for 3rd parties to have access to that data without the identity of the company being revealed.\n\nThe BIT is supposed to protect the identity of organisations, people and things.\n\nIn my example, Maxidex is the pharmaceutical trade name of the drug. Dexamethasone is the active ingredient. I would suggest that Maxidex is PII, Dexamethasone is not.\n\nMaxidex is really supposed to be covered by ...\n\n\"Names (incl. First Names, Last Names, Full Names, Entity Names)\"\n\n... perhaps we should include \"Product Names\" in that inclusion list.\n\n\"Product Identifier\" would be a new element on the list.\n\nDoes anyone have a strong opinion on this? All thoughts and deliberations welcome!","username":"pknowles","ts":"2019-11-05T18:12:15.900Z"}
{"msg":"After feedback from a few key privacy experts, we have decided to not include _product identifiers_ in the taxonomy. Thanks @janl & @TomWeiss for your valuable input.","username":"pknowles","ts":"2019-11-05T23:16:03.700Z"}
{"msg":"After feedback from a few key privacy experts, it has been decided not to include _product identifiers_ in the taxonomy. Thanks to @janl and @TomWeiss for your valuable input.","username":"pknowles","ts":"2019-11-05T23:16:03.700Z"}
{"msg":"Has joined the channel.","username":"TomWeiss","ts":"2019-11-05T23:16:03.736Z","type":"uj"}
{"msg":"Has joined the channel.","username":"gordon_hkpkiforum","ts":"2019-11-11T08:49:25.143Z","type":"uj"}
{"msg":"@pknowles Any Agenda for tomorrow?","username":"VipinB","ts":"2019-11-11T16:23:02.706Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 12th November, 2019\n\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Presentation: DIDAuthZ ( @george.aristy ) - 20 mins\n• Consent Q&A led by @janl - 10 mins\n• Discussion: Schema and CredDef structures for Sovrin implementation (incl. use of hashlinks) ( @pknowles / C.Stöcker) - 20 mins\n• Implementing modular blocks in ODCA objects ( @pknowles / @mtfk ) - 10 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-11-12T09:06:37.984Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 12th November, 2019\n\n10am-11.15am PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Presentation: DIDAuthZ ( @george.aristy ) - 20 mins\n• Consent Q&A led by @janl - 10 mins\n• Discussion: Schema and CredDef structures for Sovrin implementation (incl. using hashlinks) ( @pknowles / C.Stöcker) - 20 mins\n• Implementing modular blocks in ODCA objects ( @pknowles / @mtfk ) - 10 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-11-12T09:06:37.984Z"}
{"msg":"@pknowles @mitfk About Modular blocks: I was on the call- It was not clear whether hl:<hash> would only refer to IPFS or you need any kind of disambiguation if the immutable store was different.\n\nReally liked the idea that having a common place to get schema modules from creates a pathway for interoperability and freedom from attribute limitations on Sovrin.\nAlso Novartis' issues with selective disclosures was telling; since I believe we do not have such concepts today (everyone always asks for more data than they need- since they consume data in quanta associated with documents eg. All the data on the drivers license or the passport)- I think selective disclosure although popular with the SSI crowd may not have great take-up unless it is backed by regulation and by changing the schemas of data needed by relying parties with regulation.\n\nAll in all a worthwhile discussion and I was glad I spent time.","username":"VipinB","ts":"2019-11-12T19:29:04.138Z"}
{"msg":"The other idea was using time to live as forcing a polling mechanism to introduce a push-like (event driven) mechanism into revocation- seems like this is used in many places (ttl for drivers license is 10 yrs in US); but if you get stopped by cops they do check the license revocation registry in real time.","username":"VipinB","ts":"2019-11-12T19:32:28.748Z"}
{"msg":"@mtfk :top: ","username":"pknowles","ts":"2019-11-12T19:58:20.242Z"}
{"msg":"@VipinB  regarding the links basically I always tend to talk abotu DRI (Decentralized Resource Identifier) which is basically what is URL but content based. Means DRI could become a standard how you link data points which are immutable. If it is Sovrin schema or IPFS schema does not matter it could goes as 'dri://sov/schema/112354' or 'dri://ipfs/112354' which points to same content. This way no matter where the object is you can be 100% that is same thing. Same concept as with `magnet` link This way this \"hashlink\" can be actually DRI which then make whole process super simple. ","username":"mtfk","ts":"2019-11-12T21:10:59.166Z"}
{"msg":"Thanks @mtfk dri is a good solution, was not evident from slide I think","username":"VipinB","ts":"2019-11-12T21:41:30.353Z"}
{"msg":"Tagging @drummondreed into this \"DRI (Decentralized Resource Identifier)\" thread as he should be able to provide us with a small _to do_ list to start the process of making `DRI` a standard. It looks like an essential piece of the puzzle so we should put some strong focus into this topic.","username":"pknowles","ts":"2019-11-13T00:48:45.441Z"}
{"msg":"Tagging @drummondreed into this \"DRI (Decentralized Resource Identifier)\" thread. I reckon that he will be able to provide us with a small _to do_ list to help start the process of making `DRI` a standard. It looks like an essential piece of the puzzle so lets put some strong focus on this point.","username":"pknowles","ts":"2019-11-13T00:48:45.441Z"}
{"msg":"Tagging @drummondreed into this \"DRI (Decentralized Resource Identifier)\" thread. I reckon that Drummond will be able to provide us with a small _to do_ list to help guide us in process of making `DRI` a standard. It looks like an essential piece of the puzzle so lets put some strong focus on this.","username":"pknowles","ts":"2019-11-13T00:48:45.441Z"}
{"msg":"Tagging @drummondreed into this \"DRI (Decentralized Resource Identifier)\" thread. I reckon that Drummond will be able to provide us with a small todo list to help guide us in process of making `DRI` a standard. It looks like an essential piece of the puzzle so lets put some strong focus on this.","username":"pknowles","ts":"2019-11-13T00:48:45.441Z"}
{"msg":"Tagging @drummondreed into this \"DRI (Decentralized Resource Identifier)\" thread. I reckon that Drummond will be able to help guide us in the process of making `DRI` a standard. It looks like an essential piece of the puzzle so lets put some strong focus on this.","username":"pknowles","ts":"2019-11-13T00:48:45.441Z"}
{"msg":"Tagging @drummondreed into this \"DRI (Decentralized Resource Identifier)\" thread. I reckon that Drummond will be able to help guide us in the process of making DRI a standard. It looks like an essential piece of the puzzle so lets put some strong focus on this.","username":"pknowles","ts":"2019-11-13T00:48:45.441Z"}
{"msg":"Tagging @drummondreed into this \"DRI (Decentralized Resource Identifier)\" thread. I reckon that Drummond will be able to help guide us in the process of making DRI a standard. It looks like an essential puzzle piece so lets put some strong focus on this.","username":"pknowles","ts":"2019-11-13T00:48:45.441Z"}
{"msg":"Tagging @drummondreed into this \"DRI (Decentralized Resource Identifier)\" thread. I reckon that Drummond will be able to help guide us in the process of making DRI a standard. It looks like an essential puzzle piece so lets put some strong focus on it.","username":"pknowles","ts":"2019-11-13T00:48:45.441Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, November 26th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-11-13T01:19:20.919Z"}
{"msg":"@channel Regarding how we locate immutable data points, it would be great if we could come up with a stable solution for any use case. I think we can do that by delving into this idea of a *DRI* (Decentralized Resource Identifier) which is basically a similar concept to URL but content based. DRI could become a standard for how you link data points which are immutable. In other words, it wouldn't matter whether we're dealing with a Sovrin schema or an IPFS schema as 'dri://sov/schema/112354' and 'dri://ipfs/112354' would point to the same content. In this way, no matter where the object is housed, you can be 100% sure that we're referencing the same one. This is a similar concept to a _magnet link_. A DRI would make the whole process very simple. [ Ref. for _magnet link_: https://en.wikipedia.org/wiki/Magnet_URI_scheme ]. Thoughts?","username":"pknowles","ts":"2019-11-13T08:31:04.867Z"}
{"msg":"FAO all #indy-semantics channel members. Regarding how we locate immutable data points, it would be great if we could come up with a stable solution for any use case. I think we can do that by delving into this idea of a *DRI* (Decentralized Resource Identifier) which is basically a similar concept to URL but content based. DRI could become a standard for how you link data points which are immutable. In other words, it wouldn't matter whether we're dealing with a Sovrin schema or an IPFS schema as 'dri://sov/schema/112354' and 'dri://ipfs/112354' would point to the same content. In this way, no matter where the object is housed, you can be 100% sure that we're referencing the same one. This is a similar concept to a _magnet link_. A DRI would make the whole process very simple. [ Ref. for _magnet link_: https://en.wikipedia.org/wiki/Magnet_URI_scheme ]. Thoughts and feedback?","username":"pknowles","ts":"2019-11-13T08:31:04.867Z"}
{"msg":"FAO all #indy-semantics channel members. \n\nRegarding how we locate immutable data points, it would be great if we could come up with a stable solution for any use case. I think we can do that by delving into this idea of a *DRI* (Decentralized Resource Identifier) which is basically a similar concept to URL but content based. DRI could become a standard for how you link data points which are immutable. In other words, it wouldn't matter whether we're dealing with a Sovrin schema or an IPFS schema as 'dri://sov/schema/112354' and 'dri://ipfs/112354' would point to the same content. In this way, no matter where the object is housed, you can be 100% sure that we're referencing the same one. This is a similar concept to a _magnet link_. A DRI would make the whole process very simple. [ Ref. for _magnet link_: https://en.wikipedia.org/wiki/Magnet_URI_scheme ]. Thoughts and feedback?","username":"pknowles","ts":"2019-11-13T08:31:04.867Z"}
{"msg":"FAO all #indy-semantics channel members ... \n\nRegarding how we locate immutable data points, it would be great if we could come up with a stable solution for any use case. I think we can do that by delving into this idea of a *DRI* (Decentralized Resource Identifier) which is basically a similar concept to URL but content based. DRI could become a standard for how you link data points which are immutable. In other words, it wouldn't matter whether we're dealing with a Sovrin schema or an IPFS schema as 'dri://sov/schema/112354' and 'dri://ipfs/112354' would point to the same content. In this way, no matter where the object is housed, you can be 100% sure that we're referencing the same one. This is a similar concept to a _magnet link_. A DRI would make the whole process very simple. [ Ref. for _magnet link_: https://en.wikipedia.org/wiki/Magnet_URI_scheme ]. Thoughts and feedback?","username":"pknowles","ts":"2019-11-13T08:31:04.867Z"}
{"msg":"FAO all #indy-semantics channel members ... \n\nIt would be great if we could come up with a stable solution for any use case involving the location of immutable data points. A popular idea that has been touched upon on a number of occasions is the concept of using a *DRI* (Decentralized Resource Identifier) which is basically a similar concept to URL but content based. DRI could become a standard for how you link data points which are immutable. In other words, it wouldn't matter whether we're dealing with a Sovrin schema or an IPFS schema as 'dri://sov/schema/112354' and 'dri://ipfs/112354' would point to the same content. In this way, no matter where the object is housed, you can be 100% sure that we're referencing the same one. This is a similar concept to a _magnet link_. A DRI would make the whole process very simple. [ Ref. for _magnet link_: https://en.wikipedia.org/wiki/Magnet_URI_scheme ]. Thoughts and feedback?","username":"pknowles","ts":"2019-11-13T08:31:04.867Z"}
{"msg":"FAO all #indy-semantics channel members ... \n\nIt would be great if we could come up with a stable solution for any use case involving the locating of immutable data points. A popular idea that has been touched upon on a number of occasions is the concept of using a *DRI* (Decentralized Resource Identifier) which is basically a similar concept to URL but content based. DRI could become a standard for how you link data points which are immutable. In other words, it wouldn't matter whether we're dealing with a Sovrin schema or an IPFS schema as 'dri://sov/schema/112354' and 'dri://ipfs/112354' would point to the same content. In this way, no matter where the object is housed, you can be 100% sure that we're referencing the same one. This is a similar concept to a _magnet link_. A DRI would make the whole process very simple. [ Ref. for _magnet link_: https://en.wikipedia.org/wiki/Magnet_URI_scheme ]. Thoughts and feedback?","username":"pknowles","ts":"2019-11-13T08:31:04.867Z"}
{"msg":"FAO all #indy-semantics channel members ... \n\nIt would be great if we could come up with a stable solution for any use case involving immutable data point location. A popular idea that has been touched upon on a number of occasions is the concept of using a *DRI* (Decentralized Resource Identifier) which is basically a similar concept to URL but content based. DRI could become a standard for how you link data points which are immutable. In other words, it wouldn't matter whether we're dealing with a Sovrin schema or an IPFS schema as 'dri://sov/schema/112354' and 'dri://ipfs/112354' would point to the same content. In this way, no matter where the object is housed, you can be 100% sure that we're referencing the same one. This is a similar concept to a _magnet link_. A DRI would make the whole process very simple. [ Ref. for _magnet link_: https://en.wikipedia.org/wiki/Magnet_URI_scheme ]. Thoughts and feedback?","username":"pknowles","ts":"2019-11-13T08:31:04.867Z"}
{"msg":"FAO all #indy-semantics channel members ... \n\nIt would be great if we could come up with a stable solution for any use case involving immutable data point location. A popular idea that has been touched upon on a number of occasions is the concept of using a *DRI* (Decentralized Resource Identifier) which is basically a similar concept to URL but content based. DRI could become a standard for how you link data points which are immutable. In other words, it wouldn't matter whether we're dealing with a Sovrin schema or an IPFS schema as 'dri://sov/schema/112354' and 'dri://ipfs/112354' would point to the same content. In this way, no matter where the object is housed, you can be 100% sure that we're referencing the same one. This is a similar concept to a _magnet link_. A DRI would make the whole process very simple. [ Ref. for _magnet link_: https://en.wikipedia.org/wiki/Magnet_URI_scheme ]. Thoughts and feedback welcome.","username":"pknowles","ts":"2019-11-13T08:31:04.867Z"}
{"msg":"FAO all #indy-semantics channel members ... \n\nIt would be great if we could come up with a stable identifier that can be used for any use case involving immutable data points. A popular idea that has been touched upon on a number of occasions is the concept of using a *DRI* (Decentralized Resource Identifier) which is basically a similar concept to URL but content based. DRI could become a standard for how you link data points which are immutable. In other words, it wouldn't matter whether we're dealing with a Sovrin schema or an IPFS schema as 'dri://sov/schema/112354' and 'dri://ipfs/112354' would point to the same content. In this way, no matter where the object is housed, you can be 100% sure that we're referencing the same one. This is a similar concept to a _magnet link_. A DRI would make the whole process very simple. [ Ref. for _magnet link_: https://en.wikipedia.org/wiki/Magnet_URI_scheme ]. Thoughts and feedback welcome.","username":"pknowles","ts":"2019-11-13T08:31:04.867Z"}
{"msg":"FAO all #indy-semantics channel members ... \n\nIt would be great if we could come up with a stable identifier that can be used for any use case involving immutable data points. A popular idea that has been touched upon on a number of occasions is the concept of using a *DRI* (Decentralized Resource Identifier) which is basically a similar concept to URL but content based. DRI could become a standard for how you link data points which are immutable. In other words, it wouldn't matter whether we're dealing with a Sovrin schema or an IPFS schema as 'dri://sov/schema/112354' and 'dri://ipfs/112354' would point to the same content. In this way, no matter where the object is housed, you can be 100% sure that we're referencing the same object. This is a similar concept to a _magnet link_. A DRI would make the whole process very simple. [ Ref. for _magnet link_: https://en.wikipedia.org/wiki/Magnet_URI_scheme ]. Thoughts and feedback welcome.","username":"pknowles","ts":"2019-11-13T08:31:04.867Z"}
{"msg":"*Rich Schemas* - New RFC under review for the schema object (and corresponding HIPE in Indy). Review comments welcome. https://github.com/hyperledger/aries-rfcs/tree/master/features/0281-rich-schemas [For more info, reach out to @kenebert ]","username":"pknowles","ts":"2019-11-13T20:31:35.901Z"}
{"msg":"*Rich Schemas* - New RFC under review for the schema object (and corresponding HIPE in Indy). Review comments welcome. https://github.com/hyperledger/aries-rfcs/tree/master/features/0281-rich-schemas [For more info, reach out to @kenebert directly]","username":"pknowles","ts":"2019-11-13T20:31:35.901Z"}
{"msg":"*Rich Schemas* - New RFC under review for the schema object (and corresponding HIPE in Indy). Review comments welcome. https://github.com/hyperledger/aries-rfcs/tree/master/features/0281-rich-schemas [For more info, reach out to @kenebert directly.]","username":"pknowles","ts":"2019-11-13T20:31:35.901Z"}
{"msg":"*Rich Schemas* - New RFC under review for the schema object (and corresponding HIPE in Indy). Review comments welcome. https://github.com/hyperledger/aries-rfcs/tree/master/features/0281-rich-schemas [For more info, reach out to @kenebert or @brentzundel directly.]","username":"pknowles","ts":"2019-11-13T20:31:35.901Z"}
{"msg":"*Rich Schemas* - New RFC under review for the schema object (and corresponding HIPE in Indy). Review comments welcome. https://github.com/hyperledger/aries-rfcs/tree/master/features/0281-rich-schemas [For more info, reach out to @kenebert or @brentzundel .]","username":"pknowles","ts":"2019-11-13T20:31:35.901Z"}
{"msg":"@pknowles In the example that you provided (also @mtfk ) 'dri://ipfs/112354' does 112354 refer to the hash of the attributes that you are including in the super-schema; I was looking for a reference to DRI to see whether there are formal standards for this. Was not able to come up with any. Maybe I am not looking in the right place. Magnet of course has lots of references. DRI is a special case of URI?","username":"VipinB","ts":"2019-11-14T21:22:13.732Z"}
{"msg":"DRI was invented by me as nice name for the thing which we need. There is no standard for it, maybe one day. Basically DRI does not much differ from what magnet link is. Maybe except that magnet link has a bad reputation of piracy behind it ;) I did a presentation about DRI in one of our semantic call you can check it out.","username":"mtfk","ts":"2019-11-14T22:14:29.183Z"}
{"msg":"DRI deck available at --> https://drive.google.com/drive/u/0/folders/17COuFJCbNgSrHo2blFyA38my9sNFRDn2","username":"pknowles","ts":"2019-11-14T22:33:08.182Z"}
{"msg":"DRI video presentation available at --> https://drive.google.com/drive/u/0/folders/1VslH6Wy4WQbGzZ1uAcWFWE1mpkq03drP","username":"pknowles","ts":"2019-11-14T22:35:59.931Z"}
{"msg":"DRI video presentation available from 8 mins 55 secs at --> https://drive.google.com/drive/u/0/folders/1VslH6Wy4WQbGzZ1uAcWFWE1mpkq03drP","username":"pknowles","ts":"2019-11-14T22:35:59.931Z"}
{"msg":"DRI video presentation available at --> (from 8 mins 55 secs) https://drive.google.com/drive/u/0/folders/1VslH6Wy4WQbGzZ1uAcWFWE1mpkq03drP","username":"pknowles","ts":"2019-11-14T22:35:59.931Z"}
{"msg":"DRI video presentation available at --> https://drive.google.com/drive/u/0/folders/1VslH6Wy4WQbGzZ1uAcWFWE1mpkq03drP (from 8 mins 55 secs)","username":"pknowles","ts":"2019-11-14T22:35:59.931Z"}
{"msg":"DRI video presentation available at --> https://drive.google.com/drive/u/0/folders/1VslH6Wy4WQbGzZ1uAcWFWE1mpkq03drP (from 8 mins 55 secs onwards)","username":"pknowles","ts":"2019-11-14T22:35:59.931Z"}
{"msg":"DRI video presentation available at --> https://drive.google.com/drive/u/0/folders/1VslH6Wy4WQbGzZ1uAcWFWE1mpkq03drP (from 8 mins 55 secs)","username":"pknowles","ts":"2019-11-14T22:35:59.931Z"}
{"msg":"DRI deck available at --> https://drive.google.com/drive/u/0/folders/17COuFJCbNgSrHo2blFyA38my9sNFRDn2","username":"pknowles","ts":"2019-11-14T22:41:07.512Z"}
{"msg":"@mtfk Are we able to use \"content-type\" and \"content-id\" DID matrix parameters as a DRI solution? https://github.com/w3c/did-core/pull/61","username":"pknowles","ts":"2019-11-14T23:56:26.091Z"}
{"msg":"@mtfk Are we able to use \"content-type\" and \"content-id\" DID matrix parameters as a DRI solution for now? https://github.com/w3c/did-core/pull/61","username":"pknowles","ts":"2019-11-14T23:56:26.091Z"}
{"msg":"In theory we can use anything which points to immutable file","username":"mtfk","ts":"2019-11-15T06:36:04.566Z"}
{"msg":"The problem is that having schema on the ledger does not seems like a good idea as there is size limitation as well performance to se/query/","username":"mtfk","ts":"2019-11-15T06:38:33.575Z"}
{"msg":"The problem is that having schema on the ledger does not seems like a good idea as there is size limitation as well performance to search/query/","username":"mtfk","ts":"2019-11-15T06:38:33.575Z"}
{"msg":"Should we be inventing our own? I will take a look at the slides. Magnet seems like a good way to get at a URI with an embedded hash, it  contains a fingerprint of the doc as well. I am sure that someone will bring up the whole collision thing. Which of course may have to be addressed in your write-up and why a salt is not necessary.\nHaving the schema on the ledger- means (in my mind) there is a schema on the ledger- (the ledger has to be readable publicly- if the schema is public- at the minimum) or there is a way to get to schema using a pointer (DRI); or there is a way to assemble the schema using multiple pointers(DRIs). When I say pointer I mean that it has to be also reachable and readable by all (if it is a public schema).  Now you are also telling me that the hash at the tail of the schema will be the same for all dris that point to the same document and will be a fingerprint.\nQuerying is another story, since the schema details are subsumed in the DRI. Querying from the ledger is always hard (for random searches).","username":"VipinB","ts":"2019-11-15T19:11:08.653Z"}
{"msg":"Thanks for your input, @VipinB . We'll bash this about some more to get consensus of opinion. Magnet may well be our best option here rather than DID. In any case, @mtfk and I have to come to a definite decision this week as we need a solid solution for a current pilot that we're working on.","username":"pknowles","ts":"2019-11-18T06:54:33.752Z"}
{"msg":"FAO all #indy-semantics channel members ... \n\nIt would be great if we could come up with a stable identifier that can be used for any use case involving immutable data points. A popular idea that has been touched upon on a number of occasions is the concept of using a *DRI* (Decentralized Resource Identifier) which is basically a similar concept to URL but content based. DRI could become a standard for how you link data points which are immutable. In other words, it wouldn't matter whether we're dealing with a Sovrin schema or an IPFS schema as 'dri://sov/schema/112354' and 'dri://ipfs/112354' would point to the same content. In this way, no matter where the object is housed, you can be 100% sure that we're referencing the same object. This is a similar concept to a _magnet link_. A DRI would make the whole process very simple. [ Ref. for _magnet link_: https://en.wikipedia.org/wiki/Magnet_URI_scheme ]. Thoughts and feedback welcome.","username":"pknowles","ts":"2019-11-18T21:33:45.753Z"}
{"msg":"@kenebert @brentzundel @mtfk Is it theoretically  possible to point to schema objects not anchored on the Sovrin ledger and still build on-ledger CredDefs? At this stage, we don't necessarily need to know how to do it but that it is possible in theory.","username":"pknowles","ts":"2019-11-20T14:56:06.110Z"}
{"msg":"@kenebert @brentzundel @mtfk Is it theoretically  possible to point to schema objects not anchored on the Sovrin ledger and still build on-ledger CredDefs? At this stage, we don't necessarily need to know how to do it, just whether or not it is possible in theory.","username":"pknowles","ts":"2019-11-20T14:56:06.110Z"}
{"msg":"@kenebert @brentzundel @mtfk Is it theoretically  possible to point to schema objects not anchored on the Sovrin ledger and still build on-ledger CredDefs? At this stage, we don't necessarily need to know \"how\" to do it but whether or not it \"can\" be done.","username":"pknowles","ts":"2019-11-20T14:56:06.110Z"}
{"msg":"I believe so, is just question of resolution process of fetching schema  right now it fetch from ledger but it could get it from other places.","username":"mtfk","ts":"2019-11-20T16:04:36.509Z"}
{"msg":"Theoretically, yes.","username":"brentzundel","ts":"2019-11-20T17:05:25.912Z"}
{"msg":"Here's the link I mentioned in the Aries call this morning ...following Paul's talk ...the idea is about Universal Digital Identities and Universal Digital Identifiers having varying discernible Levels of Trust: https://hyperonomy.com/2019/11/21/trusted-digital-web-levels-of-universal-trust/","username":"mwherman2000","ts":"2019-11-21T19:40:16.437Z"}
{"msg":"Here's the link I mentioned in the Aries call this morning ...following Paul's talk ...the idea is about Universal Digital Identities and Universal Digital Identifiers having varying _discernible _Levels of Trust: https://hyperonomy.com/2019/11/21/trusted-digital-web-levels-of-universal-trust/","username":"mwherman2000","ts":"2019-11-21T19:40:16.437Z"}
{"msg":"Thanks for sharing, Michael!","username":"pknowles","ts":"2019-11-21T19:50:39.653Z"}
{"msg":"Tomorrow at 2pm CET I would take part in MyData Webinary where together with Schluss we would dive into integration between digital wallet (PDA) and data vaults. More info at: https://mydata.org/webinars/\nFeel free to join!","username":"mtfk","ts":"2019-11-21T20:10:09.397Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 26th November, 2019\n\n10am-11.15pm PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Future scope of the Indy Semantics WG - 10 mins\n• Update: ODCA as a standard ( pknowles ) - 10 mins\n• Presentation: Linking to uncontrolled immutable data points - Hashlinks vs. Magnet links ( mtfk ) - 10 mins\n[Ref.: Hashlinks - https://tools.ietf.org/html/draft-sporny-hashlink-04 / Magnet links - https://en.wikipedia.org/wiki/Magnet_URI_scheme ]\n• Open workshop: Determining external schema object requirements for on-ledger CredDef builds - 30 mins\n[Part 1. Schema bases - WG call: 26NOV2019 / Part 2. Overlays - WG call: 10DEC2019]\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-11-26T04:33:22.841Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 26th November, 2019\n\n10am-11.15pm PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Future scope of the Indy Semantics WG - 10 mins\n• Update: ODCA as a standard ( @pknowles ) - 10 mins\n• Short presentation: Linking to uncontrolled immutable data points - Hashlinks vs. Magnet links ( @mtfk ) - 10 mins\n[Ref.: Hashlinks - https://tools.ietf.org/html/draft-sporny-hashlink-04 / Magnet links - https://en.wikipedia.org/wiki/Magnet_URI_scheme ]\n• Open workshop: Determining external schema object requirements for on-ledger CredDef builds - 30 mins\n[Part 1. Schema bases - WG call: 26NOV2019 / Part 2. Overlays - WG call: 10DEC2019]\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-11-26T04:35:44.603Z"}
{"msg":"Has joined the channel.","username":"IWontDiscloseMyIdentity","ts":"2019-11-26T04:55:16.033Z","type":"uj"}
{"msg":"The decks and agenda from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. Unfortunately, due to altered Zoom settings, the call did not record. My humblest apologies. The Zoom settings have now been reset. The next meeting is on Tuesday, December 10th. https://drive.google.com/drive/u/0/folders/1FXajIhHJhRlGEDNf-JDIS_KPrOs9mnU4","username":"pknowles","ts":"2019-11-26T21:00:36.903Z"}
{"msg":"Has joined the channel.","username":"lsl88","ts":"2019-11-27T15:37:50.298Z","type":"uj"}
{"msg":"Can you add me as a demo for next week Paul?   Trusted Digital Web: Universal DID Data Server","username":"mwherman2000","ts":"2019-12-02T17:24:04.553Z"}
{"msg":"","username":"mwherman2000","ts":"2019-12-02T17:27:36.186Z","attachments":[{"type":"file","title":"Clipboard - December 2, 2019 10:27 AM","title_link":"/file-upload/DuF6JZvu2LcFrLdcv/Clipboard%20-%20December%202,%202019%2010:27%20AM","image_url":"/file-upload/DuF6JZvu2LcFrLdcv/Clipboard%20-%20December%202,%202019%2010:27%20AM","image_type":"image/png","image_size":143622,"url":"/file-upload/DuF6JZvu2LcFrLdcv/Clipboard%20-%20December%202,%202019%2010:27%20AM","remote":false,"fileId":"DuF6JZvu2LcFrLdcv","fileName":"Clipboard - December 2, 2019 10:27 AM"}]}
{"msg":"Absolutely. How long do you need for the demo?","username":"pknowles","ts":"2019-12-02T21:18:53.683Z"}
{"msg":"30 with Q&A","username":"mwherman2000","ts":"2019-12-04T01:09:21.903Z"}
{"msg":"Just posted this a few minutes ago: https://hyperonomy.com/2019/12/03/trusted-digital-web-first-trusted-web-page-delivered-today-dec-3-2019/","username":"mwherman2000","ts":"2019-12-04T01:10:08.695Z"}
{"msg":"During today Aries call I briefly mentioned about the need of schema interop (RFC in preparation). Basic idea is to make sure that schema can be reused across networks and can be resolved for any place. We believe that having interoperabale object like schema is the key for decentralized data economy. As we know schema is not only used as data structure for verifiable credentials. In my opinion there is much more use cases outside VC, like data storage, data transportation, data requests. Having one schema for VC and other for other data structure does not make sens this is why we need to seek for interoperability for this crucial object. \nWhat we are looking for is schema which:\n- can be resolved from any place (without need to be member of particular network) \n- can be uniquely identifiable across different networks and systems (best content based - DRI - hashlinks)\n- does not have limit on size nor amount of attributes\n- have to be immutable - once posted never cahnges (see above content based identifiers)\n- support any type of the data (blobs, text, arrays etc, so one of the attribute could be your MRI picture) \n- anything else?....","username":"mtfk","ts":"2019-12-04T21:29:23.843Z"}
{"msg":"@kenebert ^","username":"mtfk","ts":"2019-12-04T21:29:50.541Z"}
{"msg":"obviously we are seeing ODCA with schema_base as a candidate which fulfill all above and we are looking for suggestion about how we could introduce changes to existing systems like indy and VC to support that flow as well.  ","username":"mtfk","ts":"2019-12-04T21:31:48.083Z"}
{"msg":"Hyperledger has a new process for managing calendars. Administrators of the mailing list group have the right to create calendar appointments. I requested to become an admin of the Indy group so that I could migrate our meetings to the new calendar. I think that I correctly created this meeting for every other Tuesday. Please let me know if I got it right @pknowles ","username":"esplinr","ts":"2019-12-05T21:20:18.526Z"}
{"msg":"The interface required my adding a meeting organizer. I added @kenebert because he  was sitting next to me and I could warn him.","username":"esplinr","ts":"2019-12-05T21:20:41.529Z"}
{"msg":"I don't know if that gives him any powers, or if it is just used when Hyperledger staff need to contact someone about a meeting.","username":"esplinr","ts":"2019-12-05T21:21:02.727Z"}
{"msg":"Let me know if you decide to cancel the meeting scheduled for December 24. I can remove it from the calendar for you.","username":"esplinr","ts":"2019-12-05T21:21:22.462Z"}
{"msg":"If someone else wants to become an admin and help manage this let me know.","username":"esplinr","ts":"2019-12-05T21:21:54.425Z"}
{"msg":"Thanks, @esplinr . That all sounds fine. The next Indy Semantics WG call is next Tuesday (Dec 10th). You can go ahead and cancel the following one (Dec 24th). Cheers.","username":"pknowles","ts":"2019-12-05T22:34:32.740Z"}
{"msg":"Excellent. I was able to make Ken an admin for the Indy mailing list, so he can help maintain the appointments.","username":"esplinr","ts":"2019-12-05T22:36:37.325Z"}
{"msg":"Thank you for catching the missing meeting on the 10th. I fixed that and removed the meeting on the 24th.","username":"esplinr","ts":"2019-12-05T22:38:39.515Z"}
{"msg":"It takes a few minutes for the change to propagate through the system.","username":"esplinr","ts":"2019-12-05T22:38:52.191Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 10th December, 2019\n\n10am-11.15pm PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Presentation/Demo: Trusted Digital Web: Universal DID Data Server ( @mwherman2000 ) - 40 mins\n[Ref.: https://hyperonomy.com/2019/12/03/trusted-digital-web-first-trusted-web-page-delivered-today-dec-3-2019/ ]\n• New ODCA overlay: “Mapping overlay” ( @pknowles ) - 10 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2019-12-10T17:18:50.501Z"}
{"msg":"For the demo, it will be useful to know a little bit about the technical details of DNS ...n particular, that DNS is an extensible framework in addition to being a foundational  protocol and a service on the Internet.  This article will help you on the DNS side of things: https://hyperonomy.com/2019/01/02/dns-domain-name-service-a-detailed-high-level-overview/","username":"mwherman2000","ts":"2019-12-10T17:34:28.866Z"}
{"msg":"For the demo, it will be useful to know a little bit about the technical details of DNS ...in particular, that DNS is an extensible framework in addition to being a foundational  protocol and a service on the Internet.  This article will help you on the DNS side of things: https://hyperonomy.com/2019/01/02/dns-domain-name-service-a-detailed-high-level-overview/","username":"mwherman2000","ts":"2019-12-10T17:34:28.866Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. As the next scheduled meeting happens to fall on Christmas Eve, we'll give that one a miss and reconvene in the new year. The next meeting will be on Tuesday, January 7th. Wishing the Hyperledger community a wonderful festive period. See you on the other side! https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-12-11T06:02:11.294Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. As the next scheduled meeting happens to fall on Christmas Eve, we'll give that one a miss and reconvene in the new year. The next meeting will be on Tuesday, January 7th. I'd like to take this opportunity to wish the Hyperledger community a wonderful festive season. See you on the other side! https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-12-11T06:02:11.294Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. As the next scheduled meeting happens to fall on Christmas Eve, we'll give that one a miss and reconvene in the new year. The next meeting will be on Tuesday, January 7th. I'd like to take this opportunity to wish the Hyperledger community a wonderful festive season and I look forward to catching up with many of you on the other side! https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-12-11T06:02:11.294Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. As the next scheduled meeting happens to fall on Christmas Eve, we'll give that one a miss and reconvene in the new year. The next meeting will be on Tuesday, January 7th. I'd like to take this opportunity to wish the Hyperledger community a wonderful festive period and I look forward to catching up with many of you on the other side! https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-12-11T06:02:11.294Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. As the next scheduled meeting happens to fall on Christmas Eve, we'll give that one a miss and reconvene in the new year. The next meeting will be on Tuesday, January 7th. I'd like to take this opportunity to wish the Hyperledger community a wonderful festive period and look forward to catching up with many of you on the other side! https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-12-11T06:02:11.294Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. As the next scheduled meeting happens to fall on Christmas Eve, we'll give that one a miss and reconvene in the new year. The next meeting will be on Tuesday, January 7th. I'd like to take this opportunity to wish Hyperledger community members a wonderful festive period and look forward to catching up with many of you on the other side! https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2019-12-11T06:02:11.294Z"}
{"msg":"As a follow-up to my demo last Tuesday and the question about \"secure didttp:\":1) I've now implemented didttps: (Secure DID Trusted Transport Protocol) using TLS over Tcp port 853 (instead of DNS Tcp port 53)","username":"mwherman2000","ts":"2019-12-14T04:05:58.912Z"}
{"msg":"As a follow-up to my demo last Tuesday and the question about \"secure didttp:\":\n1) I've now implemented didttps: (Secure DID Trusted Transport Protocol) using TLS over Tcp port 853 (instead of DNS Tcp port 53)\n2) Here's a good explanation about the differences between DNS over TLS vs. DNS over HTTPS: https://www.ma-no.org/en/networking/configuring-dns-over-tls-and-dns-over-https-with-any-dns-server","username":"mwherman2000","ts":"2019-12-14T04:05:58.912Z"}
{"msg":"Has left the channel.","username":"stone-ch","ts":"2019-12-15T04:41:40.262Z","type":"ul"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 7th January, 2020\n\n10am-11.15pm PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Demo: Using Hashlinks to resolve data payloads outside of the credential definition ( @mtfk ) - 20 mins\n• Complimentary technologies to support the SSI community and related use cases ( @pknowles ) - 10 mins\n[Ref.: e.g. semantic containers - https://www.ownyourdata.eu/en/semcon/ ]\n• Use case: Proposal for a Pharma consortia “Data Sharing Hub” with SSI onboarding for all health subjects ( @pknowles ) - 20 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2020-01-07T17:39:20.757Z"}
{"msg":"The agenda, video, notes, etc. from yesterday's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, January 21st. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2020-01-08T23:12:10.781Z"}
{"msg":"The word _encode_ is used for both _binary-to-text encoding_ (e.g. sha256) and _character encoding_ (e.g. utf-8). Having spoken to @kdenhartog  , we decided that it would make sense to change the name of the current \"encode overlay\" to \"character overlay\" so that we have room to manoeuvre when we start working in the _binary-to-text encoding_ space. In other words, we will eventually have both a \"character overlay\" and a \"binary-to-text overlay\". Problem solved. Thanks, Kyle.","username":"pknowles","ts":"2020-01-15T22:02:01.165Z"}
{"msg":"The word _encode_ is used for both _binary-to-text encoding_ (e.g. sha256) and _character encoding_ (e.g. utf-8). Having spoken to @kdenhartog  , we decided that it would make sense to change the name of the current \"encode overlay\" to \"character encoding overlay\" so that we have room to manoeuvre when we start working in the _binary-to-text encoding_ space. In other words, we will eventually have both a \"character encoding overlay\" and a \"binary-to-text encoding overlay\". Problem solved. Thanks, Kyle.","username":"pknowles","ts":"2020-01-15T22:02:01.165Z"}
{"msg":"Has joined the channel.","username":"EdEykholt","ts":"2020-01-20T03:30:21.705Z","type":"uj"}
{"msg":"Due to a daily light agenda, today's *Indy Semantics WG* call is postponed to next Tuesday (Jan.28th) at the usual time. Apologies for any inconvenience. Speak to you next week. Paul","username":"pknowles","ts":"2020-01-21T17:22:01.182Z"}
{"msg":"Due to a fairly light agenda, today's *Indy Semantics WG* call is postponed to next Tuesday (Jan.28th) at the usual time. Apologies for any inconvenience. Speak to you next week. Paul","username":"pknowles","ts":"2020-01-21T17:22:01.182Z"}
{"msg":"Due to a fairly light agenda, today's *Indy Semantics WG* call is postponed to next Tuesday (Jan.28th) at the usual time. Apologies for any inconvenience. Paul","username":"pknowles","ts":"2020-01-21T17:22:01.182Z"}
{"msg":"I can update the calendar for you.","username":"esplinr","ts":"2020-01-21T23:15:41.281Z"}
{"msg":"Oh, you meet every two weeks. When will you be meeting after Jan 28?\n*  Feb 4, per the existing appointment\n* Feb 11, switching to the opposite cadence of bi-weekly\n* Feb 18, skipping one session and moving back to the current schedule\nLet me know and I can make the calendar match.","username":"esplinr","ts":"2020-01-21T23:18:03.851Z"}
{"msg":"Thanks, @esplinr . It'll be Jan 28, Feb 4, Feb 18, Mar 3, etc.","username":"pknowles","ts":"2020-01-22T01:19:01.214Z"}
{"msg":"Good to know. The calendar should reflect that now.  If you see any problems, or need any changes in the future, either Ken Ebert or I can make them.","username":"esplinr","ts":"2020-01-22T16:04:42.319Z"}
{"msg":"Has joined the channel.","username":"domwoe","ts":"2020-01-25T18:31:19.696Z","type":"uj"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 7th January, 2020\n\n10am-11.15pm PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Presentation: Semantic Container for Data Mobility ( C.Fabianek ) - 35 mins\n[Ref.: semantic containers - https://www.ownyourdata.eu/en/semcon/ ]\n• Presentation: Decentralized Data Network and the case for introducing a new identifier for non-governed entities, the \"DRI\" ( @pknowles ) - 20 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#","username":"pknowles","ts":"2020-01-28T17:34:20.832Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 28th January, 2020\n\n10am-11.15pm PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Presentation: Semantic Container for Data Mobility ( C.Fabianek ) - 35 mins\n[Ref.: semantic containers - https://www.ownyourdata.eu/en/semcon/ ]\n• Presentation: Decentralized Data Network and the case for introducing a new identifier for non-governed entities, the \"DRI\" ( @pknowles ) - 20 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#","username":"pknowles","ts":"2020-01-28T17:34:20.832Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 28th January, 2020\n\n10am-11.15pm PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Presentation: Semantic Container for Data Mobility ( C.Fabianek ) - 35 mins\n[Ref.: semantic containers - https://www.ownyourdata.eu/en/semcon/ ]\n• Presentation: Decentralized Data Network and the case for introducing an identifier for non-governed entities ( @pknowles ) - 20 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#","username":"pknowles","ts":"2020-01-28T17:34:20.832Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 28th January, 2020\n\n10am-11.15pm PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Presentation: Semantic Container for Data Mobility (C.Fabianek) - 35 mins\n[Ref.: semantic containers - https://www.ownyourdata.eu/en/semcon/ ]\n• Presentation: Decentralized Data Network and the case for introducing an identifier for non-governed entities ( @pknowles ) - 20 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#","username":"pknowles","ts":"2020-01-28T17:34:20.832Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, January 28th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2020-01-29T03:43:56.492Z"}
{"msg":"The semantics group have recently been discussing how to best resolve large data objects in verifiable credentials. A key technology, component and endpoint in that resolve is *Semantic Containers* for transient storage and data mobility. For anyone interested to learn more about the technology, click on the above link, go to \"Videos\", \"2020-01-28\" and watch the WG call video from 12 mins 55 secs onwards. Thanks to Christoph Fabianek from OwnYourData for a fascinating presentation/discussion regarding the technology.","username":"pknowles","ts":"2020-01-29T04:01:12.668Z"}
{"msg":"Kantara is decommissioning the \"Consent and Information Sharing\" WG. A new WG is now in place to take on the remit of that group, the \"Information Sharing Interoperability\" WG. As such, there is now a new home/URL for the \"Blinding Identity Taxonomy\". If you click on the link, you'll notice that we removed any mention of PII in the descriptive intro. Here is the new URL for the BIT ...","username":"pknowles","ts":"2020-01-30T12:45:56.555Z"}
{"msg":"Kantara is decommissioning the \"Consent and Information Sharing\" WG. A new WG is now in place to take on the remit of that group, the \"Information Sharing Interoperability\" WG. As such, there is now a new home/URL for the *Blinding Identity Taxonomy*. If you click on the link, you'll notice that we removed any mention of PII in the descriptive intro. Here is the new URL for the BIT ...","username":"pknowles","ts":"2020-01-30T12:45:56.555Z"}
{"msg":"https://kantarainitiative.org/confluence/display/WGISI/Blinding+Identity+Taxonomy","username":"pknowles","ts":"2020-01-30T12:46:12.919Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 4th February, 2020\n\n10am-11.15pm PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Use case: Proposal for a Pharma consortium ‘Data Sharing Hub’ with SSI onboarding for all subjects ( @pknowles ) - 20 mins \n• Demo: Latest version of hashed data transportation using Hyperledger Aries VC tool  ( @mtfk ) - 20 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2020-02-04T17:12:49.583Z"}
{"msg":"Has joined the channel.","username":"rehuman","ts":"2020-02-04T19:04:24.430Z","type":"uj"}
{"msg":"Thank you @pknowles ","username":"rehuman","ts":"2020-02-04T19:04:25.116Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, February 18th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2020-02-04T20:10:20.394Z"}
{"msg":"Thanks for the input from the semantics group and especially to @swcurran for helping to get the flow sequence right for the following model. I presented this generic model during yesterday's semantics call describing how to go about *SSI onboarding prior to data capture consent*. I've pitched this IMI/PharmaLedger \"Blockchain Enabled Healthcare\" proposal to Roche. It would include the creation of a transformation tool to transform schema from ODM-XML format [ https://www.cdisc.org/standards/data-exchange/odm ] in their Data Capture Hub (DCH) to OCA-formatted objects which would enable consortium members to use interoperable schema objects when interacting with data transported to a new Data Sharing Hub (DSH) under the IMI umbrella. If anyone is working on a similar flow, feel free to use this model as a reference. ","username":"pknowles","ts":"2020-02-06T03:59:17.369Z"}
{"msg":"Thanks for the input from the semantics group and especially to @swcurran for helping to get the flow sequence right for the following model. I presented this generic model during yesterday's semantics call describing how to go about *SSI onboarding prior to data capture consent*. I've pitched this IMI/PharmaLedger \"Blockchain Enabled Healthcare\" proposal to Roche. It would include the creation of a transformation tool to transform schema from ODM-XML format [ https://www.cdisc.org/standards/data-exchange/odm ] in their Data Capture Hub (DCH) to OCA-formatted objects which would enable consortium members to use interoperable schema objects when interacting with data transported to a new Data Sharing Hub (DSH) under the IMI umbrella. If anyone is working on a similar flow, feel free to use this model as a reference point. ","username":"pknowles","ts":"2020-02-06T03:59:17.369Z"}
{"msg":"Thanks for the input from the semantics group and especially to @swcurran for helping to get the flow sequence right for the following model. I presented this generic model during yesterday's semantics call describing how to go about *SSI onboarding prior to data capture consent*. I've pitched this IMI/PharmaLedger \"Blockchain Enabled Healthcare\" proposal to Roche. It would include the creation of a transformation tool to transform schema from ODM-XML format [ https://www.cdisc.org/standards/data-exchange/odm ] in their Data Capture Hub (DCH) to OCA-formatted objects which would enable consortium members to use interoperable schema objects when interacting with data transported to a new Data Sharing Hub (DSH) under the IMI umbrella. If anyone is working on a similar flow, feel free to use this model as a point of reference. For anyone interested in a fuller description of the use case, go to https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32 , click on \"Videos\" and \"2020-02-04\" to get to the use case presentation.","username":"pknowles","ts":"2020-02-06T03:59:17.369Z"}
{"msg":"Thanks for the input from the semantics group and especially to @swcurran for helping to get the flow sequence right for the following model. I presented this flow diagram during yesterday's semantics call describing how to go about *SSI onboarding prior to data capture consent*. I've pitched this IMI/PharmaLedger \"Blockchain Enabled Healthcare\" proposal to Roche. It would include the creation of a transformation tool to transform schema from ODM-XML format [ https://www.cdisc.org/standards/data-exchange/odm ] in their Data Capture Hub (DCH) to OCA-formatted objects which would enable consortium members to use interoperable schema objects when interacting with data transported to a new Data Sharing Hub (DSH) under the IMI umbrella. If anyone is working on a similar flow, feel free to use this model as a point of reference. For anyone interested in a fuller description of the use case, go to https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32 , click on \"Videos\" and \"2020-02-04\" to get to the use case presentation.","username":"pknowles","ts":"2020-02-06T03:59:17.369Z"}
{"msg":"Thanks for the input from the semantics group and especially to @swcurran for helping to get the flow sequence right for the following model. I presented this flow diagram during yesterday's semantics call describing how to go about *SSI onboarding prior to data capture consent*. I've pitched this IMI/PharmaLedger \"Blockchain Enabled Healthcare\" proposal to Roche. It would include the creation of a transformation tool to transform schema from ODM-XML format [ https://www.cdisc.org/standards/data-exchange/odm ] in their Data Capture Hub (DCH) to OCA-formatted objects which would enable consortium members to use interoperable schema objects when interacting with data transported to a new Data Sharing Hub (DSH) under the IMI umbrella. If anyone is working on a similar flow, feel free to use this model as a point of reference. For anyone interested in a fuller description of the use case, go to https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32 , click on \"Videos\" and \"2020-02-04\" to get to the use case presentation. PDF attachment below.","username":"pknowles","ts":"2020-02-06T03:59:17.369Z"}
{"msg":"Thanks for the input from the semantics group and especially to @swcurran for helping to get the flow sequence right for the following model. I presented this flow diagram during yesterday's semantics call describing how to go about *SSI onboarding prior to data capture consent*. I've pitched this IMI/PharmaLedger \"Blockchain Enabled Healthcare\" proposal to Roche. It would include the creation of a transformation tool to transform schema from ODM-XML format [ https://www.cdisc.org/standards/data-exchange/odm ] in their Data Capture Hub (DCH) to OCA-formatted objects which would enable consortium members to use interoperable schema objects when interacting with data transported to a new Data Sharing Hub (DSH) under the IMI umbrella. If anyone is working on a similar flow, feel free to use this model as a point of reference. For anyone interested in a fuller description of the use case, go to https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32 , click on \"Videos\" and \"2020-02-04\" to get to the use case presentation. PDF attachment below. :arrow_down: ","username":"pknowles","ts":"2020-02-06T03:59:17.369Z"}
{"msg":"Thanks for the input from the semantics group and especially to @swcurran for helping to get the flow sequence right for the following model. I presented this flow diagram during yesterday's semantics call describing how to go about *SSI onboarding prior to data capture consent*. I've pitched this IMI/PharmaLedger \"Blockchain Enabled Healthcare\" proposal to Roche. It would include the creation of a transformation tool to transform schema from ODM-XML format [ https://www.cdisc.org/standards/data-exchange/odm ] in their Data Capture Hub (DCH) to OCA-formatted objects which would enable consortium members to use interoperable schema objects when interacting with data transported to a new Data Sharing Hub (DSH) under the IMI umbrella. If anyone is working on a similar flow, feel free to use this model as a point of reference. For anyone interested in a fuller description of the use case, go to https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32 , click on \"Videos\" and \"2020-02-04\" to view the use case presentation. PDF attached below. :arrow_down: ","username":"pknowles","ts":"2020-02-06T03:59:17.369Z"}
{"msg":"","username":"pknowles","ts":"2020-02-06T03:59:25.360Z","attachments":[{"type":"file","title":"2020-02-04 Extract.pdf","title_link":"/file-upload/WgfBWcKaoki9SStfN/2020-02-04%20Extract.pdf","url":"/file-upload/WgfBWcKaoki9SStfN/2020-02-04%20Extract.pdf","remote":false,"fileId":"WgfBWcKaoki9SStfN","fileName":"2020-02-04 Extract.pdf"}]}
{"msg":"","username":"pknowles","ts":"2020-02-06T04:16:14.318Z","attachments":[{"type":"file","title":"2020-02-04 Extract.pdf","title_link":"/file-upload/Fepta4uoskcYDbdFa/2020-02-04%20Extract.pdf","url":"/file-upload/Fepta4uoskcYDbdFa/2020-02-04%20Extract.pdf","remote":false,"fileId":"Fepta4uoskcYDbdFa","fileName":"2020-02-04 Extract.pdf"}]}
{"msg":"Because the Indy Contributors call hasn't been convenient for us all to work together, we want to schedule a call to discuss Rich Schemas. Would tomorrow at 8AM Mountain work for people? (especially @kenebert )","username":"esplinr","ts":"2020-02-10T18:25:42.800Z"}
{"msg":"Yes.","username":"kenebert","ts":"2020-02-10T18:25:59.328Z"}
{"msg":"Has joined the channel.","username":"NikhilPrakash","ts":"2020-02-12T00:50:22.794Z","type":"uj"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 18th February, 2020\n\n10am-11.15pm PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Update: Rich Schema ( @kenebert ) - 15 mins\n• Update: Development plans for Kantara Initiative’s Consent Receipt v.2.0 (Mark Lizar, OpenConsent) - 10 mins\n• Use case: Proposal for a Pharma consortium ‘Data Sharing Hub’ with SSI onboarding for all subjects [Part 2] ( @pknowles ) - 10 mins \n• Demo/update: OCA middleware tools updates ( @mtfk ) - 15 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2020-02-18T17:10:48.025Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 18th February, 2020\n\n10am-11.15pm PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Update: Rich Schema ( @kenebert ) - 15 mins\n• Update: Development plans for Kantara Initiative’s Consent Receipt v.2.0 (Mark Lizar, OpenConsent) - 10 mins\n• Use case: Proposal for a Pharma consortium ‘Data Sharing Hub’ with SSI onboarding for all subjects [Part 2] ( @pknowles ) - 10 mins \n• Demo/update: OCA middleware tooling ( @mtfk ) - 15 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2020-02-18T17:10:48.025Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 18th February, 2020\n\n10am-11.15pm PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Update: Rich Schema ( @kenebert ) - 15 mins\n• Update: Development plans for Kantara Initiative’s Consent Receipt v.2.0 (Mark Lizar, OpenConsent) - 10 mins\n• Demo: Using Verifiable Credentials to resolve external schemas and data payloads using Hashlinks ( @mtfk ) - 15 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2020-02-18T17:10:48.025Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, March 3rd. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2020-02-18T21:16:56.436Z"}
{"msg":"FYI - @ankita.p ","username":"ajayjadhav","ts":"2020-02-19T08:23:07.171Z"}
{"msg":"@ajayjadhav @ankita.p Welcome to the Hyperledger Indy Semantics channel. Feel free to reach out if you have any specific queries.","username":"pknowles","ts":"2020-02-19T08:46:16.503Z"}
{"msg":"Has joined the channel.","username":"ankita.p","ts":"2020-02-19T08:46:16.540Z","type":"uj"}
{"msg":"Thanks @pknowles ","username":"ajayjadhav","ts":"2020-02-20T10:53:21.877Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/indy-semantics?msg=Zr66LT5cbtajk4XZ3) Thank you @pknowles ","username":"ankita.p","ts":"2020-02-28T06:46:03.066Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/indy-semantics?msg=Zr66LT5cbtajk4XZ3","url":"https://chat.hyperledger.org/channel/indy-semantics?msg=Zr66LT5cbtajk4XZ3","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 3rd March, 2020\n\n10am-11.15pm PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Overview: \"Decentralized Data Network for Dummies\" ( @pknowles ) - 15 mins\n• Formation of The Human Colossus Foundation: First steps and why it was founded ( @pknowles / @mtfk ) - 15 mins\n• Use case: Proposal for a Pharma consortium ˜Data Sharing Hub” with SSI onboarding for all subjects ( @pknowles ) - 15 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2020-03-03T17:07:46.999Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 3rd March, 2020\n\n10am-11.15pm PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Overview: \"Decentralized Data Network for Dummies\" ( @pknowles ) - 15 mins\n• Formation of The Human Colossus Foundation: First steps and why it was founded ( @pknowles / @mtfk ) - 15 mins\n• Use case: Proposal for a Pharma consortium \"Data Sharing Hub\" with SSI onboarding for all subjects ( @pknowles ) - 15 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2020-03-03T17:07:46.999Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, March 17th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2020-03-03T20:22:56.514Z"}
{"msg":"Has joined the channel.","username":"Abhishekkishor","ts":"2020-03-12T19:44:50.289Z","type":"uj"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 17th March, 2020\n\n10am-11.15pm PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Update: The Human Colossus Foundation: Synergy for a Decentralized Data Economy ( @pknowles ) - 15 mins\n• Discussion: Resource DID / DRI - What properties are required and can it be kept in the DID space? ( @mtfk / @pknowles ) - 15 mins\n• Update: Sovrin Transition Committee - Action plan and road ahead ( @pknowles ) - 15 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2020-03-17T16:30:48.080Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 17th March, 2020\n\n10am-11.15pm PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Update: The Human Colossus Foundation: Synergy for a Decentralized Data Economy ( @pknowles ) - 10 mins\n• Discussion: Resource DID / DRI - What properties are required and can it be kept in the DID space? ( @mtfk / @pknowles ) - 40 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2020-03-17T16:30:48.080Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, March 17th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2020-03-17T20:52:04.825Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, March 31st. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2020-03-17T20:52:04.825Z"}
{"msg":"The most important discussion regarding _DIDs for everything_ is in full flow. If anyone has any firm thoughts on DID spec inclusion/exclusion of resource identifiers, speak now or forever hold your peace. https://github.com/w3c/did-core/issues/233","username":"pknowles","ts":"2020-03-20T16:22:49.485Z"}
{"msg":"The most important discussion regarding _DIDs for everything_ is in full flow. If anyone has any firm thoughts on DID spec inclusion/exclusion of object identifiers, speak now or forever hold your peace. https://github.com/w3c/did-core/issues/233","username":"pknowles","ts":"2020-03-20T16:22:49.485Z"}
{"msg":"Evernym published a demo video yesterday to explain ...\n* The rich schema implementation in Indy Node and Indy VDR\n* Aries interoperability between LibVCX and Streetcred\nhttps://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF","username":"pknowles","ts":"2020-03-28T01:46:00.126Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate *OCA* / *rich schema* integration. Their investigation will no doubt provide valuable knowledge to the Indy/Aries community. I believe we will need to introduce two new overlays to make full integration possible: an \"order overlay\" (mappings) and a \"binary-to-text encoding overlay\" (encodings). I look forward to feeding back with news of their findings.\n\nThe best resource for OCA is The Human Colossus GitHub repository: https://github.com/thclab\n\nFor the latest update on where Evernym are at with their rich schema project development work, head to 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nI believe that we will ultimately need to introduce two new overlays to make full integration possible: an \"order overlay\" (what the rich schema guys refer to as _mappings_) and a \"binary-to-text encoding overlay\" (what they refer to as _encodings_) but let's see what Carsten's team can find out following a deep dive.\n\nNew overlays for the development pipeline include ...\n\n- _Risk overlay_ to allow issuers to add a unique sensitivity level to any attributes that have been flagged in the schema base. (Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- _Order overlay_ to allow issues to set a distinct attribute order within the schema.\n- _Binary-to-text encoding overlay_ to allow the encoding of binary data in a sequence of printable characters.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA / rich schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we need to introduce two new overlays to make full integration possible: an \"order overlay\" (_mappings_) and a \"binary-to-text encoding overlay\" (_encodings_). I look forward to receiving feed back following Spherity's deep dive.\n\nThe best resource for *OCA* is The Human Colossus GitHub repository: https://github.com/thclab\n\nFor the latest update on where Evernym are at with their *rich schema* project development work, head to 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nNew overlays for the development pipeline include ...\n\n- _Risk overlay_ to allow issuers to add a unique sensitivity level to any attributes that have been flagged in the schema base. (Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- _Order overlay_ to allow issues to set a distinct attribute order within the schema.\n- _Binary-to-text encoding overlay_ to allow the encoding of binary data in a sequence of printable characters.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA / rich schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: an \"order\" overlay (_mappings_) and a \"binary-to-text encoding\" overlay (_encodings_). I look forward to receiving feed back from Spherity following their deep dive.\n\nThe best resource for *OCA* is The Human Colossus GitHub repository: https://github.com/thclab\n\nFor the latest update on where Evernym are at with their *rich schema* project development work, head to 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nNew overlays in the development pipeline include ...\n\n- _Risk overlay_ to allow issuers to add a unique sensitivity level to any attributes that have been flagged in the schema base. (Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- _Order overlay_ to allow issues to set a distinct attribute order within the schema.\n- _Binary-to-text encoding overlay_ to allow the encoding of binary data in a sequence of printable characters.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA / rich schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feed back from Spherity following their deep dive.\n\nThe best resource for *OCA* is The Human Colossus GitHub repository: https://github.com/thclab\n\nFor the latest update on where Evernym are at with their *rich schema* project development work, head to 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nNew overlays in the development pipeline include ...\n\n- _Risk overlay_ to allow issuers to add a unique sensitivity level to any attributes that have been flagged in the schema base. (Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- _Order overlay_ to allow issues to set a distinct attribute order within the schema.\n- _Binary-to-text encoding overlay_ to allow the encoding of binary data in a sequence of printable characters.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA / rich schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feed back from Spherity following their deep dive.\n\nThe best resource for *OCA* is The Human Colossus GitHub repository: https://github.com/thclab\n\nFor the latest update on where Evernym are at with their *rich schema* project development work, head to 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nNew overlays in the development pipeline include ...\n\n- _Risk overlay_ to allow issuers to add a unique sensitivity level to any attributes that have been flagged in the schema base. (Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- _Order overlay_ to allow issues to set a distinct attribute order within the schema.\n- _Binary-to-text encoding overlay_ to allow the encoding of binary data in a sequence of printable characters.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA / rich schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feed back from Spherity following their deep dive.\n\nThe best resource for *OCA* is The Human Colossus GitHub repository: https://github.com/thclab\n\nFor the latest update on where Evernym are at with their *rich schema* project development work, go to 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nNew overlays in the development pipeline include ...\n\n- _Risk overlay_ to allow issuers to add a unique sensitivity level to any attributes that have been flagged in the schema base. (Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- _Order overlay_ to allow issues to set a distinct attribute order within the schema.\n- _Binary-to-text encoding overlay_ to allow the encoding of binary data in a sequence of printable characters.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA / rich schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feed back from Spherity following their deep dive.\n\nThe best resource for *OCA* is The Human Colossus GitHub repository: https://github.com/thclab\n\nFor the latest update on where Evernym are at with their *rich schema* project development work, go to 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nNew overlays in the development pipeline include ...\n\n- _Risk overlay_ to allow issuers to add a unique sensitivity level to any attributes that have been flagged in the schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n\n- _Order overlay_ to allow issues to set a distinct attribute order within the schema.\n\n- _Binary-to-text encoding overlay_ to allow the encoding of binary data in a sequence of printable characters.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA / rich schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best resource for *OCA* is The Human Colossus GitHub repository: https://github.com/thclab\n\nFor the latest update on where Evernym are at with their *rich schema* project development work, go to 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nNew overlays in the development pipeline include ...\n\n- _Risk overlay_ to allow issuers to add a unique sensitivity level to any attributes that have been flagged in the schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n\n- _Order overlay_ to allow issues to set a distinct attribute order within the schema.\n\n- _Binary-to-text encoding overlay_ to allow the encoding of binary data in a sequence of printable characters.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA / rich schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best resource for *OCA* is The Human Colossus GitHub repository: https://github.com/thclab\n\nFor the latest update on where Evernym are at with their *rich schema* project development work, go to 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nNew overlays in the development pipeline include ...\n\n- A _risk overlay_ to allow issuers to add a unique sensitivity level to any attributes that have been flagged in the schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n\n- An _order overlay_ to allow issues to set a distinct attribute order within the schema.\n\n- A _binary-to-text encoding overlay_ to allow the encoding of binary data in a sequence of printable characters.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA / rich schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best resource for *OCA* is The Human Colossus GitHub repository: https://github.com/thclab\n\nFor the latest update on where Evernym are at with their *rich schema* project development work, go to 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nNew overlays in the development pipeline include ...\n- A _risk overlay_ to allow issuers to add a unique sensitivity level to any attributes that have been flagged in the schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n\n- An _order overlay_ to allow issues to set a distinct attribute order within the schema.\n\n- A _binary-to-text encoding overlay_ to allow the encoding of binary data in a sequence of printable characters.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA / rich schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best resource for *OCA* is The Human Colossus GitHub repository: https://github.com/thclab\n\nFor the latest update on where Evernym are at with their *rich schema* project development work, go to 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nNew overlays in the development pipeline include, ...\n\n- A _risk overlay_ to allow issuers to add a unique sensitivity level to any attributes that have been flagged in the schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n\n- An _order overlay_ to allow issues to set a distinct attribute order within the schema.\n\n- A _binary-to-text encoding overlay_ to allow the encoding of binary data in a sequence of printable characters.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA / rich schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best resource for *OCA* is The Human Colossus GitHub repository: https://github.com/thclab\n\nFor the latest update on where Evernym are at with their *rich schema* project development work, go to 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nNew overlays in the development pipeline include, ...\n\n- *Risk overlay* to allow issuers to add a unique sensitivity level to attributes that have been flagged as sensitive in a schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- *Order overlay* to allow issuers to add a definitive order to attributes in a schema base.\n- *Binary-to-text encoding overlay* _(encoding of binary data in a sequence of printable characters)_ to allow issuers to lock in hash functions (e.g. SHA-256 encryption) to ordered attributes defined by an _order overlay_.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA / rich schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best resource for *OCA* is The Human Colossus GitHub repository: https://github.com/thclab\n\nFor the latest update on where Evernym are at with their *rich schema* project development work, go from 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nNew overlays in the development pipeline include, ...\n\n- *Risk overlay* to allow issuers to add a unique sensitivity level to attributes that have been flagged as sensitive in a schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- *Order overlay* to allow issuers to add a definitive order to attributes in a schema base.\n- *Binary-to-text encoding overlay* _(encoding of binary data in a sequence of printable characters)_ to allow issuers to lock in hash functions (e.g. SHA-256 encryption) to ordered attributes defined by an _order overlay_.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA / rich schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best resource for *OCA* is The Human Colossus GitHub repository: https://github.com/thclab\n\nI've never been too keen on the term _Rich Schema_ as they have nothing to do with the data capture side of the network model - the common schema space. For those who are new to the concept, think of rich schema as _rich credential schema_. That is more accurate in terms of the network model.\n\n_(Note: Identity people naming semantic objects usually ends up in a land grab! Same issue with DIDs and there being no DID home for non-governed objects!)_\n\nFor the latest update on where Evernym are at with their *rich schema* project development work, go from 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nNew overlays in the development pipeline include, ...\n\n- *Risk overlay* to allow issuers to add a unique sensitivity level to attributes that have been flagged as sensitive in a schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- *Order overlay* to allow issuers to add a definitive order to attributes in a schema base.\n- *Binary-to-text encoding overlay* _(encoding of binary data in a sequence of printable characters)_ to allow issuers to lock in hash functions (e.g. SHA-256 encryption) to ordered attributes defined by an _order overlay_.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA and rich schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best resource for *OCA* is The Human Colossus GitHub repository: https://github.com/thclab\n\nI've never been too keen on the term _Rich Schema_ as they have nothing to do with the data capture side of the network model - the common schema space. For those who are new to the concept, think of rich schema as _rich credential schema_. That is more accurate in terms of the network model.\n\n_(Note: Identity people naming semantic objects usually ends up in a land grab! Same issue with DIDs and there being no DID home for non-governed objects!)_\n\nFor the latest update on where Evernym are at with their *rich schema* project development work, go from 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nNew overlays in the development pipeline include, ...\n\n- *Risk overlay* to allow issuers to add a unique sensitivity level to attributes that have been flagged as sensitive in a schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- *Order overlay* to allow issuers to add a definitive order to attributes in a schema base.\n- *Binary-to-text encoding overlay* _(encoding of binary data in a sequence of printable characters)_ to allow issuers to lock in hash functions (e.g. SHA-256 encryption) to ordered attributes defined by an _order overlay_.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA and rich schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best resource for *OCA* is The Human Colossus GitHub repository: https://github.com/thclab\n\nI've never been too keen on the term _Rich Schema_ as they have nothing to do with the data capture side of the network model - the common schema space. For those who are new to the concept, think of rich schema as _rich credential schema_. That is more accurate in terms of the network model. _(Note: Identity people naming semantic objects usually ends up in a land grab! Same issue with DIDs and there being no DID home for non-governed objects!)_\n\nFor the latest update on where Evernym are at with their *rich schema* project development work, go from 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nNew overlays in the development pipeline include, ...\n\n- *Risk overlay* to allow issuers to add a unique sensitivity level to attributes that have been flagged as sensitive in a schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- *Order overlay* to allow issuers to add a definitive order to attributes in a schema base.\n- *Binary-to-text encoding overlay* _(encoding of binary data in a sequence of printable characters)_ to allow issuers to lock in hash functions (e.g. SHA-256 encryption) to ordered attributes defined by an _order overlay_.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA and rich schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best resource for *OCA* is The Human Colossus GitHub repository: https://github.com/thclab\n\nI've never been too keen on the term _Rich Schema_ as they have nothing to do with the data capture side of the network model - the common schema space. For those who are new to the concept, think of rich schema as _rich credential schema_. That is more accurate in terms of the network model. _(Note: Identity people naming semantic objects usually ends up in a land grab. Same issue with DIDs and there being no DID home for non-governed objects!)_\n\nFor the latest update on where Evernym are at with their *rich schema* project development work, go from 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nNew overlays in the development pipeline include, ...\n\n- *Risk overlay* to allow issuers to add a unique sensitivity level to attributes that have been flagged as sensitive in a schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- *Order overlay* to allow issuers to add a definitive order to attributes in a schema base.\n- *Binary-to-text encoding overlay* _(encoding of binary data in a sequence of printable characters)_ to allow issuers to lock in hash functions (e.g. SHA-256 encryption) to ordered attributes defined by an _order overlay_.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA and rich schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best *OCA* resource is The Human Colossus GitHub repository: https://github.com/thclab\n\nI've never been too keen on the term _Rich Schema_ as they have nothing to do with the data capture side of the network model - the common schema space. For those who are new to the concept, think of rich schema as _rich credential schema_. That is more accurate in terms of the network model. _(Note: Identity people naming semantic objects usually ends up in a land grab. Same issue with DIDs and there being no DID home for non-governed objects!)_\n\nFor the latest update on where Evernym are at with their *rich schema* project development work, go from 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nNew overlays in the development pipeline include, ...\n\n- *Risk overlay* to allow issuers to add a unique sensitivity level to attributes that have been flagged as sensitive in a schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- *Order overlay* to allow issuers to add a definitive order to attributes in a schema base.\n- *Binary-to-text encoding overlay* _(encoding of binary data in a sequence of printable characters)_ to allow issuers to lock in hash functions (e.g. SHA-256 encryption) to ordered attributes defined by an _order overlay_.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA and rich schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best *OCA* resource is The Human Colossus GitHub repository: https://github.com/thclab\n\nI've never been too keen on the term _Rich Schema_ as they have nothing to do with the data capture side of the network model - the common schema space. For those who are new to the concept, think of rich schema as _rich credential schema_. That would be more accurate in terms of the network model. _(Note: Identity people naming semantic objects usually ends up in a land grab. Same issue with DIDs and there being no DID home for non-governed objects!)_\n\nFor the latest update on where Evernym are at with their *rich schema* project development work, go from 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nNew overlays in the development pipeline include, ...\n\n- *Risk overlay* to allow issuers to add a unique sensitivity level to attributes that have been flagged as sensitive in a schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- *Order overlay* to allow issuers to add a definitive order to attributes in a schema base.\n- *Binary-to-text encoding overlay* _(encoding of binary data in a sequence of printable characters)_ to allow issuers to lock in hash functions (e.g. SHA-256 encryption) to ordered attributes defined by an _order overlay_.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA and rich schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best *OCA* resource is The Human Colossus GitHub repository: https://github.com/thclab\n\nNew overlays in the development pipeline include, ...\n\n- *Risk overlay* to allow issuers to add a unique sensitivity level to attributes that have been flagged as sensitive in a schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- *Order overlay* to allow issuers to add a definitive order to attributes in a schema base.\n- *Binary-to-text encoding overlay* _(encoding of binary data in a sequence of printable characters)_ to allow issuers to lock in hash functions (e.g. SHA-256 encryption) to ordered attributes defined by an _order overlay_.\n\nI've never been too keen on the term _Rich Schema_ as they have nothing to do with the data capture side of the network model - the common schema space. For those who are new to the concept, think of rich schema as _rich credential schema_. That would be more accurate in terms of the network model. _(Note: Identity people naming semantic objects usually ends up in a land grab. Same issue with DIDs and there being no DID home for non-governed objects!)_\n\nFor the latest update on where Evernym are at with their *rich schema* project development work, go from 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nList of Rich Schema RFCs ...\n- 0120: *Rich Schema Objects Common* - https://github.com/hyperledger/indy-hipe/tree/master/text/0120-rich-schemas-common\n- 0138: *Contexts for Rich Schema Objects* - https://github.com/hyperledger/indy-hipe/blob/master/text/0138-rich-schema-context\n- 0149: *Rich Schema Schemas* - https://github.com/hyperledger/indy-hipe/blob/master/text/0149-rich-schema-schema\n- 0154: *Rich Schema Encoding* - https://github.com/hyperledger/indy-hipe/blob/master/text/0154-rich-schema-encoding\n- 0155: *Rich Schema Mapping* - https://github.com/hyperledger/indy-hipe/blob/master/text/0155-rich-schema-mapping\n- 0156: *Rich Schema Credential Definition* - https://github.com/hyperledger/indy-hipe/blob/master/text/0156-rich-schema-cred-def","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA and rich schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best *OCA* resource is The Human Colossus GitHub repository: https://github.com/thclab\n\nNew overlays in the development pipeline include, ...\n- *Risk overlay* to allow issuers to add a unique sensitivity level to attributes that have been flagged as sensitive in a schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- *Order overlay* to allow issuers to add a definitive order to attributes in a schema base.\n- *Binary-to-text encoding overlay* _(encoding of binary data in a sequence of printable characters)_ to allow issuers to lock in hash functions (e.g. SHA-256 encryption) to ordered attributes defined by an _order overlay_.\n\nI've never been too keen on the term _Rich Schema_ as they have nothing to do with the data capture side of the network model - the common schema space. For those who are new to the concept, think of rich schema as _rich credential schema_. That would be more accurate in terms of the network model. _(Note: Identity people naming semantic objects usually ends up in a land grab. Same issue with DIDs and there being no DID home for non-governed objects!)_\n\nFor the latest update on where Evernym are at with their *rich schema* project development work, go from 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nList of Rich Schema RFCs ...\n- 0120: *Rich Schema Objects Common* - https://github.com/hyperledger/indy-hipe/tree/master/text/0120-rich-schemas-common\n- 0138: *Contexts for Rich Schema Objects* - https://github.com/hyperledger/indy-hipe/blob/master/text/0138-rich-schema-context\n- 0149: *Rich Schema Schemas* - https://github.com/hyperledger/indy-hipe/blob/master/text/0149-rich-schema-schema\n- 0154: *Rich Schema Encoding* - https://github.com/hyperledger/indy-hipe/blob/master/text/0154-rich-schema-encoding\n- 0155: *Rich Schema Mapping* - https://github.com/hyperledger/indy-hipe/blob/master/text/0155-rich-schema-mapping\n- 0156: *Rich Schema Credential Definition* - https://github.com/hyperledger/indy-hipe/blob/master/text/0156-rich-schema-cred-def","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA and rich schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best *OCA* resource is The Human Colossus GitHub repository: https://github.com/thclab\n\nNew overlays in the development pipeline include, ...\n- *Risk overlay* to allow issuers to add a unique sensitivity level to attributes that have been flagged as sensitive in a schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- *Order overlay* to allow issuers to add a definitive order to attributes in a schema base.\n- *Binary-to-text encoding overlay* _(encoding of binary data in a sequence of printable characters)_ to allow issuers to lock in hash functions (e.g. SHA-256 encryption) to ordered attributes defined by an _order overlay_.\n\nFor the latest update on where Evernym are at with their *rich schema* project development work, go from 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nList of Rich Schema RFCs ...\n- 0120: *Rich Schema Objects Common* - https://github.com/hyperledger/indy-hipe/tree/master/text/0120-rich-schemas-common\n- 0138: *Contexts for Rich Schema Objects* - https://github.com/hyperledger/indy-hipe/blob/master/text/0138-rich-schema-context\n- 0149: *Rich Schema Schemas* - https://github.com/hyperledger/indy-hipe/blob/master/text/0149-rich-schema-schema\n- 0154: *Rich Schema Encoding* - https://github.com/hyperledger/indy-hipe/blob/master/text/0154-rich-schema-encoding\n- 0155: *Rich Schema Mapping* - https://github.com/hyperledger/indy-hipe/blob/master/text/0155-rich-schema-mapping\n- 0156: *Rich Schema Credential Definition* - https://github.com/hyperledger/indy-hipe/blob/master/text/0156-rich-schema-cred-def\n\nI've never been too keen on the term _Rich Schema_ as they have nothing to do with the data capture side of the network model - the common schema space. For those who are new to the concept, think of rich schema as _rich credential schema_. That would be more accurate in terms of the network model. _(Note: Identity people naming semantic objects usually ends up in a land grab. Same issue with DIDs and there being no DID home for non-governed objects!)_","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA and rich schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best *OCA* resource is The Human Colossus GitHub repository: https://github.com/thclab\n\nNew overlays in the development pipeline include, ...\n- *Risk overlay* to allow issuers to add a unique sensitivity level to attributes that have been flagged as sensitive in a schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- *Order overlay* to allow issuers to add a definitive order to attributes in a schema base.\n- *Binary-to-text encoding overlay* _(encoding of binary data in a sequence of printable characters)_ to allow issuers to lock in hash functions (e.g. SHA-256 encryption) to ordered attributes defined by an _order overlay_.\n\nFor the latest update on where Evernym are at with their *rich schema* project development work, go from 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nList of Rich Schema RFCs ...\n- 0120: *Rich Schema Objects Common* - https://github.com/hyperledger/indy-hipe/tree/master/text/0120-rich-schemas-common\n- 0138: *Contexts for Rich Schema Objects* - https://github.com/hyperledger/indy-hipe/blob/master/text/0138-rich-schema-context\n- 0149: *Rich Schema Schemas* - https://github.com/hyperledger/indy-hipe/blob/master/text/0149-rich-schema-schema\n- 0154: *Rich Schema Encoding* - https://github.com/hyperledger/indy-hipe/blob/master/text/0154-rich-schema-encoding\n- 0155: *Rich Schema Mapping* - https://github.com/hyperledger/indy-hipe/blob/master/text/0155-rich-schema-mapping\n- 0156: *Rich Schema Credential Definition* - https://github.com/hyperledger/indy-hipe/blob/master/text/0156-rich-schema-cred-def\n\nI've never been too keen on the term _Rich Schema_ as they have nothing to do with the data capture side of the network model - the common schema space. For those who are new to the concept, think of rich schema as _rich credential schema_. That would be more accurate in terms of the network model. _(Note: Identity people naming semantic objects usually ends up in a land grab. Same thing with DIDs and there being no DID home for non-governed objects!)_","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA and rich schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best *OCA* (Overlays Capture Architecture) resource is The Human Colossus GitHub repository: https://github.com/thclab\n\nNew overlays in the development pipeline include, ...\n- *Risk overlay* to allow issuers to add a unique sensitivity level to attributes that have been flagged as sensitive in a schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- *Order overlay* to allow issuers to add a definitive order to attributes in a schema base.\n- *Binary-to-text encoding overlay* _(encoding of binary data in a sequence of printable characters)_ to allow issuers to lock in hash functions (e.g. SHA-256 encryption) to ordered attributes defined by an _order overlay_.\n\nFor the latest update on where Evernym are at with their *Rich Schema* project development work, go from 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nList of Rich Schema RFCs ...\n- 0120: *Rich Schema Objects Common* - https://github.com/hyperledger/indy-hipe/tree/master/text/0120-rich-schemas-common\n- 0138: *Contexts for Rich Schema Objects* - https://github.com/hyperledger/indy-hipe/blob/master/text/0138-rich-schema-context\n- 0149: *Rich Schema Schemas* - https://github.com/hyperledger/indy-hipe/blob/master/text/0149-rich-schema-schema\n- 0154: *Rich Schema Encoding* - https://github.com/hyperledger/indy-hipe/blob/master/text/0154-rich-schema-encoding\n- 0155: *Rich Schema Mapping* - https://github.com/hyperledger/indy-hipe/blob/master/text/0155-rich-schema-mapping\n- 0156: *Rich Schema Credential Definition* - https://github.com/hyperledger/indy-hipe/blob/master/text/0156-rich-schema-cred-def\n\nI've never been too keen on the term _Rich Schema_ as they have nothing to do with the data capture side of the network model - the common schema space. For those who are new to the concept, think of rich schema as _rich credential schema_. That would be more accurate in terms of the network model. _(Note: Identity people naming semantic objects usually ends up in a land grab. Same thing with DIDs and there being no DID home for non-governed objects!)_","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA and Rich Schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best *OCA* (Overlays Capture Architecture) resource is The Human Colossus GitHub repository: https://github.com/thclab\n\nNew overlays in the development pipeline include, ...\n- *Risk overlay* to allow issuers to add a unique sensitivity level to attributes that have been flagged as sensitive in a schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- *Order overlay* to allow issuers to add a definitive order to attributes in a schema base.\n- *Binary-to-text encoding overlay* _(encoding of binary data in a sequence of printable characters)_ to allow issuers to lock in hash functions (e.g. SHA-256 encryption) to ordered attributes defined by an _order overlay_.\n\nFor the latest update on where Evernym are at with their *Rich Schema* project development work, go from 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nList of Rich Schema RFCs ...\n- 0120: *Rich Schema Objects Common* - https://github.com/hyperledger/indy-hipe/tree/master/text/0120-rich-schemas-common\n- 0138: *Contexts for Rich Schema Objects* - https://github.com/hyperledger/indy-hipe/blob/master/text/0138-rich-schema-context\n- 0149: *Rich Schema Schemas* - https://github.com/hyperledger/indy-hipe/blob/master/text/0149-rich-schema-schema\n- 0154: *Rich Schema Encoding* - https://github.com/hyperledger/indy-hipe/blob/master/text/0154-rich-schema-encoding\n- 0155: *Rich Schema Mapping* - https://github.com/hyperledger/indy-hipe/blob/master/text/0155-rich-schema-mapping\n- 0156: *Rich Schema Credential Definition* - https://github.com/hyperledger/indy-hipe/blob/master/text/0156-rich-schema-cred-def\n\nI've never been too keen on the term _Rich Schema_ as they have nothing to do with the data capture side of the network model - the common schema space. For those who are new to the concept, think of rich schema as _rich credential schema_. That would be more accurate in terms of the network model. _(Note: Identity people naming semantic objects usually ends up in a land grab. Same thing with DIDs and there being no DID home for non-governed objects!)_","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA and Rich Schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best *OCA* (Overlays Capture Architecture) resource is The Human Colossus GitHub repository: https://github.com/thclab\n\nNew overlays in the development pipeline include, ...\n- *Risk overlay* to allow issuers to add a unique sensitivity level to attributes that have been flagged as sensitive in a schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- *Order overlay* to allow issuers to add a definitive order to attributes in a schema base.\n- *Binary-to-text encoding overlay* _(encoding of binary data in a sequence of printable characters)_ to allow issuers to lock in hash functions (e.g. SHA-256 encryption) to ordered attributes defined by an _order overlay_.\n\nFor the latest update on where Evernym are at with their *Rich Schema* project development work, go from 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nList of Rich Schema RFCs ...\n- 0120: *Rich Schema Objects Common* - https://github.com/hyperledger/indy-hipe/tree/master/text/0120-rich-schemas-common\n- 0138: *Contexts for Rich Schema Objects* - https://github.com/hyperledger/indy-hipe/blob/master/text/0138-rich-schema-context\n- 0149: *Rich Schema Schemas* - https://github.com/hyperledger/indy-hipe/blob/master/text/0149-rich-schema-schema\n- 0154: *Rich Schema Encoding* - https://github.com/hyperledger/indy-hipe/blob/master/text/0154-rich-schema-encoding\n- 0155: *Rich Schema Mapping* - https://github.com/hyperledger/indy-hipe/blob/master/text/0155-rich-schema-mapping\n- 0156: *Rich Schema Credential Definition* - https://github.com/hyperledger/indy-hipe/blob/master/text/0156-rich-schema-cred-def\n\nI've never been too keen on the term _Rich Schema_ as they have nothing to do with the data capture side of the network model - the common schema space. For those who are new to the concept, think of rich schema as _rich credential schema_. That would be more accurate in terms of the network model. _(Note: Identity people naming semantic objects usually ends up in a land grab. Same thing with DIDs and there being no DID home for non-governed objects!)_\n\n_ZKP Entry Architecture_ vs _Overlays Capture Architecture_ ... Just a thought. (I like synergy throughout!)","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA and Rich Schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best *OCA* (Overlays Capture Architecture) resource is The Human Colossus GitHub repository: https://github.com/thclab\n\nNew overlays in the development pipeline include, ...\n- *Risk overlay* to allow issuers to add a unique sensitivity level to attributes that have been flagged as sensitive in a schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- *Order overlay* to allow issuers to add a definitive order to attributes in a schema base.\n- *Binary-to-text encoding overlay* _(encoding of binary data in a sequence of printable characters)_ to allow issuers to lock in hash functions (e.g. SHA-256 encryption) to ordered attributes defined by an _order overlay_.\n\nFor the latest update on where Evernym are at with their *Rich Schema* project development work, go from 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nList of Rich Schema RFCs ...\n- 0120: *Rich Schema Objects Common* - https://github.com/hyperledger/indy-hipe/tree/master/text/0120-rich-schemas-common\n- 0138: *Contexts for Rich Schema Objects* - https://github.com/hyperledger/indy-hipe/blob/master/text/0138-rich-schema-context\n- 0149: *Rich Schema Schemas* - https://github.com/hyperledger/indy-hipe/blob/master/text/0149-rich-schema-schema\n- 0154: *Rich Schema Encoding* - https://github.com/hyperledger/indy-hipe/blob/master/text/0154-rich-schema-encoding\n- 0155: *Rich Schema Mapping* - https://github.com/hyperledger/indy-hipe/blob/master/text/0155-rich-schema-mapping\n- 0156: *Rich Schema Credential Definition* - https://github.com/hyperledger/indy-hipe/blob/master/text/0156-rich-schema-cred-def\n\nI've never been too keen on the term _Rich Schema_ as they have nothing to do with the data capture side of the network model - the common schema space. For those who are new to the concept, think of rich schema as _rich credential schema_. That would be more accurate in terms of the network model. _(Note: Identity people naming semantic objects usually ends up in a land grab. Same thing with DIDs and there being no DID home for non-governed objects!)_\n\n_ZKP Entry Architecture_ vs _Overlays Capture Architecture_ ... Just a thought.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA and Rich Schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best *OCA* (Overlays Capture Architecture) resource is The Human Colossus GitHub repository: https://github.com/thclab\n\nNew overlays in the development pipeline include, ...\n- *Risk overlay* to allow issuers to add a unique sensitivity level to attributes that have been flagged as sensitive in a schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- *Order overlay* to allow issuers to add a definitive order to attributes in a schema base.\n- *Binary-to-text encoding overlay* _(encoding of binary data in a sequence of printable characters)_ to allow issuers to lock in hash functions (e.g. SHA-256 encryption) to ordered attributes defined by an _order overlay_.\n\nFor the latest update on where Evernym are at with their *Rich Schema* project development work, go from 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nList of Rich Schema RFCs ...\n- 0120: *Rich Schema Objects Common* - https://github.com/hyperledger/indy-hipe/tree/master/text/0120-rich-schemas-common\n- 0138: *Contexts for Rich Schema Objects* - https://github.com/hyperledger/indy-hipe/blob/master/text/0138-rich-schema-context\n- 0149: *Rich Schema Schemas* - https://github.com/hyperledger/indy-hipe/blob/master/text/0149-rich-schema-schema\n- 0154: *Rich Schema Encoding* - https://github.com/hyperledger/indy-hipe/blob/master/text/0154-rich-schema-encoding\n- 0155: *Rich Schema Mapping* - https://github.com/hyperledger/indy-hipe/blob/master/text/0155-rich-schema-mapping\n- 0156: *Rich Schema Credential Definition* - https://github.com/hyperledger/indy-hipe/blob/master/text/0156-rich-schema-cred-def\n\nI've never been too keen on the term _Rich Schema_ as they have nothing to do with the female side of the network model - the _Schema_ space (as opposed to the _Credential_ space). For those who are new to the concept, think of rich schema as _rich credential schema_. That would be more accurate in terms of painting a picture on where that piece sits. _(Note: Identity people naming Semantic objects usually ends up in a land grab. Same thing with DIDs and there being no DID home for non-governed objects!)_\n\n_ZKP Entry Architecture_ vs _Overlays Capture Architecture_ ... Just a thought.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA and Rich Schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best *OCA* (Overlays Capture Architecture) resource is The Human Colossus GitHub repository: https://github.com/thclab\n\nNew overlays in the development pipeline include, ...\n- *Risk overlay* to allow issuers to add a unique sensitivity level to attributes that have been flagged as sensitive in a schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- *Order overlay* to allow issuers to add a definitive order to attributes in a schema base.\n- *Binary-to-text encoding overlay* _(encoding of binary data in a sequence of printable characters)_ to allow issuers to lock in hash functions (e.g. SHA-256 encryption) to ordered attributes defined by an _order overlay_.\n\nFor the latest update on where Evernym are at with their *Rich Schema* project development work, go from 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nList of Rich Schema RFCs ...\n- 0120: *Rich Schema Objects Common* - https://github.com/hyperledger/indy-hipe/tree/master/text/0120-rich-schemas-common\n- 0138: *Contexts for Rich Schema Objects* - https://github.com/hyperledger/indy-hipe/blob/master/text/0138-rich-schema-context\n- 0149: *Rich Schema Schemas* - https://github.com/hyperledger/indy-hipe/blob/master/text/0149-rich-schema-schema\n- 0154: *Rich Schema Encoding* - https://github.com/hyperledger/indy-hipe/blob/master/text/0154-rich-schema-encoding\n- 0155: *Rich Schema Mapping* - https://github.com/hyperledger/indy-hipe/blob/master/text/0155-rich-schema-mapping\n- 0156: *Rich Schema Credential Definition* - https://github.com/hyperledger/indy-hipe/blob/master/text/0156-rich-schema-cred-def\n\nI've never been too keen on the term _Rich Schema_ as they have nothing to do with the female side of the network model - the _Schema_ space (as opposed to the _Credential_ space). For those who are new to the concept, think of rich schema as _rich credential schema_. That would be more accurate in terms of painting a picture on where that piece sits. _(Note: Identity people naming Semantic objects usually ends up in a land grab. Same thing with DIDs and there being no DID home for non-governed objects!)_\n\n_ZKP Entry Architecture_ vs _Overlays Capture Architecture_ ... Just a thought. \n\nSee mini-deck below to help naming of network components.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA and Rich Schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best *OCA* (Overlays Capture Architecture) resource is The Human Colossus GitHub repository: https://github.com/thclab\n\nNew overlays in the development pipeline include, ...\n- *Risk overlay* to allow issuers to add a unique sensitivity level to attributes that have been flagged as sensitive in a schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- *Order overlay* to allow issuers to add a definitive order to attributes in a schema base.\n- *Binary-to-text encoding overlay* _(encoding of binary data in a sequence of printable characters)_ to allow issuers to lock in hash functions (e.g. SHA-256 encryption) to ordered attributes defined by an _order overlay_.\n\nFor the latest update on where Evernym are at with their *Rich Schema* project development work, go from 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nList of Rich Schema RFCs ...\n- 0120: *Rich Schema Objects Common* - https://github.com/hyperledger/indy-hipe/tree/master/text/0120-rich-schemas-common\n- 0138: *Contexts for Rich Schema Objects* - https://github.com/hyperledger/indy-hipe/blob/master/text/0138-rich-schema-context\n- 0149: *Rich Schema Schemas* - https://github.com/hyperledger/indy-hipe/blob/master/text/0149-rich-schema-schema\n- 0154: *Rich Schema Encoding* - https://github.com/hyperledger/indy-hipe/blob/master/text/0154-rich-schema-encoding\n- 0155: *Rich Schema Mapping* - https://github.com/hyperledger/indy-hipe/blob/master/text/0155-rich-schema-mapping\n- 0156: *Rich Schema Credential Definition* - https://github.com/hyperledger/indy-hipe/blob/master/text/0156-rich-schema-cred-def\n\nI've never been keen on the term _Rich Schema_ as they have nothing to do with the female side of the network model - the _Schema_ space (as opposed to the _Credential_ space). For those who are new to the concept, think of Rich Schema as a claim entry architecture. That would be more accurate in terms of painting a picture on where that piece sits. _(Note: Identity people naming Semantic objects usually ends up in a land grab. Same thing with DIDs and there being no DID home for non-governed objects!)_\n\n_ZKP Entry Architecture_ vs _Overlays Capture Architecture_ ... Just a thought. \n\nSee mini-deck below to help naming of network components.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA and Rich Schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best *OCA* (Overlays Capture Architecture) resource is The Human Colossus GitHub repository: https://github.com/thclab\n\nNew overlays in the development pipeline include, ...\n- *Risk overlay* to allow issuers to add a unique sensitivity level to attributes that have been flagged as sensitive in a schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- *Order overlay* to allow issuers to add a definitive order to attributes in a schema base.\n- *Binary-to-text encoding overlay* _(encoding of binary data in a sequence of printable characters)_ to allow issuers to lock in hash functions (e.g. SHA-256 encryption) to ordered attributes defined by an _order overlay_.\n\nFor the latest update on where Evernym are at with their *Rich Schema* project development work, go from 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nList of Rich Schema RFCs ...\n- 0120: *Rich Schema Objects Common* - https://github.com/hyperledger/indy-hipe/tree/master/text/0120-rich-schemas-common\n- 0138: *Contexts for Rich Schema Objects* - https://github.com/hyperledger/indy-hipe/blob/master/text/0138-rich-schema-context\n- 0149: *Rich Schema Schemas* - https://github.com/hyperledger/indy-hipe/blob/master/text/0149-rich-schema-schema\n- 0154: *Rich Schema Encoding* - https://github.com/hyperledger/indy-hipe/blob/master/text/0154-rich-schema-encoding\n- 0155: *Rich Schema Mapping* - https://github.com/hyperledger/indy-hipe/blob/master/text/0155-rich-schema-mapping\n- 0156: *Rich Schema Credential Definition* - https://github.com/hyperledger/indy-hipe/blob/master/text/0156-rich-schema-cred-def\n\nI've never been keen on the term _Rich Schema_ as they have nothing to do with the female side of the network model - the _Schema_ space (as opposed to the _Credential_ space). For those who are new to the concept, think of Rich Schema as a claim entry architecture. That would be more accurate in terms of painting a picture on where that piece sits. _(Note: Identity people naming Semantic objects usually ends up in a land grab. Same thing with DIDs and there being no DID home for non-governed objects!)_\n\n_ZKP Entry Architecture_ vs _Overlays Capture Architecture_ \n\n\"ZEA\" is a dramatically better name than \"Rich Schema\". I'll put it down as an agenda item for the next Semantics WG call.\n\nSee mini-deck below to help naming of network components.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA and Rich Schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best *OCA* (Overlays Capture Architecture) resource is The Human Colossus GitHub repository: https://github.com/thclab\n\nNew overlays in the development pipeline include, ...\n- *Risk overlay* to allow issuers to add a unique sensitivity level to attributes that have been flagged as sensitive in a schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- *Order overlay* to allow issuers to add a definitive order to attributes in a schema base.\n- *Binary-to-text encoding overlay* _(encoding of binary data in a sequence of printable characters)_ to allow issuers to lock in hash functions (e.g. SHA-256 encryption) to ordered attributes defined by an _order overlay_.\n\nFor the latest update on where Evernym are at with their *Rich Schema* project development work, go from 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nList of Rich Schema RFCs ...\n- 0120: *Rich Schema Objects Common* - https://github.com/hyperledger/indy-hipe/tree/master/text/0120-rich-schemas-common\n- 0138: *Contexts for Rich Schema Objects* - https://github.com/hyperledger/indy-hipe/blob/master/text/0138-rich-schema-context\n- 0149: *Rich Schema Schemas* - https://github.com/hyperledger/indy-hipe/blob/master/text/0149-rich-schema-schema\n- 0154: *Rich Schema Encoding* - https://github.com/hyperledger/indy-hipe/blob/master/text/0154-rich-schema-encoding\n- 0155: *Rich Schema Mapping* - https://github.com/hyperledger/indy-hipe/blob/master/text/0155-rich-schema-mapping\n- 0156: *Rich Schema Credential Definition* - https://github.com/hyperledger/indy-hipe/blob/master/text/0156-rich-schema-cred-def\n\nI've never been a fan on the name _Rich Schema_ as the framework has nothing to do with the female (data capture) side of the network model - the _Schema_ space (as opposed to the _Credential_ space). For those who are new to the concept, think of Rich Schema as a claim entry architecture. That would be more accurate in terms of painting a picture on where that piece sits.\n\n_ZKP Entry Architecture_ vs _Overlays Capture Architecture_ \n\n@brentzundel / @kenebert - \"ZEA\" is a dramatically better name than \"Rich Schema\". I'll put it down as an agenda item for the next Semantics WG call to open up the discussion. See mini-deck below to help naming of network components.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA and Rich Schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best *OCA* (Overlays Capture Architecture) resource is The Human Colossus GitHub repository: https://github.com/thclab\n\nNew overlays in the development pipeline include, ...\n- *Risk overlay* to allow issuers to add a unique sensitivity level to attributes that have been flagged as sensitive in a schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- *Order overlay* to allow issuers to add a definitive order to attributes in a schema base.\n- *Binary-to-text encoding overlay* _(encoding of binary data in a sequence of printable characters)_ to allow issuers to lock in hash functions (e.g. SHA-256 encryption) to ordered attributes defined by an _order overlay_.\n\nFor the latest update on where Evernym are at with their *Rich Schema* project development work, go from 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nList of Rich Schema RFCs ...\n- 0120: *Rich Schema Objects Common* - https://github.com/hyperledger/indy-hipe/tree/master/text/0120-rich-schemas-common\n- 0138: *Contexts for Rich Schema Objects* - https://github.com/hyperledger/indy-hipe/blob/master/text/0138-rich-schema-context\n- 0149: *Rich Schema Schemas* - https://github.com/hyperledger/indy-hipe/blob/master/text/0149-rich-schema-schema\n- 0154: *Rich Schema Encoding* - https://github.com/hyperledger/indy-hipe/blob/master/text/0154-rich-schema-encoding\n- 0155: *Rich Schema Mapping* - https://github.com/hyperledger/indy-hipe/blob/master/text/0155-rich-schema-mapping\n- 0156: *Rich Schema Credential Definition* - https://github.com/hyperledger/indy-hipe/blob/master/text/0156-rich-schema-cred-def\n\nI've never been a fan on the name _Rich Schema_ as the framework has nothing to do with the female (data capture) side of the network model - the _Schema_ space. Rich Schema sit in the _Credential_ space. For those who are new to the concept, think of Rich Schema as a claim entry architecture. That would be more accurate in terms of painting a picture on where that piece sits.\n\n_ZKP Entry Architecture_ vs _Overlays Capture Architecture_ \n\n@brentzundel / @kenebert - \"ZEA\" is a dramatically better name than \"Rich Schema\". I'll put it down as an agenda item for the next Semantics WG call to open up the discussion. See mini-deck below to help naming of network components.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA and Rich Schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best *OCA* (Overlays Capture Architecture) resource is The Human Colossus GitHub repository: https://github.com/thclab\n\nNew overlays in the development pipeline include, ...\n- *Risk overlay* to allow issuers to add a unique sensitivity level to attributes that have been flagged as sensitive in a schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- *Order overlay* to allow issuers to add a definitive order to attributes in a schema base.\n- *Binary-to-text encoding overlay* _(encoding of binary data in a sequence of printable characters)_ to allow issuers to lock in hash functions (e.g. SHA-256 encryption) to ordered attributes defined by an _order overlay_.\n\nFor the latest update on where Evernym are at with their *Rich Schema* project development work, go from 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nList of Rich Schema RFCs ...\n- 0120: *Rich Schema Objects Common* - https://github.com/hyperledger/indy-hipe/tree/master/text/0120-rich-schemas-common\n- 0138: *Contexts for Rich Schema Objects* - https://github.com/hyperledger/indy-hipe/blob/master/text/0138-rich-schema-context\n- 0149: *Rich Schema Schemas* - https://github.com/hyperledger/indy-hipe/blob/master/text/0149-rich-schema-schema\n- 0154: *Rich Schema Encoding* - https://github.com/hyperledger/indy-hipe/blob/master/text/0154-rich-schema-encoding\n- 0155: *Rich Schema Mapping* - https://github.com/hyperledger/indy-hipe/blob/master/text/0155-rich-schema-mapping\n- 0156: *Rich Schema Credential Definition* - https://github.com/hyperledger/indy-hipe/blob/master/text/0156-rich-schema-cred-def\n\nI've never been a fan on the name _Rich Schema_ as the framework has nothing to do with the female (data capture) side of the network - the _Schema_ space. Rich Schema actually sit in the _Credential_ space. For those who are new to the concept, think of Rich Schema as a claim entry architecture. That would be more accurate in terms of painting a picture on where that piece sits.\n\n_ZKP Entry Architecture_ vs _Overlays Capture Architecture_ \n\n@brentzundel / @kenebert - \"ZEA\" is a dramatically better name than \"Rich Schema\". I'll put it down as an agenda item for the next Semantics WG call to open up the discussion. See mini-deck below to help naming of network components.","username":"pknowles","ts":"2020-03-28T02:54:23.652Z"}
{"msg":"","username":"pknowles","ts":"2020-03-28T08:53:31.812Z","attachments":[{"type":"file","title":"Identifiers.pdf","title_link":"/file-upload/ztWAt4HhXuipK7HjR/Identifiers.pdf","url":"/file-upload/ztWAt4HhXuipK7HjR/Identifiers.pdf","remote":false,"fileId":"ztWAt4HhXuipK7HjR","fileName":"Identifiers.pdf"}]}
{"msg":"","username":"pknowles","ts":"2020-03-28T08:54:13.243Z","attachments":[{"type":"file","title":"Identifiers.pdf","title_link":"/file-upload/yXZNLbLt4CsxKsyLF/Identifiers.pdf","url":"/file-upload/yXZNLbLt4CsxKsyLF/Identifiers.pdf","remote":false,"fileId":"yXZNLbLt4CsxKsyLF","fileName":"Identifiers.pdf"}]}
{"msg":"The Spherity [https://spherity.com] developers are keen to investigate OCA and Rich Schema integration. Their investigation will no doubt provide valuable feedback to the Indy/Aries community. I believe we'll need to develop two new overlays to make full integration possible: (i.) an _order overlay_ (mappings) and (ii.) a _binary-to-text encoding overlay_ (encodings). I look forward to receiving feedback from Spherity following their deep dive.\n\nThe best *OCA* (Overlays Capture Architecture) resource is The Human Colossus GitHub repository: https://github.com/thclab\n\nNew overlays in the development pipeline include, ...\n- *Risk overlay* to allow issuers to add a unique sensitivity level to attributes that have been flagged as sensitive in a schema base. \n(Context: https://wiki.idesg.org/wiki/index.php/Trustworthy_Healthcare_Provider#Data_Categorization)\n- *Order overlay* to allow issuers to add a definitive order to attributes in a schema base.\n- *Binary-to-text encoding overlay* _(encoding of binary data in a sequence of printable characters)_ to allow issuers to lock in hash functions (e.g. SHA-256 encryption) to ordered attributes defined by an _order overlay_.\n\nFor the latest update on where Evernym are at with their *Rich Schema* project development work, go from 8 mins 15 secs of the following demo video. This was posted just yesterday so is bang up to date. https://www.youtube.com/watch?v=lZ84bCxEKWo&list=PLRp0viTDxBWGLdZk0aamtahB9cpJGV7ZF\n\nList of Rich Schema RFCs ...\n- 0120: *Rich Schema Objects Common* - https://github.com/hyperledger/indy-hipe/tree/master/text/0120-rich-schemas-common\n- 0138: *Contexts for Rich Schema Objects* - https://github.com/hyperledger/indy-hipe/blob/master/text/0138-rich-schema-context\n- 0149: *Rich Schema Schemas* - https://github.com/hyperledger/indy-hipe/blob/master/text/0149-rich-schema-schema\n- 0154: *Rich Schema Encoding* - https://github.com/hyperledger/indy-hipe/blob/master/text/0154-rich-schema-encoding\n- 0155: *Rich Schema Mapping* - https://github.com/hyperledger/indy-hipe/blob/master/text/0155-rich-schema-mapping\n- 0156: *Rich Schema Credential Definition* - https://github.com/hyperledger/indy-hipe/blob/master/text/0156-rich-schema-cred-def\n\nI've never been too keen on the term _Rich Schema_ as they have nothing to do with the female side of the network model - the _Schema_ space (as opposed to the _Credential_ space). For those who are new to the concept, think of rich schema as _rich credential schema_. That would be more accurate in terms of painting a picture on where that piece sits. _(Note: Identity people naming Semantic objects usually ends up in a land grab. Same thing with DIDs and there being no DID home for non-governed objects!)_\n\n_ZKP Entry Architecture_ vs _Overlays Capture Architecture_ ... Just a thought. \n\nSee mini-deck below to help naming of network components.","username":"pknowles","ts":"2020-03-28T09:41:41.167Z"}
{"msg":"Has joined the channel.","username":"mohammadhossein73","ts":"2020-03-29T05:48:45.775Z","type":"uj"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 31st March, 2020\n\n10am-11.15pm PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Presentation: Entity and Object Identifiers: Elements, components and characteristics of a  decentralised network ( @pknowles ) - 15 mins\n• Discussion: DIDs for non-governed objects. Can they have a home under the DID umbrella? ( @mtfk  / @pknowles  ) - 10 mins\n• Presentation: Safe data sharing amidst a global pandemic ( @pknowles  ) - 15 mins\n• Update: Sovrin Transition Committee  - Comms plan and steward testimonials ( @pknowles ) - 10 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2020-03-31T16:50:54.254Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 31st March, 2020\n\n10am-11.15pm PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Presentation: Entity and Object Identifiers: Elements, components and characteristics of a  decentralised network ( @pknowles ) - 15 mins\n• Discussion: DIDs for non-governed objects. Can they have a home under the DID umbrella? ( @mtfk  / @pknowles  ) - 15 mins\n• Presentation: Safe data sharing amidst a global pandemic ( @pknowles  ) - 15 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2020-03-31T16:50:54.254Z"}
{"msg":"The agenda, video, notes, etc. from yesterday's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, April 14th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2020-04-01T06:48:49.910Z"}
{"msg":"Has left the channel.","username":"brentzundel","ts":"2020-04-03T20:39:32.592Z","type":"ul"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 14th April, 2020\n\n10am-11.15pm PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Live demo: Overlays Capture Architecture (OCA): A standardized global solution for data capture ( @mtfk ) - 20 mins\n• Live demo: COVID-19 demo using Aries Toolbox ( @janl ) - 20 mins\n• COVID-19 initiative: “Tools” focus groups for building credentials and initiating data flows ( @pknowles )- 10 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727\nPassword: 1234","username":"pknowles","ts":"2020-04-14T16:41:45.817Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 14th April, 2020\n\n10am-11.15pm PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Live demo: Overlays Capture Architecture (OCA): A standardized global solution for data capture ( @mtfk ) - 20 mins\n• Live demo: COVID-19 demo using Aries Toolbox ( @janl ) - 20 mins\n• COVID-19 initiative: “Tools” focus groups for building credentials and initiating data flows ( @pknowles ) - 10 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727\nPassword: 1234","username":"pknowles","ts":"2020-04-14T16:41:45.817Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, April 28th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2020-04-14T20:51:17.034Z"}
{"msg":" Is there anyone who has done KeyCloak SSo integration with DIDs ? ","username":"SethiSaab","ts":"2020-04-15T08:45:33.650Z"}
{"msg":"We've done it with verified credentials, but not DIDs.","username":"swcurran","ts":"2020-04-15T13:39:36.716Z"}
{"msg":"https://github.com/bcgov/vc-authn-oidc","username":"swcurran","ts":"2020-04-15T13:40:10.301Z"}
{"msg":"https://github.com/bcgov/vc-authn-oidc - there are demos that can be run in the repo and we have some online - see the DemoInstructions.md in the docs folder","username":"swcurran","ts":"2020-04-15T13:40:10.301Z"}
{"msg":"Hi Team , I want to integrate Cloud HSM with Indy for key management . Is there anyone who has done that before ? ","username":"SethiSaab","ts":"2020-04-22T06:37:05.654Z"}
{"msg":"or if anyone can provide some reference","username":"SethiSaab","ts":"2020-04-22T06:38:12.398Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 28th April, 2020\n\n10am-11.15pm PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles  \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Update: Trust-over-IP Foundation ( @pknowles ) - 10 mins\n• Update: Sovrin Ecosystem ( @pknowles ) - 10 mins\n• Update: Internet Identity Workshop (IIW) [30th edition] ( @pknowles ) - 10 mins\n• Update: COVID-19 Credentials Initiative: Tools and technology ( @pknowles ) - 10 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2020-04-28T16:46:11.812Z"}
{"msg":"The agenda, video, notes, etc. from today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, May 12th. https://drive.google.com/drive/u/0/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou?ogsrc=32","username":"pknowles","ts":"2020-04-28T23:30:50.556Z"}
{"msg":"@mtfk and I hosted an IIW session on *OCA* [Overlays Capture Architecture] yesterday which included a demo using the Aries toolbox. \nHere is the video link - https://drive.google.com/file/d/13yuupet1o_oysdEjM99avsT5aPqs4DY9/view?usp=sharing","username":"pknowles","ts":"2020-04-30T06:56:03.579Z"}
{"msg":"I hosted an IIW session on the *MHM* [Mouse Head Model] on Thursday. Here is the video link ...\nhttps://drive.google.com/file/d/1TbUtUMjl_dbGQSlU0CMph2cFXhxMCD_p/view?usp=sharing","username":"pknowles","ts":"2020-05-02T00:55:20.115Z"}
{"msg":"Over the course of discussions with experts in the _Identity_ and _Consent_ communities before and during IIW, I believe that a clearer picture is starting to emerge on when the collective \"we\" should be using the word \"trust\" and when we should be using the word \"assurance\". The reason that this nuance is so important is that, having already knitted some key _Identity_ and _Semantics_ components together, The Human Colossus Foundation will now be shifting our focus to the _Consent_ piece by opening up discussions with the Open Consent Group as we start knitting _Identity_, _Consent_ and _Semantics_ components together as we continue to build middleware tooling for a Decentralized Data Economy (DDE). On the next *Indy Semantics WG* call I want to bring some focus on the \"trust\" versus \"assurance\" naming issue in a bid to gain consensus from key stakeholders from the three ecosystems so that we can all jump the hurdle together and continue down the \"decentralized\" path with renewed confidence. In my granular breakdown during the call, I hope to shed some light on when best to use the two terms. If anyone is interested in this debate, please join us on Tuesday, May 12th at 10am-11.15pm PT / 1pm-2.15pm ET / 6pm-7.15pm GMT. This is less of a bun fight and more of a focussed discussion of human interaction versus system interaction within the model. Those are the kernels.","username":"pknowles","ts":"2020-05-02T08:00:04.089Z"}
{"msg":"Over the course of discussions with experts in the _Identity_ and _Consent_ communities before and during IIW, I believe that a clearer picture is starting to emerge on when the collective \"we\" should be using the word \"trust\" and when we should be using the word \"assurance\". The reason that this nuance is so important is that, having already knitted some key _Identity_ and _Semantics_ components together, The Human Colossus Foundation will now be shifting our focus to the _Consent_ piece by opening up discussions with the Open Consent Group as we start knitting _Identity_, _Consent_ and _Semantics_ components together as we continue to build middleware tooling for a Decentralized Data Economy (DDE). On the next *Indy Semantics WG* call I want to bring some focus on the \"trust\" versus \"assurance\" naming issue in a bid to gain consensus from key stakeholders from the three ecosystems so that we can all jump the hurdle together and continue down the \"decentralized\" path with renewed confidence. In my granular breakdown during the call, I hope to shed some light on when best to use the two terms. If anyone is interested in this debate, please join us on Tuesday, May 12th at 10am-11.15pm PT / 1pm-2.15pm ET / 6pm-7.15pm GMT. This is less of a bun fight and more of a focussed discussion of _human interaction_ versus _system interaction_ within the model. Those are the kernels.","username":"pknowles","ts":"2020-05-02T08:00:04.089Z"}
{"msg":"Over the course of discussions with experts in the _Identity_ and _Consent_ communities before and during IIW, I believe that a clearer picture is starting to emerge on when the collective \"we\" should be using the word \"trust\" and when we should be using the word \"assurance\". The reason that this nuance is so important is that, having already knitted some key _Identity_ and _Semantics_ components together, The Human Colossus Foundation will now be shifting our focus to the _Consent_ piece by opening up discussions with the Open Consent Group as we start knitting _Identity_, _Consent_ and _Semantics_ components together as we continue to build middleware tooling for a Decentralized Data Economy (DDE). On the next *Indy Semantics WG* call I want to bring some focus on the \"trust\" versus \"assurance\" naming issue in a bid to gain consensus from key stakeholders from the three ecosystems so that we can all jump the hurdle together and continue down the \"decentralized\" path with renewed confidence. In my granular breakdown during the call, I hope to shed some light on when best to use the two terms. If anyone is interested in this debate, please join us on Tuesday, May 12th at 10am-11.15pm PT / 1pm-2.15pm ET / 6pm-7.15pm GMT. This is less of a bun fight and more of a focussed discussion of _human interaction_ versus _machine interaction_ within the model. Those are the kernels.","username":"pknowles","ts":"2020-05-02T08:00:04.089Z"}
{"msg":"Over the course of discussions with experts in the _Identity_ and _Consent_ communities before and during IIW, I believe that a clearer picture is starting to emerge on when the collective \"we\" should be using the word \"trust\" and when we should be using the word \"assurance\". The reason that this nuance is so important is that, having already knitted some key _Identity_ and _Semantics_ components together, The Human Colossus Foundation will now be shifting our focus to the _Consent_ piece by opening up discussions with the Open Consent Group as we start knitting _Identity_, _Consent_ and _Semantics_ components together as we continue to build open source middleware tooling for a Decentralized Data Economy (DDE). On the next *Indy Semantics WG* call I want to bring some focus on the \"trust\" versus \"assurance\" naming issue in a bid to gain consensus from key stakeholders from the three ecosystems so that we can all jump the hurdle together and continue down the \"decentralized\" path with renewed confidence. In my granular breakdown during the call, I hope to shed some light on when best to use the two terms. If anyone is interested in this debate, please join us on Tuesday, May 12th at 10am-11.15pm PT / 1pm-2.15pm ET / 6pm-7.15pm GMT. This is less of a bun fight and more of a focussed discussion of _human interaction_ versus _machine interaction_ within the model. Those are the kernels.","username":"pknowles","ts":"2020-05-02T08:00:04.089Z"}
{"msg":"Over the course of discussions with experts in the _Identity_ and _Consent_ communities before and during IIW, I believe that a clearer picture is starting to emerge on when the collective \"we\" should be using the word \"trust\" and when we should be using the word \"assurance\". The reason that this nuance is so important is that, having already knitted some key _Identity_ and _Semantics_ components together, The Human Colossus Foundation will now be shifting our focus to the _Consent_ piece by opening up discussions with the Open Consent Group as we start knitting _Identity_, _Consent_ and _Semantics_ components together as we continue to build open source middleware tooling for a Decentralized Data Economy (DDE). On the next *Indy Semantics WG* call I want to bring some focus on the \"trust\" versus \"assurance\" naming issue in a bid to gain consensus from key stakeholders from the three ecosystems so that we can all jump the hurdle together and continue down the \"decentralized\" path with renewed confidence. In my granular breakdown during the call, I hope to shed some light on when best to use the two terms. If anyone is interested in this debate, please join us on Tuesday, May 12th at 10am-11.15pm PT / 1pm-2.15pm ET / 6pm-7.15pm GMT. This will be less of a bun fight and more of a focussed discussion of _human interaction_ versus _machine interaction_ within the model. Those are the kernels here.","username":"pknowles","ts":"2020-05-02T08:00:04.089Z"}
{"msg":"Over the course of discussions with experts in the _Identity_ and _Consent_ communities before and during IIW, I believe that a clearer picture is starting to emerge on when the collective \"we\" should be using the word \"trust\" and when we should be using the word \"assurance\". The reason that this nuance is so important is that, having already knitted some key _Identity_ and _Semantics_ components together, The Human Colossus Foundation will now be shifting our focus to the _Consent_ piece by opening up discussions with the Open Consent Group as we start knitting _Identity_, _Consent_ and _Semantics_ components together as we continue to build open source middleware tooling for a Decentralized Data Economy (DDE).\n\nOn the next *Indy Semantics WG* call, I want to bring some focus on the \"trust\" versus \"assurance\" naming issue in a bid to gain consensus from key stakeholders from all three ecosystems so that we can all jump the hurdle together and continue down the \"decentralized\" path with renewed confidence. In my granular breakdown during the call, I hope to shed some light on when best to use the two terms.\n\nIf anyone is interested in this debate, please join us on *Tuesday, May 12th* at 10am-11.15pm PT / 1pm-2.15pm ET / 6pm-7.15pm GMT. This will be less of a bun fight and more of a focussed discussion of human interaction versus machine interaction within the model. Those are the kernels at play here.","username":"pknowles","ts":"2020-05-02T08:00:04.089Z"}
{"msg":"Over the course of discussions with experts in the _Identity_ and _Consent_ communities before and during IIW, I believe that a clearer picture is starting to emerge on when the collective \"we\" should be using the word \"trust\" and when we should be using the word \"assurance\". The reason that this nuance is so important is that, having already knitted some key _Identity_ and _Semantics_ components together, The Human Colossus Foundation will now be shifting our focus to the _Consent_ piece by opening up discussions with the Open Consent Group to start knitting _Identity_, _Consent_ and _Semantics_ components together as we continue to build open source middleware tooling for a Decentralized Data Economy (DDE).\n\nOn the next *Indy Semantics WG* call, I want to bring some focus on the \"trust\" versus \"assurance\" naming issue in a bid to gain consensus from key stakeholders from all three ecosystems so that we can all jump the hurdle together and continue down the \"decentralized\" path with renewed confidence. In my granular breakdown during the call, I hope to shed some light on when best to use the two terms.\n\nIf anyone is interested in this debate, please join us on *Tuesday, May 12th* at 10am-11.15pm PT / 1pm-2.15pm ET / 6pm-7.15pm GMT. This will be less of a bun fight and more of a focussed discussion of human interaction versus machine interaction within the model. Those are the kernels at play here.","username":"pknowles","ts":"2020-05-02T08:00:04.089Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 12th May, 2020\n\n10am-11.15pm PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: pknowles \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Discussion: Trust versus Assurance ( pknowles ) - 35 mins• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2020-05-12T15:31:33.848Z"}
{"msg":"Here is the agenda and dial-in information for today's *Indy Semantics WG* call. These calls provide an opportunity for Hyperledger Indy community members to discuss issues pertaining to the Semantics layer of the stack. Anyone is welcome to join the call.\n\nMeeting: Indy Semantics Working Group\nDate: Tuesday, 12th May, 2020\n\n10am-11.15pm PT\n11am-12.15pm MT\n12pm-1.15pm CT\n1pm-2.15pm ET\n6pm-7.15pm GMT\n7pm-8.15pm CET\n\nChair: @pknowles \n\nAgenda:\n• Introductions (Open) - 5 mins\n• Discussion: Trust versus Assurance ( @pknowles ) - 40 mins\n• Any other business (Open) - 5 mins\n\nWhere: Online\n\nJoin from PC, Mac, Linux, iOS or Android: https://zoom.us/j/2157245727\n\nOr iPhone one-tap : US: +16465588665,,2157245727# or +14086380986,,2157245727#\n\nOr by Telephone … https://zoom.us/zoomconference?m=a0jD_rTMnh0ZYGQDOKPCNrK_0dP7WPfp1\n\nMeeting ID : 2157245727","username":"pknowles","ts":"2020-05-12T15:31:33.848Z"}
{"msg":"Hi @pknowles, I am getting a request for password. I do not see it in the above invite.","username":"janl","ts":"2020-05-12T17:04:16.560Z"}
{"msg":"Me too.","username":"kenebert","ts":"2020-05-12T17:04:29.693Z"}
{"msg":"it must be a very easy too knowing Paul","username":"janl","ts":"2020-05-12T17:04:47.885Z"}
{"msg":"try 1234","username":"janl","ts":"2020-05-12T17:05:15.913Z"}
{"msg":"I read further up","username":"janl","ts":"2020-05-12T17:05:21.824Z"}
{"msg":"Paul  is having a lonely meeting by himself.","username":"kenebert","ts":"2020-05-12T17:05:31.758Z"}
{"msg":"Thanks for joining the meeting @kenebert and @janl . Can't believe you cracked the password. Talented chaps.","username":"pknowles","ts":"2020-05-12T19:41:41.614Z"}
{"msg":"Thanks for joining the meeting @kenebert and @janl. Can't believe you cracked the password. Talented chaps.","username":"pknowles","ts":"2020-05-12T19:41:41.614Z"}
{"msg":"Thanks for joining the meeting @kenebert and @janl . Can't believe you cracked the password. Talented chaps.","username":"pknowles","ts":"2020-05-12T19:41:41.614Z"}
{"msg":"Thanks for joining the call @kenebert and @janl . Can't believe you cracked the password. Talented chaps.","username":"pknowles","ts":"2020-05-12T19:41:41.614Z"}
{"msg":"Thanks for joining the call @kenebert and @janl . Can't believe you cracked the password. Talented chaps. :wink: ","username":"pknowles","ts":"2020-05-12T19:41:41.614Z"}
{"msg":"Thanks for dialling in @kenebert and @janl . Talented chaps. You cracked the password.  :wink: ","username":"pknowles","ts":"2020-05-12T19:41:41.614Z"}
{"msg":"My old Dativa email address is defunct and, with it, my access to the shared area. As soon as have write access again, I'll upload the agenda, video, notes, etc. to the usual place. Apologies in advance for the delay.","username":"pknowles","ts":"2020-05-12T19:52:40.654Z"}
{"msg":"The agenda, video, notes, etc. from Tuesday's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. The next meeting will be on Tuesday, May 26th. https://drive.google.com/drive/folders/1zkXr--0DG7I1k62vaFuotEzIaTIUH0ou","username":"pknowles","ts":"2020-05-14T10:08:30.177Z"}
{"msg":"@drummondreed :top: ","username":"pknowles","ts":"2020-05-14T10:24:27.053Z"}
{"msg":"Thanks Paul.","username":"drummondreed","ts":"2020-05-14T16:46:59.331Z"}
{"msg":"This is as granular as I think I can go regarding the Trust over IP dual-stack.\n\n_Human trust in digital systems = Social Cohesion + Cryptographic Assurance_\n\nIf anyone has any thoughts, I'm all ears.","username":"pknowles","ts":"2020-05-18T16:36:36.904Z"}
{"msg":"This is as granular as I think I can go regarding the Trust over IP dual-stack.\n\n_Human trust in digital systems = Social trustworthiness + Cryptographic assurance_\n\nIf anyone has any thoughts, I'm all ears.","username":"pknowles","ts":"2020-05-18T16:36:36.904Z"}
{"msg":"This is as granular as I think I can go regarding the Trust over IP dual-stack.\n\n_Human trust in digital systems = Social cohesion + Cryptographic assurance_\n\nIf anyone has any thoughts, I'm all ears.","username":"pknowles","ts":"2020-05-18T16:36:36.904Z"}
{"msg":"This is as granular as I think I can go regarding the Trust over IP dual-stack.\n\n_Digital trust = Human accountability + Cryptographic assurance_\n\nIf anyone has any thoughts, I'm all ears.","username":"pknowles","ts":"2020-05-18T16:36:36.904Z"}
{"msg":"NEWSFLASH: After nearly 18 months in existence, the *Hyperledger Indy Semantics WG* will be closing shop for good on *June 1st*. We are currently in the process of setting up a new *Decentralized Semantics WG* at the *Trust over IP Foundation*. The mission and scope of the new group will be to define a data capture architecture consisting of immutable schema bases and interoperable overlays for Internet-scale deployment. For more information, check out the new wiki page at https://wiki.trustoverip.org/pages/viewpage.action?pageId=65746 ","username":"pknowles","ts":"2020-05-26T06:19:32.421Z"}
{"msg":"Today's *Indy Semantics WG* call will be the final one!","username":"pknowles","ts":"2020-05-26T06:21:02.104Z"}
{"msg":"The slides and video from Today's *Indy Semantics WG* call have been uploaded to the following HL Indy shared area. https://drive.google.com/drive/folders/1DWZ97eBD4QpX_CWK2SxD_3Ed5KjIvCF8","username":"pknowles","ts":"2020-05-26T20:14:01.509Z"}
{"msg":"","username":"pknowles","ts":"2020-05-26T20:19:02.868Z","attachments":[{"type":"file","title":"Screenshot 2020-05-26 at 22.14.53.png","title_link":"/file-upload/xYDHi2KxSk7tBQtQv/Screenshot%202020-05-26%20at%2022.14.53.png","image_url":"/file-upload/xYDHi2KxSk7tBQtQv/Screenshot%202020-05-26%20at%2022.14.53.png","image_type":"image/png","image_size":191448,"url":"/file-upload/xYDHi2KxSk7tBQtQv/Screenshot%202020-05-26%20at%2022.14.53.png","remote":false,"fileId":"xYDHi2KxSk7tBQtQv","fileName":"Screenshot 2020-05-26 at 22.14.53.png"}]}
{"msg":"","username":"pknowles","ts":"2020-05-26T20:19:02.868Z","attachments":[{"type":"file","title":"Screenshot 2020-05-26 at 22.14.53.png","title_link":"/file-upload/xYDHi2KxSk7tBQtQv/Screenshot%202020-05-26%20at%2022.14.53.png","image_url":"/file-upload/xYDHi2KxSk7tBQtQv/Screenshot%202020-05-26%20at%2022.14.53.png","image_type":"image/png","image_size":191448,"url":"/file-upload/xYDHi2KxSk7tBQtQv/Screenshot%202020-05-26%20at%2022.14.53.png","remote":false,"fileId":"xYDHi2KxSk7tBQtQv","fileName":"Screenshot 2020-05-26 at 22.14.53.png"}]}
{"msg":"","username":"pknowles","ts":"2020-05-26T20:19:02.868Z","attachments":[{"type":"file","title":"Screenshot 2020-05-26 at 22.14.53.png","title_link":"/file-upload/xYDHi2KxSk7tBQtQv/Screenshot%202020-05-26%20at%2022.14.53.png","image_url":"/file-upload/xYDHi2KxSk7tBQtQv/Screenshot%202020-05-26%20at%2022.14.53.png","image_type":"image/png","image_size":191448,"url":"/file-upload/xYDHi2KxSk7tBQtQv/Screenshot%202020-05-26%20at%2022.14.53.png","remote":false,"fileId":"xYDHi2KxSk7tBQtQv","fileName":"Screenshot 2020-05-26 at 22.14.53.png"}]}
{"msg":"For more information, check out the new wiki page at https://wiki.trustoverip.org/pages/viewpage.action?pageId=65746","username":"pknowles","ts":"2020-05-26T20:19:52.743Z"}
{"msg":"For more information on the newly proposed *Decentralized Semantics WG* at the *Trust over IP Foundation*, check out the wiki page at https://wiki.trustoverip.org/pages/viewpage.action?pageId=65746","username":"pknowles","ts":"2020-05-26T20:19:52.743Z"}
{"msg":"If you are interested in being included in the kick-off plans for the newly proposed *Decentralized Semantics WG* at the *Trust over IP Foundation*, please add your name and email address to the following list. We will then add your name to the wiki and send a calendar invite to your email address. Please note that your email address will not be added to the wiki for privacy reasons.\n\nhttps://drive.google.com/file/d/1XiE4IzeVke-tm0oCHC_GsKp2JgGuXIkZ/view?usp=sharing","username":"pknowles","ts":"2020-05-27T05:19:11.897Z"}
{"msg":"@all FINAL NOTIFICATION: The *Hyperledger Indy Semantics WG* will be terminated on *Monday, June 1st*. A new *Decentralized Semantics WG* will be established at the *Trust over IP Foundation* in its place. The mission and scope of the new work group will be to define a data capture architecture consisting of immutable schema bases and interoperable overlays for Internet-scale deployment. For more information, check out the new wiki page at https://wiki.trustoverip.org/pages/viewpage.action?pageId=65746\n\nIf you are interested in being included in the kick-off plans for the new work group, please add your name and email address to the following distribution list. We will then add your name to the wiki and send a calendar invite to your email address. Please note that your email address will not be added to the wiki for privacy reasons. https://drive.google.com/file/d/1XiE4IzeVke-tm0oCHC_GsKp2JgGuXIkZ/view?usp=sharing","username":"pknowles","ts":"2020-05-29T09:59:51.076Z"}
{"msg":"Has left the channel.","username":"MALodder","ts":"2020-05-29T13:38:05.562Z","type":"ul"}
{"msg":"UPDATE: The newly proposed *Decentralized Semantics WG* at the *Trust over IP Foundation* will be reviewed by the *ToIP Steering Committee* on *Wednesday, June 10th*. To be kept in the loop, please add your name and email address to the following distribution list. We will then add your name to the wiki and send a calendar invite to your email address. Please note that your email address will not be added to the wiki for privacy reasons. https://drive.google.com/file/d/1XiE4IzeVke-tm0oCHC_GsKp2JgGuXIkZ/view?usp=sharing","username":"pknowles","ts":"2020-06-01T19:25:20.897Z"}
{"msg":"Has left the channel.","username":"swcurran","ts":"2020-06-01T19:38:59.096Z","type":"ul"}
{"msg":"Has left the channel.","username":"george.aristy","ts":"2020-06-02T19:23:29.915Z","type":"ul"}
{"msg":"Hi Team , I need to setup production level Indy node for my client. Could someone please provide me any reference . As i haven't set it up for Production before . Thanks","username":"SethiSaab","ts":"2020-06-04T12:41:45.830Z"}
{"msg":"Due to the transition to the Decentralized Semantics WG at the ToIP Foundation, should I remove the Tuesday meetings for Indy Semantics from the Hyperledger calendar?","username":"esplinr","ts":"2020-06-23T13:52:23.140Z"}
{"msg":"@pknowles ?","username":"esplinr","ts":"2020-06-23T13:58:04.842Z"}
{"msg":"Hi @esplinr - Yes, please remove the entry from the calendar. Thanks for reaching out.","username":"pknowles","ts":"2020-06-24T18:03:08.937Z"}
{"msg":"UPDATE: Apologies for the delay regarding news of the *Decentralized Semantics WG* at the *Trust over IP Foundation*. The WG has been formally approved. We are just awaiting sign off on the J_DF Working Group Charter_ and then we can get things moving. Thanks for your patience.","username":"pknowles","ts":"2020-06-24T18:15:50.063Z"}
{"msg":"UPDATE: Apologies for the delay regarding news of the *Decentralized Semantics WG* at the *Trust over IP Foundation*. The WG has been formally approved. We are just awaiting sign off on the _JDF Working Group Charter_ and then we can get things moving. Thanks for your patience.","username":"pknowles","ts":"2020-06-24T18:15:50.063Z"}
{"msg":"Hello everyone,\n\nI'm excited to announce that the *Decentralized Semantics Working Group* has now been formalized.\nWiki: https://wiki.trustoverip.org/display/HOME/Decentralized+Semantics+Working+Group\nMailing List: decentralized-semantics-wg@lists.trustoverip.org (please self-subscribe at https://lists.trustoverip.org/g/decentralized-semantics-wg)\nMeeting Series:  Weekly on Tuesday at 09:00 US PT, 12:00 US ET, 16:00 UTC (note:  once you self-subscribe to the list, you will be added to the calendar invite)\nIMPORTANT:  If you or your employer are existing Members of the Trust over IP Foundation, but have not yet signed the Decentralized Semantics Working Group Charter, you or your employer can sign here.  If you or your employer are not yet Members but are interested in joining the Trust over IP Foundation and this working group, please request a membership agreement at https://trustoverip.org/members/join/.\n\nFor the protection of all Members, participation in this Working Group is limited to members, including their employees, of the Trust over IP Foundation Decentralized Semantics Working Group, who have signed the membership documents and thus agreed to the intellectual property rules governing participation.  If you or your employer are not a member of the working group, we ask that you not participate in Working Group activities beyond observing.\n\nThe kickoff meeting will be on Tuesday, July 7th. I look forward to meeting many of you then.\n\nBest regards,\nPaul","username":"pknowles","ts":"2020-06-29T14:49:17.568Z"}
{"msg":"Hello everyone,\n\nI'm excited to announce that the *Decentralized Semantics Working Group* has now been formalized.\n\nWiki: https://wiki.trustoverip.org/display/HOME/Decentralized+Semantics+Working+Group\nMailing List: decentralized-semantics-wg@lists.trustoverip.org (please self-subscribe at https://lists.trustoverip.org/g/decentralized-semantics-wg)\nMeeting Series:  Weekly on Tuesday at 09:00 US PT, 12:00 US ET, 16:00 UTC (note:  once you self-subscribe to the list, you will be added to the calendar invite)\n\nIMPORTANT:  If you or your employer are existing Members of the Trust over IP Foundation, but have not yet signed the Decentralized Semantics Working Group Charter, you or your employer can sign here.  If you or your employer are not yet Members but are interested in joining the Trust over IP Foundation and this working group, please request a membership agreement at https://trustoverip.org/members/join/.\n\nFor the protection of all Members, participation in this Working Group is limited to members, including their employees, of the Trust over IP Foundation Decentralized Semantics Working Group, who have signed the membership documents and thus agreed to the intellectual property rules governing participation.  If you or your employer are not a member of the working group, we ask that you not participate in Working Group activities beyond observing.\n\nThe kickoff meeting will be on Tuesday, July 7th. I look forward to meeting many of you then.\n\nBest regards,\nPaul","username":"pknowles","ts":"2020-06-29T14:49:17.568Z"}
{"msg":"Hello everyone,\n\nI'm excited to announce that the *Decentralized Semantics Working Group* has now been formalized.\n\nWiki: https://wiki.trustoverip.org/display/HOME/Decentralized+Semantics+Working+Group\nMailing List: decentralized-semantics-wg@lists.trustoverip.org (please self-subscribe at https://lists.trustoverip.org/g/decentralized-semantics-wg)\nMeeting Series:  *Weekly on Tuesday at 09:00 US PT, 12:00 US ET, 16:00 UTC* (note:  once you self-subscribe to the list, you will be added to the calendar invite)\n\nIMPORTANT:  If you or your employer are existing Members of the Trust over IP Foundation, but have not yet signed the Decentralized Semantics Working Group Charter, you or your employer can sign here.  If you or your employer are not yet Members but are interested in joining the Trust over IP Foundation and this working group, please request a membership agreement at https://trustoverip.org/members/join/.\n\nFor the protection of all Members, participation in this Working Group is limited to members, including their employees, of the Trust over IP Foundation Decentralized Semantics Working Group, who have signed the membership documents and thus agreed to the intellectual property rules governing participation.  If you or your employer are not a member of the working group, we ask that you not participate in Working Group activities beyond observing.\n\nThe kickoff meeting will be on *Tuesday, July 7th*. I look forward to meeting many of you then.\n\nBest regards,\nPaul","username":"pknowles","ts":"2020-06-29T14:49:17.568Z"}
{"msg":"The mission statement for the *Decentralized Semantics WG* at Trust over IP is \"to define a data capture architecture consisting of immutable schema bases and interoperable overlays for Internet-scale deployment.\" As promised during last week's successful kickoff meeting, Robert and I have put together an Overlays Capture Architecture (*OCA*) presentation/live demo for today's WG call. We hope to see some of you then! Call time: 09:00 US PT, 12:00 US ET, 16:00 UTC.\n\nDSWG meeting page: https://wiki.trustoverip.org/display/HOME/DSWG+Meeting+Page","username":"pknowles","ts":"2020-07-14T09:53:54.748Z"}
{"msg":"The mission statement for the *Decentralized Semantics WG* at *Trust over IP* is \"to define a data capture architecture consisting of immutable schema bases and interoperable overlays for Internet-scale deployment.\" As promised during last week's successful kickoff meeting, Robert and I have put together an Overlays Capture Architecture (*OCA*) presentation/live demo for today's WG call. We hope to see some of you then! Call time: 09:00 US PT, 12:00 US ET, 16:00 UTC.\n\nDSWG meeting page: https://wiki.trustoverip.org/display/HOME/DSWG+Meeting+Page","username":"pknowles","ts":"2020-07-14T09:53:54.748Z"}
{"msg":"The main purpose of today's *Decentralized Semantics WG* meeting at *Trust over IP* is to allow the conveners of 3 proposed TFs (task forces) to present to the group: (i.) _Imaging TF_ (Conveners: Scott Whitmire/Moira Schieke); (ii.) _Medical Information TF_ (Conveners: Scott Whitmire/Moira Schieke); and (iii.) _Notice & Consent TF_ (Conveners: Mark Lizar/Salvatore D'Agostino). We look forward to seeing many of you then! Call time: 09:00 US PT, 12:00 US ET, 16:00 UTC.\n\nDSWG meeting page: https://wiki.trustoverip.org/display/HOME/DSWG+Meeting+Page","username":"pknowles","ts":"2020-07-21T10:45:55.248Z"}
{"msg":"Has joined the channel.","username":"Moshe7","ts":"2020-07-27T19:40:32.223Z","type":"uj"}
{"msg":"The main purpose of today's *Decentralized Semantics WG* meeting at *Trust over IP* is to allow @mtfk to give a tutorial on the _OCA Editor_ and _OCA Repository_. We look forward to seeing many of you then! Call time: 09:00 US PT, 12:00 US ET, 16:00 UTC.\n\nDSWG meeting page: https://wiki.trustoverip.org/display/HOME/DSWG+Meeting+Page","username":"pknowles","ts":"2020-07-28T14:42:01.512Z"}
{"msg":"The main purpose of today's *Decentralized Semantics WG* meeting at *Trust over IP* is to discuss _binary-to-text encoding objects_ (as defined on, for example, _Hyperledger Ursa_) and _Zero-knowledge proof_ (ZKP) functionality which OCA will need to support. We look forward to seeing many of you then! Call time: 09:00 US PT, 12:00 US ET, 16:00 UTC.\n\nDSWG meeting page: https://wiki.trustoverip.org/display/HOME/DSWG+Meeting+Page","username":"pknowles","ts":"2020-08-04T15:25:45.577Z"}
{"msg":"Has joined the channel.","username":"ankita.p17","ts":"2020-10-12T08:40:53.745Z","type":"uj"}
{"msg":"Has joined the channel.","username":"robdaa","ts":"2020-10-31T18:04:01.536Z","type":"uj"}
{"msg":"Greetings. Just saw the Overlays 101 ssimeetup presentation again. Great stuff and seeking to get involved. Thanks Paul and Robert!","username":"robdaa","ts":"2020-10-31T18:04:01.784Z"}
{"msg":"Thanks, @robdaa. We’ll be working on a revamped *Overlays Capture Architecture* (OCA) technical specification over the next few days which will be added as a new RFC on the Trust over IP GitHub repo. In the meantime, although in desperate need of lick of paint, *Aries RFC 0013: Overlays* is still the best technical resource out there presently. The *Semantics WG* at *Trust over IP* is the home for OCA pre-standards work. This is where you can keep up to date with all of the latest OCA developments. Those calls take place every Tuesday (11am MST / 6pm CET). For anyone interested in joining the ToIP Semantics WG as a contributing member, send an email to David Luchuk at dluchuk@contractor.linuxfoundation.org who will be able to help with the onboarding process. Feel free to namecheck me. It is free to join as an individual contributing member.\n\nhttps://wiki.trustoverip.org/display/HOME/Semantics+Working+Group","username":"pknowles","ts":"2020-10-31T18:46:33.630Z"}
{"msg":"Thanks, @robdaa. We’ll be working on a revamped *Overlays Capture Architecture* (OCA) technical specification over the next few days which will be added as a new RFC on the Trust over IP GitHub repo. In the meantime, although in desperate need of lick of paint, *Aries RFC 0013: Overlays* is still the best technical resource out there presently. The *Semantics WG* at *Trust over IP* is the home for OCA pre-standards work. This is where you can keep up to date with all of the latest OCA developments. Those calls take place every Tuesday (11am MST / 6pm CET). If you are interested in joining the ToIP Semantics WG as a contributing member, send an email to David Luchuk at dluchuk@contractor.linuxfoundation.org who will be able to help with the onboarding process. Feel free to namecheck me. It is free to join as an individual contributing member.\n\nhttps://wiki.trustoverip.org/display/HOME/Semantics+Working+Group","username":"pknowles","ts":"2020-10-31T18:46:33.630Z"}
{"msg":"Thanks, @robdaa . We’ll be working on a revamped *Overlays Capture Architecture* (OCA) technical specification over the next few days which will be added as a new RFC on the Trust over IP GitHub repo. In the meantime, although in desperate need of lick of paint, *Aries RFC 0013: Overlays* is still the best technical resource out there presently. The *Semantics WG* at *Trust over IP* is the home for OCA pre-standards work. This is where you can keep up to date with all of the latest OCA developments. Those calls take place every Tuesday (11am MST / 6pm CET). If you are interested in joining the ToIP Semantics WG as a contributing member, send an email to David Luchuk at dluchuk@contractor.linuxfoundation.org who will be able to help with the onboarding process. Feel free to namecheck me. It is free to join as an individual contributing member.\n\nhttps://wiki.trustoverip.org/display/HOME/Semantics+Working+Group","username":"pknowles","ts":"2020-10-31T18:46:33.630Z"}
{"msg":"Has joined the channel.","username":"mccown","ts":"2020-11-05T15:33:38.610Z","type":"uj"}
{"msg":"Has joined the channel.","username":"ioddo","ts":"2020-11-17T07:53:34.072Z","type":"uj"}
{"msg":"Has left the channel.","username":"windley","ts":"2021-01-17T22:33:48.179Z","type":"ul"}
{"msg":"Has joined the channel.","username":"ascatox","ts":"2021-03-15T11:01:19.959Z","type":"uj"}
{"msg":"Has left the channel.","username":"troyronda","ts":"2021-03-29T16:37:42.632Z","type":"ul"}
{"msg":"Has joined the channel.","username":"rjones","ts":"2022-02-12T22:02:57.659Z","type":"uj"}
{"msg":"[Please move to Discord](https://discord.com/channels/905194001349627914/905205711850594336)","username":"rjones","ts":"2022-02-12T22:02:58.300Z"}
{"msg":"[Please get an account on the Hyperledger discord](https://discord.gg), then [join Indy](https://discord.com/channels/905194001349627914/905205711850594336)","username":"rjones","ts":"2022-02-12T22:02:58.300Z"}
{"msg":"Has left the channel.","username":"rjones","ts":"2022-02-13T01:33:46.084Z","type":"ul"}
{"msg":"","username":"rjones","ts":"2022-03-23T17:26:52.359Z","type":"room_changed_topic"}
{"msg":"","username":"rjones","ts":"2022-03-23T17:26:52.368Z","type":"room_changed_description"}
{"msg":"","username":"rjones","ts":"2022-03-23T17:26:52.372Z","type":"room_changed_announcement"}
