{"msg":"User <em>User_1</em> added by <em>rjones</em>.","username":"rjones","ts":"2018-02-13T18:45:38.670Z","type":"au"}
{"msg":"User <em>User_1</em> removed by <em>rjones</em>.","username":"rjones","ts":"2018-02-13T18:45:48.901Z","type":"ru"}
{"msg":"User <em>User_2</em> added by <em>rjones</em>.","username":"rjones","ts":"2018-02-13T18:47:05.344Z","type":"au"}
{"msg":"Dan","username":"rjones","ts":"2018-02-13T18:47:15.145Z","type":"subscription-role-added"}
{"msg":"Dan","username":"rjones","ts":"2018-02-13T18:47:21.153Z","type":"user-unmuted"}
{"msg":"User <em>User_3</em> added by <em>rjones</em>.","username":"rjones","ts":"2018-02-13T18:47:51.584Z","type":"au"}
{"msg":"User <em>User_4</em> added by <em>rjones</em>.","username":"rjones","ts":"2018-02-13T18:47:57.625Z","type":"au"}
{"msg":"User <em>User_5</em> added by <em>rjones</em>.","username":"rjones","ts":"2018-02-13T18:48:03.122Z","type":"au"}
{"msg":"User <em>User_6</em> added by <em>rjones</em>.","username":"rjones","ts":"2018-02-13T18:48:09.369Z","type":"au"}
{"msg":"User <em>User_7</em> added by <em>rjones</em>.","username":"rjones","ts":"2018-02-13T18:48:15.407Z","type":"au"}
{"msg":"User <em>User_8</em> added by <em>rjones</em>.","username":"rjones","ts":"2018-02-13T18:48:22.630Z","type":"au"}
{"msg":"User <em>User_9</em> added by <em>rjones</em>.","username":"rjones","ts":"2018-02-13T18:48:28.558Z","type":"au"}
{"msg":"User <em>User_10</em> added by <em>rjones</em>.","username":"rjones","ts":"2018-02-13T18:48:35.019Z","type":"au"}
{"msg":"User <em>User_11</em> added by <em>rjones</em>.","username":"rjones","ts":"2018-02-13T18:48:42.725Z","type":"au"}
{"msg":"User <em>User_12</em> added by <em>rjones</em>.","username":"rjones","ts":"2018-02-13T18:48:48.857Z","type":"au"}
{"msg":"User <em>User_13</em> added by <em>rjones</em>.","username":"rjones","ts":"2018-02-13T18:48:54.669Z","type":"au"}
{"msg":"User <em>User_14</em> added by <em>rjones</em>.","username":"rjones","ts":"2018-02-13T18:49:00.267Z","type":"au"}
{"msg":"User <em>User_15</em> added by <em>rjones</em>.","username":"rjones","ts":"2018-02-13T18:49:05.690Z","type":"au"}
{"msg":"User <em>User_16</em> added by <em>rjones</em>.","username":"rjones","ts":"2018-02-13T18:49:11.521Z","type":"au"}
{"msg":"User <em>User_17</em> added by <em>rjones</em>.","username":"rjones","ts":"2018-02-13T18:49:18.211Z","type":"au"}
{"msg":"User <em>User_18</em> added by <em>rjones</em>.","username":"rjones","ts":"2018-02-13T18:49:26.201Z","type":"au"}
{"msg":"zac","username":"rjones","ts":"2018-02-13T18:49:35.856Z","type":"subscription-role-added"}
{"msg":"zac","username":"rjones","ts":"2018-02-13T18:49:36.988Z","type":"user-unmuted"}
{"msg":"pschwarz","username":"rjones","ts":"2018-02-13T18:49:41.509Z","type":"subscription-role-added"}
{"msg":"pschwarz","username":"rjones","ts":"2018-02-13T18:49:42.155Z","type":"user-unmuted"}
{"msg":"grkvlt","username":"rjones","ts":"2018-02-13T18:49:45.885Z","type":"subscription-role-added"}
{"msg":"grkvlt","username":"rjones","ts":"2018-02-13T18:49:46.386Z","type":"user-unmuted"}
{"msg":"dplumb","username":"rjones","ts":"2018-02-13T18:49:50.022Z","type":"subscription-role-added"}
{"msg":"dplumb","username":"rjones","ts":"2018-02-13T18:49:50.800Z","type":"user-unmuted"}
{"msg":"agunde","username":"rjones","ts":"2018-02-13T18:49:55.110Z","type":"subscription-role-added"}
{"msg":"agunde","username":"rjones","ts":"2018-02-13T18:49:55.790Z","type":"user-unmuted"}
{"msg":"amundson","username":"rjones","ts":"2018-02-13T18:50:00.025Z","type":"subscription-role-added"}
{"msg":"amundson","username":"rjones","ts":"2018-02-13T18:50:00.465Z","type":"user-unmuted"}
{"msg":"cianx","username":"rjones","ts":"2018-02-13T18:50:05.699Z","type":"subscription-role-added"}
{"msg":"cianx","username":"rjones","ts":"2018-02-13T18:50:07.776Z","type":"user-unmuted"}
{"msg":"TomBarnes","username":"rjones","ts":"2018-02-13T18:50:12.684Z","type":"subscription-role-added"}
{"msg":"TomBarnes","username":"rjones","ts":"2018-02-13T18:50:12.764Z","type":"user-unmuted"}
{"msg":"jsmitchell","username":"rjones","ts":"2018-02-13T18:50:28.443Z","type":"subscription-role-added"}
{"msg":"jsmitchell","username":"rjones","ts":"2018-02-13T18:50:28.999Z","type":"user-unmuted"}
{"msg":"drozd","username":"rjones","ts":"2018-02-13T18:50:32.675Z","type":"subscription-role-added"}
{"msg":"drozd","username":"rjones","ts":"2018-02-13T18:50:33.155Z","type":"user-unmuted"}
{"msg":"MicBowman","username":"rjones","ts":"2018-02-13T18:50:36.530Z","type":"subscription-role-added"}
{"msg":"MicBowman","username":"rjones","ts":"2018-02-13T18:50:37.001Z","type":"user-unmuted"}
{"msg":"RyanBanks","username":"rjones","ts":"2018-02-13T18:50:40.574Z","type":"subscription-role-added"}
{"msg":"RyanBanks","username":"rjones","ts":"2018-02-13T18:50:41.044Z","type":"user-unmuted"}
{"msg":"achenette","username":"rjones","ts":"2018-02-13T18:50:43.554Z","type":"subscription-role-added"}
{"msg":"achenette","username":"rjones","ts":"2018-02-13T18:50:44.042Z","type":"user-unmuted"}
{"msg":"adamludvik","username":"rjones","ts":"2018-02-13T18:50:46.981Z","type":"subscription-role-added"}
{"msg":"adamludvik","username":"rjones","ts":"2018-02-13T18:50:47.361Z","type":"user-unmuted"}
{"msg":"askmish","username":"rjones","ts":"2018-02-13T18:50:50.038Z","type":"subscription-role-added"}
{"msg":"askmish","username":"rjones","ts":"2018-02-13T18:50:50.368Z","type":"user-unmuted"}
{"msg":"boydjohnson","username":"rjones","ts":"2018-02-13T18:50:53.641Z","type":"user-unmuted"}
{"msg":"boydjohnson","username":"rjones","ts":"2018-02-13T18:50:55.539Z","type":"subscription-role-added"}
{"msg":"@Dan you are the channel owner, everyone else is a channel moderator, feel free to hand out ownership as you like. I _think_ moderators (which everyone else is) can invite an unmute people?","username":"rjones","ts":"2018-02-13T18:52:52.757Z"}
{"msg":"cool. Thanks!","username":"Dan","ts":"2018-02-13T18:53:36.652Z"}
{"msg":"To everyone else: you should be able to speak in here, anyone else that joins will be muted. I think when you unmute someone they may speak, but they may need to become a moderator. If you have any issues helpdesk@hyperledger.org :)","username":"rjones","ts":"2018-02-13T18:54:57.757Z"}
{"msg":"I'm not a huge fan of limiting who can talk, and if we have a very liberal policy about who can talk then the channel name isn't great.","username":"amundson","ts":"2018-02-13T18:59:54.390Z"}
{"msg":"that said, looking forward to more public discussions","username":"amundson","ts":"2018-02-13T19:00:19.011Z"}
{"msg":"@grkvlt, silas, and I were chatting in the seth channel about priorities for seth - would be good for everyone who has thoughts to dump some comments there.","username":"amundson","ts":"2018-02-13T19:05:27.650Z"}
{"msg":"@amundson the request was to set up an analog to the #fabric-maintainers channel.","username":"rjones","ts":"2018-02-13T19:09:57.332Z"}
{"msg":"yep. that's what I asked for. not to restrict discussion, of course, but to provide a channel where we can discuss forward progress on sawtooth separately from trouble shooting questions more commonly discussed on #sawtooth ","username":"Dan","ts":"2018-02-13T19:38:36.143Z"}
{"msg":"User <em>User_19</em> added by <em>Dan</em>.","username":"Dan","ts":"2018-02-13T19:40:07.080Z","type":"au"}
{"msg":"Room name changed to: <em>sawtooth-core-dev</em> by <em>Dan</em>","username":"Dan","ts":"2018-02-14T19:00:46.566Z","type":"r"}
{"msg":"changed name per amundson's comment. ","username":"Dan","ts":"2018-02-14T19:01:13.829Z"}
{"msg":"Sawtooth core development discussions","username":"Dan","ts":"2018-02-14T19:02:32.580Z","type":"room_changed_topic"}
{"msg":"#sawtooth tends to facilitate sawtooth troubleshooting and application development. this channel is focused on discussions germane to core developers.","username":"Dan","ts":"2018-02-14T19:03:42.073Z","type":"room_changed_description"}
{"msg":"#sawtooth tends to facilitate sawtooth troubleshooting and application development. this channel is focused on discussions internal implementation details.","username":"Dan","ts":"2018-02-14T19:04:45.990Z","type":"room_changed_description"}
{"msg":"We've added @grkvlt as a core contributor / seth maintainer!\n_merge button activated_","username":"Dan","ts":"2018-02-14T19:44:59.455Z"}
{"msg":"thanks guys, appreciate it - hope i can contribute some useful stuff!","username":"grkvlt","ts":"2018-02-14T19:46:11.605Z"}
{"msg":"thanks for the room rename @Dan ","username":"amundson","ts":"2018-02-14T19:52:40.004Z"}
{"msg":"Has joined the channel.","username":"ColinAlstad","ts":"2018-02-16T17:11:07.521Z","type":"uj"}
{"msg":"Has joined the channel.","username":"akeelnazir","ts":"2018-02-17T13:06:04.854Z","type":"uj"}
{"msg":"Has joined the channel.","username":"aczire","ts":"2018-02-20T20:06:24.140Z","type":"uj"}
{"msg":"Has left the channel.","username":"aczire","ts":"2018-02-20T20:07:03.506Z","type":"ul"}
{"msg":"Has joined the channel.","username":"tomislav","ts":"2018-02-20T23:09:11.294Z","type":"uj"}
{"msg":"Has joined the channel.","username":"vCloudernBeer","ts":"2018-02-21T02:06:24.130Z","type":"uj"}
{"msg":"I propose that we adopt an RFC process similar to the one used by Rust, documented here - https://github.com/rust-lang/rfcs","username":"amundson","ts":"2018-02-21T17:41:02.389Z"}
{"msg":"Unless there are objections, I'd like to create this repo while the hackfest is still going on and draft our rules (based off of those in the Rust README.md).","username":"amundson","ts":"2018-02-21T17:42:10.478Z"}
{"msg":"Has joined the channel.","username":"tkuhrt","ts":"2018-02-21T18:36:47.088Z","type":"uj"}
{"msg":"Has joined the channel.","username":"kdenhartog","ts":"2018-02-21T18:47:22.231Z","type":"uj"}
{"msg":"Has joined the channel.","username":"nage","ts":"2018-02-21T18:47:24.095Z","type":"uj"}
{"msg":"That sounds good to me","username":"pschwarz","ts":"2018-02-21T18:49:32.078Z"}
{"msg":"so, i just fixed an issue in the validator which I need to also fix in 1.0, so I made two pull requests, one against `master` and one against `1-0`, since there isn't really any change. is this the best way to do things?","username":"grkvlt","ts":"2018-02-21T19:33:29.225Z"}
{"msg":"i just fixed an issue in the validator which I need to also fix in 1.0, so I made two pull requests, one against `master` and one against `1-0`, since there isn't really any change. is this the best way to do things?","username":"grkvlt","ts":"2018-02-21T19:33:29.225Z"}
{"msg":"also, looks like my PRs aren't getting built any more? see https://github.com/hyperledger/sawtooth-core/pull/1461","username":"grkvlt","ts":"2018-02-21T19:46:08.425Z"}
{"msg":"e.g. https://build.sawtooth.me/job/Sawtooth-Hyperledger/job/sawtooth-core/job/fix%252Fget-block-txn-handler/1/console","username":"grkvlt","ts":"2018-02-21T19:47:02.657Z"}
{"msg":"but https://build.sawtooth.me/job/Sawtooth-Hyperledger/job/sawtooth-core/job/PR-1461/1/ is fine...","username":"grkvlt","ts":"2018-02-21T19:48:26.894Z"}
{"msg":"I see two issues: 1) git is hard for iterating on documents. 2) we also have jira as a source of record for features ","username":"Dan","ts":"2018-02-21T20:14:02.051Z"}
{"msg":"@grkvlt looks like that's building. maybe you manually kicked it off or someone else did?","username":"Dan","ts":"2018-02-21T20:16:30.374Z"}
{"msg":"There's multiple builds, the one that fails is `continuous-integration/jenkins/branch` but `continuous-integration/jenkins/pr-head` and `continuous-integration/jenkins/pr-merge` seem to work. Looks like Jenkins can't work out the GitHub user for the one that fails?","username":"grkvlt","ts":"2018-02-21T20:19:02.235Z"}
{"msg":"```[Pipeline] readTrusted\nObtained bin/whitelist from 2335d3aa64375ea9fe1d65334cef2984f13cd927\n[Pipeline] readTrusted\nObtained COMMITTERS from 2335d3aa64375ea9fe1d65334cef2984f13cd927\n[Pipeline] sh\n[jenkins-Sawtooth-Hyperledger-sawtooth-core-fix%2Fget-block-txn-handler-1] Running shell script\n+ ./bin/whitelist  COMMITTERS\nUSAGE: ./bin/whitelist [user] [whitelist]\n```","username":"grkvlt","ts":"2018-02-21T20:19:50.722Z"}
{"msg":"Jira is not great for collaborating on documents, either","username":"pschwarz","ts":"2018-02-21T21:00:11.432Z"}
{"msg":"User <em>User_20</em> added by <em>Dan</em>.","username":"Dan","ts":"2018-02-21T22:41:23.457Z","type":"au"}
{"msg":"@TreyZhong https://sawtooth.hyperledger.org/docs/core/releases/latest/app_developers_guide.html","username":"Dan","ts":"2018-02-21T22:42:12.846Z"}
{"msg":"Has joined the channel.","username":"TreyZhong","ts":"2018-02-21T22:42:13.073Z","type":"uj"}
{"msg":"@grkvlt looks like a jenkins or jenkinsfile issue we will have to dive into","username":"amundson","ts":"2018-02-21T23:17:56.950Z"}
{"msg":"@grkvlt as far as 1.0 backports, @Dan @pschwarz @agunde and I were just talking about backport strategy while at the hackfest","username":"amundson","ts":"2018-02-21T23:27:44.710Z"}
{"msg":"The general approach is going to bundle up the backports into a single PR, do a LR7 (long-running 7-day) test on it before merging it to 1-0. the idea is that then 1-0 is releasable at any given point.","username":"amundson","ts":"2018-02-21T23:28:49.567Z"}
{"msg":"@Dan and I are the release maintainers for 1.0 and we both need to approve backports","username":"amundson","ts":"2018-02-21T23:29:55.846Z"}
{"msg":"@pschwarz has a release of backports targeted for 1.0.2, and I assume he will add your fix to that","username":"amundson","ts":"2018-02-21T23:30:29.938Z"}
{"msg":"we will write this up / revise it going forward. we are trying to reconcile what we would normally do (just open PRs against both branches) with our desire for long-running testing.","username":"amundson","ts":"2018-02-21T23:31:17.108Z"}
{"msg":"we are targeting Monday as the cut-off for 1.0.2 backports","username":"amundson","ts":"2018-02-21T23:32:06.891Z"}
{"msg":"I looked more at the rfc link amundson posted. I see what he wants to do and where this fits wrt jira. I'm good with all that. I will be sad if we don't call them `slap`s but it will be easier for people to understand / find if they are called rfcs. ","username":"Dan","ts":"2018-02-21T23:47:27.398Z"}
{"msg":"ok, I'll request sawtooth-rfcs","username":"amundson","ts":"2018-02-22T00:00:44.569Z"}
{"msg":"@amundson understood re: 1.0 thanks, so i'll only merge the `master` version of that fix and leave PR 1462 for the 1.0.2 release","username":"grkvlt","ts":"2018-02-22T00:20:12.740Z"}
{"msg":"@grkvlt I will probably close it, since I will cherry pick the change from master - an earlier change will also be cherry picked that would cause a conflict","username":"pschwarz","ts":"2018-02-22T00:25:50.614Z"}
{"msg":"@pschwarz note that that will cause the error you picked up on (thanks for spotting it) since the thread pool object name changes from `thread_pool` to `client_thread_pool` in `master`","username":"grkvlt","ts":"2018-02-22T00:27:15.081Z"}
{"msg":"Right, that `client_thread_pool` will also be cherry picked","username":"pschwarz","ts":"2018-02-22T00:27:48.940Z"}
{"msg":"That's what I meant","username":"pschwarz","ts":"2018-02-22T00:28:00.082Z"}
{"msg":"+!","username":"grkvlt","ts":"2018-02-22T00:28:01.944Z"}
{"msg":"kelly_","username":"Dan","ts":"2018-02-22T01:34:44.067Z","type":"user-unmuted"}
{"msg":"silasdavis","username":"Dan","ts":"2018-02-22T02:02:27.103Z","type":"user-unmuted"}
{"msg":"Has joined the channel.","username":"Gabisan","ts":"2018-02-22T12:03:08.997Z","type":"uj"}
{"msg":"Guys, I'm thinking that the _Copyright 2017 Intel_ should maybe be _Copyright 2017-2018 the Hyperledger Foundation_ or not there at all? For example, my changes certainly aren't copyrighted by Intel...","username":"grkvlt","ts":"2018-02-22T15:17:35.536Z"}
{"msg":"@grkvlt There is no copyright assignment as far as I know; if you add substantial changes, it is probably appropriate to add an additional Copyright line at the top of the file. For example: https://github.com/Cargill/sawtooth-supply-chain/commit/36ed7da0647016bd6f98a6b643bccfd0b3c1a769#diff-8ec4e10999f55039260973f374ce05c3R1","username":"amundson","ts":"2018-02-22T17:08:11.035Z"}
{"msg":"@TomBarnes @Dan ^ any additional thoughs/feedback on copyright header approach?","username":"amundson","ts":"2018-02-22T17:20:51.116Z"}
{"msg":"Not sure - will have to seek guidance.","username":"TomBarnes","ts":"2018-02-22T17:26:31.225Z"}
{"msg":"@rjones who is the best person at Hyperledger to discuss things like copyright headers, etc.?","username":"amundson","ts":"2018-02-22T17:29:53.719Z"}
{"msg":"Mike Dolan, probably. It is a sticky issue. For instance, we took all date references out of our headers for AllSeen Alliance.","username":"rjones","ts":"2018-02-22T17:32:05.474Z"}
{"msg":"@amundson : escalate through Todd @tbenzies ","username":"rjones","ts":"2018-02-22T17:32:56.345Z"}
{"msg":"Has joined the channel.","username":"tbenzies","ts":"2018-02-22T17:32:56.743Z","type":"uj"}
{"msg":"ok, thanks. I assume we can look at other projects for reference too.","username":"amundson","ts":"2018-02-22T17:33:42.748Z"}
{"msg":"let's summarize anything we learn here, please so we all see it","username":"amundson","ts":"2018-02-22T17:34:09.643Z"}
{"msg":"Took a quick look at Fabric - files are marked \"Copyright IBM\" - so same model there.","username":"TomBarnes","ts":"2018-02-22T17:34:30.063Z"}
{"msg":"I'm not 100% on the way IP assignation works for Hyper ledger","username":"rjones","ts":"2018-02-22T17:34:30.270Z"}
{"msg":"More specifically \"Copyright IBM Corp. 2016 All Rights Reserved.\"","username":"TomBarnes","ts":"2018-02-22T17:35:21.198Z"}
{"msg":"If you have to add a specific copyright for every person that touches a file, I can't see that scaling.","username":"rjones","ts":"2018-02-22T17:35:23.893Z"}
{"msg":"I've seen \"Substantial changes\" as a rule in other non-hyperledger projects","username":"amundson","ts":"2018-02-22T17:35:59.874Z"}
{"msg":"Took a quick look at Apache Spark - no evidence of copyright claims there - just the Apache license.  https://github.com/apache/spark","username":"TomBarnes","ts":"2018-02-22T17:36:37.393Z"}
{"msg":"looks like @tbenzies is in this room and isn't muted","username":"amundson","ts":"2018-02-22T17:38:39.217Z"}
{"msg":"This is the guidance from the Apache foundation: http://www.apache.org/legal/src-headers.html#headers","username":"TomBarnes","ts":"2018-02-22T17:40:02.071Z"}
{"msg":"I'd go with tthis as @TomBarnes  suggests - it seems to work well in the Apache projects I contribute to. So we just remve copyright altogether, but keep Apache-2.0 license header?","username":"grkvlt","ts":"2018-02-22T18:19:03.606Z"}
{"msg":"Has joined the channel.","username":"kyogesh91","ts":"2018-02-22T20:29:00.981Z","type":"uj"}
{"msg":"if linux foundation doesn't have guidance then we should do the apache guidance. ","username":"Dan","ts":"2018-02-23T03:38:33.402Z"}
{"msg":"btw, I think we have an unwritten policy on merges.. need to get it written, but preference is for `rebase and merge` avoids merge commits cluttering history\nOther thing that hasn't made it to email yet is backports to 1.0 branch require normal +2 approval and approval from @amundson and @dan as 1.0 release maintainers. If you add any dependencies add @TomBarnes too. \nAt the hackfest we discussed using jenkins artifacts from the PR in an LR test to vet the changes - this seems like a good way to continue our 1.0 KPIs in point releases.","username":"Dan","ts":"2018-02-23T03:44:26.247Z"}
{"msg":"@agunde is the rust sdk versioned as 0.1.0 because it is incomplete and long term intent is to link version to sawtooth-core?","username":"Dan","ts":"2018-02-23T04:19:07.457Z"}
{"msg":"Good question. That version was put picked 7 months ago when the Rust SDK did not have transaction processor support. As we move closer to finalizing the API and doing other clean ups, the version should be updated. @amundson thoughts?","username":"agunde","ts":"2018-02-23T14:49:19.173Z"}
{"msg":"@grkvlt hi - to clarify, per the Apache guidelines, we remove the copyright from the individual files and move it to the NOTICE file.","username":"TomBarnes","ts":"2018-02-23T16:25:47.643Z"}
{"msg":"I took this discussion to #tsc https://chat.hyperledger.org/channel/tsc?msg=rT6r8wEehRRExxYmx","username":"Dan","ts":"2018-02-23T16:49:43.201Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/tsc?msg=rT6r8wEehRRExxYmx","url":"https://chat.hyperledger.org/channel/tsc?msg=rT6r8wEehRRExxYmx","remote":true,"fileId":null,"fileName":null}]}
{"msg":"I'm not sure Cargill will be on board with no copyright header, at least without some discussion","username":"amundson","ts":"2018-02-23T18:37:26.397Z"}
{"msg":"@agunde @Dan I would be comfortable versioning it with the same version as the rest of core, once we decide on _ vs. -","username":"amundson","ts":"2018-02-23T18:38:43.308Z"}
{"msg":"or no (_-)sdk","username":"amundson","ts":"2018-02-23T18:39:01.973Z"}
{"msg":"Has joined the channel.","username":"pmettu","ts":"2018-02-26T22:48:07.006Z","type":"uj"}
{"msg":"Has joined the channel.","username":"VikasJakhar","ts":"2018-02-27T20:05:16.952Z","type":"uj"}
{"msg":"idea for future development: a `seth-workload` cli tool similar to current `smallbank-workload` and also new intkey tool being proposed?","username":"grkvlt","ts":"2018-03-01T16:17:16.308Z"}
{"msg":"that makes sense to me","username":"amundson","ts":"2018-03-01T18:17:37.349Z"}
{"msg":"head on over to #sawtooth-ci for Jenkins/Build/CI discussion","username":"amundson","ts":"2018-03-01T23:22:35.724Z"}
{"msg":"Has joined the channel.","username":"formax","ts":"2018-03-02T23:17:15.928Z","type":"uj"}
{"msg":"Has joined the channel.","username":"cuevrob","ts":"2018-03-05T17:01:12.835Z","type":"uj"}
{"msg":"Has left the channel.","username":"rjones","ts":"2018-03-06T01:54:56.479Z","type":"ul"}
{"msg":"We are creating a Sawtooth RFC process, which will serve as a framework for design discussion.","username":"amundson","ts":"2018-03-06T16:07:38.615Z"}
{"msg":"I can't add any more reviewers to the PR (github has a 15 person limit)","username":"amundson","ts":"2018-03-06T16:07:58.018Z"}
{"msg":"however, everyone should review this PR which includes the process: https://github.com/hyperledger/sawtooth-rfcs/pull/3","username":"amundson","ts":"2018-03-06T16:08:16.322Z"}
{"msg":"Has joined the channel.","username":"mikezaccardo","ts":"2018-03-06T20:14:20.860Z","type":"uj"}
{"msg":"@Dan not sure if this question is for you... in the poet enclave code, how do you know that the incoming sealed data is really sealed data structure? are you assuming that the decryption will fail? The question is really about the validity of the conversion from uint_8* to sgx_sealed_data_t","username":"MicBowman","ts":"2018-03-07T17:56:32.986Z"}
{"msg":"Has joined the channel.","username":"vishwasbalakrishna","ts":"2018-03-07T21:35:02.315Z","type":"uj"}
{"msg":"Yeah I don't recall if my hands were in that or not, but that looks to be the case.. assume decryption will fail, and in case that was a bad assumption then do some sanity checks on what gets decrypted","username":"Dan","ts":"2018-03-08T14:23:29.465Z"}
{"msg":"this repo is now live - https://github.com/hyperledger/sawtooth-rfcs","username":"amundson","ts":"2018-03-08T18:27:40.878Z"}
{"msg":"I hope we enjoy the process more than we hate it. :)","username":"amundson","ts":"2018-03-08T18:28:10.730Z"}
{"msg":"thx, @amundson - it looks useful for managing features going forward. i'm assuming `core_changes.md` will be created with core sub-team specific notes, which can be copied and modified for e.g. seth, hyper directory, explorer, et al","username":"grkvlt","ts":"2018-03-08T19:06:41.659Z"}
{"msg":"yeah. for core, we will focus on things like API / protocol compatibility requrements, etc.","username":"amundson","ts":"2018-03-08T19:41:50.669Z"}
{"msg":"@amundson with respect to creating the hyperledger/sawtooth-sdk-go repo, do we want to keep the commit history from sawtooth-core by cloning, or start from fresh commits?","username":"adamludvik","ts":"2018-03-08T19:42:56.266Z"}
{"msg":"we should attempt to keep history to the extent possible","username":"amundson","ts":"2018-03-08T19:46:59.070Z"}
{"msg":"if we felt the repo is too big and wanted to purge, we could purge everything except the go sdk from the commit history","username":"amundson","ts":"2018-03-08T19:47:38.385Z"}
{"msg":"That is what I was thinking. Clone the repo and then do a purge commit to get it to a state similar to: https://github.com/rberg2/sawtooth-go-sdk","username":"adamludvik","ts":"2018-03-08T20:37:18.618Z"}
{"msg":"Has joined the channel.","username":"Gandalf","ts":"2018-03-09T03:53:36.444Z","type":"uj"}
{"msg":"so, using something like `git filter-branch --tree-filter \"find . -not -path './sdk/go'\"` to remove history?","username":"grkvlt","ts":"2018-03-09T18:46:48.157Z"}
{"msg":"so, using something like `git filter-branch --tree-filter \"find . -not -path './sdk/go'\"` to remove unwanted history?","username":"grkvlt","ts":"2018-03-09T18:46:48.157Z"}
{"msg":"It will be similar to what we did with seth. I think I did it manually, but an automated option would be fine. This would be a one time thing and then the new repo would track new history from that point on.","username":"adamludvik","ts":"2018-03-12T14:09:55.269Z"}
{"msg":"Has joined the channel.","username":"smgulley","ts":"2018-03-12T14:30:11.270Z","type":"uj"}
{"msg":"Has joined the channel.","username":"rjones","ts":"2018-03-13T17:07:27.599Z","type":"uj"}
{"msg":"https://github.com/hyperledger/sawtooth-hyper-directory/network/dependencies @dan @rbuysse @rberg2 @amundson ","username":"rjones","ts":"2018-03-13T17:08:45.407Z"}
{"msg":"https://github.com/hyperledger/sawtooth-hyper-directory/network/dependencies @Dan @rbuysse @rberg2 @amundson ","username":"rjones","ts":"2018-03-13T17:08:45.407Z"}
{"msg":"Has joined the channel.","username":"rbuysse","ts":"2018-03-13T17:08:45.505Z","type":"uj"}
{"msg":"Has joined the channel.","username":"rberg2","ts":"2018-03-13T17:08:45.536Z","type":"uj"}
{"msg":"That code was contributed by Chris Spanton.  Does anyone know if he is on Rocket Chat? @cianx @boydjohnson @dplumb?","username":"amundson","ts":"2018-03-14T17:28:02.080Z"}
{"msg":"I haven't seen him on rocket chat?","username":"boydjohnson","ts":"2018-03-14T17:28:28.194Z"}
{"msg":"I haven't seen him on rocket chat.","username":"boydjohnson","ts":"2018-03-14T17:28:28.194Z"}
{"msg":"Has left the channel.","username":"rjones","ts":"2018-03-14T18:27:54.050Z","type":"ul"}
{"msg":"First Cargill contribution made it to a PR - https://github.com/hyperledger/sawtooth-supply-chain/pull/40","username":"amundson","ts":"2018-03-14T21:05:39.257Z"}
{"msg":"Awesome!\n_(there's a typo in the PR message you should fix though @amundson)_ :-D","username":"Dan","ts":"2018-03-14T21:41:52.528Z"}
{"msg":"heh","username":"amundson","ts":"2018-03-14T21:42:33.444Z"}
{"msg":"@amundson do you know why the python ecdsa library was dropped?","username":"MicBowman","ts":"2018-03-14T21:53:27.415Z"}
{"msg":"was it a licensing issue?","username":"MicBowman","ts":"2018-03-14T21:53:39.159Z"}
{"msg":"(it appears to be MIT)","username":"MicBowman","ts":"2018-03-14T21:53:45.534Z"}
{"msg":"check with @TomBarnes. I think it might have been a whitelisting issue.","username":"Dan","ts":"2018-03-14T21:56:47.515Z"}
{"msg":"ok... it looks like its MIT license","username":"MicBowman","ts":"2018-03-14T21:57:40.756Z"}
{"msg":"we are trying to make a lightweight client for 17.10... and secp256 doesn't compile with python 3.6","username":"MicBowman","ts":"2018-03-14T21:58:35.075Z"}
{"msg":"I didn't know about the secp256/python 3.6 issue, we will have to investigate that","username":"amundson","ts":"2018-03-14T23:12:27.185Z"}
{"msg":"just became aware there's an infrastructure channel: https://chat.hyperledger.org/channel/infra-support","username":"Dan","ts":"2018-03-15T14:13:33.775Z"}
{"msg":"I'm considering writing up an RFC for adding partial validation compatibility - basically storing sub-tree merkle hashes in the block so that a portion of the tree can be verified independently using only transactions which modify that part of the tree. @Dan - we could use this for validator registry, so it can be validated early in consensus checks without processing all other transactions","username":"amundson","ts":"2018-03-15T15:05:15.095Z"}
{"msg":"Not sure I understand that. The issue that poet runs into is that a registration isn't committed before nodes want to start publishing.","username":"Dan","ts":"2018-03-15T20:21:03.536Z"}
{"msg":"@amundson can you clarify your feedback on https://github.com/hyperledger/sawtooth-core/pull/1501?","username":"Dan","ts":"2018-03-15T20:21:28.749Z"}
{"msg":"Has joined the channel.","username":"rjones","ts":"2018-03-16T23:24:28.171Z","type":"uj"}
{"msg":"I realize in advance that this is the wrong forum. Could whoever is in control of https://github.com/sawtooth-build account please accept the invites it has pending? it would make my life easier.","username":"rjones","ts":"2018-03-16T23:25:25.092Z"}
{"msg":"I think the owner needs to visit https://github.com/hyperledger/ when authenticated as that user to see the invites.","username":"rjones","ts":"2018-03-16T23:27:54.302Z"}
{"msg":"Has joined the channel.","username":"amolk","ts":"2018-03-17T04:14:22.505Z","type":"uj"}
{"msg":"Has joined the channel.","username":"pankajgoyal","ts":"2018-03-17T05:11:32.094Z","type":"uj"}
{"msg":"@pankajgoyal you may need to rebase your PR 1501 and re-push it. Build is failing probably due to some changes in go.","username":"Dan","ts":"2018-03-19T15:56:43.033Z"}
{"msg":"Has joined the channel.","username":"matthewehoward","ts":"2018-03-19T18:12:51.052Z","type":"uj"}
{"msg":"@adamludvik @askmish regarding https://jira.hyperledger.org/browse/STL-1113, the poet fork resolver seemed to have a contract with the BlockValidator that it would never be asked to look at a non-poet block. However the BlockValidator relies on the current chain's consensus for resolving forks without regard to what consensus the candidate block may have used. The exact assignment of which consensus is current seems to have evolved around 4-5 months ago. Where I left off was this commit that indicates no changes were made other than splitting the class into its own file. https://github.com/hyperledger/sawtooth-core/commit/c07b4645ce63b994c3d1528f55f9e5c64b849f2e. To resolve the bug it would be great to get the logs @pschwarz and probably to decide on the contract between consensus and block validator @adamludvik & @askmish. ","username":"Dan","ts":"2018-03-20T03:23:20.543Z"}
{"msg":"@pankajgoyal #1501 is blocking release 1.0.2. Kindly prioritize the rebase please.","username":"Dan","ts":"2018-03-20T14:21:43.555Z"}
{"msg":"@pankajgoyal thanks for the rebase. I've prodded jenkins to rebuild the PR. It built cleanly now and I have merged #1501  @pschwarz .","username":"Dan","ts":"2018-03-20T18:43:52.214Z"}
{"msg":"Create a back port PR for it","username":"pschwarz","ts":"2018-03-20T18:44:50.589Z"}
{"msg":"https://github.com/hyperledger/sawtooth-core/pull/1531 ","username":"Dan","ts":"2018-03-20T19:17:36.115Z"}
{"msg":"@TomBarnes ^","username":"Dan","ts":"2018-03-20T19:17:41.299Z"}
{"msg":"@Dan I don't know if you've noticed, but you can create and add groups to reviews. It's pretty nice.","username":"rjones","ts":"2018-03-20T19:19:27.325Z"}
{"msg":"tell me more!","username":"Dan","ts":"2018-03-20T19:20:34.035Z"}
{"msg":"I think you have permissions to make subgroups of: https://github.com/orgs/hyperledger/teams/sawtooth-core-contributors and then you can add the group in the review area","username":"rjones","ts":"2018-03-20T19:20:56.184Z"}
{"msg":"","username":"rjones","ts":"2018-03-20T19:21:31.006Z","attachments":[{"type":"file","title":"sawtooth.png","title_link":"/file-upload/3buZPnWRvmaew83BE/sawtooth.png","image_url":"/file-upload/3buZPnWRvmaew83BE/sawtooth.png","image_type":"image/png","image_size":50032,"url":"/file-upload/3buZPnWRvmaew83BE/sawtooth.png","remote":false,"fileId":"3buZPnWRvmaew83BE","fileName":"sawtooth.png"}]}
{"msg":"you can add any of those groups - some of which are probably a little broad :)","username":"rjones","ts":"2018-03-20T19:21:45.776Z"}
{"msg":"if I'm wrong, and you can't make a sub team, tell me what ones you want and I'll add them and make you a maintainer. Then you can add what accounts you like","username":"rjones","ts":"2018-03-20T19:23:46.105Z"}
{"msg":"if you go here: https://github.com/orgs/hyperledger/teams/sawtooth-core-contributors/teams are you able to add a team?","username":"rjones","ts":"2018-03-20T19:24:17.476Z"}
{"msg":"heh my question is answered :)","username":"rjones","ts":"2018-03-20T19:26:04.721Z"}
{"msg":"Cool. Yes I could create a team. I will use this for great evil. >:D","username":"Dan","ts":"2018-03-20T19:26:04.842Z"}
{"msg":"mazel tov!","username":"rjones","ts":"2018-03-20T19:26:10.275Z"}
{"msg":"with great powers come varying degrees of responsibilities ;)","username":"rjones","ts":"2018-03-20T19:26:32.822Z"}
{"msg":"also... who owns https://github.com/sawtooth-build ? is it in use? could you talk them into accepting my invites? they have alike a dozen outstanding","username":"rjones","ts":"2018-03-20T19:27:59.932Z"}
{"msg":"I don't know who that is. Could have been something one of us did a long time ago? I have no recollection ... :beers: :cocktail: ... of many things.","username":"Dan","ts":"2018-03-20T19:34:10.577Z"}
{"msg":"I'll remove it and see if anyone complains","username":"rjones","ts":"2018-03-20T19:35:50.281Z"}
{"msg":"from the 'if it was really important then i wouldn't be able to delete it in the first place' school of devops...","username":"grkvlt","ts":"2018-03-20T19:49:28.279Z"}
{"msg":"@grkvlt I set it to `read` access from `write` access. If nobody complains in a few weeks, I'll remove it","username":"rjones","ts":"2018-03-20T19:55:05.783Z"}
{"msg":"@ryanbeck ^ just in case sawtooth-build is something you know about","username":"Dan","ts":"2018-03-20T20:04:00.529Z"}
{"msg":"Has joined the channel.","username":"ryanbeck","ts":"2018-03-20T20:04:00.648Z","type":"uj"}
{"msg":"Has joined the channel.","username":"ShikarSharma","ts":"2018-03-20T22:56:18.472Z","type":"uj"}
{"msg":"Has left the channel.","username":"rbuysse","ts":"2018-03-21T17:14:04.801Z","type":"ul"}
{"msg":"Has joined the channel.","username":"rbuysse","ts":"2018-03-21T17:14:11.966Z","type":"uj"}
{"msg":"@amundson @pschwarz @jsmitchell Have you seen this? https://blog.ethereum.org/2015/06/26/state-tree-pruning/","username":"adamludvik","ts":"2018-03-21T17:39:07.368Z"}
{"msg":"Has left the channel.","username":"rbuysse","ts":"2018-03-21T18:03:13.434Z","type":"ul"}
{"msg":"Has joined the channel.","username":"rbuysse","ts":"2018-03-21T18:03:31.599Z","type":"uj"}
{"msg":"@adamludvik quite similar to our discussions","username":"amundson","ts":"2018-03-21T18:20:14.021Z"}
{"msg":"That look interesting, will give it a read","username":"pschwarz","ts":"2018-03-21T18:25:49.039Z"}
{"msg":"rbuysse","username":"Dan","ts":"2018-03-21T18:31:43.338Z","type":"subscription-role-added"}
{"msg":"Has left the channel.","username":"rbuysse","ts":"2018-03-21T18:33:41.961Z","type":"ul"}
{"msg":"Has joined the channel.","username":"rbuysse","ts":"2018-03-21T18:33:52.488Z","type":"uj"}
{"msg":"Does everyone agree that in order to do run-time state-pruning correctly, there needs to be some form of reference counting at each node in the merkle tree? The model described in that ethereum blog post uses reference counting and drops state after some number of blocks.","username":"adamludvik","ts":"2018-03-21T18:41:46.924Z"}
{"msg":"@MicBowman did you have some state pruning logic around the v0.4 timeframe?","username":"Dan","ts":"2018-03-21T18:46:53.988Z"}
{"msg":"Has joined the channel.","username":"rnagler","ts":"2018-03-21T19:12:45.641Z","type":"uj"}
{"msg":"@dan sorry for the slow response... yes","username":"MicBowman","ts":"2018-03-21T23:38:45.774Z"}
{"msg":"or at least state compression","username":"MicBowman","ts":"2018-03-21T23:38:59.517Z"}
{"msg":"@MicBowman can you elaborate on compression vs. pruning?","username":"amundson","ts":"2018-03-22T00:18:04.255Z"}
{"msg":"Has left the channel.","username":"rjones","ts":"2018-03-22T19:04:20.022Z","type":"ul"}
{"msg":"The Sawtooth Governance Model RFC has entered the final comment period and can be found here: https://github.com/hyperledger/sawtooth-rfcs/pull/6. @amundson @pschwarz @Dan @agunde @jsmitchell please confirm your approval of the RFC. Once the RFC is merged, we can create the initial sub teams.","username":"adamludvik","ts":"2018-03-22T20:19:38.904Z"}
{"msg":"or maybe most of you already did...","username":"adamludvik","ts":"2018-03-22T20:19:54.700Z"}
{"msg":"@adamludvik I'd like to see broader representation on the product/user, compliance, and research side in terms of core team","username":"kelly_","ts":"2018-03-22T23:18:24.102Z"}
{"msg":"I for one have contributed no code, but the verbiage says \"The root team includes stakeholders who are actively involved in the Sawtooth\ncommunity and have expertise within the project.\"","username":"kelly_","ts":"2018-03-22T23:19:09.985Z"}
{"msg":"I think @TomBarnes would be another valuable add as well","username":"kelly_","ts":"2018-03-22T23:19:29.526Z"}
{"msg":"\"Steering the project toward specific use cases where Sawtooth can have a major impact\"","username":"kelly_","ts":"2018-03-22T23:20:31.145Z"}
{"msg":"wrt my role with Sawtooth I think that I could be useful here, and bringing a customer/ecosystem perspective","username":"kelly_","ts":"2018-03-22T23:21:05.561Z"}
{"msg":"will add comments to the Github","username":"kelly_","ts":"2018-03-22T23:22:12.876Z"}
{"msg":"I think the core team would be better served by having a balanced representation of key stakeholders.  I would like to suggest that we revise it include Shawn, James, and Peter from Bitwise, and Dan, Tom, and Kelly from Intel.","username":"TomBarnes","ts":"2018-03-22T23:23:21.625Z"}
{"msg":"I also think the initial core sub-team membership should be documented as either part of the governance PR, or one immediately following, so that it is clearly articulated to ourselves and the community.","username":"TomBarnes","ts":"2018-03-22T23:24:52.831Z"}
{"msg":"apologize if I am late in commenting, this was my first time seeing this document","username":"kelly_","ts":"2018-03-22T23:27:24.859Z"}
{"msg":"I apologize for not raising this concern in yesterdays discussion  - I did express concern about technical merit being the sole determinant for inclusion in teams, but was unable to more clearly articulate it.","username":"TomBarnes","ts":"2018-03-22T23:29:14.784Z"}
{"msg":"@kelly_ sorry for the confusion. seems like we have more discussions to have. the intent was sub-teams largely do the voting on RFCs, with a broad involvement there (including all the examples you gave, localized to those sub-teams). root team was picked from developers involved in the current code base's construction and had a lead role in architecture/design and day-to-day development. for an open source project, those seemed like fair criteria for initial selection. the bar was set very high, and it thus excludes a fair number of developers that work on Sawtooth every day.","username":"amundson","ts":"2018-03-23T00:50:24.981Z"}
{"msg":"yep understood @amundson. i'd still like to be considered for the high level team, I haven't seen the sub teams yet so will look into that","username":"kelly_","ts":"2018-03-23T01:12:59.304Z"}
{"msg":"oops @amundson ","username":"kelly_","ts":"2018-03-23T01:13:05.565Z"}
{"msg":"w.r.t open source project i think it's fair to consider non-development because there is a lot more involved than just the development piece, e.g. evangelism, customer engagement, funding, etc.","username":"kelly_","ts":"2018-03-23T01:13:48.247Z"}
{"msg":"also understand that there are some regular developers that have been excluded","username":"kelly_","ts":"2018-03-23T01:14:31.223Z"}
{"msg":"I think @TomBarnes makes a valid point with it being 'represented by key stakeholders'","username":"kelly_","ts":"2018-03-23T01:15:15.347Z"}
{"msg":"also ideally would liek to the core maintainers to expand beyond intel and bitwise, and think folks like @grkvlt are on that path","username":"kelly_","ts":"2018-03-23T01:15:40.850Z"}
{"msg":"Seems that this is like the PMC in an Apache project? as opposed to the people who have a commit bit...","username":"grkvlt","ts":"2018-03-23T01:16:05.469Z"}
{"msg":"@grkvlt yep, that is similar to what i was thinking","username":"kelly_","ts":"2018-03-23T01:17:01.176Z"}
{"msg":"And PMC is a strict subset of Committers, normally","username":"grkvlt","ts":"2018-03-23T01:17:16.850Z"}
{"msg":"OK","username":"grkvlt","ts":"2018-03-23T01:17:32.225Z"}
{"msg":"oh, that was not my understanding","username":"kelly_","ts":"2018-03-23T01:20:07.528Z"}
{"msg":"in fact the opposite","username":"kelly_","ts":"2018-03-23T01:20:11.158Z"}
{"msg":"The role of the PMC from a Foundation perspective is oversight. The main role of the PMC is not code and not coding - but to ensure that all legal issues are addressed, that procedure is followed, and that each and every release is the product of the community as a whole. That is key to our litigation protection mechanisms.","username":"kelly_","ts":"2018-03-23T01:20:24.934Z"}
{"msg":"so that is probably a little to 'legal' oriented","username":"kelly_","ts":"2018-03-23T01:20:32.930Z"}
{"msg":"too*","username":"kelly_","ts":"2018-03-23T01:20:52.270Z"}
{"msg":"So I was thinking  more about the role, vs the selection criteria","username":"kelly_","ts":"2018-03-23T01:23:05.436Z"}
{"msg":"TBH, in Apache that's the way it is as well, practically speaking. The fact that PMC members have commit rights means they either founded the project or used to be an active developer, they may no longer be writing code but they still are active managing the project","username":"grkvlt","ts":"2018-03-23T01:23:54.477Z"}
{"msg":"yep exactly","username":"kelly_","ts":"2018-03-23T01:24:12.833Z"}
{"msg":"Of course if PMC members want to write code too, that's even better!","username":"grkvlt","ts":"2018-03-23T01:25:27.184Z"}
{"msg":"Yea, I mean to be fully transparent, I have an issue with not having a voice on setting the direction and values of the project. I've been instrumental in the founding of Hyperledger, getting Sawtooth brought into it, obtaining funding for the majority of Sawtooth development (which has been done both internally and externally), bringing users and developers into the project, and evangelizing for it. I'd like to also think I've had some influence into the technical direction in the beginning of the project, and at a minimum helping to drive requirements and technical direction","username":"kelly_","ts":"2018-03-23T01:28:47.681Z"}
{"msg":"So I recognize that this is open source and code counts, but I think it's a bit myopic to only give those directly writing code a say","username":"kelly_","ts":"2018-03-23T01:29:52.307Z"}
{"msg":"at the highest level I would say clearly Intel and Bitwise have the most invested in the development of Sawtooth and I'd like to continue to see more equitable 'joint-ownership' if you will","username":"kelly_","ts":"2018-03-23T01:31:49.703Z"}
{"msg":"My off the cuff thought on maintainers is that the split between 'product' and 'developer' should be relative to the needs of what they are maintaing","username":"kelly_","ts":"2018-03-23T01:34:58.531Z"}
{"msg":"so a community outreach subteam may have 1 developer and 5 evangelists","username":"kelly_","ts":"2018-03-23T01:35:14.435Z"}
{"msg":"where sawtooth core team may be 4 developers and 2 product people","username":"kelly_","ts":"2018-03-23T01:35:26.559Z"}
{"msg":"and I think the overall Sawtooth project likely needs to include (at some point), developers, architects, product, marketing/design, and compliance/legal","username":"kelly_","ts":"2018-03-23T01:36:35.942Z"}
{"msg":"One thing that worries (?) me a little bit about this RFC and governance model is that it seems to be Sawtooth specific, in that it had to be created from an existing Rust project document. I'd have thought that the Hyperledger Foundation itself would have provided the model and structure for the projects it incubates. So, Fabric, Sawtooth, Iroha, whatever, all have the same structure and policies. This is based on my experience as a PMC member and committer at multiple ASF projects, where Apache provides a lot of structure and guidance. Not sure about CNCF, they may be more free-form, like Hyperledger.","username":"grkvlt","ts":"2018-03-23T01:38:08.696Z"}
{"msg":"One thing that worries (?) me a little bit about this RFC and governance model is that it seems to be Sawtooth specific, in that it had to be created from an existing Rust project document. I'd have thought that the Hyperledger Foundation itself would have provided the model and structure for the projects it incubates. So, should Fabric, Sawtooth, Iroha, whatever, not all have the same structure and policies.?This is based on my experience as a PMC member and committer at multiple ASF projects, where Apache provides a lot of structure and guidance. Not sure about CNCF, they may be more free-form, like Hyperledger.","username":"grkvlt","ts":"2018-03-23T01:38:08.696Z"}
{"msg":"there is some overall LF governance","username":"kelly_","ts":"2018-03-23T01:38:34.673Z"}
{"msg":"but it doesnt discuss project specifics (e.g. +2 for a merge)","username":"kelly_","ts":"2018-03-23T01:38:51.447Z"}
{"msg":"Maybe there should be foundation wide standards, and the Sawtooth decisions could become the template, then?","username":"grkvlt","ts":"2018-03-23T01:40:01.279Z"}
{"msg":"this is about the extent i've seen from Fabric - https://hyperledger-fabric.readthedocs.io/en/release-1.1/CONTRIBUTING.html#maintainers","username":"kelly_","ts":"2018-03-23T01:41:31.268Z"}
{"msg":"which does differ from the proposed RFC","username":"kelly_","ts":"2018-03-23T01:42:07.268Z"}
{"msg":"e.g. majority rule for adding a maintainer vs unanimous","username":"kelly_","ts":"2018-03-23T01:42:15.525Z"}
{"msg":"Yeah, I prefer the Apache model which is that a proposal passes if there is at least one PMC +1 vote and no -1 votes.","username":"grkvlt","ts":"2018-03-23T01:46:02.192Z"}
{"msg":"Since the PMC will have members who may not be able to give a binding +1 due to insufficient knowledge in the specific area, so unanimous agreement is not always possible","username":"grkvlt","ts":"2018-03-23T01:47:31.758Z"}
{"msg":"Especially true if the PMC is made up of non-active developers, like you propose, which I think is the right decision","username":"grkvlt","ts":"2018-03-23T01:48:21.890Z"}
{"msg":"@grkvlt you clearly have a lot of experience on this, any feedback on the RFC would be appreciated","username":"kelly_","ts":"2018-03-23T01:50:56.825Z"}
{"msg":"@amundson let's chat tomorrow, i'm about to head out for dinner","username":"kelly_","ts":"2018-03-23T01:51:22.600Z"}
{"msg":"I added some comments to the PR. In particular I think the sub-teams should be project based, for things that have a deliverable artifact like Seth or the Go SDK, not cross-cutting concerns like CI or release management, and also that the reviewer/committer/maintainer split is too complex, and could be replaced with maintainer only.This is basically the way ASF PMCs and permissions work, which is what I'm familiar with... ","username":"grkvlt","ts":"2018-03-23T14:03:23.466Z"}
{"msg":"@grkvlt I don't think defining this cross-project at the HL level would be productive, though other projects have and are welcome to follow our lead.","username":"amundson","ts":"2018-03-23T14:04:12.247Z"}
{"msg":"sure, i think get it working right with sawtooth before suggesting it as the one true Hyperledger way ;)","username":"grkvlt","ts":"2018-03-23T14:04:54.539Z"}
{"msg":"I think it is important to consider that the projects all have different people and operate in very different ways currently. As a HL whole we couldn't even all agree to use github; and that's fine, as long as we allow projects to do what works for them (and not against them).","username":"amundson","ts":"2018-03-23T14:08:22.194Z"}
{"msg":"The reason we have sub-teams as we do in that list of examples is very intentionally not at the repository level. As one project, we need to make sure we work together as a whole. SDKs for example.  We have some principles on SDKs currently and not all SDKs adhere to them. Those SDKs need work prior to being considered complete, having a stable API, or being mature.  The SDK sub-team would vote on RFCs that would define those criteria or proposals to change the SDKs (which should mostly all have the same features and feel).  If we wanted to add SDK code to handle batch submissions to the REST API, the SDK team should consider that across SDKs. The SDK sub-team therefore should be comprised from maintainers across SDKs so that we both get good representation for those decisions.","username":"amundson","ts":"2018-03-23T14:21:15.381Z"}
{"msg":"It is also important to point out that while that sounds like only the sub-team is involved, that is absolutely not the case. The intent is that the sub-team is where we drive consensus but that the discussion is open to participation by anyone.","username":"amundson","ts":"2018-03-23T14:22:20.395Z"}
{"msg":"As currently written, being on a sub-team does not grant you maintainership at the repo level. I think at the repo level, it is very important that maintainers know the code intimately. So we wouldn't expect someone on the consensus sub-team who has not committed anything to PoET to be approving PoET PRs. That is best left to those that intimately know that code base.","username":"amundson","ts":"2018-03-23T14:33:07.778Z"}
{"msg":"Has joined the channel.","username":"cheetara","ts":"2018-03-23T14:33:20.742Z","type":"uj"}
{"msg":"ok, sure, but it seems like a lot of overhead in terms of managing users and rights.","username":"grkvlt","ts":"2018-03-23T14:42:00.056Z"}
{"msg":"also, not suggesting a 1-1 mapping of teams to repos, more like 1-many, where eg sdk team manages several repos, for each language sdk","username":"grkvlt","ts":"2018-03-23T14:42:40.588Z"}
{"msg":"also, at some point you just have to trust the developers... ","username":"grkvlt","ts":"2018-03-23T14:43:39.972Z"}
{"msg":"the thing that appealed to me about sawtooth and seth was how i was able to get involved without too much in the way of barriers to entry, that's a really good way of getting people to help with your project, and imo you don't want to lose that","username":"grkvlt","ts":"2018-03-23T14:46:06.113Z"}
{"msg":"it can be quite intimidating coming to a new open source project and not being sure if you're doing the right thing, following the rules properly etc. the ASF helps because i know all projects there have a similar management structure, and familiarity with one is good for the rest. fortuntely everyone here has been really helpful and encouraging, so as long as we keep that up, great","username":"grkvlt","ts":"2018-03-23T14:48:12.244Z"}
{"msg":"@grkvlt @kelly_ really good thoughts and feedback","username":"adamludvik","ts":"2018-03-23T14:55:35.196Z"}
{"msg":"Especially about keeping the community open, helpful, and encouraging. I think the goal is to make transparent much of the existing structure within the project so that we can continue to grow as a community in a healthy way.","username":"adamludvik","ts":"2018-03-23T15:06:27.045Z"}
{"msg":"@grkvlt the levels reviewer/committer/maintainer is there because it maps well to github (though we didn't want to call out the mechanics in the RFC). there is a desire to let contributors review PRs even if they don't contribute code (thus read-only github perms and 'reviewer' group); to be able to allow trusted folks to click merge ('committer' without reaching the high bar of maintainer and then maintainers being the approvers.","username":"amundson","ts":"2018-03-23T15:30:03.476Z"}
{"msg":"it is not intended to be complex, but it does make more explicit some things that are just implied today","username":"amundson","ts":"2018-03-23T15:30:32.033Z"}
{"msg":"i guess you can use github teams/groups to separate roles?","username":"grkvlt","ts":"2018-03-23T15:31:10.487Z"}
{"msg":"so, as an example, once poet spins off, maybe I get committer rights but I'm not a poet maintainer. I can review, create PRs, and merge, but maintainers of PoET that are working on that code and know it well are the maintainers (and thus their approval is required to merge).","username":"amundson","ts":"2018-03-23T15:33:23.934Z"}
{"msg":"yes, we have the ability to create groups with the roles in github. I suspect 'reviewer' is one large list across the project, maybe 'committer' is project specific or project-wide and then maintainer groups be managed more specifically to the repo (and matching MAINTAINER.md we add to the repos).","username":"amundson","ts":"2018-03-23T15:34:51.566Z"}
{"msg":"the reviewer level is going to help a lot when folks are just joining the project because the threshold can be low. we can also add folks from other HL projects or with just a passing interesting so they can help with specific PR reviews.","username":"amundson","ts":"2018-03-23T15:36:32.911Z"}
{"msg":"(I find it super annoying when you can't add someone as a reviewer)","username":"amundson","ts":"2018-03-23T15:37:07.558Z"}
{"msg":"ok, that makes more sense, especially if it makes it easier to bring people in to the project quickly at a low level - this should be a very light touch process, then more formal when we want to give actual write access","username":"grkvlt","ts":"2018-03-23T16:02:38.634Z"}
{"msg":"Has joined the channel.","username":"yoni","ts":"2018-03-27T13:29:14.027Z","type":"uj"}
{"msg":"@amundson the apt repo fails for python 3.6... is there a reason for the restriction?","username":"MicBowman","ts":"2018-03-27T22:05:32.649Z"}
{"msg":"There is no restriction, but it is an Ubuntu 16.04 repo","username":"amundson","ts":"2018-03-27T22:44:35.806Z"}
{"msg":"(no restriction other than it's all compiled against 16.04 stuff)","username":"amundson","ts":"2018-03-27T22:45:17.576Z"}
{"msg":"Has joined the channel.","username":"rjones","ts":"2018-03-27T23:46:08.812Z","type":"uj"}
{"msg":"do you know what doesn't work? trying to run on 17.10... as far as i can tell, everything should run just fine","username":"MicBowman","ts":"2018-03-27T23:51:22.817Z"}
{"msg":"we've been albe to install libsecp256k1 by installing the stock library then the python","username":"MicBowman","ts":"2018-03-27T23:51:58.910Z"}
{"msg":"@yoni since your question involves changes to the Sawtooth SDK it is probably better asked in this channel as there is less noise","username":"kelly_","ts":"2018-03-28T01:32:08.870Z"}
{"msg":"copying the question over here","username":"kelly_","ts":"2018-03-28T01:32:25.018Z"}
{"msg":"\"second try, your inputs will be much appreciated :)\n\nWorking on private ledger design and need to re-validate the header signature from within the C++ transaction processor (decrypt signature with public key and make sure it matches hash of transaction header).\nThis require a change to sawtooth SDK since currently the transaction object that comes into TP in the apply method is a class that wraps the protobuf header and this class prevents access to the serialized header bytes.\nThere are 2 ways we thought about on how to make this change in the SDK and would like to open a discussion here on which approach is better.\nOption 1: add getter to the txn wrapping class that will re-serialize the protobuf transaction header and return it.\nOption 2: add flag when register transaction processor that will state that this TP should receive transaction as protobuf serialized object and not with the wrapper class.\n\nI have tested option 1 locally and it worked fine (changed sawtooth_sdk.h and transaction_handler.h)\"","username":"kelly_","ts":"2018-03-28T01:32:27.460Z"}
{"msg":"I think @amundson is the current expert on SDKs","username":"kelly_","ts":"2018-03-28T01:33:46.216Z"}
{"msg":"I think @EugeneYYY is on the c++ sdk but others probably have an opinion on how they would prefer it structured","username":"kelly_","ts":"2018-03-28T01:35:53.508Z"}
{"msg":"Has joined the channel.","username":"EugeneYYY","ts":"2018-03-28T01:35:53.599Z","type":"uj"}
{"msg":"which I think is @zac @pschwarz @boydjohnson ","username":"kelly_","ts":"2018-03-28T01:36:42.703Z"}
{"msg":"and @agunde too ","username":"kelly_","ts":"2018-03-28T01:36:52.576Z"}
{"msg":"@MicBowman where I would start on that is getting the dependency debs to compile on 17.10, then compile sawtooth on 17.10. I've been meaning to take a look but haven't found the time. sawtooth-core/bin/build_deps builds the dependencies.","username":"amundson","ts":"2018-03-28T01:58:18.646Z"}
{"msg":"Ryan and I have been working on a new build methodology that decreases the amount of custom scripts (RFCs for this is nearly finished, and we have some prototypes done), but it is probably realistically a month out yet. (My only point is don't get too aggressive redoing the build since something better is coming.)","username":"amundson","ts":"2018-03-28T01:58:30.304Z"}
{"msg":"sorry, the name of that script is bin/build_ext_debs","username":"amundson","ts":"2018-03-28T01:59:07.647Z"}
{"msg":"there is a comment at the top of the file on how to run it with \"-t ubuntu:xenial\"","username":"amundson","ts":"2018-03-28T02:00:15.748Z"}
{"msg":"(so you will want to change that to the 17.10 release name)","username":"amundson","ts":"2018-03-28T02:00:36.216Z"}
{"msg":"if we get those compiling, we can add them to a 17.10 repo on repo.sawtooth.me","username":"amundson","ts":"2018-03-28T02:02:02.425Z"}
{"msg":"after that, to get sawtooth debs built, we will need to adjust bin/build_all to use a 17.10 docker image. you can look in there, and then realize why we are redoing the build system. anyway, the relevant function in that file is build_debs(), which gets called if you do 'bin/build_all debs' (I think, I didn't just try that).  It references ci/sawtooth-build-debs, which is the docker image we need to make 17.10.  sawtooth-core/ci/sawtooth-build-debs also has some docs at the top on how to run it directly but usually it is run through bin/build_all.","username":"amundson","ts":"2018-03-28T02:06:49.933Z"}
{"msg":"once we know what modifications we need to ci/sawtooth-build-debs, then it should be straightforward to put it together and start producing debs for both 16.04 and 17.10 when we do releases, etc.","username":"amundson","ts":"2018-03-28T02:07:44.184Z"}
{"msg":"@yoni @kelly_ this is maybe not the right channel. it is too locked down to be useful for such discussions. but I'll answer it here anyway since I didn't see it in the other channel.","username":"amundson","ts":"2018-03-28T02:12:43.526Z"}
{"msg":" This was discussed (last week?) in a previous engineering call.  This change will require an RFC.  Option 1 will not be considered, since we have a fundamental and strict rule against re-serializing transaction/batch/block bytes as it introduces an unnecessary point for indeterminism.  However, you could prototype your work doing that approach by forking the SDK. There are two other options. Option 2, as you describe, might be implemented by adding a field to TpRegisterRequest called 'raw_process_request' (a bool), and then either a) adding a new message TpProcessRawRequest (and maybe TpPRocessRawResponse) which is the same as TpProcessRequest but with header as bytes; or b) adding an additional field to TpProcessRequest called 'header_raw' or 'raw_header' which is used instead of 'header' if raw_process_request was set during registration. ","username":"amundson","ts":"2018-03-28T02:22:23.179Z"}
{"msg":"Option 3 would be adding additional TP_* methods to retrieve the raw transaction data specifically, similar to state requests. This option is very inefficient.","username":"amundson","ts":"2018-03-28T02:24:06.957Z"}
{"msg":"I think I'm preferring Option 2b, though we need to fully explore the impact this may have on backward compatibility (I don't expect unsolvable problems).","username":"amundson","ts":"2018-03-28T02:25:36.298Z"}
{"msg":"That would cover changes to the validator. Then we would need to determine how this should be presented to the user in the various SDKs. Ideally, it would be invisible because most TPs won't need this feature.","username":"amundson","ts":"2018-03-28T02:27:10.406Z"}
{"msg":"Backward compatibility is the largest constraint. We will support all existing TP implementations as they are today (for the 'stable/mature' SDKs anyway) without requiring modification, and that includes using old SDKs to interface with the validator. I don't think there are problems here that can't be solved but it is a topic the RFC should cover.","username":"amundson","ts":"2018-03-28T02:28:56.315Z"}
{"msg":"I think if we had an example in python and C++, then we could ask the other SDK maintainers for samples for the other SDKs","username":"amundson","ts":"2018-03-28T02:33:52.549Z"}
{"msg":"May I rename this channel to #sawtooth-maintainers ? ","username":"rjones","ts":"2018-03-28T03:53:26.581Z"}
{"msg":"@rjones let's not rename it yet; we should consider it with some other channels but we haven't decided what we want them to be just yet","username":"amundson","ts":"2018-03-28T12:40:40.053Z"}
{"msg":"Created the branch `1-0-staging-00` for backports.  Please create backport PR’s against this branch. It will be used for running regression tests.","username":"pschwarz","ts":"2018-03-28T14:38:48.991Z"}
{"msg":"thanks, @amundson ","username":"MicBowman","ts":"2018-03-28T15:08:27.051Z"}
{"msg":"@amundson what about a sawtooth-sdk channel?","username":"kelly_","ts":"2018-03-28T15:10:27.673Z"}
{"msg":"just trying to find a spot where @yoni can have a discussion with sdk owners that isnt so crowded with the getting started folks in teh general sawtooth channel","username":"kelly_","ts":"2018-03-28T15:10:58.922Z"}
{"msg":"that will probably be one of them, but we should hold off so they match sub-teams as we create them","username":"amundson","ts":"2018-03-28T16:10:10.390Z"}
{"msg":"chat channels being too busy is a nice problem to have :)","username":"amundson","ts":"2018-03-28T16:10:59.622Z"}
{"msg":"how do you want to refer to the sawtooth burrow evm in the smart contract paper?","username":"MicBowman","ts":"2018-03-28T16:28:16.497Z"}
{"msg":"i believe it is used as Hyperledger Sawtooth Burrow-EVM","username":"MicBowman","ts":"2018-03-28T16:28:41.343Z"}
{"msg":"Seth, Sawtooth Seth, Hyperledger Sawtooth Seth","username":"amundson","ts":"2018-03-28T17:47:01.093Z"}
{"msg":"rbuysse","username":"rjones","ts":"2018-03-30T02:25:52.741Z","type":"user-unmuted"}
{"msg":"jsmitchell","username":"rjones","ts":"2018-03-30T02:29:31.220Z","type":"subscription-role-removed"}
{"msg":"jsmitchell","username":"rjones","ts":"2018-03-30T02:29:36.088Z","type":"subscription-role-added"}
{"msg":"Test","username":"jsmitchell","ts":"2018-03-30T02:40:22.562Z"}
{"msg":"hey!","username":"rjones","ts":"2018-03-30T02:40:34.473Z"}
{"msg":":thumbsup:","username":"rbuysse","ts":"2018-03-30T03:33:01.998Z"}
{"msg":"Has joined the channel.","username":"victer","ts":"2018-03-30T11:39:28.187Z","type":"uj"}
{"msg":"@rjones can we rename sawtooth-hyperdirectory to sawtooth-next-directory per the branding guidence from greg wallace?","username":"kelly_","ts":"2018-04-02T21:13:43.101Z"}
{"msg":"On GitHub? Please send email to helpdesk@hyperledger.org","username":"rjones","ts":"2018-04-02T21:15:24.550Z"}
{"msg":"will do, thanks!","username":"kelly_","ts":"2018-04-02T21:17:02.780Z"}
{"msg":"@rbuysse @rberg2 @amundson @Dan do you see the alert here? https://github.com/hyperledger/sawtooth-next-directory","username":"rjones","ts":"2018-04-03T00:08:49.526Z"}
{"msg":"Hi, Ry - Tom barnes here - i do not see any alert when i navigate to https://github.com/hyperledger/sawtooth-next-directory","username":"TomBarnes","ts":"2018-04-03T00:12:26.614Z"}
{"msg":"@TomBarnes you aren't an admin of sawtooth on github","username":"rjones","ts":"2018-04-03T00:15:22.347Z"}
{"msg":"no i dont think i am","username":"TomBarnes","ts":"2018-04-03T00:15:40.619Z"}
{"msg":"right, I'm saying, you aren't. the issue is in one of your dependencies having a CVE","username":"rjones","ts":"2018-04-03T00:17:03.388Z"}
{"msg":"sawtooth-core of sawtooth-next-directory?","username":"TomBarnes","ts":"2018-04-03T00:18:24.688Z"}
{"msg":"sawtooth-core or sawtooth-next-directory?","username":"TomBarnes","ts":"2018-04-03T00:18:24.688Z"}
{"msg":"this group: https://github.com/orgs/hyperledger/teams/sawtooth-core-admins ","username":"rjones","ts":"2018-04-03T00:19:26.383Z"}
{"msg":"i guess i'll have to leave it to the admins","username":"TomBarnes","ts":"2018-04-03T00:20:22.977Z"}
{"msg":"rberg2","username":"rjones","ts":"2018-04-03T15:18:41.136Z","type":"user-unmuted"}
{"msg":"rberg2","username":"rjones","ts":"2018-04-03T15:18:44.882Z","type":"subscription-role-added"}
{"msg":"@rjones @kelly_ is following up with some of next-directory devs","username":"amundson","ts":"2018-04-04T16:22:50.933Z"}
{"msg":"early access to some RFCs:","username":"amundson","ts":"2018-04-04T16:28:42.932Z"}
{"msg":"https://github.com/Cargill/sawtooth-rfcs/blob/c003-supply-chain-expand-data-types/text/0000-supply-chain-expand-data-types.md","username":"amundson","ts":"2018-04-04T16:28:50.253Z"}
{"msg":"https://github.com/Cargill/sawtooth-rfcs/blob/c004-supply-chain-universal-client/text/0000-supply-chain-universal-client.md","username":"amundson","ts":"2018-04-04T16:29:08.679Z"}
{"msg":"https://github.com/Cargill/sawtooth-rfcs/blob/c005-supply-chain-property-references/text/0000-supply-chain-property-references.md","username":"amundson","ts":"2018-04-04T16:29:23.265Z"}
{"msg":"https://github.com/Cargill/sawtooth-rfcs/blob/c007-supply-chain-client-sdk/text/0000-supply-chain-client-sdk.md","username":"amundson","ts":"2018-04-04T16:29:36.438Z"}
{"msg":"Has joined the channel.","username":"peakcodes","ts":"2018-04-06T21:35:29.709Z","type":"uj"}
{"msg":"what's the status of https://github.com/hyperledger/sawtooth-sdk-go currently? it looks like it's a copy of the current sawtooth-core, is that correct? it'd be nice if we used `git filter-branch` to create the repo this time, as it gives better history","username":"grkvlt","ts":"2018-04-07T18:15:09.225Z"}
{"msg":"see https://github.com/grkvlt/tmp-hyperledger-sawtooth-go-sdk/commits/master for an example of what i mean","username":"grkvlt","ts":"2018-04-07T18:45:00.360Z"}
{"msg":"see https://github.com/grkvlt/tmp-hyperledger-sawtooth-go-sdk/commits/master for an example of what i mean (note only 70 commits, the ones relevant to the go SDK)","username":"grkvlt","ts":"2018-04-07T18:45:00.360Z"}
{"msg":"Has joined the channel.","username":"sv2011","ts":"2018-04-07T23:11:32.156Z","type":"uj"}
{"msg":"Has joined the channel.","username":"Anton 202","ts":"2018-04-09T04:46:06.510Z","type":"uj"}
{"msg":"@grkvlt, @dplumb and @rberg2 are working on it.","username":"adamludvik","ts":"2018-04-09T14:33:37.157Z"}
{"msg":"I'm not familiar with using `git filter-branch`. There is a PR that deletes a bunch and moves a bunch around to make it look like github.com/rberg2/sawtooth-sdk-go","username":"adamludvik","ts":"2018-04-09T14:35:15.425Z"}
{"msg":"ok. fyi, the commands i used were: `git filter-branch --prune-empty --subdirectory-filter sdk/go master && git mv src/sawtooth_sdk/* . && rm -rf src`","username":"grkvlt","ts":"2018-04-09T14:35:18.370Z"}
{"msg":"that does what we want, and only keeps commits that touch `sdk/go`","username":"grkvlt","ts":"2018-04-09T14:35:55.840Z"}
{"msg":"which is better, i think","username":"grkvlt","ts":"2018-04-09T14:36:11.920Z"}
{"msg":"@amundson have you used `git filter-branch` before? Is that a better solution than keeping all history?","username":"adamludvik","ts":"2018-04-09T14:36:43.809Z"}
{"msg":"@amundson see my repo above for what it would look like","username":"grkvlt","ts":"2018-04-09T14:37:21.099Z"}
{"msg":"my latest attempts are here https://github.com/rberg2/sawtooth-sdk-go  I am still having some issues getting the tests to pass due to import paths, and I need to figure out for to build the mocs I think.","username":"rberg2","ts":"2018-04-09T14:45:38.658Z"}
{"msg":"my latest attempts are here https://github.com/rberg2/sawtooth-sdk-go  I am still having some issues getting the tests to pass due to import paths, and I need to figure out how to build the mocs I think.","username":"rberg2","ts":"2018-04-09T14:45:38.658Z"}
{"msg":"@rberg2 yeah, you would be better using the `filter-branch` command to create the repo, so you don't end up with ~6k commits that are not relevant. you can then cherry pick the last few commits from your repo on top to get the equivalent. i'd be happy to set it all up for you, if you want? it'd take half an hour...","username":"grkvlt","ts":"2018-04-09T14:55:07.117Z"}
{"msg":"@adamludvik yes, I have used it for that purpose in the past","username":"amundson","ts":"2018-04-09T15:06:50.944Z"}
{"msg":"I think that if we don't need to edit past commits (which we have sign-offs on), we shouldn't do it.","username":"amundson","ts":"2018-04-09T15:07:54.430Z"}
{"msg":"that would be my only concern with it though, like I said, I've used filter-branch a lot in the past","username":"amundson","ts":"2018-04-09T15:08:35.005Z"}
{"msg":"if we were bad people and checked in a lot of jar files in history, certainly we would need to prune","username":"amundson","ts":"2018-04-09T15:09:47.147Z"}
{"msg":"if there's a legal reason for keeping the commits intact, of course, but i'm not 100% sure there would be? the developers have already agreed that their code can be modified, which is all we are doing. i think it's a standard practice for splitting repositories, and it gives a neater history imo...","username":"grkvlt","ts":"2018-04-09T15:11:18.280Z"}
{"msg":"Do we have a list of who the maintainers of the go sdk are?","username":"amundson","ts":"2018-04-09T15:16:11.218Z"}
{"msg":"If so, probably makes sense to see if they have consensus on this topic","username":"amundson","ts":"2018-04-09T15:17:31.495Z"}
{"msg":"I could see an argument to be made that even given it's small size currently, the repo size is still important to reduce because the repo itself being used within the dev workflow","username":"amundson","ts":"2018-04-09T15:18:34.626Z"}
{"msg":"we would probably take the same approach for the other SDKs potentially as well. Java, Javascript, etc.","username":"amundson","ts":"2018-04-09T15:20:13.638Z"}
{"msg":"@rjones would anyone at LF want to weigh in on this discussion (whether to modify commits when splitting repos)?","username":"amundson","ts":"2018-04-09T15:23:15.866Z"}
{"msg":"We don't have a go sdk maintainer list yet, so a decision would be deferred to the core maintainers list for now. I am fine with either method.","username":"adamludvik","ts":"2018-04-09T15:27:30.419Z"}
{"msg":"I say filter. Less is more.","username":"Dan","ts":"2018-04-09T15:44:10.255Z"}
{"msg":"@amundson I don't remember who I was talking to about this - I was surprised you weren't using `filter-branch`. My _feeling_ about this is the codebase in total is what you need to obey the license for, since each commit is part of the codebase. The upside to `filter-branch` is commands like `git bisect` will still let you debug usefully. Having a thousand extra commits is going to make your life worse.","username":"rjones","ts":"2018-04-09T16:26:00.377Z"}
{"msg":"s/you/they/","username":"rjones","ts":"2018-04-09T16:26:09.758Z"}
{"msg":"@amundson @Dan given the canonical way to import code into a project under LF aegis is a squash commit...","username":"rjones","ts":"2018-04-09T16:28:18.010Z"}
{"msg":"I almost threw up :)","username":"amundson","ts":"2018-04-09T16:30:04.637Z"}
{"msg":"(re: squash commit)","username":"amundson","ts":"2018-04-09T16:30:26.691Z"}
{"msg":"seems like fairly strong consensus brewing so far, if no one brings an alternate position","username":"amundson","ts":"2018-04-09T16:30:56.013Z"}
{"msg":"Has joined the channel.","username":"fedotovcorp","ts":"2018-04-10T10:15:36.092Z","type":"uj"}
{"msg":"RFC preview: https://github.com/Cargill/sawtooth-rfcs/blob/c006-docker-compose-builds/text/0000-docker-compose-builds.md","username":"amundson","ts":"2018-04-10T15:47:27.990Z"}
{"msg":"@amundson you mentioned a sawtooth-website. there are some collateral I want to add in the next month or so on the marketing/community side which would include things like 1) whitepaper 2) logos 3) press-kit (one pager, PDF overview) etc.","username":"kelly_","ts":"2018-04-10T16:19:02.147Z"}
{"msg":"do you think st-website is the appropriate place for those even if they dont neccesarily get exposed via the website","username":"kelly_","ts":"2018-04-10T16:19:44.023Z"}
{"msg":"though most of them could easily/should be via link","username":"kelly_","ts":"2018-04-10T16:19:53.445Z"}
{"msg":"probably, yes","username":"amundson","ts":"2018-04-10T16:50:13.038Z"}
{"msg":"I'd like to get the website repo initialized later in the week or next week","username":"amundson","ts":"2018-04-10T16:52:52.482Z"}
{"msg":"ok works for me","username":"kelly_","ts":"2018-04-10T17:17:26.653Z"}
{"msg":"RFC Preview: https://github.com/peterschwarz/sawtooth-rfcs/blob/state-pruning-change-log/text/0000-state-pruning.md","username":"pschwarz","ts":"2018-04-10T18:10:44.487Z"}
{"msg":"@pschwarz, somewhat unrelated but I know diskIO is a bit of an issue for us and saw this getting added to GETH","username":"kelly_","ts":"2018-04-10T18:30:29.006Z"}
{"msg":"https://github.com/ethereum/go-ethereum/pull/15857","username":"kelly_","ts":"2018-04-10T18:30:30.292Z"}
{"msg":"this is one other recent piece of 'prior art' that discusses state pruning for geth - https://github.com/ethereumproject/go-ethereum/issues/440","username":"kelly_","ts":"2018-04-10T18:41:03.097Z"}
{"msg":"and... last thing re: prior art","username":"kelly_","ts":"2018-04-10T18:46:34.172Z"}
{"msg":"\"Parity offers continuous state trie pruning. The default --pruning fast will keep only the latest 64 states by default. It's expected to grow at a rate of a few GB per year\"","username":"kelly_","ts":"2018-04-10T18:46:38.243Z"}
{"msg":"there is information on parity's 4 pruning modes here - https://ethereum.stackexchange.com/questions/3332/what-is-the-parity-light-pruning-mode?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa","username":"kelly_","ts":"2018-04-10T18:47:19.045Z"}
{"msg":"`    --pruning=[METHOD]\n        Configure pruning of the state/storage trie. METHOD may be one of auto,\n        archive, fast: archive - keep all state trie data. No pruning. fast -\n        maintain journal overlay. Fast but 50MB used. auto - use the method most\n        recently synced or default to fast if none synced. (default: auto)\n\n    --pruning-history=[NUM]\n        Set a minimum number of recent states to keep in memory when pruning is\n        active. (default: 64)\n\n    --pruning-memory=[MB]\n        The ideal amount of memory in megabytes to use to store recent states. As\n        many states as possible will be kept within this limit, and at least\n        --pruning-history states will always be kept. (default: 32)`","username":"kelly_","ts":"2018-04-10T18:53:14.650Z"}
{"msg":"@adamludvik - while also digging around, this PR for GETH has the interface for when a consensus engine needs to send p2p messages - https://github.com/ethereum/go-ethereum/pull/16385/files","username":"kelly_","ts":"2018-04-10T19:06:54.577Z"}
{"msg":"looks very similar to ours","username":"adamludvik","ts":"2018-04-10T20:31:08.257Z"}
{"msg":"Thanks @kelly_  will look at those","username":"pschwarz","ts":"2018-04-10T20:50:15.295Z"}
{"msg":"@amundson @Dan Backport PR: https://github.com/hyperledger/sawtooth-core/pull/1564","username":"pschwarz","ts":"2018-04-10T21:28:33.903Z"}
{"msg":"Has joined the channel.","username":"TheOnlyJoey","ts":"2018-04-12T13:29:49.654Z","type":"uj"}
{"msg":"Has left the channel.","username":"TheOnlyJoey","ts":"2018-04-12T13:30:03.263Z","type":"ul"}
{"msg":"is everyone cool with doing this in all our docker files? - https://github.com/hyperledger/sawtooth-supply-chain/pull/45/files","username":"amundson","ts":"2018-04-12T15:17:11.633Z"}
{"msg":"@rberg2 @rbuysse ^","username":"amundson","ts":"2018-04-12T15:17:36.621Z"}
{"msg":"related to https://jira.hyperledger.org/browse/STL-1078","username":"amundson","ts":"2018-04-12T15:19:20.612Z"}
{"msg":"likely this would not actually fix STL-1078 (which was a DNS error?) but maybe a good thing anyway? or is the complexity not worth it?","username":"amundson","ts":"2018-04-12T15:21:06.615Z"}
{"msg":"I don't like the conplexity","username":"rbuysse","ts":"2018-04-12T15:24:40.778Z"}
{"msg":"if it's a problem people are seeing often we should just switch to the HA pool ","username":"rbuysse","ts":"2018-04-12T15:25:28.669Z"}
{"msg":"that seems like a fine idea to me, I have seen keyserver.ubuntu.com hickup a few times over the years, or we could change the first apt-key to use the pool","username":"rberg2","ts":"2018-04-12T15:25:29.029Z"}
{"msg":"Its a simple code, just an or operation. \nThis is a common, standard fix for handling reliability issues: when a keyserver is down or unresponsive or something like that.","username":"askmish","ts":"2018-04-12T15:31:00.686Z"}
{"msg":"@Dan here is the Rust/Python logging facade I was talking about: https://github.com/hyperledger/sawtooth-core/commit/7ea8654ffc30c92f6250234e2f8e9dc892b61010","username":"adamludvik","ts":"2018-04-13T18:01:36.315Z"}
{"msg":"Has joined the channel.","username":"santiagop","ts":"2018-04-13T20:07:37.730Z","type":"uj"}
{"msg":"Merged: https://github.com/hyperledger/sawtooth-rfcs/pull/6","username":"adamludvik","ts":"2018-04-16T15:52:57.316Z"}
{"msg":"Has joined the channel.","username":"jaxdave","ts":"2018-04-16T15:54:46.359Z","type":"uj"}
{"msg":"Has joined the channel.","username":"yosra","ts":"2018-04-17T12:30:06.902Z","type":"uj"}
{"msg":"@jsmitchell see if you can post ","username":"Dan","ts":"2018-04-18T19:33:43.067Z"}
{"msg":"Nope","username":"jsmitchell","ts":"2018-04-18T21:31:28.063Z"}
{"msg":"Ok, well let me know if that changes.","username":"Dan","ts":"2018-04-19T00:27:22.235Z"}
{"msg":"Has joined the channel.","username":"rkrish82","ts":"2018-04-19T02:59:33.984Z","type":"uj"}
{"msg":"Yep","username":"jsmitchell","ts":"2018-04-19T03:20:12.412Z"}
{"msg":"It actually did work","username":"jsmitchell","ts":"2018-04-19T03:20:19.319Z"}
{"msg":"I just thought it was funny to post “Nope”","username":"jsmitchell","ts":"2018-04-19T03:20:33.965Z"}
{"msg":"I'm going to need a longer explanation to understand whether you can post in this channel. ","username":"Dan","ts":"2018-04-19T12:42:34.851Z"}
{"msg":"@Dan yes, I can post in this channel?","username":"rjones","ts":"2018-04-19T13:50:39.223Z"}
{"msg":"Testing if I can post here","username":"askmish","ts":"2018-04-20T10:54:32.699Z"}
{"msg":"can anyone see this?","username":"askmish","ts":"2018-04-20T10:54:45.395Z"}
{"msg":"Nope","username":"amolk","ts":"2018-04-20T12:08:41.797Z"}
{"msg":"Me neither","username":"Dan","ts":"2018-04-20T14:58:04.991Z"}
{"msg":"pankaj","username":"TomBarnes","ts":"2018-04-20T16:11:48.009Z"}
{"msg":"yep","username":"TomBarnes","ts":"2018-04-20T20:10:30.545Z"}
{"msg":"i mean nope","username":"TomBarnes","ts":"2018-04-20T20:10:50.252Z"}
{"msg":":)","username":"TomBarnes","ts":"2018-04-20T20:11:00.371Z"}
{"msg":"Has joined the channel.","username":"jeffreychengmw","ts":"2018-04-23T13:04:25.477Z","type":"uj"}
{"msg":"I've submitted a RFC PR for Sawtooth Sabre (on-chain smart contracts executed in WebAssembly) - https://github.com/hyperledger/sawtooth-rfcs/pull/7","username":"amundson","ts":"2018-04-23T19:11:33.364Z"}
{"msg":"@TomBarnes @Dan @jsmitchell @kelly_ @pschwarz @agunde @adamludvik - as root team members, please review this RFC ^","username":"amundson","ts":"2018-04-23T19:14:51.315Z"}
{"msg":":woo:","username":"kelly_","ts":"2018-04-23T19:15:08.698Z"}
{"msg":"A working implementation of Sabre exists which is capable of running Sawtooth Supply Chain with relatively minor modifications; that will be submitted soon (hopefully we can vote on the RFC prior to that)","username":"amundson","ts":"2018-04-23T19:18:21.675Z"}
{"msg":"reviewed","username":"jsmitchell","ts":"2018-04-23T19:18:41.777Z"}
{"msg":"Note that @jsmitchell had access to this for a long time, but held out feedback to get the first red x. :)","username":"amundson","ts":"2018-04-23T19:19:19.217Z"}
{"msg":"you think i just save up your typos for later use?","username":"jsmitchell","ts":"2018-04-23T19:19:50.797Z"}
{"msg":"s/reviewed/First!/","username":"amundson","ts":"2018-04-23T19:19:51.145Z"}
{"msg":"@amundson quick question - and maybe better to put in the RFC comments, but it seems like the contract deployer gets to control the namespace that the contract writes to","username":"kelly_","ts":"2018-04-23T19:37:06.243Z"}
{"msg":"doesn't this make the contract less 'trustless' vs the code being the only one managing that namespace.","username":"kelly_","ts":"2018-04-23T19:37:21.857Z"}
{"msg":"what if i had supply chain writing into a namespace. then i deploy another contract and permit it to write to the same namespace, and i change the ownership of all supply chain assets to my pubkey","username":"kelly_","ts":"2018-04-23T19:38:04.370Z"}
{"msg":"is there something to prevent that?","username":"kelly_","ts":"2018-04-23T19:38:24.612Z"}
{"msg":"that can happen now with regular TPs","username":"jsmitchell","ts":"2018-04-23T19:38:27.541Z"}
{"msg":"and that is what the pokitdok contributed namespace thingy prevents","username":"jsmitchell","ts":"2018-04-23T19:38:39.299Z"}
{"msg":"right, so i'm wondering if there is a similar thing to isolate sabre contracts","username":"kelly_","ts":"2018-04-23T19:39:09.185Z"}
{"msg":"so, there would need to be a mechanism to subpermit sabre contracts","username":"jsmitchell","ts":"2018-04-23T19:39:18.369Z"}
{"msg":"ok got it, just wanted to make sure i was understanding it correctly","username":"kelly_","ts":"2018-04-23T19:39:30.973Z"}
{"msg":"@agunde ^ any thoughts? you've been closer to the conversations than i have","username":"jsmitchell","ts":"2018-04-23T19:39:54.683Z"}
{"msg":"in ethereum the default is that only that contract can write to that namespace, and if you want to update the smart contract than you design in a proxy contract to sit in between, which inherently instills some new trust model for if you trust the owner of the proxy contract","username":"kelly_","ts":"2018-04-23T19:42:07.205Z"}
{"msg":"not saying one is better than the other, just comparing/contrasting the defaults","username":"kelly_","ts":"2018-04-23T19:42:33.586Z"}
{"msg":"There is a concept of \"owners\" of a namespace. The second contract would need to be granted permission to read and write fromm the supply-chian namespace by those owners before they would be able to overwrite the supply-chain state.  ","username":"agunde","ts":"2018-04-23T19:52:16.864Z"}
{"msg":"@agunde if you deployed a contract with a random owner (say pubkey=00000000000000000000000000000000), would that effectively lock the deployment so that from there on out, only that one contract could write to that namespace","username":"kelly_","ts":"2018-04-23T20:09:34.799Z"}
{"msg":"maybe thats a simple way to prevent additional contracts from writing to that namespace, or to prevent the owner from deleting/updating the contract once deployed","username":"kelly_","ts":"2018-04-23T20:13:30.899Z"}
{"msg":"There are administrators whose public keys are stored in the setting sawtooth.swa.administrators that could still override the permissions on that namespace.  ","username":"agunde","ts":"2018-04-23T20:15:51.730Z"}
{"msg":"so there would still be some trust in the sawtooth administrators, but could you do the above to remove 'trust' in the person that deployed the smart contract?","username":"kelly_","ts":"2018-04-23T20:19:33.477Z"}
{"msg":"To be clear there are two sets of owners. Owners of a contract and owners of a namespace. Theses are not necessarily the same set. If the owner was set to an invalid key for a contract, no new versions would be able to be uploaded. The down side is the contract would also not be able to be deleted. ","username":"agunde","ts":"2018-04-23T20:26:08.128Z"}
{"msg":"got it, and similarly for a namespace too right?","username":"kelly_","ts":"2018-04-23T20:26:26.441Z"}
{"msg":"except for the sawtooth.swa.administrators, yes","username":"agunde","ts":"2018-04-23T20:26:38.692Z"}
{"msg":"sweet, that actually sounds pretty useful","username":"kelly_","ts":"2018-04-23T20:26:48.359Z"}
{"msg":"I didn't know if there was something hard-coded where the deployer always had access","username":"kelly_","ts":"2018-04-23T20:27:11.060Z"}
{"msg":"one other random question. if you didn't want anyone as an admin of sawtooth network, is it possible to set all of the settings in the genesis block and then have a null value/non-functional value for swa.administrators","username":"kelly_","ts":"2018-04-23T20:28:56.443Z"}
{"msg":"or is a key required in swa.administrators to get the right TPs loaded after the genesis block","username":"kelly_","ts":"2018-04-23T20:29:18.166Z"}
{"msg":"I was thinking that by default the contract deployer was set as an owner. But you brought up good points on why you might not want to do that. ","username":"agunde","ts":"2018-04-23T20:29:42.519Z"}
{"msg":"Only swa.administrators are allowed to create the initial namespace registry.","username":"agunde","ts":"2018-04-23T20:30:52.717Z"}
{"msg":"ok so you couldn't launch a functioning network without swa.administrators","username":"kelly_","ts":"2018-04-23T20:31:39.531Z"}
{"msg":"Right. Once the namespace are created though you could null it out. You would just need to make sure that the namespace registries and owners are set up correctly. ","username":"agunde","ts":"2018-04-23T20:32:16.980Z"}
{"msg":"ok cool that makes a ton of sense","username":"kelly_","ts":"2018-04-23T20:32:26.976Z"}
{"msg":"I could see a variety of different deployment models where you may or may not want admins/namespace owners/contract owners","username":"kelly_","ts":"2018-04-23T20:32:43.112Z"}
{"msg":"so nice to have that flexibility","username":"kelly_","ts":"2018-04-23T20:32:47.702Z"}
{"msg":"So, as an example, if I'm the owner of the intkey namespace, I can allow specific contracts permissions to that namespace. The owner of the namespace thus must trust the owners of those contracts, who can upload new versions of the contracts.  It is a form of delegation.","username":"amundson","ts":"2018-04-24T01:31:39.059Z"}
{"msg":"It is intended to permissioned but simple. We can add more complexity later. A system like the one used in Ethereum where smart contracts can only access their own namespace would be trivial; but, it provides only a subset of the functionality.","username":"amundson","ts":"2018-04-24T01:37:58.547Z"}
{"msg":"Has joined the channel.","username":"deb","ts":"2018-04-24T06:57:35.780Z","type":"uj"}
{"msg":"Has joined the channel.","username":"Subhadip 1","ts":"2018-04-24T06:57:46.840Z","type":"uj"}
{"msg":"Has joined the channel.","username":"aviralwal","ts":"2018-04-24T10:40:56.838Z","type":"uj"}
{"msg":"Just realized I don't think @achenette 's app dev guide changes including setting up multi-node networks made it into a release? Probably missed the window for release v1.0.3, what do we think about getting those into v1.04?","username":"Dan","ts":"2018-04-24T15:35:23.224Z"}
{"msg":"That would be nice, especially we could include this week's corrections for the multi-node procedure.  I hope to have those corrections done soon (if Jenkins is willing and I can successfully coach sTyL3 through his first PR), so the repaired multi-node procedure would be available for v1.04.","username":"achenette","ts":"2018-04-24T15:45:33.576Z"}
{"msg":"@TomBarnes @amundson regarding branch/tag on sawtooth-supply-chain, is this the right commit for the tip of that branch? https://github.com/hyperledger/sawtooth-supply-chain/commit/4701a5c0337b6d002349a9061d3dd7670e4c80e6. I Think that's the last commit before culling python?\nOr we discussed just branching with the first stable rust. Is that current head of master?","username":"Dan","ts":"2018-04-24T15:55:09.672Z"}
{"msg":"@Dan I was literally just looking at that","username":"amundson","ts":"2018-04-24T15:55:48.652Z"}
{"msg":"must be on same brain wave :)","username":"Dan","ts":"2018-04-24T15:56:01.117Z"}
{"msg":"@achenette that would be great, can you pull together the requisite commits and submit them as backports to 1.0. ","username":"Dan","ts":"2018-04-24T15:56:15.999Z"}
{"msg":"@Dan that isn't the right one, but I'll find it","username":"amundson","ts":"2018-04-24T15:56:59.783Z"}
{"msg":"First, I'm going to create a 0-8 branch in supply chain from the commit prior to Zac's 1.0 update (8b1551e54c838abfc399d295cdf717155f127356)","username":"amundson","ts":"2018-04-24T16:07:52.257Z"}
{"msg":"Second, I think we should create a 0-9 branch starting with commit 40ae875e794c372e4342df46906b308aefb42059 which is prior to Rust changes going in; we should then backport non-Rust stuff from master to 0-9","username":"amundson","ts":"2018-04-24T16:09:17.438Z"}
{"msg":"Third, master becomes 1.10.x","username":"amundson","ts":"2018-04-24T16:09:28.023Z"}
{"msg":"Third, master becomes 0.10.x","username":"amundson","ts":"2018-04-24T16:09:28.023Z"}
{"msg":"Backporting might not be important. I think if all stakeholders are comfortable with the current rust implementation, then the last python commit is good to have, but don't need to 'maintain' it. v0.10.x should satisfy @tom 's need (supposing that point is stable).","username":"Dan","ts":"2018-04-24T18:40:40.225Z"}
{"msg":"well, we are adding features to master, so it depends on what you mean by stable","username":"amundson","ts":"2018-04-24T18:49:21.230Z"}
{"msg":"right now, supply chain master requires Sawtooth's 1.1.x SDK (from master), as we have backported the Rust SDK to 1.0","username":"amundson","ts":"2018-04-24T18:51:31.043Z"}
{"msg":"backporting the Rust SDK would probably make sense","username":"amundson","ts":"2018-04-24T18:52:31.917Z"}
{"msg":"stable = not broke","username":"Dan","ts":"2018-04-24T19:20:25.884Z"}
{"msg":"so i'm interpreting supply-chain 0.9 as python and 0.10 as rust. \nboth supply-chain 0.9 and 0.10 work with sawtooth 1.0. \nassuming 0.10 is 'fully operational' (can destroy planets) then 0.9 is a historical footnote.\nI don't think anyone needs backports then to supply-chain 0.9\nsupply-chain master depends on sawtooth 1.1 features (i.e. sawtooth master) and would not be appropriate for e.g. AMI's.\nSo backports / fixes to supply-chain 0.10 would be relevant.\n","username":"Dan","ts":"2018-04-24T19:36:15.384Z"}
{"msg":"and if 0.9 == python then you may want 1 commit further ee22df267be45e271c1079af25393f07df102e0e which I think gets rid of a dead path for bandit. not a big deal if you've already branched.","username":"Dan","ts":"2018-04-24T19:39:13.453Z"}
{"msg":"Commit ee22df267be45e271c1079af25393f07df102e0e is after some of the Rust commits. Using 'git log --graph' helps visualize how things are merged together.  But, we can backport it.","username":"amundson","ts":"2018-04-25T00:50:17.976Z"}
{"msg":"Has joined the channel.","username":"techalchemist","ts":"2018-04-25T10:51:03.318Z","type":"uj"}
{"msg":"good tip!","username":"Dan","ts":"2018-04-25T13:13:28.689Z"}
{"msg":"@askmish @amolk short notice, but I asked Adam if he could go over the consensus engine stuff at the sawtooth tech forum tomorrow. Would be great if you can make it. I think it is at 20:30 your time. ","username":"Dan","ts":"2018-04-25T13:28:24.002Z"}
{"msg":"0-8 and 0-9 branches now exist in sawtooth-supply-chain","username":"amundson","ts":"2018-04-25T13:29:55.094Z"}
{"msg":"I'm testing the version change to master before I push it","username":"amundson","ts":"2018-04-25T13:30:35.324Z"}
{"msg":"sawtooth-supply-chain master is now 0.10.x","username":"amundson","ts":"2018-04-25T13:37:41.218Z"}
{"msg":"","username":"adamludvik","ts":"2018-04-25T17:35:54.675Z","attachments":[{"type":"file","title":"Consensus Engine SDK.pdf","title_link":"/file-upload/sHqJ4JeqnHg36Co9s/Consensus%20Engine%20SDK.pdf","url":"/file-upload/sHqJ4JeqnHg36Co9s/Consensus%20Engine%20SDK.pdf","remote":false,"fileId":"sHqJ4JeqnHg36Co9s","fileName":"Consensus Engine SDK.pdf"}]}
{"msg":"^ early previous of slides for tech forum tomorrow","username":"adamludvik","ts":"2018-04-25T17:36:23.092Z"}
{"msg":"RFC for State Pruning: https://github.com/hyperledger/sawtooth-rfcs/pull/8","username":"pschwarz","ts":"2018-04-26T16:34:16.204Z"}
{"msg":"Folks, is the RAFT code being re-written in rust?","username":"amolk","ts":"2018-04-26T18:16:39.927Z"}
{"msg":"The intent is to use existing rust code if possible then adapt or reimplement if necessary.","username":"Dan","ts":"2018-04-26T18:58:10.747Z"}
{"msg":"IIRC, this is the most viable candidate, which is based on etcd's Go implementation of Raft: https://github.com/pingcap/raft-rs","username":"adamludvik","ts":"2018-04-26T19:02:34.933Z"}
{"msg":"yep","username":"Dan","ts":"2018-04-26T19:06:27.559Z"}
{"msg":"Sorry guys, I asked the wrong question.. Blame it all on the confusion between 'REST', 'Rust' and 'Raft'! And being half asleep ;)","username":"amolk","ts":"2018-04-27T01:26:16.434Z"}
{"msg":"So here is the correct question: is the REST interface being rewritten in Rust? ","username":"amolk","ts":"2018-04-27T01:27:36.543Z"}
{"msg":"Or, to put it in another way, is Rest going to Rust? :)","username":"amolk","ts":"2018-04-27T03:31:59.250Z"}
{"msg":"@amolk I'm in favor of porting the REST API to Rust at some point, but as far as I know, we are not doing it currently. For application REST APIs, some of us have started using this very nice framework - https://github.com/SergioBenitez/Rocket","username":"amundson","ts":"2018-04-27T14:14:02.374Z"}
{"msg":"The reason I asked is because we've been working on increasing the unit test coverage of the REST API. If the code is being re-written, we won't bother raising PRs for it.","username":"amolk","ts":"2018-04-27T14:15:16.695Z"}
{"msg":"@amolk have you considered writing them in a manner that is not tightly coupled to the current implementation? For example, as a integration or component test were the test runs in a separate process and makes HTTP calls to it?","username":"amundson","ts":"2018-04-27T14:19:11.297Z"}
{"msg":"@amolk have you considered writing them in a manner that is not tightly coupled to the current implementation? For example, as a integration or component test where the test runs in a separate process and makes HTTP calls to it?","username":"amundson","ts":"2018-04-27T14:19:11.297Z"}
{"msg":"We're working on it on two fronts. The first is to just extend the existing unit tests to improve code coverage. The second is a more formal end-to-end test from a client perspective, first of the individual interfaces and then getting into some of the more involved usage scenarios.","username":"amolk","ts":"2018-04-27T14:21:16.338Z"}
{"msg":"Even with unit tests, if they are well-documented (in API doc comments, for example), then we should be able to translate those to Rust at some point. So I think they still have value either way.","username":"amundson","ts":"2018-04-27T14:21:32.156Z"}
{"msg":"ok","username":"amolk","ts":"2018-04-27T14:21:45.406Z"}
{"msg":"on the integration test front, I would recommend tightly coupling them to the Swagger spec if possible","username":"zac","ts":"2018-04-27T14:22:57.170Z"}
{"msg":"We did that with a tool called Dredd in marketplace and it worked reasonably well","username":"zac","ts":"2018-04-27T14:23:37.069Z"}
{"msg":"I think I agree with that. The intent is that we are implementing that spec, so if the spec doesn't match the REST API behavior it is a bug in one of them.","username":"amundson","ts":"2018-04-27T14:23:55.892Z"}
{"msg":"yes, exactly","username":"zac","ts":"2018-04-27T14:24:09.629Z"}
{"msg":"For unit tests, I wouldn't presume that the existing functions are necessarily the best structure for the REST API. If I were rewriting it (in Rust or otherwise), I would probably use it as an opportunity to do some refactoring.","username":"zac","ts":"2018-04-27T14:25:36.778Z"}
{"msg":"Though obviously, if maintaining the existing method footprint (more or less) is important, that is doable. ","username":"zac","ts":"2018-04-27T14:26:06.975Z"}
{"msg":"```Proposed RocketChat channels:\n\n#sawtooth\n  This channel is used for general sawtooth discussion, including user\n  questions.\n\n#sawtooth-announce\n  This channel is used to make announcements related to Sawtooth. This includes\n  items such as releases, acceptance of RFCs, posting on news stories related\n  to Sawtooth, etc. This is intended to be a low-volume no-discussion channel,\n  and is thus posting be restricted; if it is, access should be managed by the\n  Sawtooth community outreach subteam.\n\n#sawtooth-core-dev\n  This channel is used for Sawtooth core development discussion, including\n  discussion of the validator, CLI, REST API, and other core components. This\n  is the primary forum for the future Sawtooth core subteam.\n\n#sawtooth-consensus-dev\n  This channel is used for Sawtooth consensus development discussion, including\n  discussion of consensus-related APIs and various consensus engine\n  implementations. This is the primary forum for the future Sawtooth consensus\n  subteam.\n\n  This replaces #sawtooth-consensus.\n\n#sawtooth-infra\n  This channel is used for Sawtooth infrastructure discussion, and is\n  the primary forum for the future Sawtooth infrastructure subteam\n  discussion and related RFCs. This replaces #sawtooth-ci.\n\n#sawtooth-governance\n  This channel is used for discussion of Sawtooth governance topics. This is\n  the primary forum for discussion by the Sawtooth root team. Discussion on\n  this channel may be restricted to root team members if necessary to keep the\n  discussion soley on governance topics which require root team member\n  participation, such as discussion and voting on RFCs.\n\n#sawtooth-outreach\n  This channel is used for discussion of Sawtooth community outreach\n  initiatives, including documentation, website, demos, training, etc. This\n  is the primary forum for the future Sawtooth community outreach subteam.\n\n  This replaces #sawtooth-edx.\n\n#sawtooth-release\n  This channel is used for release management discussions. This includes\n  release topics such as dependency management, license compliance, branching\n  strategies, etc.  This channel will also contain status discussion during the\n  execution of releases. This is the primary channel of the future Sawtooth\n  release management subteam.\n\n  Note that discussion on topics which require root team approval must occur in\n  the #sawtooth-governance channel.\n\n#sawtooth-sabre\n  This channel is for discussion of Sawtooth Sabre. This includes both\n  applicaiton development and Sabre development. This is the primary forum\n  for the future Sabre subteam.\n","username":"amundson","ts":"2018-04-30T14:47:45.039Z"}
{"msg":"```Proposed RocketChat channels:\n\n#sawtooth\n  This channel is used for general sawtooth discussion, including user\n  questions.\n\n#sawtooth-announce\n  This channel is used to make announcements related to Sawtooth. This includes\n  items such as releases, acceptance of RFCs, posting on news stories related\n  to Sawtooth, etc. This is intended to be a low-volume no-discussion channel,\n  and is thus posting be restricted; if it is, access should be managed by the\n  Sawtooth community outreach subteam.\n\n#sawtooth-core-dev\n  This channel is used for Sawtooth core development discussion, including\n  discussion of the validator, CLI, REST API, and other core components. This\n  is the primary forum for the future Sawtooth core subteam.\n\n#sawtooth-consensus-dev\n  This channel is used for Sawtooth consensus development discussion, including\n  discussion of consensus-related APIs and various consensus engine\n  implementations. This is the primary forum for the future Sawtooth consensus\n  subteam.\n\n  This replaces #sawtooth-consensus.\n\n#sawtooth-infra\n  This channel is used for Sawtooth infrastructure discussion, and is\n  the primary forum for the future Sawtooth infrastructure subteam\n  discussion and related RFCs. This replaces #sawtooth-ci.\n\n#sawtooth-governance\n  This channel is used for discussion of Sawtooth governance topics. This is\n  the primary forum for discussion by the Sawtooth root team. Discussion on\n  this channel may be restricted to root team members if necessary to keep the\n  discussion soley on governance topics which require root team member\n  participation, such as discussion and voting on RFCs.\n\n#sawtooth-outreach\n  This channel is used for discussion of Sawtooth community outreach\n  initiatives, including documentation, website, demos, training, etc. This\n  is the primary forum for the future Sawtooth community outreach subteam.\n\n  This replaces #sawtooth-edx.\n\n#sawtooth-release\n  This channel is used for release management discussions. This includes\n  release topics such as dependency management, license compliance, branching\n  strategies, etc.  This channel will also contain status discussion during the\n  execution of releases. This is the primary channel of the future Sawtooth\n  release management subteam.\n\n  Note that discussion on topics which require root team approval must occur in\n  the #sawtooth-governance channel.\n\n#sawtooth-sabre\n  This channel is for discussion of Sawtooth Sabre. This includes both\n  applicaiton development and Sabre development. This is the primary forum\n  for the future Sabre subteam.\n\n#sawtooth-seth\n  This channel is for discussion of Sawtooth Seth. This includes both\n  applicaiton development and Seth development. This is the primary forum\n  for the future Seth subteam.\n\n#sawtooth-sdk-dev\n  This channel is used for Sawtooth SDK development discussion.  This includes\n  all Sawtooth SDKs. This is the primary forum for the future Sawtooth\n  application SDKs subteam.\n\n#sawtooth-supply-chain\n  This channel is for discussion of Sawtooth Supply Chain. This includes both\n  use of Sawtooth Supply Chain as well as development of Sawtooth Supply Chain.```","username":"amundson","ts":"2018-04-30T14:47:45.039Z"}
{"msg":"I'm trying to put together a plan for RocketChat channels - see above, and let's discuss.","username":"amundson","ts":"2018-04-30T14:49:21.452Z"}
{"msg":"Looks good to me.","username":"Dan","ts":"2018-04-30T14:56:23.280Z"}
{"msg":"@RyanBanks could you expand here a tad on the text you added to the Sabre RFC?","username":"Dan","ts":"2018-04-30T15:11:43.686Z"}
{"msg":"Has joined the channel.","username":"RobinBanks","ts":"2018-04-30T15:23:40.263Z","type":"uj"}
{"msg":"Sure","username":"RobinBanks","ts":"2018-04-30T15:27:03.604Z"}
{"msg":"Sabre is build on Wasmi","username":"RobinBanks","ts":"2018-04-30T15:27:49.446Z"}
{"msg":"https://github.com/paritytech/wasmi","username":"RobinBanks","ts":"2018-04-30T15:27:50.638Z"}
{"msg":"That library is responsible for interpreting the uploaded contracts. It doesn't have a mechanism build into it that can stop erroneous or malicious code.    ","username":"RobinBanks","ts":"2018-04-30T15:29:47.942Z"}
{"msg":"So if a contract has a while true loop, it'll run forever.","username":"RobinBanks","ts":"2018-04-30T15:30:42.828Z"}
{"msg":"However, we could submit a PR against wasmi to add an execution limit. Basically we'd need to replace the loop in `do_run_function` with a `for` and specify a maximum number of instructions that can be run.","username":"RobinBanks","ts":"2018-04-30T15:34:41.654Z"}
{"msg":"https://github.com/paritytech/wasmi/blob/d926993c6c796ba09ffb70bf53c6b921b3c9acef/src/runner.rs#L130","username":"RobinBanks","ts":"2018-04-30T15:34:43.843Z"}
{"msg":"Do you have any other questions @Dan?","username":"RobinBanks","ts":"2018-04-30T15:36:32.921Z"}
{"msg":"@amundson : Regarding chat channels...can you help me understand subteams and how someone who is wanting to contribute to one of the Sawtooth components (core, seth, sabre, etc.) gets involved?","username":"tkuhrt","ts":"2018-04-30T18:35:57.699Z"}
{"msg":"@tkuhrt The two related documents are: https://github.com/hyperledger/sawtooth-rfcs/ https://github.com/hyperledger/sawtooth-rfcs/blob/master/text/0000-sawtooth-governance.md","username":"amundson","ts":"2018-04-30T18:37:23.007Z"}
{"msg":"Has joined the channel.","username":"Matthieu.inBlocks","ts":"2018-05-01T13:08:32.615Z","type":"uj"}
{"msg":"During sprint planning, Peter mentioned the state pruning RFC reminding me I'm behind in reviewing that. Assuming others are too...\nhttps://github.com/hyperledger/sawtooth-rfcs/pull/8","username":"Dan","ts":"2018-05-01T16:28:02.481Z"}
{"msg":"Has joined the channel.","username":"jeremie.inblocks","ts":"2018-05-02T15:30:04.539Z","type":"uj"}
{"msg":"Thanks for the mention @Dan ","username":"pschwarz","ts":"2018-05-02T18:39:54.010Z"}
{"msg":"@agunde @TomBarnes @adamludvik @Dan @jsmitchell @kelly_ @pschwarz I've proposed the Sabre RFC be merged, please vote. The PR is https://github.com/hyperledger/sawtooth-rfcs/pull/7","username":"amundson","ts":"2018-05-02T21:00:13.940Z"}
{"msg":"voted","username":"jsmitchell","ts":"2018-05-02T21:09:16.274Z"}
{"msg":"check","username":"pschwarz","ts":"2018-05-02T21:09:44.154Z"}
{"msg":"@MicBowman @Dan and others - Nice work on the Smart Contracts paper!","username":"amundson","ts":"2018-05-03T02:49:59.153Z"}
{"msg":"Has joined the channel.","username":"tungdt_socoboy","ts":"2018-05-05T11:43:00.900Z","type":"uj"}
{"msg":"Added a new JIRA task to add a `Context.new_private_key_from_hex` method to the various SDKs and signing modules. As I see it, this is the missing piece to make the `CryptoFactory` workflow usable. Currently contexts only have a `new_random_private_key` method, which means there is no way to use them with an existing private key, you have to import and instantiate `secp256k1.Secp256k1PrivateKey` directly. This defeats the purpose of having a `CryptoFactory`.\nhttps://jira.hyperledger.org/browse/STL-1231","username":"zac","ts":"2018-05-06T20:26:03.664Z"}
{"msg":"@zac added some comments. does your use case involve loading many private keys?","username":"amundson","ts":"2018-05-07T04:33:00.817Z"}
{"msg":"Not many at a time. Just a basic web app login.","username":"zac","ts":"2018-05-07T05:10:04.561Z"}
{"msg":"However, creating a PrivateKey instance from a previously generated and stored private key is fundamental. I currently can't do that without importing the `Secp256k1PrivateKey` class directly, undermining the purpose of the `CryptoFactory`. If the factory is the best practice, I would like to use it for the educational code I am putting in front of students.","username":"zac","ts":"2018-05-07T05:25:05.365Z"}
{"msg":"I added a JIRA comment.","username":"zac","ts":"2018-05-07T05:25:17.742Z"}
{"msg":"Has joined the channel.","username":"dsl","ts":"2018-05-07T05:53:52.884Z","type":"uj"}
{"msg":"I'm writing an RFC to create a Sawtooth Supply Chain subteam, and thinking about the member list. Sensible Bitwise inclusions would be myself, @amundson, @agunde, and possibly @jsmitchell. I think it would be good to have a least one Intel representative as well. @kelly_ ? Maybe @Dan if Kelly didn't want to?","username":"zac","ts":"2018-05-07T18:41:45.981Z"}
{"msg":"How do the people pinged feel about this?","username":"zac","ts":"2018-05-07T18:42:03.421Z"}
{"msg":"Are there any PRs stuck waiting on DCO bot, and DCO bot is not firing? if so, could you please add links here? https://github.com/probot/dco/issues/69 thank you","username":"rjones","ts":"2018-05-07T22:54:49.856Z"}
{"msg":"There is now a #sawtooth-sabre channel","username":"amundson","ts":"2018-05-08T01:32:18.497Z"}
{"msg":"@rjones thanks. I think we closed the one that was stuck. I haven't seen others yet.","username":"Dan","ts":"2018-05-08T12:50:54.181Z"}
{"msg":"Has joined the channel.","username":"danintel","ts":"2018-05-09T21:33:44.162Z","type":"uj"}
{"msg":"Has joined the channel.","username":"lucienlu","ts":"2018-05-10T11:57:50.135Z","type":"uj"}
{"msg":"@TomBarnes @amundson see #TSC for some discussion on the copyright header","username":"Dan","ts":"2018-05-10T14:38:16.816Z"}
{"msg":"One comment from LF legal is that the copyright notice is not required. Putting a notice at the top of a file does not assign copyright. A legal agreement must be executed to assign copyright. The notice at the top of a file is meant to help track attributions as files are copied outside of the originating project. I've asked for clarity regarding a copyright notice at the top of the source file vs some conventional way to reference the notices file.","username":"Dan","ts":"2018-05-10T14:40:46.016Z"}
{"msg":"Conclusion is that this issue will go to the HL legal committee for some further discussion and direction.","username":"Dan","ts":"2018-05-10T14:41:04.531Z"}
{"msg":"@Dan The current conventions seem appropriate, so I'm not sure why you are advocating for a change.","username":"amundson","ts":"2018-05-10T16:45:37.882Z"}
{"msg":"Because having multiple copyright notices at the top of each file are unmanageable. And the frequency of intel copyright notices has caused at least one contributor to think they needed to include that in their contribution - I think it's generally counter to growing community.","username":"Dan","ts":"2018-05-10T16:47:09.774Z"}
{"msg":"if you are interested in Sawtooth Sabre, please join #sawtooth-sabre ","username":"amundson","ts":"2018-05-10T18:07:59.872Z"}
{"msg":"Sabre Announcement: https://lists.hyperledger.org/g/sawtooth/message/280","username":"amundson","ts":"2018-05-10T22:47:56.534Z"}
{"msg":"Hi everyone, I'm newbie in Sawtooth development, I have one question, hope someone can help. \n\nI see in Github, Sawtooth-core repository was registered as a Python repository, is that true? I see on its source code, almost all components was built by Python like rest_api, transaction families, but the validator was built by Rust, is that correct? Do you know why? Is that Python have problems? and not sufficient with Sawtooth Validator?","username":"tungdt_socoboy","ts":"2018-05-13T15:46:16.084Z"}
{"msg":"@tungdt_socoboy GitHub automagically guesses the code type.","username":"rjones","ts":"2018-05-13T16:12:37.622Z"}
{"msg":"@Dan I'm not familiar with the HL legal committee. Who has a voice on that committee? Is this a committee formed by the TSC? Is it distinct from LF legal?","username":"amundson","ts":"2018-05-13T16:17:17.534Z"}
{"msg":"@Dan I agree with the policy of not including copyright notices - I have also ended up creating new files that have apparent Intel copyright occasionally.","username":"grkvlt","ts":"2018-05-13T18:00:45.451Z"}
{"msg":"Be careful what you wish for - the logical progression here is everyone making copyright declarations in every single commit message similar to the Signed-off-by statement.","username":"amundson","ts":"2018-05-13T23:39:45.718Z"}
{"msg":"If the HL legal committee is tasked with finding suitable language for the top of the file, that's really insufficient, because it doesn't fully answer the question of how we might reconstruct an accurate copyright history.","username":"amundson","ts":"2018-05-13T23:49:57.441Z"}
{"msg":"Currently, the Copyright at the top of the file is a more accurate method of determining copyright than the commit history, even if in some cases it is not completely accurate (those instances are probably easily identified by committer not acting on behalf of the copyright holder stated at the top of the file). If we flip it around, where we are expecting commit history to do the work for us, that requires more thought and likely more work at the commit level from everyone.","username":"amundson","ts":"2018-05-13T23:54:37.839Z"}
{"msg":"@grkvlt re: \"I think we should add support for SAWTOOTH_HOME and SAWTOOTH_KEYS environment variables to most Sawtooth utilities and services.\" -- we used to have similar support for this in 0-7 with the CURRENCY_* variables and dropped it when we transitioned to 0.8. I'd happily co-author and RFC with you on the larger scope of \"path resolution process\" if you are interested (and no one is dissenting on the general idea).","username":"amundson","ts":"2018-05-14T00:31:14.348Z"}
{"msg":"@amundson really, copyright as *legal* matter is, i believe, a non-issue, since everything is licensed as APACHE-2 and all contributors, by submitting commits, license their code as APACHE-2, so the problem is more that the copyright message is *wrong*","username":"grkvlt","ts":"2018-05-14T00:34:46.875Z"}
{"msg":"but, as always, check with a lawyer ;)","username":"grkvlt","ts":"2018-05-14T00:35:00.495Z"}
{"msg":"It is an issue, because the owner of the copyright is the only legal entity which can bring a lawsuit against an infringing party","username":"amundson","ts":"2018-05-14T00:36:00.316Z"}
{"msg":"If we can not suitably determine copyright, it would probably hurt such a case in the future if one where necessary","username":"amundson","ts":"2018-05-14T00:36:34.222Z"}
{"msg":"what kind of lawsuit?","username":"grkvlt","ts":"2018-05-14T00:36:39.977Z"}
{"msg":"for the purposes of determining copyright you'll have to go on git history to get authorship, so those headers are not useful anyway","username":"grkvlt","ts":"2018-05-14T00:37:26.105Z"}
{"msg":"authorship is different than who owns copyright, and for this project, that detail matters","username":"amundson","ts":"2018-05-14T00:38:01.786Z"}
{"msg":"right, but i'm unclear how a 'Copyright 2017 Intel' message on a file will clarify that portions of that file are copyright 2018 Cloudsoft Corporation because I wrote them. it still seems like the notices aren't useful.","username":"grkvlt","ts":"2018-05-14T00:39:43.857Z"}
{"msg":"i don't recall signing anything that assigned copyright to Intel, anyway","username":"grkvlt","ts":"2018-05-14T00:40:26.689Z"}
{"msg":"well, current state, for those that have contributed for different copyright holders (Intel, Cargill, Bitwise IO, etc.) those current copyright headers are accurate","username":"amundson","ts":"2018-05-14T00:40:36.357Z"}
{"msg":"(or accurate enough)","username":"amundson","ts":"2018-05-14T00:40:41.481Z"}
{"msg":"but they'll diverge. and in the future will be more and more wrong. so, the solution used by most OSS projects is to not have copyright on files, just the license, and have (if deemed necessary) a NOTICE file with copyright statements, which is (I think) what @Dan and myself were suggesting","username":"grkvlt","ts":"2018-05-14T00:42:47.224Z"}
{"msg":"it might be good to make `CONTRIBUTING.md` more explicit about copyright issues, too?","username":"grkvlt","ts":"2018-05-14T00:44:12.761Z"}
{"msg":"Those projects are relying on being able to reverse engineer copyright from git history, which is why I bring up the issue with that for our project.","username":"amundson","ts":"2018-05-14T00:45:36.247Z"}
{"msg":"the sawtooth contributing guidlines say that too - it states that the commit for a file (with sign-off) is the developer indicating compliance with the DCO (developer certificate of origin) which is the legal source of copyright, so `git blame` and authorship *are* the source of truth for sawtooth copyrights.\n> The contribution was created in whole or in part by me and I have the right to submit it under the open source license indicated in the file\nhttp://developercertificate.org/","username":"grkvlt","ts":"2018-05-14T00:47:41.038Z"}
{"msg":"https://sawtooth.hyperledger.org/docs/core/releases/latest/community/contributing.html\n> Each commit must include a “Signed-off-by” line in the commit message (git commit -s). This sign-off indicates that you agree the commit satisfies the Developer Certificate of Origin (DCO).","username":"grkvlt","ts":"2018-05-14T00:48:04.612Z"}
{"msg":"Again, you are confusing authorship with the copyright holder.  You can determine the individual that authored it but not necessarily the copyright holder. In some cases, but not all, you can derive one from the other.","username":"amundson","ts":"2018-05-14T00:54:48.429Z"}
{"msg":"I'm not suggesting we can't make a change, but it should at least be well thought out, not on a whim without considering these issues.","username":"amundson","ts":"2018-05-14T00:57:23.900Z"}
{"msg":"hm, think i see what you mean, but for those cases, surely that's pretty much what the NOTICES file is for? but, where there is a legal issue, as i understand it authorship is often exactly what they want to know, and lawyers then as the author various things about their terms of employment, contracts and so on to determine the actual copyright holder. basically legal issues occur because the file says copyright B, and was written by A, but it turns out because A was a sub-contractor of C and did the work during office hours, the file is acually copyright C. so the *important* thing is authorship, as that lets us derive copyright in the instances where it has become a problem. the NOTICES file can give a good-faith set of copyright holders, but that's probably the best we can do.","username":"grkvlt","ts":"2018-05-14T01:06:00.831Z"}
{"msg":"hm, think i see what you mean, but for those cases, surely that's pretty much what the NOTICES file is for? but, where there is a legal issue, as i understand it authorship is often exactly what they want to know, and lawyers then ask the author various things about their terms of employment, contracts and so on to determine the actual copyright holder. basically legal issues occur because the file says copyright B, and was written by A, but it turns out because A was a sub-contractor of C and did the work during office hours, the file is acually copyright C. so the *important* thing is authorship, as that lets us derive copyright in the instances where it has become a problem. the NOTICES file can give a good-faith set of copyright holders, but that's probably the best we can do.","username":"grkvlt","ts":"2018-05-14T01:06:00.831Z"}
{"msg":"however, as you point out, let's not rush into anything!","username":"grkvlt","ts":"2018-05-14T01:07:16.491Z"}
{"msg":"FWIW - not my first time dealing with this; in 1999 this is the approach we took w/GTK+ and GIMP - https://gitlab.gnome.org/GNOME/gtk/commit/279e878bddb61086f813385dc94fd04a5465473a","username":"amundson","ts":"2018-05-14T01:07:41.665Z"}
{"msg":"also, now I feel old :)","username":"amundson","ts":"2018-05-14T01:08:18.359Z"}
{"msg":"right, have the AUTHORS file as the list of contributors...","username":"grkvlt","ts":"2018-05-14T01:12:18.483Z"}
{"msg":"would be interesting to have a definitive statement from linux foundation legal about the best practices they recommend","username":"grkvlt","ts":"2018-05-14T01:13:00.830Z"}
{"msg":"(oh, and _why_ they recommend them, of course!)","username":"grkvlt","ts":"2018-05-14T01:13:22.632Z"}
{"msg":"They aren't one of the parties which hold copyright, and its much more important that all of the primary copyright holders and maintainers agree before we move forward. Maybe that's just a reasonable proposal we haven't seen yet.","username":"amundson","ts":"2018-05-14T01:35:40.095Z"}
{"msg":"Has joined the channel.","username":"paul.sitoh","ts":"2018-05-16T16:21:00.113Z","type":"uj"}
{"msg":"@pankajgoyal plz familiarize yourself with this: https://github.com/Cargill/sawtooth-rfcs/blob/c006-docker-compose-builds/text/0000-docker-compose-builds.md ","username":"Dan","ts":"2018-05-17T12:57:45.142Z"}
{"msg":"Has joined the channel.","username":"svanschalkwyk","ts":"2018-05-18T21:11:43.892Z","type":"uj"}
{"msg":"Has joined the channel.","username":"Sarah.Conway","ts":"2018-05-21T19:48:52.288Z","type":"uj"}
{"msg":"hi all. I am new to working on marketing/PR for Hyperledger. We are writing a follow up Consensus blog for the HL site that focuses on interoperability. Can someone share a few sentences, maybe 2-3, on what concrete progress we have made or are we planning to make with #sawtooth on this front? Or feel free to point me to some urls, PPTs, etc. Thanks!","username":"Sarah.Conway","ts":"2018-05-21T20:12:38.561Z"}
{"msg":"Has joined the channel.","username":"Johnjam","ts":"2018-05-22T07:02:57.163Z","type":"uj"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=jAWsbeQsaRb7vJ7Zv) @Sarah Conway I would ask @Dan (not me--the other Dan). I understand a RAFT concensus engine is planned. RAFT uses an elected leader mechanism and is Crash Fault Tolerant, but not Byzantine Fault Tolerant. Existing Consensus engines are PoET simulator, PoET SGX, and (for development and testing only) Dev Mode.","username":"danintel","ts":"2018-05-22T14:28:42.965Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=jAWsbeQsaRb7vJ7Zv","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=jAWsbeQsaRb7vJ7Zv","remote":true,"fileId":null,"fileName":null}]}
{"msg":"oh no the spaces in username bug strikes again","username":"rjones","ts":"2018-05-22T14:29:32.987Z"}
{"msg":"Sawtooth uses an unpluggable consensus engine mechanism. New engines can be added and can be changed on-the-fly","username":"danintel","ts":"2018-05-22T14:30:27.345Z"}
{"msg":"I suggest we rename poet implementations to PoET/BFT (currently PoET/SGX) and PoET/CFT (currently PoET/Simulator) to clarify the capabilities. Also 'simulator' is misleading/confusing at this level since it just means \"without SGX\".","username":"amundson","ts":"2018-05-22T16:06:54.021Z"}
{"msg":"Agreed. Been wanting to do that for a while. (poet flavor renaming, that is)","username":"Dan","ts":"2018-05-22T16:24:47.876Z"}
{"msg":"@Sarah Conway Earlier this year Sawtooth 1.0 released with Hyperledger's only Byzantine Fault Tolerant consensus and an industry first feature we called Dynamic Consensus. Dynamic Consensus goes beyond pluggable consensus to allow networks to change consensus on the fly. Sawtooth supports 3 consensus protocols right now and two more are in development. Also in development is a change to the sawtooth consensus API that will allow consensus providers written in a variety of languages. This follows a similar pattern to Sawtooth's support for smart contracts in a variety of languages. This expands the breadth of possible consensus algorithms/protocols that can be easily coupled to Sawtooth. ","username":"Dan","ts":"2018-05-22T16:31:30.915Z"}
{"msg":"@Dan thank you very much. This is great. We'll drop it into our blog draft. ","username":"Sarah.Conway","ts":"2018-05-22T17:09:34.034Z"}
{"msg":"@Sarah Conway if it works with the blog flow you might also reach out to academia in the article... While Sawtooth is developed to be a production platform, some of us also consider Sawtooth as a great research platform for consensus and other blockchain areas. Where researchers are creating new algorithms, they might find Sawtooth makes a handy platform so that they can compare and contrast with other protocols and don't have to write all the networking and other components incidental to their algorithms.","username":"Dan","ts":"2018-05-22T17:28:19.666Z"}
{"msg":"Hi All, Is there any support for Sawtooth on Ubuntu 18.LTS? in other words how to install sawtooth on Ubuntu 18?","username":"rkrish82","ts":"2018-05-23T10:13:30.490Z"}
{"msg":"No we don't support ubuntu 18 as of now","username":"askmish","ts":"2018-05-23T12:19:28.521Z"}
{"msg":"@amundson does sawtooth use x509 cert for identifying validators?","username":"MicBowman","ts":"2018-05-23T16:20:06.532Z"}
{"msg":"are you binding ecdsa keys to any concept of an institutional identity?","username":"MicBowman","ts":"2018-05-23T16:20:30.140Z"}
{"msg":"We're interested in moving to Ubuntu 18. Certainly open to patches! :)","username":"Dan","ts":"2018-05-23T17:30:03.026Z"}
{"msg":"Please join the Hyperledger Sawtooth Technical Forum on Thursday, May 24th at 10am CDT for the following discussion:\n\nPoET 2.0 Preview (Ashish Mishra)\n\nJoin from PC, Mac, Linux, iOS or Android:\nhttps://zoom.us/my/hyperledger.community","username":"Dan","ts":"2018-05-23T18:02:27.832Z"}
{"msg":"@MicBowman identity of a validator is the public portion of the ecdsa key. could tie that to a x509 cert via a transaction family, but I don't know of an implementation of that.","username":"amundson","ts":"2018-05-24T00:21:30.526Z"}
{"msg":"@MicBowman Cargill has some not-yet-released stuff around identity that does tie ecdsa public keys to organizations; it is something we might bring to Sabre since a component of it is wasm-related.","username":"amundson","ts":"2018-05-24T00:27:11.571Z"}
{"msg":"Has joined the channel.","username":"fedealconada","ts":"2018-05-24T09:05:11.731Z","type":"uj"}
{"msg":"hi all, is it possible to have the CreateContract permission that Hyperledger Burrow has here in Sawtooth?\n","username":"fedealconada","ts":"2018-05-24T09:05:34.051Z"}
{"msg":"@fedealconada check over in #sawtooth-seth - there's probably more :eyes: over there for EVM/Burrow+sawtooth stuff.","username":"Dan","ts":"2018-05-24T13:47:23.071Z"}
{"msg":"great, thanks @Dan !","username":"fedealconada","ts":"2018-05-24T13:47:54.705Z"}
{"msg":"@dampuero thanks","username":"MicBowman","ts":"2018-05-24T14:13:19.147Z"}
{"msg":"Has joined the channel.","username":"dampuero","ts":"2018-05-24T14:13:19.367Z","type":"uj"}
{"msg":"Has joined the channel.","username":"john_whitton","ts":"2018-05-24T16:53:51.081Z","type":"uj"}
{"msg":"I'm proposing the Supply Chain Subteam RFC enter FCP - https://github.com/hyperledger/sawtooth-rfcs/pull/11 - @Dan @TomBarnes @agunde @adamludvik @jsmitchell @kelly_ @pschwarz ","username":"amundson","ts":"2018-05-25T18:45:46.816Z"}
{"msg":"I pre-populated the checklist with those that already approved or said lgtm or +1, but I'll give some time to remove approval before declaring FCP if those comments/approvals were not intended to be FCP-related","username":"amundson","ts":"2018-05-25T18:46:49.881Z"}
{"msg":"are those checkboxes some kind of special github syntax? Can you only check the one associated with your name?","username":"jsmitchell","ts":"2018-05-25T18:49:10.815Z"}
{"msg":"edit, then add an x like the others","username":"amundson","ts":"2018-05-25T18:49:26.168Z"}
{"msg":"and no, there is no special permission system","username":"amundson","ts":"2018-05-25T18:49:58.698Z"}
{"msg":"can you see a diff history with blame on that message?","username":"jsmitchell","ts":"2018-05-25T18:50:19.886Z"}
{"msg":"AFAIK, no","username":"amundson","ts":"2018-05-25T18:50:35.386Z"}
{"msg":"we could make the process such that you have to approve the PR, and then we will check your name off on the list, if you feel better about that","username":"amundson","ts":"2018-05-25T18:51:52.910Z"}
{"msg":"Has joined the channel.","username":"donatopellegrino","ts":"2018-05-28T13:26:27.533Z","type":"uj"}
{"msg":"when I looked at that a while back seemed like the rust guys were operating with the checkboxes w/o PR's / traceability. I think you need write access on the repo to do that? Anyway I'm fine operating with less process until we have some issue that requires us to add more process. this is already pretty formal for the size of team we have.","username":"Dan","ts":"2018-05-29T14:19:00.080Z"}
{"msg":"Has joined the channel.","username":"nhrishi","ts":"2018-05-30T01:25:38.581Z","type":"uj"}
{"msg":"Has joined the channel.","username":"tim-d-blue","ts":"2018-05-31T15:13:38.584Z","type":"uj"}
{"msg":"Hey Sawtooth folks! RFCs for future Supply Chain development are going to start pouring in. Get ready to read and comment _a lot_ if you are interested in the platform. ","username":"zac","ts":"2018-05-31T21:40:53.911Z"}
{"msg":"First PR is here:\nhttps://github.com/hyperledger/sawtooth-rfcs/pull/13","username":"zac","ts":"2018-05-31T21:40:59.781Z"}
{"msg":"And more:\nhttps://github.com/hyperledger/sawtooth-rfcs/pull/14\nhttps://github.com/hyperledger/sawtooth-rfcs/pull/15","username":"zac","ts":"2018-05-31T22:09:59.049Z"}
{"msg":"https://github.com/hyperledger/sawtooth-rfcs/pull/16","username":"zac","ts":"2018-05-31T22:13:12.414Z"}
{"msg":"https://github.com/hyperledger/sawtooth-rfcs/pull/17","username":"zac","ts":"2018-05-31T22:18:12.426Z"}
{"msg":"Hopefully that's enough","username":"zac","ts":"2018-05-31T22:18:19.077Z"}
{"msg":"do we have formal coding standards for rust? (like the python style rules we enforce with pylint?)","username":"Dan","ts":"2018-06-04T19:02:51.548Z"}
{"msg":"https://github.com/rust-lang-nursery/rustfmt though it currently changes often. ","username":"agunde","ts":"2018-06-04T19:16:06.569Z"}
{"msg":"thanks. looks like that follows this style guide https://github.com/rust-lang-nursery/fmt-rfcs/blob/master/guide/guide.md. ","username":"Dan","ts":"2018-06-04T21:42:54.201Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=5NJPCbecSzgTbzNAu) @Dan Speaking of pylint, I noticed the Python code is pylint3-dirty.  Has pylint3 ever been ran on the sawtooth-core code? Or is it just a very infrequent thing?","username":"danintel","ts":"2018-06-05T14:30:56.615Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=5NJPCbecSzgTbzNAu","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=5NJPCbecSzgTbzNAu","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Hi @danintel. bin/run_lint is run continuously. That uses pycodestyle and pylint. I haven't looked at pylint3. Note that we have config file(s?) for pylint to squelch some of the warnings.","username":"Dan","ts":"2018-06-05T14:48:16.188Z"}
{"msg":"Hi @danintel . bin/run_lint is run continuously. That uses pycodestyle and pylint. I haven't looked at pylint3. Note that we have config file(s?) for pylint to squelch some of the warnings.","username":"Dan","ts":"2018-06-05T14:48:16.188Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=G4vXWNjCswbK22LLA) Good to know. pylint has false positives that are suppressed with pylint3 when using Python 3-specific features, at least for me (such as with `print`).","username":"danintel","ts":"2018-06-05T16:04:11.875Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=G4vXWNjCswbK22LLA","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=G4vXWNjCswbK22LLA","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Is there a reason all the files in /var/lib/sawtooth/ are globally readable? (including the block chain and Merkle Trie)","username":"danintel","ts":"2018-06-05T22:41:15.178Z"}
{"msg":"The data within the network goes to everyone in the network. Seems like it would be a narrow use case to make the data unreadable to some users on the validator host. Do you have something in mind, or just general best practices on minimal permissions?","username":"Dan","ts":"2018-06-05T23:52:18.786Z"}
{"msg":"The data within the network goes to everyone in the network. Seems like it would be a narrow use case that would require the data to be unreadable to some users on the validator host. Do you have something in mind, or just general best practices on minimal permissions?","username":"Dan","ts":"2018-06-05T23:52:18.786Z"}
{"msg":"No use case, but security-in-depth. If someone \"breaks in\" to a host as a regular user, it would be nice if they would not have access to all the data in a node (blockchain and state).\n\nThis is distinct from everyone on the permissioned network having access to the data.","username":"danintel","ts":"2018-06-06T05:38:00.131Z"}
{"msg":"Has joined the channel.","username":"aaroncolaco","ts":"2018-06-06T08:45:40.946Z","type":"uj"}
{"msg":"That's reasonable. Personally I feel like most blockchain data is going to need to be stuff that isn't sensitive to exposure. Even if everything is encrypted and permissioned it's still shared with m individuals at n other companies. The business model around this is going to be in order to do business efficiently we all share such and such info.","username":"Dan","ts":"2018-06-06T13:17:14.798Z"}
{"msg":"@danintel I believe the intent is /var/lib/sawtooth directory is created with 750 with user:group being sawtooth:sawtooth. For deb installs, this is done via validator/packaging/ubuntu/postinst. If you are seeing different behavior on a clean ubuntu install, it would be good to figure out why.","username":"amundson","ts":"2018-06-06T17:42:34.210Z"}
{"msg":"in docker, none of that matters as everything is root","username":"amundson","ts":"2018-06-06T17:43:03.458Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=z8sr5HKCBrwNui52R) @amundson I have /var/log/sawtooth/ as 750, but /var/adm/sawtooth/ is 755. This is after installing on two Ubuntu 16.04.4 systems following the instructions for Sawtooth install on Ubuntu","username":"danintel","ts":"2018-06-06T22:30:52.501Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=z8sr5HKCBrwNui52R","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=z8sr5HKCBrwNui52R","remote":true,"fileId":null,"fileName":null}]}
{"msg":"I ran the script manually, \n`sudo bash -x ./validator/packaging/ubuntu/postinst configure`\nAnd it fixed the `/var/lib/sawtooth/` permissions to 0750. The only error was a chmod on the non-existent `/etc/sawtooth/*.toml*` directory.","username":"danintel","ts":"2018-06-06T22:58:30.576Z"}
{"msg":"I ran the script manually, \n`sudo bash -x ./validator/packaging/ubuntu/postinst configure`\nAnd it fixed the `/var/lib/sawtooth/` permissions to 0750. The only error was a chmod on the non-existent `/etc/sawtooth/*.toml*` file","username":"danintel","ts":"2018-06-06T22:58:30.576Z"}
{"msg":"hmm, what is in /var/adm/sawtooth?","username":"amundson","ts":"2018-06-06T22:58:32.453Z"}
{"msg":"So then I did `apt remove python3-sawtooth-sdk; apt install python3-sawtooth-sdk` and the permissions of `/var/adm/sawtooth`, newly recreated, is 755","username":"danintel","ts":"2018-06-06T22:59:40.709Z"}
{"msg":"Here is the contents (empty), after reinstall:\n`# ls -la /var/lib/sawtooth\ntotal 8\ndrwxr-xr-x  2 sawtooth sawtooth 4096 Apr 30 12:26 .\ndrwxr-xr-x 55 root     root     4096 Jun  6 15:57 ..`","username":"danintel","ts":"2018-06-06T23:00:04.016Z"}
{"msg":"Here is the contents (empty), after reinstall:\n`# ls -la /var/lib/sawtooth`\n`total 8`\n`drwxr-xr-x  2 sawtooth sawtooth 4096 Apr 30 12:26 .`\n`drwxr-xr-x 55 root     root     4096 Jun  6 15:57 ..`","username":"danintel","ts":"2018-06-06T23:00:04.016Z"}
{"msg":"Both /var/lib/sawtooth and /var/adm/sawtooth are 0755 and empty (after reinstall)","username":"danintel","ts":"2018-06-06T23:04:01.985Z"}
{"msg":"This is a good demo for why the files, not just the containing directory, should have tightened permissions. Which is to have multiple layers of defense (in this case against some packaging issue).","username":"danintel","ts":"2018-06-06T23:12:41.124Z"}
{"msg":"why would the sdk package make any difference?","username":"amundson","ts":"2018-06-07T17:11:55.318Z"}
{"msg":"Has joined the channel.","username":"bridgerherman","ts":"2018-06-07T18:38:00.675Z","type":"uj"}
{"msg":"Because the files are installed from package `python3-sawtooth-sdk`:\n`$ apt-get download python3-sawtooth-sdk\nGet:1 http://repo.sawtooth.me/ubuntu/1.0/stable xenial/universe amd64 python3-sawtooth-sdk all 1.0.4-1 [33.2 kB]\n$ dpkg --contents *.deb |grep /var/.../'$'\ndrwxr-xr-x root/root         0 2018-04-30 12:26 ./var/lib/\ndrwxr-xr-x root/root         0 2018-04-30 12:26 ./var/log/`\nYour question implies there is another package or another post-install method to set the permissions.  That may be the root problem.  If the python3-sawtooth-sdk installs directories and another package installs the directories, and a `postinst` script or another script modifies the ownership/permissions, there may be a race condition here.","username":"danintel","ts":"2018-06-07T20:09:38.715Z"}
{"msg":"Because the directories are installed from package `python3-sawtooth-sdk`:\n`$ apt-get download python3-sawtooth-sdk\nGet:1 http://repo.sawtooth.me/ubuntu/1.0/stable xenial/universe amd64 python3-sawtooth-sdk all 1.0.4-1 [33.2 kB]\n$ dpkg --contents *.deb |grep /var/.../'$'\ndrwxr-xr-x root/root         0 2018-04-30 12:26 ./var/lib/\ndrwxr-xr-x root/root         0 2018-04-30 12:26 ./var/log/`\nYour question implies there is another package or another post-install method to set the permissions.  That may be the root problem.  If the python3-sawtooth-sdk installs directories and another package installs the directories, and a `postinst` script or another script modifies the ownership/permissions, there may be a race condition here.","username":"danintel","ts":"2018-06-07T20:09:38.715Z"}
{"msg":"So what package runs the `postinst` script?  I think it should be `python3-sawtooth-sdk` as this package installs the directories (at least it is in the package manifest).","username":"danintel","ts":"2018-06-07T20:12:08.246Z"}
{"msg":"I also looked in the base `sawtooth_1.0.4_all.deb` Ubuntu package.  Nothing there under `var/` (just `/usr/share/doc/sawtooth/`). Is that where `postinst` is ran?  If so, it may be overwritten by the later install of `python3-sawtooth-sdk`","username":"danintel","ts":"2018-06-07T23:31:13.876Z"}
{"msg":"Or maybe fixing the `var/{log,lib}/` directory perms were done post-1.0.4 release?","username":"danintel","ts":"2018-06-07T23:42:44.373Z"}
{"msg":"I think python3-sawtooth-sdk is broken if it is doing anything with /var/{log,lib}","username":"amundson","ts":"2018-06-08T02:55:55.949Z"}
{"msg":"```\ndiff --git a/sdk/python/setup.py b/sdk/python/setup.py\nindex 799138b4..104478d1 100644\n--- a/sdk/python/setup.py\n+++ b/sdk/python/setup.py\n@@ -15,28 +15,10 @@\n\n from __future__ import print_function\n\n-import os\n import subprocess\n\n from setuptools import setup, find_packages\n\n-\n-if os.name == 'nt':\n-    conf_dir = \"C:\\\\Program Files (x86)\\\\Intel\\\\sawtooth\\\\conf\"\n-    data_dir = \"C:\\\\Program Files (x86)\\\\Intel\\\\sawtooth\\\\data\"\n-    log_dir = \"C:\\\\Program Files (x86)\\\\Intel\\\\sawtooth\\\\logs\"\n-else:\n-    conf_dir = \"/etc/sawtooth\"\n-    data_dir = \"/var/lib/sawtooth\"\n-    log_dir = \"/var/log/sawtooth\"\n-\n-data_files = [\n-    (conf_dir, []),\n-    (os.path.join(conf_dir, \"keys\"), []),\n-    (data_dir, []),\n-    (log_dir, []),\n-]\n-\n setup(\n     name='sawtooth-sdk',\n     version=subprocess.check_output(\n@@ -45,7 +27,6 @@ setup(\n     author='Hyperledger Sawtooth',\n     url='https://github.com/hyperledger/sawtooth-core',\n     packages=find_packages(),\n-    data_files=data_files,\n     install_requires=[\n         \"colorlog\",\n         \"sawtooth-signing\",\n```","username":"amundson","ts":"2018-06-08T02:58:27.488Z"}
{"msg":"I didn't test that, but it probably fixes that issue","username":"amundson","ts":"2018-06-08T02:58:39.930Z"}
{"msg":"@danintel ^","username":"amundson","ts":"2018-06-08T02:59:24.646Z"}
{"msg":"Has joined the channel.","username":"abraham","ts":"2018-06-08T04:52:20.987Z","type":"uj"}
{"msg":"I believe this commit to be the reason memory usage was so high in the 1-0-staging-01 branch were testing to become 1.0.5 https://github.com/hyperledger/sawtooth-core/commit/c4c07fb70627cc2cf442ce4d888d5adf9f7eccf5","username":"rberg2","ts":"2018-06-08T16:21:09.168Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=Hs2e6CKYQSe225XXb) Solved: The `/var/???/sawtooth` permissions are fixed in the nightly packages (`rwxr-x---`), but only if the directory didn't previously and didn't have left over files from a previous install of the earlier 1.0.4.","username":"danintel","ts":"2018-06-08T18:47:31.274Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=Hs2e6CKYQSe225XXb","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=Hs2e6CKYQSe225XXb","remote":true,"fileId":null,"fileName":null}]}
{"msg":"thanks @rberg2 ","username":"Dan","ts":"2018-06-08T19:35:34.497Z"}
{"msg":"@pschwarz @adamludvik @amundson for the 1.0.5 issue, I think we either \n1. Remove the commit above\n2. Shorten `base_keep_time`\n3. Set a size limit on both caches.\nOption 2 seems like tuning a bandaid - i.e. we may tune for a while still without full resolution.\nOption 3 seems like surgery on a bandaid - i.e. making this class a conjunction of a timed cache and a circularly linked list has a big chance of introducing new bugs.\nI'm inclined towards dropping the commit and listing the issue in the release notes as a known issue.","username":"Dan","ts":"2018-06-10T19:48:47.377Z"}
{"msg":"@dan option 3 isn't practical as these objects are not pure caches","username":"amundson","ts":"2018-06-11T06:41:55.067Z"}
{"msg":"@Dan  option 3 isn't practical as these objects are not pure caches","username":"amundson","ts":"2018-06-11T06:41:55.067Z"}
{"msg":"Hi everyone, I have a quite simple question but couldn't found an answer yet, hope someone can help me to answer this. \n\nThe question is: I know that Ethereum smart contract could be supported in Sawtooth, I wondering what natively other kind of smart contract was develop in Sawtooth? Natively like Ethereum has Ethereum Solidity smart contract run on EVM, so what kind of smart contract (chain code) natively built on Sawtooth, able to run on Sawtooth? In general, smart contract was a chain code deployed and stored inside blockchain data, is it same as in Sawtooth? Smart contract was deployed (saved in blockchain) and cannot be changed? ","username":"tungdt_socoboy","ts":"2018-06-11T10:50:58.121Z"}
{"msg":"Thank you","username":"tungdt_socoboy","ts":"2018-06-11T10:51:00.457Z"}
{"msg":"@tungdt_socoboy that's a good question for #sawtooth - there's a lot of people there that can help answer that question.  :)","username":"Dan","ts":"2018-06-11T14:09:44.210Z"}
{"msg":"It has been a known issue for quite some time, so it's not new - it's just that this fix doesn't correct it in the 1.0.x branch ","username":"pschwarz","ts":"2018-06-11T14:13:52.684Z"}
{"msg":"It's a bandaide in master, but that should be replaced in the future in completely unbackportable ways.","username":"pschwarz","ts":"2018-06-11T14:14:28.393Z"}
{"msg":"Right. So my recommendation is we drop the commit from 1.0.5. Other option I can come up with is to tune the bandaid which seems like a waste of time.","username":"Dan","ts":"2018-06-11T14:22:59.107Z"}
{"msg":"Yep","username":"pschwarz","ts":"2018-06-11T14:23:28.387Z"}
{"msg":" @Dan Yeah, drop","username":"adamludvik","ts":"2018-06-11T15:57:26.749Z"}
{"msg":"Has joined the channel.","username":"markg 17","ts":"2018-06-11T22:36:12.408Z","type":"uj"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=w6bzqeapxKfMm5qX9) @Dan Thank you, I will forward it into the #sawtooth channel","username":"tungdt_socoboy","ts":"2018-06-12T07:35:26.566Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=w6bzqeapxKfMm5qX9","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=w6bzqeapxKfMm5qX9","remote":true,"fileId":null,"fileName":null}]}
{"msg":"We should publish recommended system specs. (feedback from an HL discussion)","username":"Dan","ts":"2018-06-12T16:17:52.292Z"}
{"msg":"the documentation never says \"spinning rust is death\"","username":"rjones","ts":"2018-06-12T16:20:18.749Z"}
{"msg":"Has joined the channel.","username":"pauljithink","ts":"2018-06-14T01:39:47.195Z","type":"uj"}
{"msg":"Has joined the channel.","username":"rock_martin","ts":"2018-06-15T13:04:49.539Z","type":"uj"}
{"msg":":exclamation: PRs are up to remove the JS SDK from core :exclamation: \nhttps://github.com/hyperledger/sawtooth-core/pull/1730\nhttps://github.com/hyperledger/sawtooth-sdk-javascript/pull/2","username":"zac","ts":"2018-06-18T21:43:14.271Z"}
{"msg":"Has joined the channel.","username":"KevinODonnell","ts":"2018-06-19T02:17:46.580Z","type":"uj"}
{"msg":"Has joined the channel.","username":"yadhuksp","ts":"2018-06-19T05:11:47.522Z","type":"uj"}
{"msg":"Guess what? \nWe now have an SDK channel!! \nYay let's all go over to #sawtooth-sdk-dev and talk about how we get all the SDKs out of core. ","username":"Dan","ts":"2018-06-19T19:53:59.926Z"}
{"msg":"Has joined the channel.","username":"st","ts":"2018-06-20T11:46:58.536Z","type":"uj"}
{"msg":"Has joined the channel.","username":"pyzhang","ts":"2018-06-21T15:50:09.088Z","type":"uj"}
{"msg":"Has left the channel.","username":"rjones","ts":"2018-06-22T15:26:38.871Z","type":"ul"}
{"msg":"Has joined the channel.","username":"neocameback","ts":"2018-06-26T02:40:17.145Z","type":"uj"}
{"msg":"Hi everyone, i would like to understand why sawtooth use zeroMQ instead of other MQ like RabbitMQ or Kafka.\nWhat is the reason here, and should i change to use Kafka in my own project.\nCould anyone here give me some discussions?","username":"neocameback","ts":"2018-06-26T02:46:49.458Z"}
{"msg":"@neocameback speed and maturity of the various language bindings; no centralized or additional processes to run","username":"amundson","ts":"2018-06-26T06:59:43.270Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=3PE2NQzu4Rex9GizE) @amundson Thanks for your sharing, could you please explain more about speed and maturity of language bindings. \nI quite clear for centralized and additional processes","username":"neocameback","ts":"2018-06-26T08:22:57.884Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=3PE2NQzu4Rex9GizE","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=3PE2NQzu4Rex9GizE","remote":true,"fileId":null,"fileName":null}]}
{"msg":"@neocameback in terms of speed, 0MQ is quite fast. we tested some others when we made the selection (a couple years ago) and 0MQ was consistent across languages. for example, grpc was horrifically slow and bad in python but fine in some other languages.","username":"amundson","ts":"2018-06-26T14:08:14.532Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=anvjPbJYGaR5dRDyu) @amundson Oh, i see, thank you very much. It's important things to make decision of 0MQ","username":"neocameback","ts":"2018-06-27T02:18:48.114Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=anvjPbJYGaR5dRDyu","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=anvjPbJYGaR5dRDyu","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Has joined the channel.","username":"rootDistress","ts":"2018-06-27T07:23:48.325Z","type":"uj"}
{"msg":"Has joined the channel.","username":"TheOnlyJoey","ts":"2018-06-27T10:37:49.690Z","type":"uj"}
{"msg":"Good day, i am currently writing up a module as replacement for the rest-api using socket.io for communication, but i have a bit of trouble finding where the actual calls to the blockchain are done in the rest API, is there a simple call API spec for the basic functions or could someone highlight where i can find the actual part sending batches or receiving data on the blockchain","username":"TheOnlyJoey","ts":"2018-06-27T10:39:39.710Z"}
{"msg":"seems like those are raw socket calls? _socket.send_multipart seems to be part of what make things roll","username":"TheOnlyJoey","ts":"2018-06-27T10:50:14.619Z"}
{"msg":"zmq?","username":"TheOnlyJoey","ts":"2018-06-27T10:58:29.183Z"}
{"msg":"ah seems to use zmq?","username":"TheOnlyJoey","ts":"2018-06-27T10:58:29.183Z"}
{"msg":"@TheOnlyJoey yes, 0MQ for underlying communication. messages sent are protobuf messages. look at protos/validator.proto and protos/client_*.proto","username":"amundson","ts":"2018-06-27T13:30:37.728Z"}
{"msg":"yeah already figured out the protobuf part, actually thinking about just setting up a enet service to pingpong the protobuf strings from the blockchain to our backend","username":"TheOnlyJoey","ts":"2018-06-27T13:37:39.241Z"}
{"msg":"Also does Sawtooth support signing a transaction without a predetermined address? want to use this to generate 'physical' tokens for easy distribution on our test network","username":"TheOnlyJoey","ts":"2018-06-27T15:12:25.190Z"}
{"msg":"Has joined the channel.","username":"mychewcents","ts":"2018-06-27T19:09:30.029Z","type":"uj"}
{"msg":"I would suggest asking that out on the #sawtooth , since that is more of a general usage question, as opposed to core platform development","username":"pschwarz","ts":"2018-06-28T07:41:19.387Z"}
{"msg":"Fair enough, thanks","username":"TheOnlyJoey","ts":"2018-06-28T08:59:50.302Z"}
{"msg":"Has joined the channel.","username":"neewy","ts":"2018-06-28T12:21:02.749Z","type":"uj"}
{"msg":"Hi everyone, are there any docs available on implementation of transaction processor? I am wondering how api of Context class works, how does transaction processor takes data from Context class for validation?","username":"neewy","ts":"2018-06-28T12:25:17.732Z"}
{"msg":"@amundson @TomBarnes @jsmitchell @Dan @agunde @adamludvik @pschwarz - Hey all, I wanted to see if we could have a root team call next week to discuss roadmap items for Sawtooth","username":"kelly_","ts":"2018-06-28T14:48:39.927Z"}
{"msg":"The idea would be to brainstorm and identify some larger scale features/improvements with some rough priority for implementation in the next 6-9 months","username":"kelly_","ts":"2018-06-28T14:49:42.815Z"}
{"msg":"Just general information sharing so that we can understand what folks are working on, what they see as highest priority improvements, etc.","username":"kelly_","ts":"2018-06-28T14:50:25.108Z"}
{"msg":"I'm free noon-2pm PST on Monday as one potential timeslot, but let me know what works well for y'all","username":"kelly_","ts":"2018-06-28T14:51:04.145Z"}
{"msg":"@neewy https://sawtooth.hyperledger.org/docs/core/releases/latest/_autogen/sdk_TP_tutorial_python.html","username":"zac","ts":"2018-06-28T14:53:21.880Z"}
{"msg":"Zac, can you explain where I can find out more how Context works?","username":"neewy","ts":"2018-06-28T14:54:56.379Z"}
{"msg":"https://sawtooth.hyperledger.org/docs/core/releases/latest/sdks/python_sdk/processor.html#module-processor.context","username":"zac","ts":"2018-06-28T15:34:32.013Z"}
{"msg":"There is a search bar in those docs to the left btw","username":"zac","ts":"2018-06-28T15:35:27.791Z"}
{"msg":"Wow great","username":"neewy","ts":"2018-06-28T15:43:31.536Z"}
{"msg":"How did you generate these docs?\n","username":"neewy","ts":"2018-06-28T15:44:08.735Z"}
{"msg":" ¯\\_(ツ)_/¯","username":"zac","ts":"2018-06-28T15:45:49.658Z"}
{"msg":"Some Python tool","username":"zac","ts":"2018-06-28T15:45:58.297Z"}
{"msg":"Sphinx does the overall docs","username":"zac","ts":"2018-06-28T15:46:24.464Z"}
{"msg":"I'm not sure what does the docs generated from Python source","username":"zac","ts":"2018-06-28T15:46:40.206Z"}
{"msg":"https://github.com/hyperledger/sawtooth-core/blob/master/docs/Makefile#L67","username":"zac","ts":"2018-06-28T15:47:23.858Z"}
{"msg":"I see there is a sawtooth_signing package. Do you use it so that it provides an interface for cryptographic functionality for TPs?","username":"neewy","ts":"2018-06-28T15:47:33.913Z"}
{"msg":"yes, and the validator itself uses it","username":"zac","ts":"2018-06-28T15:47:58.065Z"}
{"msg":"and by default is that secp256k1?","username":"neewy","ts":"2018-06-28T15:48:01.385Z"}
{"msg":"yes, that is the only option at the moment","username":"zac","ts":"2018-06-28T15:48:13.896Z"}
{"msg":"I bet you've heard about collisions in SHA-512, right?","username":"neewy","ts":"2018-06-28T15:49:00.154Z"}
{"msg":"@kelly_ can you shoot @mfford an email? He can help coordinate schedules. Thx","username":"jsmitchell","ts":"2018-06-28T16:22:07.661Z"}
{"msg":"Has joined the channel.","username":"mfford","ts":"2018-06-28T16:22:09.652Z","type":"uj"}
{"msg":"ok @jsmitchell will do","username":"kelly_","ts":"2018-06-28T16:23:15.386Z"}
{"msg":"also @jsmitchell @amundson I'm going to finally have Dan mule some Sawtooth shirts back to MN this weekend","username":"kelly_","ts":"2018-06-28T16:47:41.438Z"}
{"msg":"so hopefully he can drop those off in the office sometime next week","username":"kelly_","ts":"2018-06-28T16:47:55.670Z"}
{"msg":"I'm having trouble fitting the shirts in balloons.","username":"Dan","ts":"2018-06-28T16:48:19.709Z"}
{"msg":"we're just going to tape them around your body","username":"kelly_","ts":"2018-06-28T16:51:14.832Z"}
{"msg":"Well I wish I had known that before I got the first 3 hidden.","username":"Dan","ts":"2018-06-28T16:51:57.148Z"}
{"msg":"http://i.dailymail.co.uk/i/pix/2016/02/29/16/31B3BA0400000578-3469636-image-m-23_1456761968908.jpg","username":"kelly_","ts":"2018-06-28T16:52:08.412Z"}
{"msg":"nice","username":"Dan","ts":"2018-06-28T16:52:39.331Z"}
{"msg":"Has joined the channel.","username":"rohitkhatri","ts":"2018-06-29T14:08:17.532Z","type":"uj"}
{"msg":"I have setup a `Hyperlder Sawtooth Network` from the `Sawtooth Docs`, you can find `docker-compose.yaml` I used to setup the network here:\n\n https://sawtooth.hyperledger.org/docs/core/releases/1.0/app_developers_guide/sawtooth-default.yaml\n\nI'm running a custom `transaction processor`, and what's happening is after some successful transactions, the batch status is stuck on `PENDING` and when I check the logs of `validator`, there's always a entry says this:\n\n```Unable to find entry at address 5f68a3afa88f4a92fc362957d4c87101c884c97f2fcf92acbd512a2d12ef9d5bee55ee```\n\nAnd in my `transaction processor`, I'm doing `console.log` so I can check whether the `validator` is calling the `apply` function of my processor, but I don't get any logs.\n\nIn brief, after some transactions, the validator is not calling the `apply` function of my `transaction processor`.\n\nIf anybody has faced this issue, please give a hand.","username":"rohitkhatri","ts":"2018-06-29T14:08:42.165Z"}
{"msg":"@rohitkhatri I would suggest that you ask in #sawtooth, which is more focused on app development, versus this channel which is for core development of the platform ","username":"pschwarz","ts":"2018-06-29T14:17:38.958Z"}
{"msg":"@pschwarz sure, thanks.","username":"rohitkhatri","ts":"2018-06-29T14:18:04.355Z"}
{"msg":"Anyone seen this before? (via bin/run_tests -m cli) seems like the validator container is expecting some consensus settings that its not finding. Haven't tried this on jenkins yet but at least its failing on my mac. \n```validator-1_1     | [2018-06-29 19:03:58.259 INFO     path] Skipping path loading from non-existent config file: /etc/sawtooth/path.toml\nvalidator-1_1     | [2018-06-29 19:03:58.259 ERROR    (unknown file)] error executing main\nvalidator-1_1     | Traceback (most recent call last):\nvalidator-1_1     |   File \"/project/sawtooth-core/validator/sawtooth_validator/server/cli.py\", line 104, in main\nvalidator-1_1     |     bind_consensus=args['bind_consensus'],\nvalidator-1_1     | KeyError: 'bind_consensus'\nvalidator-3_1     | [2018-06-29 19:03:58.342 DEBUG    ffi] loading library libsawtooth_validator.so\n```","username":"Dan","ts":"2018-06-29T19:15:12.676Z"}
{"msg":"Hmm is there documentation regarding doing communication directly over ZMQ instead of using the rest-api with sawtooth core?","username":"TheOnlyJoey","ts":"2018-07-06T08:35:00.752Z"}
{"msg":"don't know if there is a small module somewhere for that","username":"TheOnlyJoey","ts":"2018-07-06T08:35:18.609Z"}
{"msg":"basically all i want is to pass the serialized protobuf string from my backend directly to the blockchain without the rest-api","username":"TheOnlyJoey","ts":"2018-07-06T08:49:48.064Z"}
{"msg":"the rest-api module is a bit confusing, a _lot_ of boilerplate","username":"TheOnlyJoey","ts":"2018-07-06T11:15:13.854Z"}
{"msg":"@Dan What branch are you on?","username":"pschwarz","ts":"2018-07-06T14:51:12.041Z"}
{"msg":"that was master a few days ago","username":"Dan","ts":"2018-07-06T14:51:43.041Z"}
{"msg":"@TheOnlyJoey There is only documentation on using ZMQ directly for event subscriptions","username":"pschwarz","ts":"2018-07-06T14:51:44.258Z"}
{"msg":"Look here for some info: https://sawtooth.hyperledger.org/docs/core/nightly/master/app_developers_guide/event_subscriptions.html","username":"pschwarz","ts":"2018-07-06T14:52:11.758Z"}
{"msg":"Otherwise, you'll have to look at the protobuf messages themselves in the repo `sawtooth-core/protos`. The various client protobuf definitions will be the interesting ones for you","username":"pschwarz","ts":"2018-07-06T14:53:40.499Z"}
{"msg":"@pschwarz I think that was a red herring on the cli failure. i already pushed what I was doing to jenkins and it passed and was subsequently merged.","username":"Dan","ts":"2018-07-06T14:55:01.806Z"}
{"msg":"Huh","username":"pschwarz","ts":"2018-07-06T14:55:11.424Z"}
{"msg":"Well, clearly, I am behind on my :rocket: messages","username":"pschwarz","ts":"2018-07-06T14:55:27.943Z"}
{"msg":"@boydjohnson @dplumb @Dan  - T-mobile recently hired someone to drive the NEXT-Directory development forward","username":"kelly_","ts":"2018-07-09T23:49:02.499Z"}
{"msg":"his name is Richard, github username 'yunhangc'","username":"kelly_","ts":"2018-07-09T23:49:26.884Z"}
{"msg":"can we add him to the repo? also @Dan I noticed this PR has been approved but hasn't been merged - https://github.com/hyperledger/sawtooth-next-directory/pull/10","username":"kelly_","ts":"2018-07-09T23:50:36.996Z"}
{"msg":"I thought Mike at write access but maybe not. I just merged it.","username":"Dan","ts":"2018-07-09T23:53:31.700Z"}
{"msg":"As far as adding yunhangc I think the usual procedure is that he needs to be added the the hyperledger group and then we can add him to a specific repo or team.","username":"Dan","ts":"2018-07-09T23:54:39.795Z"}
{"msg":"great, thanks @Dan ","username":"kelly_","ts":"2018-07-09T23:54:42.714Z"}
{"msg":"who needs to add him to HL?","username":"kelly_","ts":"2018-07-09T23:55:42.452Z"}
{"msg":"Ry?","username":"kelly_","ts":"2018-07-09T23:55:47.948Z"}
{"msg":"or can he add himself?","username":"kelly_","ts":"2018-07-09T23:56:03.547Z"}
{"msg":"We do need to get the maintainers formalized for that repo into a MAINTAINERS file. Then the policy can be straight forward like the other repos. i.e. the existing maintainers can add in new maintainers. ","username":"Dan","ts":"2018-07-09T23:56:28.089Z"}
{"msg":"ok, I know Edan has improvements to push too I believe","username":"kelly_","ts":"2018-07-09T23:56:54.544Z"}
{"msg":"@rjones can you remind me how we add people to github teams as far as getting new IDs in to the hyperledger groups?","username":"Dan","ts":"2018-07-09T23:57:12.762Z"}
{"msg":"Has joined the channel.","username":"rjones","ts":"2018-07-09T23:57:12.834Z","type":"uj"}
{"msg":"I think anyone can put up a PR. That is we don't need to do anything with git permissions for PRs - I mean that separately from getting people with review/write access onboarded.","username":"Dan","ts":"2018-07-09T23:57:26.541Z"}
{"msg":"I think anyone can put up a PR.","username":"Dan","ts":"2018-07-09T23:57:26.541Z"}
{"msg":"@dan they need to be invited to the main group, then projects/etc can freely add or remove roles","username":"rjones","ts":"2018-07-10T00:07:38.648Z"}
{"msg":"so send a ticket to helpdesk@hyperledger.org with github IDs and invites will be sent","username":"rjones","ts":"2018-07-10T00:07:58.533Z"}
{"msg":"@ChrisSpanton ^","username":"Dan","ts":"2018-07-10T00:11:13.362Z"}
{"msg":"Has joined the channel.","username":"ChrisSpanton","ts":"2018-07-10T00:11:13.434Z","type":"uj"}
{"msg":"Love it! Thanks guys","username":"ChrisSpanton","ts":"2018-07-10T00:11:48.535Z"}
{"msg":"FYI - https://chat.hyperledger.org/channel/sawtooth-next-directory","username":"kelly_","ts":"2018-07-10T00:13:25.259Z"}
{"msg":"@kelly_ :woo:","username":"ChrisSpanton","ts":"2018-07-10T00:14:08.929Z"}
{"msg":"It's @Dan not @Dan. @Dan is some other guy, @kelly_ :)","username":"rjones","ts":"2018-07-10T00:15:28.577Z"}
{"msg":"case tenderness helps nobody :(","username":"rjones","ts":"2018-07-10T00:15:48.868Z"}
{"msg":"ah yes, I was wondering why I was having problems tagging him","username":"kelly_","ts":"2018-07-10T00:21:25.785Z"}
{"msg":"Has joined the channel.","username":"shannynalayna","ts":"2018-07-10T15:52:46.222Z","type":"uj"}
{"msg":"Hmmm.  Maybe I should change my handle to @dan.  That will really confuse things :robot:","username":"danintel","ts":"2018-07-11T17:43:38.941Z"}
{"msg":"That would be hilarious :grinning:","username":"Dan","ts":"2018-07-12T13:31:38.164Z"}
{"msg":"This PR for the JS SDK is in permanent \"waiting for DCO status\" mode:\nhttps://github.com/hyperledger/sawtooth-sdk-javascript/pull/2","username":"zac","ts":"2018-07-12T14:26:47.683Z"}
{"msg":"I am told either @Dan or @rjones has a fix for this","username":"zac","ts":"2018-07-12T14:27:04.322Z"}
{"msg":"holy cow, I'm not going to review all those commits by hand. @Dan: you tell me to merge it I will do it on your say-so","username":"rjones","ts":"2018-07-12T14:28:41.397Z"}
{"msg":"I don't have a fix, but I was copying them as bug cases to a dco github issue - which I think has since been closed","username":"Dan","ts":"2018-07-12T14:28:41.435Z"}
{"msg":"Yes please merge.","username":"Dan","ts":"2018-07-12T14:28:57.481Z"}
{"msg":"in the past it's been one or two commits to look at.","username":"rjones","ts":"2018-07-12T14:28:57.878Z"}
{"msg":"please make that comment on the PR :)","username":"rjones","ts":"2018-07-12T14:29:21.308Z"}
{"msg":"That PR is grabbing a chunk of sawtooth core and putting it in a new repo that's why there's so many commits.","username":"Dan","ts":"2018-07-12T14:29:29.882Z"}
{"msg":"roger wilco","username":"Dan","ts":"2018-07-12T14:29:33.404Z"}
{"msg":"I believe it has passed DCO in the past","username":"zac","ts":"2018-07-12T14:30:40.447Z"}
{"msg":"Though I don't remember for sure","username":"zac","ts":"2018-07-12T14:31:17.053Z"}
{"msg":"You didn't add any new commits though. That was just picking up commits previously merged to core right?","username":"Dan","ts":"2018-07-12T14:32:39.666Z"}
{"msg":"I did add new commits","username":"zac","ts":"2018-07-12T14:35:11.715Z"}
{"msg":"A couple dozen","username":"zac","ts":"2018-07-12T14:35:16.358Z"}
{"msg":"They are all signed except for the merge commit","username":"zac","ts":"2018-07-12T14:35:24.123Z"}
{"msg":"(I just double checked)","username":"zac","ts":"2018-07-12T14:35:45.991Z"}
{"msg":"what's done is done :)","username":"rjones","ts":"2018-07-12T14:39:02.341Z"}
{"msg":"it's perfect","username":"Dan","ts":"2018-07-12T14:43:21.442Z"}
{"msg":"@Dan Assuming I can get the remove PR in core to pass its build, are we good to go ahead and merge that now?\nhttps://github.com/hyperledger/sawtooth-core/pull/1730","username":"zac","ts":"2018-07-12T14:45:45.464Z"}
{"msg":"meaning that now that js sdk is in it's own repo can we remove it from core?","username":"Dan","ts":"2018-07-12T14:47:29.308Z"}
{"msg":"I assume yes, and I've approved #1730. ","username":"Dan","ts":"2018-07-12T14:49:47.601Z"}
{"msg":"Yeah","username":"zac","ts":"2018-07-12T14:54:16.763Z"}
{"msg":"It has been approved for a little while, I just want to get final buy in from the various product owners before I actually pull the trigger","username":"zac","ts":"2018-07-12T14:54:39.477Z"}
{"msg":"Has joined the channel.","username":"benoit.razet","ts":"2018-07-12T16:49:32.190Z","type":"uj"}
{"msg":"Has joined the channel.","username":"sidhujag","ts":"2018-07-12T18:58:32.620Z","type":"uj"}
{"msg":"Has joined the channel.","username":"PHeinz","ts":"2018-07-12T18:58:37.837Z","type":"uj"}
{"msg":"Has joined the channel.","username":"FrankCastellucci","ts":"2018-07-12T20:16:02.646Z","type":"uj"}
{"msg":"@jsmitchell Perhaps 'generational' wasn't the right term as it can potentially be more complex. Datomic is a perfect implementation of the concept whereas an identifiable data element (with a key) is never actually modified but, instead, the original 'version' is stored and a new 'version' occupies the key location. In addition, and references to the original are maintained as that represented the reference state at the time of creation.  ","username":"FrankCastellucci","ts":"2018-07-12T20:45:42.899Z"}
{"msg":"@jsmitchell Perhaps 'generational' wasn't the right term as it can potentially be more complex. Datomic is a perfect example of the concept whereas an identifiable data element (with a key) is never actually modified but, instead, the original 'version' is stored and a new 'version' occupies the key location. In addition, and references to the original are maintained as that represented the reference state at the time of creation.  ","username":"FrankCastellucci","ts":"2018-07-12T20:45:42.899Z"}
{"msg":"https://docs.datomic.com/cloud/whatis/data-model.html","username":"FrankCastellucci","ts":"2018-07-12T20:46:41.062Z"}
{"msg":"well, that is somewhat like how the copy-on-write works in the merkle trie","username":"jsmitchell","ts":"2018-07-12T21:17:26.112Z"}
{"msg":"we are storing all those versions (at least until they are pruned)","username":"jsmitchell","ts":"2018-07-12T21:17:44.089Z"}
{"msg":"Can they be accessed? Do they have any meta-data associated with them?","username":"FrankCastellucci","ts":"2018-07-13T00:48:39.924Z"}
{"msg":"Has joined the channel.","username":"RealDeanZhao","ts":"2018-07-13T02:22:17.965Z","type":"uj"}
{"msg":"yes, they can be accessed via prior state root hashes","username":"jsmitchell","ts":"2018-07-13T13:59:21.764Z"}
{"msg":"from a user's perspective, through the rest-pi it's possible to get the blocks, which include the `state_root_hash` in its protobuff. So it's not too difficult to have a one-to-one mapping between the block ids and state_root_hash","username":"benoit.razet","ts":"2018-07-13T14:06:06.313Z"}
{"msg":"the rest-api allows to retrieves data from the merkle trie based on a block id","username":"benoit.razet","ts":"2018-07-13T14:06:36.759Z"}
{"msg":"with the `/state` endpoint","username":"benoit.razet","ts":"2018-07-13T14:07:06.487Z"}
{"msg":"@jsmitchell Is pruning automatic or configurable?","username":"FrankCastellucci","ts":"2018-07-13T14:56:10.575Z"}
{"msg":"it's configurable by depth, i think","username":"jsmitchell","ts":"2018-07-13T14:56:38.322Z"}
{"msg":"@pschwarz is the prunester, but he is on vacation until monday","username":"jsmitchell","ts":"2018-07-13T14:56:56.557Z"}
{"msg":"OK, I'll rummage... the ideal is an endpoint that given an address returns it's history (like an audit) but something that can guarantee in an audit scenario is one use-case... ","username":"FrankCastellucci","ts":"2018-07-13T14:59:42.972Z"}
{"msg":"@all : 2FA will soon be required across all GitHub orgs. If you do not have 2FA enabled for your account, you will be automatically removed from the Hyperledger org and will need to be re-added. Please check to ensure you have 2FA enabled. https://help.github.com/articles/securing-your-account-with-two-factor-authentication-2fa/","username":"rjones","ts":"2018-07-13T21:13:27.962Z"}
{"msg":"Has joined the channel.","username":"pidof","ts":"2018-07-14T17:37:37.983Z","type":"uj"}
{"msg":"ry love that policy ... ","username":"pidof","ts":"2018-07-14T17:38:12.136Z"}
{"msg":"@FrankCastellucci State pruning is configured via the `--state-pruning-block-depth` cli flag or `state_pruning_block_depth` configuration setting in your validator toml.  It defaults to 100.  ","username":"pschwarz","ts":"2018-07-16T14:10:26.368Z"}
{"msg":"@pschwarz So, is that the # of changes to a particular addresses data to support? If so, what happens when it is exceeded?","username":"FrankCastellucci","ts":"2018-07-16T14:31:38.593Z"}
{"msg":"No, pruning occurs at block boundaries","username":"pschwarz","ts":"2018-07-16T15:21:07.286Z"}
{"msg":"So, a state root hash that is below that depth will be pruned, which means all values in the state tree that are no longer referenced by future trees will be deleted","username":"pschwarz","ts":"2018-07-16T15:21:56.567Z"}
{"msg":"Has joined the channel.","username":"kodonnel","ts":"2018-07-16T15:33:48.565Z","type":"uj"}
{"msg":"@pschwarz Thanks for clarifying","username":"FrankCastellucci","ts":"2018-07-16T16:12:04.901Z"}
{"msg":"Very interesting thread @pschwarz @FrankCastellucci . Out of curiosity, does it mean that, in the case where the content at a specific address (in the merkle tree) is changed several times by the transactions in a single block, only the last change would be retrievable, and all the intermediate changes non retrievable (once the block is further the `state_pruning_block_depth`)? ","username":"benoit.razet","ts":"2018-07-17T13:13:14.713Z"}
{"msg":"@benoit.razet the only thing that hits state is the aggregate(final) set of address changes due to the transactions in the block. if multiple transactions in a single block modify an address, there will only be one 'set'. You could see the transaction level changes in the receipts if you needed to. Otherwise, writing timestamped history to a portion of state is an option.","username":"jsmitchell","ts":"2018-07-17T13:51:59.869Z"}
{"msg":"thanks @jsmitchell for the answer and reminding the timestamped history option","username":"benoit.razet","ts":"2018-07-17T14:06:20.520Z"}
{"msg":"If a specific property (auditability, security, etc) has to be designed for a Dapp, it's always interesting to understand the fundamentals of sawtooth-core to be able to understand how this property can be ensured using sawtooth-core features or at the application level, or a mix of both. Thanks for the feedback, always insightful","username":"benoit.razet","ts":"2018-07-17T14:12:06.971Z"}
{"msg":"What is the `timestamped history`? A TP provided piece of info?","username":"FrankCastellucci","ts":"2018-07-17T14:27:12.363Z"}
{"msg":"yeah, could be a thing that the tp decides to write to state as part of processing transactions","username":"jsmitchell","ts":"2018-07-17T14:37:07.108Z"}
{"msg":"I thought that maybe meant the client submitting timestamps as part of the txn fields in like in supply chain. If the TP is going to do it then I assume it has to use the blockinfo TP pattern.","username":"Dan","ts":"2018-07-17T14:40:05.099Z"}
{"msg":"well, the transaction could include a client submitted timestamp","username":"jsmitchell","ts":"2018-07-17T14:40:37.818Z"}
{"msg":"but the transaction doesn't need to contain anything special for the 'log entry'","username":"jsmitchell","ts":"2018-07-17T14:40:55.972Z"}
{"msg":"for example, in intkey, you could modify the transaction processor to write an ordered list of things that the transactions have done to that intkey address","username":"jsmitchell","ts":"2018-07-17T14:45:38.848Z"}
{"msg":"I assume that a TP written timestamp would fail the hash compare (validator) as it would be different for each invocation of the TP on a single transaction, no?","username":"FrankCastellucci","ts":"2018-07-17T14:48:26.985Z"}
{"msg":"yes, the tp can't just invent the timestamp","username":"jsmitchell","ts":"2018-07-17T14:52:17.193Z"}
{"msg":"it either needs to be from the blockinfo state location (a la seth), or from the transaction","username":"jsmitchell","ts":"2018-07-17T14:52:39.109Z"}
{"msg":"If the complete history of a state can't be retrieved from a validator, then include this history in the state at the tp level","username":"benoit.razet","ts":"2018-07-17T14:59:32.587Z"}
{"msg":"@Dan we need the update for Sawtooth: https://wiki.hyperledger.org/groups/tsc/project-updates/sawtooth-2018-jul prior to the TSC call","username":"rjones","ts":"2018-07-18T17:23:00.631Z"}
{"msg":"I'm sure one of the other maintainers would love to do that sometime ;)\nThanks for the ping @rjones I'll get that together this afternoon.","username":"Dan","ts":"2018-07-18T18:08:13.985Z"}
{"msg":"I'm sure one of the other maintainers would love to do that sometime ;)\nThanks for the ping @Ry I'll get that together this afternoon.","username":"Dan","ts":"2018-07-18T18:08:13.985Z"}
{"msg":"I'm sure one of the other maintainers would love to do that sometime ;)\nThanks for the ping @rjones y I'll get that together this afternoon.","username":"Dan","ts":"2018-07-18T18:08:13.985Z"}
{"msg":"@here maintainers let me know if there are any issues you would like raised with the TSC. In the past there were comments from some about feeling the TSC and projects were disconnected from one another. Anything like that.\nI don't think @amundson is around but he had mentioned recently about being blocked from editing the project page.","username":"Dan","ts":"2018-07-18T18:54:06.554Z"}
{"msg":"Here's what I've got so far... received feedback from Kelly but no-one else (yeah kind of short notice, but I'm sure everyone is watching the TSC updates and new this was due thurs ;) )","username":"Dan","ts":"2018-07-18T21:21:56.938Z"}
{"msg":"https://wiki.hyperledger.org/groups/tsc/project-updates/sawtooth-2018-jul?&#additional_information","username":"Dan","ts":"2018-07-18T21:21:58.952Z"}
{"msg":"@Dan s/our latest bug fix/our latest bug fix release/","username":"jsmitchell","ts":"2018-07-18T21:51:57.411Z"}
{"msg":"s/given increase submissions/given increased submissions/","username":"jsmitchell","ts":"2018-07-18T21:52:13.734Z"}
{"msg":"I've a couple of PR recently related to the python->rust replacement of `block_info` and `sawtooth_settings`. Is the new Rust implementation of these TPs backward compatible with the retired Python version? ","username":"benoit.razet","ts":"2018-07-19T01:09:46.428Z"}
{"msg":"I've seen a couple of PR recently related to the python->rust replacement of `block_info` and `sawtooth_settings`. Is the new Rust implementation of these TPs backward compatible with the retired Python version? ","username":"benoit.razet","ts":"2018-07-19T01:09:46.428Z"}
{"msg":"Has joined the channel.","username":"praspadm","ts":"2018-07-19T05:57:31.797Z","type":"uj"}
{"msg":"Has joined the channel.","username":"johnfranklin","ts":"2018-07-19T06:10:05.931Z","type":"uj"}
{"msg":"@benoit.razet that's definitely the intent","username":"jsmitchell","ts":"2018-07-19T13:21:08.214Z"}
{"msg":"Has joined the channel.","username":"jeffhoekman","ts":"2018-07-19T15:38:59.682Z","type":"uj"}
{"msg":"Had a few comments from different sources that backpressure is appearing too aggressive. I don't have concrete case / repro yet, but enough anecdotes that I wanted to share sooner than later.","username":"Dan","ts":"2018-07-19T15:42:35.407Z"}
{"msg":"Has joined the channel.","username":"johnsourour","ts":"2018-07-19T17:13:40.929Z","type":"uj"}
{"msg":"It doesn't appear that in the python `sawtooth-sdk` that the protobufs for SettingPayload, SettingProposal, et. al. are packaged.","username":"FrankCastellucci","ts":"2018-07-19T19:59:39.079Z"}
{"msg":"It doesn't appear that in the python `sawtooth-sdk 1.0.4` that the protobufs for SettingPayload, SettingProposal, et. al. are packaged.","username":"FrankCastellucci","ts":"2018-07-19T19:59:39.079Z"}
{"msg":"It doesn't appear that in the python `sawtooth-sdk 1.0.4` that the protobufs for SettingPayload, SettingProposal, et. al. are *not* packaged.","username":"FrankCastellucci","ts":"2018-07-19T19:59:39.079Z"}
{"msg":"am I missing something?","username":"FrankCastellucci","ts":"2018-07-19T19:59:46.948Z"}
{"msg":"It has the singular 'setting' but not the one this one: https://github.com/hyperledger/sawtooth-core/tree/master/families/settings/protos","username":"FrankCastellucci","ts":"2018-07-19T20:02:56.982Z"}
{"msg":"It has the singular 'setting' but not this one: https://github.com/hyperledger/sawtooth-core/tree/master/families/settings/protos","username":"FrankCastellucci","ts":"2018-07-19T20:02:56.982Z"}
{"msg":"I'll create a subset in our app but curious if A) Was it left out for a reason and B) Should I open a defect for that?","username":"FrankCastellucci","ts":"2018-07-19T20:22:40.924Z"}
{"msg":"I hate emojii","username":"FrankCastellucci","ts":"2018-07-19T20:22:55.502Z"}
{"msg":"@Dan on master or 1.0.4?","username":"jsmitchell","ts":"2018-07-19T20:44:54.726Z"}
{"msg":"@jsmitchell Using the pip installed 1.0.4 sdk","username":"FrankCastellucci","ts":"2018-07-19T20:55:10.333Z"}
{"msg":"`pip show sawtooth-sdk`","username":"FrankCastellucci","ts":"2018-07-19T21:03:09.050Z"}
{"msg":"Lists the protobufs from the main `/protos` only","username":"FrankCastellucci","ts":"2018-07-19T21:03:29.256Z"}
{"msg":"@FrankCastellucci sorry, different topics - i was asking @dan about the backpressure comment","username":"jsmitchell","ts":"2018-07-19T21:09:46.371Z"}
{"msg":"I believe 1.0.4.  @grkvlt I think one of the \"too much\" backpressure anecdotes came from your company. Do you happen to know what I'm talk about?","username":"Dan","ts":"2018-07-19T21:35:27.215Z"}
{"msg":"Has joined the channel.","username":"kirkwood","ts":"2018-07-23T04:01:04.260Z","type":"uj"}
{"msg":"Has joined the channel.","username":"zath","ts":"2018-07-25T07:22:18.346Z","type":"uj"}
{"msg":"@amundson fyi, crypto-lib discussion on the simple signer interface.. writeup: https://docs.google.com/document/d/1BvAXUGR6Gur12yEPbqCegiAuOChiZqEMp6CO3z8RxMk/edit#","username":"Dan","ts":"2018-07-25T14:23:52.952Z"}
{"msg":"@Dan ok, thought that was DOA, didn't realize there was actually anything going on there","username":"amundson","ts":"2018-07-25T14:43:49.056Z"}
{"msg":"is the proposal to start from scratch and design yet-another-api instead of extending/generalizing the sawtooth approach?","username":"amundson","ts":"2018-07-25T14:44:31.685Z"}
{"msg":"Maybe I should have just 'at'-ed you over on the crypto-lib channel so we could have the discussion there. it looks similar to what we have but doesn't yet specify the constructor/factory.","username":"Dan","ts":"2018-07-25T14:57:34.944Z"}
{"msg":"yeah, I'm interested in a discussion of iterating on what we have, but not necessarily debating an API from scratch. we did that, remember? not easy, even when we all basically agree. I do wish we would have written up all our opposing requirements more formally.","username":"amundson","ts":"2018-07-25T15:08:47.119Z"}
{"msg":"Has joined the channel.","username":"adeebahmed","ts":"2018-07-25T21:35:52.582Z","type":"uj"}
{"msg":"@dhuseby was just mentioning alpine linux to me on another thread. supposed to be tiny. i.e. smaller dockers. Maybe as people are developing new components it might be worth trying your new environment on alpine first before defaulting to ubuntu. ","username":"Dan","ts":"2018-07-26T17:42:57.386Z"}
{"msg":"Has joined the channel.","username":"dhuseby","ts":"2018-07-26T17:42:57.710Z","type":"uj"}
{"msg":"Has joined the channel.","username":"sjqnn","ts":"2018-07-27T16:39:53.831Z","type":"uj"}
{"msg":"Has joined the channel.","username":"zZz","ts":"2018-07-28T09:16:17.376Z","type":"uj"}
{"msg":"Hi, is it normal behavior that a validator cannot process anymore transactions after he receives a transaction with an invalid `family_name` in the protobuf of the transaction (like `intkeykey` instead of `intkey`) ?","username":"benoit.razet","ts":"2018-07-30T16:03:29.064Z"}
{"msg":"sounds like a bug","username":"jsmitchell","ts":"2018-07-30T17:26:37.473Z"}
{"msg":"@jsmitchell ok, I filed this ticket https://jira.hyperledger.org/browse/STL-1373","username":"benoit.razet","ts":"2018-07-30T17:31:15.743Z"}
{"msg":"wait, are you restricting the transaction families in settings?","username":"jsmitchell","ts":"2018-07-30T17:40:43.252Z"}
{"msg":"if not, this probably looks like a new transaction type that the validator just doesn't have a registered transaction processor for yet, and it will pause until one connects.","username":"jsmitchell","ts":"2018-07-30T17:41:28.546Z"}
{"msg":"I thought about that. is this intended? sounds a little bit risky to me to block all the other legit transactions until a tp would connect because what if it does not","username":"benoit.razet","ts":"2018-07-30T17:43:06.012Z"}
{"msg":"We could potentially change the behavior for publishing (inclusion of an unknown transaction), but I think the behavior needs to be as is for block validation, because how would you make progress otherwise (the alternative is a forked network?). It's good practice to use that setting in any case.","username":"jsmitchell","ts":"2018-07-30T17:45:19.877Z"}
{"msg":"that makes sense for block validation, because at least one validator has been able to execute the transaction. Do you happen to know if using the setting disable this possibility o running into the issue?","username":"benoit.razet","ts":"2018-07-30T18:16:22.861Z"}
{"msg":"for the record, for folks running into a similar issue, restarting the validators fixes the problem.","username":"benoit.razet","ts":"2018-07-30T18:26:49.848Z"}
{"msg":"@jsmitchell I tried declaring the `transaction_families` with sawtooth_settings and does not prevent the bug: sending a transaction with no corresponding TP still stop the validator from processing any further transaction. I updated STL-1373 with this info","username":"benoit.razet","ts":"2018-07-30T19:08:17.123Z"}
{"msg":"ok, thanks @benoit.razet ","username":"jsmitchell","ts":"2018-07-30T19:17:47.624Z"}
{"msg":"@benoit.razet Good catch and good to know, I thought it would continue to process other txns with legit families registered... didn't realize it gums up the works for all","username":"FrankCastellucci","ts":"2018-07-30T19:58:14.620Z"}
{"msg":"I had the same issue, but adding family name and version in sawtooth.validator.transaction_families during the bootstrap solved it with a 'failing transaction...since it isn't required in the configuration'","username":"Johnjam","ts":"2018-07-31T06:24:24.703Z"}
{"msg":"@Johnjam thanks! I take it back, I had not loaded the batch containing the `sawtooth.validator.transaction_families` properly. @FrankCastellucci  @jsmitchell ","username":"benoit.razet","ts":"2018-07-31T12:44:52.521Z"}
{"msg":"@benoit.razet I tested with more than one batch at a time and it freezes sometimes. I'm in detached HEAD (commit b3e30e8c7828daff8049551e21a25a426a4d03e8) and when I send 10 batches with an invalid transaction and then 10 batches with a valid transaction afterwards, I have your bug. I don't know if it's already resolved in a newer version of master.","username":"Johnjam","ts":"2018-07-31T13:33:20.035Z"}
{"msg":"I can totally be wrong but if the `sawtooth.validator.transaction_families` is not used then it freezes with 1.0.4 and master ","username":"benoit.razet","ts":"2018-07-31T15:08:30.866Z"}
{"msg":"I can totally be wrong but if the `sawtooth.validator.transaction_families` is not used then it freezes with 1.0.4 and a master I pulled last week ","username":"benoit.razet","ts":"2018-07-31T15:08:30.866Z"}
{"msg":"In my tests, this configuration was set. I'll try again with the last master when I'll figure out how to setup the new architecture.","username":"Johnjam","ts":"2018-07-31T15:14:42.444Z"}
{"msg":"Help, I have an unknown, the main purpose of initializing a lot of thread pool like component_thread_pool, network_thread_pool, client_thread_pool, sig_pool in sawtooth 1.0?","username":"zZz","ts":"2018-07-31T16:07:47.705Z"}
{"msg":"I have an unknown, the main purpose of initializing a lot of thread pool like component_thread_pool, network_thread_pool, client_thread_pool, sig_pool in sawtooth 1.0.","username":"zZz","ts":"2018-07-31T16:07:47.705Z"}
{"msg":"Reminder - general questions should go to #sawtooth - this channel is for core development discusisons","username":"jsmitchell","ts":"2018-07-31T16:17:02.072Z"}
{"msg":"Reminder - general questions should go to #sawtooth - this channel is for core development discussions","username":"jsmitchell","ts":"2018-07-31T16:17:02.072Z"}
{"msg":"thanks you","username":"zZz","ts":"2018-07-31T16:18:10.388Z"}
{"msg":"Has joined the channel.","username":"diegos","ts":"2018-08-01T16:30:01.577Z","type":"uj"}
{"msg":"Hi, I was going through the smallbank golang example, playing a little with it found a couple of things and want to make sure is the right behavior: \n1) If any place in the transaction processor something returns any error different than InvalidTransactionError the transaction is resend to the TP by the validator again and again until it is successful or returns InvalidTransactionError.\n2) Because of 1) if the transaction being processed has 2 legs (for example debiting one account first and crediting a second account, like saveAccount(new_source_account, context) and saveAccount(new_dest_account, context)), if the second leg fails with an error different than InvalidTransactionError, when the validator sends the transaction again, the first leg was already debited in the first try, so it's debited again and again until the second leg passes or you are out of funds on the first account :-)\nIs this right?\nIf so, I think is very important to be very defensive on the transaction processor code to catch anything different than InvalidTransactionError or to totally avoid doing legs on the TP and instead doing 2 transactions inside a batch to be atomic.","username":"diegos","ts":"2018-08-01T19:59:42.115Z"}
{"msg":"Hi, I was going through the smallbank golang example, playing a little with it found a couple of things and want to make sure is the right behavior: \n1) If any place in the transaction processor something returns any error different than InvalidTransactionError the transaction is resend to the validator again and again until it is successful or returns InvalidTransactionError.\n2) Because of 1) if the transaction being processed has 2 legs (for example debiting one account first and crediting a second account, like saveAccount(new_source_account, context) and saveAccount(new_dest_account, context)), if the second leg fails with an error different than InvalidTransactionError, when the validator sends the transaction again, the first leg was already debited in the first try, so it's debited again and again until the second leg passes or you are out of funds on the first account :-)\nIs this right?\nIf so, I think is very important to be very defensive on the transaction processor code to catch anything different than InvalidTransactionError or to totally avoid doing legs on the TP and instead doing 2 transactions inside a batch to be atomic.","username":"diegos","ts":"2018-08-01T19:59:42.115Z"}
{"msg":"No intermediate transactions commit in the datastore.","username":"Dan","ts":"2018-08-01T22:06:06.418Z"}
{"msg":"Each time the transaction is resubmitted to the TP it will have a fresh context of state.","username":"Dan","ts":"2018-08-01T22:06:41.401Z"}
{"msg":"Has joined the channel.","username":"huy.nguyen","ts":"2018-08-02T03:34:17.146Z","type":"uj"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=7NcNmsdm4NfbYcDLK) @Dan did not test this issue with v1.0.5, but with v1.0.4, I fire an Internal error or an unknown error on purpose when doing the second leg, and when the TP is called again the context state is not fresh, it has already the first leg applied, so when the TP processed it successfully on the second time, now the transaction is committed to the datastore but with the first account debited twice","username":"diegos","ts":"2018-08-02T19:56:17.816Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=7NcNmsdm4NfbYcDLK","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=7NcNmsdm4NfbYcDLK","remote":true,"fileId":null,"fileName":null}]}
{"msg":"@diegos 7 that sounds extremely unlikely","username":"jsmitchell","ts":"2018-08-02T19:57:07.899Z"}
{"msg":"do you have any logs showing this behavior?","username":"jsmitchell","ts":"2018-08-02T19:57:40.608Z"}
{"msg":":-) yes it was shocking for me, going to run it again to capture the logs. Actually this issue triggers me to review all my code to catch any error and found that the intkey-tp-go is not catching the CBOR errors. where is the best place to post that? here? jira? or github?","username":"diegos","ts":"2018-08-02T20:03:55.718Z"}
{"msg":"https://www.hyperledger.org/blog/2018/08/02/from-xos-to-crypto-assets","username":"kelly_","ts":"2018-08-02T21:03:58.337Z"}
{"msg":"nice work everyone! ^","username":"kelly_","ts":"2018-08-02T21:04:03.271Z"}
{"msg":"","username":"diegos","ts":"2018-08-02T21:22:24.462Z","attachments":[{"type":"file","title":"Clipboard - August 2, 2018 6:22 PM","title_link":"/file-upload/jyJwszqjxpWraBBBa/Clipboard%20-%20August%202,%202018%206:22%20PM","image_url":"/file-upload/jyJwszqjxpWraBBBa/Clipboard%20-%20August%202,%202018%206:22%20PM","image_type":"image/png","image_size":17024,"url":"/file-upload/jyJwszqjxpWraBBBa/Clipboard%20-%20August%202,%202018%206:22%20PM","remote":false,"fileId":"jyJwszqjxpWraBBBa","fileName":"Clipboard - August 2, 2018 6:22 PM"}]}
{"msg":"","username":"diegos","ts":"2018-08-02T21:23:06.427Z","attachments":[{"type":"file","title":"Clipboard - August 2, 2018 6:22 PM","title_link":"/file-upload/iJMMEN5WtqncCQzva/Clipboard%20-%20August%202,%202018%206:22%20PM","image_url":"/file-upload/iJMMEN5WtqncCQzva/Clipboard%20-%20August%202,%202018%206:22%20PM","image_type":"image/png","image_size":304782,"url":"/file-upload/iJMMEN5WtqncCQzva/Clipboard%20-%20August%202,%202018%206:22%20PM","remote":false,"fileId":"iJMMEN5WtqncCQzva","fileName":"Clipboard - August 2, 2018 6:22 PM"}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=oRbNnPHoiAu82wdJq) this is v1.0.4, latter going to try the same on v.1.0.5","username":"diegos","ts":"2018-08-02T21:24:17.721Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=oRbNnPHoiAu82wdJq","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=oRbNnPHoiAu82wdJq","remote":true,"fileId":null,"fileName":null}]}
{"msg":"on v1.0.5 is the same behavior","username":"diegos","ts":"2018-08-02T21:40:38.846Z"}
{"msg":"@diegos 7 log the transaction signature in your TP","username":"jsmitchell","ts":"2018-08-02T21:40:42.714Z"}
{"msg":"on those Error Arriba lines","username":"jsmitchell","ts":"2018-08-02T21:41:04.412Z"}
{"msg":"ok","username":"diegos","ts":"2018-08-02T21:41:12.357Z"}
{"msg":"the request signature is already in the log, on these lines: [DEBUG] exosp txn 5dda534650110d95554620a760898b972b53d15d8f3f3eaffb2919e58c37089667bd19754c9a1de5cdd9ea9eb67167b1d773a1da2e2646dad6a55c80571f0c50","username":"diegos","ts":"2018-08-02T22:04:40.754Z"}
{"msg":"it looks like it is running the same transaction multiple times during block construction. That should never happen.","username":"jsmitchell","ts":"2018-08-02T22:06:07.093Z"}
{"msg":"if the TP return any error diferrent than InvalidTransactionError, it runs again and again, actually if it is never successfull it loops ferever, hanging the validator","username":"diegos","ts":"2018-08-02T22:08:07.906Z"}
{"msg":"yes, that is by design","username":"jsmitchell","ts":"2018-08-02T22:09:20.266Z"}
{"msg":"if your transaction is invalid, you need to return InvalidTransactionError","username":"jsmitchell","ts":"2018-08-02T22:09:32.818Z"}
{"msg":"correct, lern that the hard way :-)","username":"diegos","ts":"2018-08-02T22:09:51.463Z"}
{"msg":"the problem is thata glich could happend, and if the transaction has more than one leg it's not atomic","username":"diegos","ts":"2018-08-02T22:11:50.312Z"}
{"msg":"there are lots of ways a bad transaction processor can cause non-determinism","username":"jsmitchell","ts":"2018-08-02T22:12:22.120Z"}
{"msg":"What did the first execution of that transaction result in? Success, an InternalError, or an InvalidTransaction?","username":"jsmitchell","ts":"2018-08-02T22:14:12.058Z"}
{"msg":"It's fails 2 times on purpose sending and unknown error (fmt.Errorf(\"something\"), also has the same behavior if I send InternalError","username":"diegos","ts":"2018-08-02T22:16:10.665Z"}
{"msg":"do you still have that system running?","username":"jsmitchell","ts":"2018-08-02T22:16:15.340Z"}
{"msg":"it would be interesting to see the raw block contents of the block which starts 0d72fe","username":"jsmitchell","ts":"2018-08-02T22:16:48.606Z"}
{"msg":"Have all in docker-compose. Could start from zero, now I did the test using v1.0.5, I could run it from zero, capturing the new log and the blocks.","username":"diegos","ts":"2018-08-02T22:18:51.357Z"}
{"msg":"ok, here is my suspicion -- the block only contains the transaction once. It is being rerun three times determinstically during both block publishing and block validation because of what you are doing with returning InternalError. That all makes sense. What does not make sense is that the second and third invocations of the transaction during publishing seem to start from an invalid base context.","username":"jsmitchell","ts":"2018-08-02T22:20:37.480Z"}
{"msg":"@boydjohnson @pschwarz ^","username":"jsmitchell","ts":"2018-08-02T22:20:49.712Z"}
{"msg":"possible incorrect behavior in context manager on failed transaction","username":"jsmitchell","ts":"2018-08-02T22:23:08.221Z"}
{"msg":"Yes, on the log you could see the starting balance of each new try ( DEC balance: 9000 amount: 1000 newbalance: 8000)","username":"diegos","ts":"2018-08-02T22:23:15.764Z"}
{"msg":"yes, i understand. This is totally weird.","username":"jsmitchell","ts":"2018-08-02T22:23:36.980Z"}
{"msg":"the intkey-tp-go is not catching the CBOR errors. where is the best place to post that? here? jira? or github?","username":"diegos","ts":"2018-08-02T22:30:21.728Z"}
{"msg":"No, it will retry Internal error transactions, just with a back off - the expectation is that the TP needs to restart","username":"pschwarz","ts":"2018-08-03T00:02:30.527Z"}
{"msg":"Has joined the channel.","username":"lcinacio","ts":"2018-08-04T17:10:25.732Z","type":"uj"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=8noLswr5H3mP5mmAF) @pschwarz Hi, sorry I create a confusion, there are 2 different issues, (1) the first one is that when a transaction fails doing a second leg with an InternalError or an unknown error after doing the first leg (like debiting a FROM wallet), when the transaction is processed again, the context is not fresh, it already has being debited on the first try, so if now the transaction is successful (both first and second legs), the FROM wallet is debited twice. And (2) the  intkey-tp-go is not catching the CBOR errors correctly.","username":"diegos","ts":"2018-08-06T14:04:09.712Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=8noLswr5H3mP5mmAF","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=8noLswr5H3mP5mmAF","remote":true,"fileId":null,"fileName":null}]}
{"msg":"I tried to set up the env using poet simulator.. but the poet-key-state-* files are created by the user root```\n-rw-r--r--  1 sawtooth sawtooth 1099511627776 Aug  7 09:27 block-00.lmdb\n-rw-r--r--  1 sawtooth sawtooth          8192 Aug  7 09:27 block-00.lmdb-lock\n-rw-r--r--  1 sawtooth sawtooth           128 Aug  7 09:27 block-chain-id\n-rw-r--r--  1 sawtooth sawtooth 1099511627776 Aug  7 09:27 merkle-00.lmdb\n-rw-r--r--  1 sawtooth sawtooth          8192 Aug  7 09:27 merkle-00.lmdb-lock\n-rw-r--r--  1 root     root     1099511627776 Aug  7 09:27 poet-key-state-0333172a.lmdb\n-rw-r--r--  1 root     root              8192 Aug  7 09:27 poet-key-state-0333172a.lmdb-lock\n``` ","username":"RealDeanZhao","ts":"2018-08-07T09:33:57.569Z"}
{"msg":"I tried to set up the env using poet simulator.. but the poet-key-state-* files are created by the user root which make the validator has no permission to the file```\n-rw-r--r--  1 sawtooth sawtooth 1099511627776 Aug  7 09:27 block-00.lmdb\n-rw-r--r--  1 sawtooth sawtooth          8192 Aug  7 09:27 block-00.lmdb-lock\n-rw-r--r--  1 sawtooth sawtooth           128 Aug  7 09:27 block-chain-id\n-rw-r--r--  1 sawtooth sawtooth 1099511627776 Aug  7 09:27 merkle-00.lmdb\n-rw-r--r--  1 sawtooth sawtooth          8192 Aug  7 09:27 merkle-00.lmdb-lock\n-rw-r--r--  1 root     root     1099511627776 Aug  7 09:27 poet-key-state-0333172a.lmdb\n-rw-r--r--  1 root     root              8192 Aug  7 09:27 poet-key-state-0333172a.lmdb-lock\n``` ","username":"RealDeanZhao","ts":"2018-08-07T09:33:57.569Z"}
{"msg":"Has joined the channel.","username":"Jirateep","ts":"2018-08-11T12:52:05.965Z","type":"uj"}
{"msg":"Has joined the channel.","username":"Johannes2511","ts":"2018-08-15T07:21:06.585Z","type":"uj"}
{"msg":"Has joined the channel.","username":"henrytill","ts":"2018-08-16T17:36:20.115Z","type":"uj"}
{"msg":"we will likely start a release discussion on #sawtooth-release soon","username":"amundson","ts":"2018-08-16T23:52:04.312Z"}
{"msg":"great!","username":"TomBarnes","ts":"2018-08-16T23:52:30.427Z"}
{"msg":"Has joined the channel.","username":"Gabe","ts":"2018-08-17T20:26:00.909Z","type":"uj"}
{"msg":"Has joined the channel.","username":"alchmeina","ts":"2018-08-23T14:16:36.036Z","type":"uj"}
{"msg":"I would like to update the list of run-time dependencies for Sawtooth. ","username":"TomBarnes","ts":"2018-08-24T18:24:13.554Z"}
{"msg":"Can I get some help in confiting tha the fllowing list contains all of the current Rust run-time dependencies for Sawtooth-core, sawtooth-poet, and sawtooth-raft?","username":"TomBarnes","ts":"2018-08-24T18:25:38.537Z"}
{"msg":"`              module    version  role                path                                                                                                \n              ------    -------  ----                ----                                                                                                \n                clap   >=2.29.0  dependencies        sawtooth-core\\adm\\Cargo.toml                                                                        \n                libc   >=0.2.35  dependencies        sawtooth-core\\adm\\Cargo.toml                                                                        \n           lmdb-zero    >=0.4.1  dependencies        sawtooth-core\\adm\\Cargo.toml                                                                        \n            protobuf        2.0  dependencies        sawtooth-core\\adm\\Cargo.toml                                                                        \n        sawtooth_sdk       none  dependencies        sawtooth-core\\adm\\Cargo.toml                                                                        \n               serde        1.0  dependencies        sawtooth-core\\adm\\Cargo.toml                                                                        \n        serde_derive        1.0  dependencies        sawtooth-core\\adm\\Cargo.toml                                                                        \n          serde_yaml        0.7  dependencies        sawtooth-core\\adm\\Cargo.toml                                                                        \n               ctrlc        3.0  dependencies        sawtooth-core\\sdk\\rust\\Cargo.toml                                                                   \n                 hex        0.3  dependencies        sawtooth-core\\sdk\\rust\\Cargo.toml                                                                   \n                 log        0.3  dependencies        sawtooth-core\\sdk\\rust\\Cargo.toml                                                                   \n                rand      0.4.2  dependencies        sawtooth-core\\sdk\\rust\\Cargo.toml                                                                   \n         rust-crypto     0.2.36  dependencies        sawtooth-core\\sdk\\rust\\Cargo.toml                                                                   \n           secp256k1      0.7.1  dependencies        sawtooth-core\\sdk\\rust\\Cargo.toml                                                                   \n                uuid        0.5  dependencies        sawtooth-core\\sdk\\rust\\Cargo.toml                                                                   \n                 zmq       none  dependencies        sawtooth-core\\sdk\\rust\\Cargo.toml                                                                   \n              log4rs        0.8  dependencies        sawtooth-raft\\Cargo.toml                                                                            \n       log4rs-syslog        3.0  dependencies        sawtooth-raft\\Cargo.toml                                                                            \n                raft      0.3.0  dependencies        sawtooth-raft\\Cargo.toml                                                                            \n          serde_json          1  dependencies        sawtooth-raft\\Cargo.toml\n`\n","username":"TomBarnes","ts":"2018-08-24T18:28:49.811Z"}
{"msg":"maybe this is better","username":"TomBarnes","ts":"2018-08-24T18:30:16.926Z"}
{"msg":"","username":"TomBarnes","ts":"2018-08-24T18:30:26.120Z","attachments":[{"type":"file","title":"Clipboard - August 24, 2018 11:30 AM","title_link":"/file-upload/5TPghK8pQHbqMMpKH/Clipboard%20-%20August%2024,%202018%2011:30%20AM","image_url":"/file-upload/5TPghK8pQHbqMMpKH/Clipboard%20-%20August%2024,%202018%2011:30%20AM","image_type":"image/png","image_size":161917,"url":"/file-upload/5TPghK8pQHbqMMpKH/Clipboard%20-%20August%2024,%202018%2011:30%20AM","remote":false,"fileId":"5TPghK8pQHbqMMpKH","fileName":"Clipboard - August 24, 2018 11:30 AM"}]}
{"msg":"Can I get some help in confirming that the following list contains all of the current Python run-time dependencies for Sawtooth-core, sawtooth-poet, and sawtooth-raft?","username":"TomBarnes","ts":"2018-08-24T18:31:19.580Z"}
{"msg":"","username":"TomBarnes","ts":"2018-08-24T18:32:03.891Z","attachments":[{"type":"file","title":"Clipboard - August 24, 2018 11:31 AM","title_link":"/file-upload/jmZCfmPvpzGw4yGr2/Clipboard%20-%20August%2024,%202018%2011:31%20AM","image_url":"/file-upload/jmZCfmPvpzGw4yGr2/Clipboard%20-%20August%2024,%202018%2011:31%20AM","image_type":"image/png","image_size":145247,"url":"/file-upload/jmZCfmPvpzGw4yGr2/Clipboard%20-%20August%2024,%202018%2011:31%20AM","remote":false,"fileId":"jmZCfmPvpzGw4yGr2","fileName":"Clipboard - August 24, 2018 11:31 AM"}]}
{"msg":"Are we still using lmdb (py-lmdb) now that we've moved to Rust?  Are there other Python packages still called out in setup.py files that are no longer being used?","username":"TomBarnes","ts":"2018-08-25T01:12:32.100Z"}
{"msg":"thew py-lmdb project no longer has a maintainer, so its probably not a good component to be using in the long term.","username":"TomBarnes","ts":"2018-08-25T01:13:10.039Z"}
{"msg":"Has joined the channel.","username":"wchang","ts":"2018-08-31T00:11:06.205Z","type":"uj"}
{"msg":"Has joined the channel.","username":"ZorbaGrue","ts":"2018-08-31T13:45:08.602Z","type":"uj"}
{"msg":"@jsmitchell @Dan @pschwarz I've added a comment to https://jira.hyperledger.org/browse/STL-1374 about a backpressure issue ","username":"benoit.razet","ts":"2018-08-31T15:13:09.531Z"}
{"msg":"I tried to follow the path in the sawtooth-core code to see if I could spot anything in the `ClientBatchSubmitBackpressureHandler` code and its ramification, but could not spot anything :( The ramifications go pretty far with all the components that are on the`client_thread_pool`","username":"benoit.razet","ts":"2018-08-31T15:16:52.425Z"}
{"msg":"thanks","username":"Dan","ts":"2018-08-31T15:18:34.030Z"}
{"msg":"Unfortunately I don't observe the bug on all the networks, only on one. I hope it's not a configuration thing.","username":"benoit.razet","ts":"2018-08-31T15:18:34.959Z"}
{"msg":"Hi @benoit.razet I assume you're not doing the TP stop/start step mentioned in the issue. Also, I'm wondering if the issue is resolved in the master branch. We used to observe significant backpressure a couple of months ago but things seem pretty stable now.","username":"amolk","ts":"2018-08-31T15:30:06.539Z"}
{"msg":"@amolk that's right, no TP stop/start step. Independently, I've been preparing for moving to 1.1 (master). Do you suggest I should do that sooner rather than later?","username":"benoit.razet","ts":"2018-08-31T15:58:18.548Z"}
{"msg":"Has joined the channel.","username":"sureshtedla","ts":"2018-08-31T17:31:53.569Z","type":"uj"}
{"msg":"The way that I'm reading that bug, I think the submitter is running into an issue that has more to do with how that particular version of the workload generator is written.  It doesn't know how to deal with back pressure.  So it doesn't know to _not_ submit increment and decrement txns on keys that were not set (due to back-pressure), so it will submit a bunch of invalid transactions","username":"pschwarz","ts":"2018-08-31T18:25:57.666Z"}
{"msg":"ah! I'll continue working on narrowing down the pb","username":"benoit.razet","ts":"2018-08-31T19:11:48.491Z"}
{"msg":"[Java-SDK]Hi. I keep struggling to find the appropriate *sawtooth.sdk.protobuf.Message.MessageType* to use when trying to filter results by a specific field. There are a lot of values defined and for the ones i tried using i keep getting same exception when setting a field on the request:\n`java.lang.IllegalArgumentException: FieldDescriptor does not match message type.`\nDo you have any ideas\\suggestions regarding this? Thanks.","username":"ZorbaGrue","ts":"2018-09-01T09:22:28.227Z"}
{"msg":"@ZorbaGrue you should ask in #sawtooth ","username":"rjones","ts":"2018-09-02T13:53:47.198Z"}
{"msg":"When I am running validator for Off-Chain permissioning then I am getting following error : \n========================================================================\n","username":"deb","ts":"2018-09-04T09:25:18.394Z"}
{"msg":"ubuntu@ip-172-31-27-120:~$  sudo -u sawtooth sawtooth-validator -vv\n[2018-09-04 09:24:58.661 INFO     path] Skipping path loading from non-existent config file: /etc/sawtooth/path.toml\n[2018-09-04 09:24:58.662 INFO     validator] Loading validator information from config: /etc/sawtooth/validator.toml\nTraceback (most recent call last):\n  File \"/usr/bin/sawtooth-validator\", line 9, in <module>\n    load_entry_point('sawtooth-validator==1.0.5', 'console_scripts', 'sawtooth-validator')()\n  File \"/usr/lib/python3/dist-packages/sawtooth_validator/server/cli.py\", line 238, in main\n    load_validator_config(opts_config, path_config.config_dir)\n  File \"/usr/lib/python3/dist-packages/sawtooth_validator/server/cli.py\", line 179, in load_validator_config\n    toml_config = load_toml_validator_config(conf_file)\n  File \"/usr/lib/python3/dist-packages/sawtooth_validator/config/validator.py\", line 60, in load_toml_validator_config\n    toml_config = toml.loads(raw_config)\n  File \"/usr/lib/python3/dist-packages/toml.py\", line 331, in loads\n    value, vtype = load_value(pair[1])\n  File \"/usr/lib/python3/dist-packages/toml.py\", line 451, in load_value\n    return (load_array(v), \"array\")\n  File \"/usr/lib/python3/dist-packages/toml.py\", line 513, in load_array\n    nval, ntype = load_value(a[i])\n  File \"/usr/lib/python3/dist-packages/toml.py\", line 418, in load_value\n    raise Exception(\"Stuff after closed string. WTF?\")\nException: Stuff after closed string. WTF?\n","username":"deb","ts":"2018-09-04T09:25:20.513Z"}
{"msg":"@deb sounds like you have an invalid validator.toml file","username":"jsmitchell","ts":"2018-09-04T14:58:03.022Z"}
{"msg":"If you are using master and haven’t edited the toml file, there was just a PR merged which corrected a typo in the example file","username":"jsmitchell","ts":"2018-09-04T15:05:04.800Z"}
{"msg":"@jsmitchell @pschwarz @Dan I added a comment to https://jira.hyperledger.org/browse/STL-1374  on my side, it was actually a red herring, nothing wrong with the back pressure :thumbsup: . The problem was that I forgot to add the `sawtooth_validator_registry` to the on-chain setting of transaction families. The validators were able to process batches for some number of blocks until they were locked out because they could not register there pubkeys as part of a `sawtooth_validator_registry` that was filtered.","username":"benoit.razet","ts":"2018-09-04T15:19:39.599Z"}
{"msg":"@jsmitchell @pschwarz @Dan I added a comment to https://jira.hyperledger.org/browse/STL-1374  on my side, it was actually a red herring, nothing wrong with the back pressure :thumbsup: . The problem was that I forgot to add the `sawtooth_validator_registry` to the on-chain setting of transaction families. The validators were able to process batches for some number of blocks until they were locked out because they could not register their pubkeys as part of a `sawtooth_validator_registry` txn that was filtered.","username":"benoit.razet","ts":"2018-09-04T15:19:39.599Z"}
{"msg":"@jsmitchell @pschwarz @Dan I added a comment to https://jira.hyperledger.org/browse/STL-1374  on my side, it was actually a red herring, nothing wrong with the back pressure :thumbsup: . The problem was that I forgot to add the `sawtooth_validator_registry` to the on-chain setting of transaction families. The validators were able to process batches for some number of blocks until they were locked out because they could not register their pubkeys as part of a `sawtooth_validator_registry` that was filtered.","username":"benoit.razet","ts":"2018-09-04T15:19:39.599Z"}
{"msg":"@benoit.razet (et. al.) is that just a problem when using PoET or is it independent of consensus (neglecting to add `sawtooth.validator.transaction_families`)? TIA","username":"FrankCastellucci","ts":"2018-09-04T20:25:15.618Z"}
{"msg":"good question @FrankCastellucci  I always assumed the `sawtooth_validator_registry` was for PoET, but maybe it's for other consensus engines too. I'm curious to know the answer now. ","username":"benoit.razet","ts":"2018-09-04T20:30:39.743Z"}
{"msg":"btw: On last weeks Tech meeting @Dan and I were discussing zksnarks, commitments, nullifiers and zk-rangeproofs... a WIP","username":"FrankCastellucci","ts":"2018-09-04T20:32:54.123Z"}
{"msg":"sawtooth_validator_registry is just used by poet.","username":"Dan","ts":"2018-09-04T20:36:05.746Z"}
{"msg":"BTW, we've been seeing significant backpressure the last few nightly builds (1455-1 onwards)","username":"amolk","ts":"2018-09-05T05:46:10.904Z"}
{"msg":"Is there plans to up the python builds for 3.5.3+? Most specific is signing dependencies on secp256k1 which breaks on install with later python versions?","username":"FrankCastellucci","ts":"2018-09-05T20:17:25.998Z"}
{"msg":"Nope no plans (at least that I have) to upgrade python. Longer term I'm interested in replacing secp, but that's pretty long term. One option will be the crypto-lib lab but we'll need to see how that comes together.","username":"Dan","ts":"2018-09-06T01:15:59.460Z"}
{"msg":"Has joined the channel.","username":"Naman_13","ts":"2018-09-06T10:41:42.206Z","type":"uj"}
{"msg":"I had a question, with respect to Event subscription through this developer guide - https://sawtooth.hyperledger.org/docs/core/nightly/master/app_developers_guide/zmq_event_subscription.html\n\nCan somebody tell me where exactly I'm supposed to write the subscription? Should I write it in my web-server python file or should I write it in my transaction processor file? Could somebody give me a code example I could see and probably implement? Thanks!","username":"Naman_13","ts":"2018-09-06T10:41:55.895Z"}
{"msg":"Hi @Naman_13 can you try posting this on #sawtooth? We use this channel for discussing internal development of sawtooth.","username":"Dan","ts":"2018-09-06T12:10:36.214Z"}
{"msg":"Recently, we've started to stress the validators more than we previously did, by submitting batches at high pace, and possibly resubmitting identical batches. That must stress the validators in a way we did not in the past, and they start to fail with the following message: ```  \n[2018-09-06 16:24:39.253 ERROR    future] An unhandled error occurred while running future callback\nTraceback (most recent call last):\n  File \"/usr/lib/python3/dist-packages/sawtooth_validator/networking/future.py\", line 79, in run_callback\n    self._callback_func(self._request, self._result)\n  File \"/usr/lib/python3/dist-packages/sawtooth_validator/execution/executor.py\", line 154, in _future_done_callback\n    error_data=response.extended_data)\n  File \"/usr/lib/python3/dist-packages/sawtooth_validator/execution/scheduler_parallel.py\", line 659, in set_transaction_execution_result\n    txn_signature)\n  File \"/usr/lib/python3/dist-packages/sawtooth_validator/execution/scheduler_parallel.py\", line 580, in _remove_subsequent_result_because_of_batch_failure\n    if self._is_txn_to_replay(txn_id, poss_successor, seen):\n  File \"/usr/lib/python3/dist-packages/sawtooth_validator/execution/scheduler_parallel.py\", line 559, in _is_txn_to_replay\n    possible_successor)\n  File \"/usr/lib/python3/dist-packages/sawtooth_validator/execution/scheduler_parallel.py\", line 540, in _is_in_same_batch\n    self._batches_by_txn_id[txn_id_2]\nKeyError: '746807039356e72cf30c653b925e8b955d1664aff1303db68f6069c15c9504a84b1dd4fe3024c6a7ed103316ae1dc922629fb008b0146e3c1346677e4c1bd95b'\n```","username":"benoit.razet","ts":"2018-09-06T16:42:06.986Z"}
{"msg":"and that's after more than 40000 blocks in","username":"benoit.razet","ts":"2018-09-06T16:42:23.208Z"}
{"msg":"any idea?","username":"benoit.razet","ts":"2018-09-06T16:42:43.307Z"}
{"msg":"@boydjohnson ^","username":"jsmitchell","ts":"2018-09-06T16:43:26.793Z"}
{"msg":"Has joined the channel.","username":"LeonardoCarvalho","ts":"2018-09-07T13:09:49.137Z","type":"uj"}
{"msg":"Hello all, I'm here as well","username":"LeonardoCarvalho","ts":"2018-09-07T13:11:41.271Z"}
{"msg":":)","username":"LeonardoCarvalho","ts":"2018-09-07T13:11:42.097Z"}
{"msg":"So, a little question","username":"LeonardoCarvalho","ts":"2018-09-07T13:11:55.198Z"}
{"msg":" I'm using an DEALER - ROUTER - ROUTER 0mq topology\nand I need to know in advance, or at connection time\nthe Socket ID of the 0mq socket on the remote validator\nLooks like this is a known pattern: https://github.com/zeromq/pyzmq/issues/974 ","username":"LeonardoCarvalho","ts":"2018-09-07T13:11:57.529Z"}
{"msg":"I've changed in my core code with this lines:","username":"LeonardoCarvalho","ts":"2018-09-07T13:12:14.718Z"}
{"msg":"","username":"LeonardoCarvalho","ts":"2018-09-07T13:12:50.837Z","attachments":[{"type":"file","title":"Clipboard - September 7, 2018 10:12 AM","title_link":"/file-upload/jnji5nGh9xakYzJFL/Clipboard%20-%20September%207,%202018%2010:12%20AM","image_url":"/file-upload/jnji5nGh9xakYzJFL/Clipboard%20-%20September%207,%202018%2010:12%20AM","image_type":"image/png","image_size":53983,"url":"/file-upload/jnji5nGh9xakYzJFL/Clipboard%20-%20September%207,%202018%2010:12%20AM","remote":false,"fileId":"jnji5nGh9xakYzJFL","fileName":"Clipboard - September 7, 2018 10:12 AM"}]}
{"msg":"in sawtooth_validator/networking/interconnect.py","username":"LeonardoCarvalho","ts":"2018-09-07T13:13:07.044Z"}
{"msg":"@ line 342","username":"LeonardoCarvalho","ts":"2018-09-07T13:13:29.913Z"}
{"msg":"should I create a ticket and submit a change? Would that be useful?","username":"LeonardoCarvalho","ts":"2018-09-07T13:13:51.503Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=MMSuwSwea53QzCoDt) @LeonardoCarvalho Yes, please create a JIRA ticket. A PR would be good too.","username":"danintel","ts":"2018-09-07T17:01:03.976Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=MMSuwSwea53QzCoDt","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=MMSuwSwea53QzCoDt","remote":true,"fileId":null,"fileName":null}]}
{"msg":"@LeonardoCarvalho is that topology the same or different than what the other components are using?","username":"amundson","ts":"2018-09-07T21:08:22.703Z"}
{"msg":"I'm not aware ...","username":"LeonardoCarvalho","ts":"2018-09-07T21:15:06.502Z"}
{"msg":"But I can say that, if there's no empty 0mq messages being used, and I didn't found one, the impact is zilch","username":"LeonardoCarvalho","ts":"2018-09-07T21:18:27.391Z"}
{"msg":"@LeonardoCarvalho I'd like to understand what is different between what we do now and what you are proposing. We have quite a few different SDK implementations, so I suspect a difference in your implementation that might be unnecessary. The impact of change here is not zilch, since the behavior of the validator is part of the stable API surface, so if this enables a new pattern, we want to understand if that pattern is a desirable thing to support (for potentially a long time). Then we have to convince ourselves that there are no backward-compatible side-effects (probably easy, but at least one reviewer would have to dig deep).","username":"amundson","ts":"2018-09-08T02:46:13.063Z"}
{"msg":"Sure, I'll try to summarize here, I can create a ticket with more info on JIRA, to further discussion","username":"LeonardoCarvalho","ts":"2018-09-08T12:03:02.267Z"}
{"msg":"Basically, during the creation of a Reactive patter on Java SDK, I noticed that a ROUTER socket, on the TP, could replicate the Majordomo Protocol from ZeroMQ","username":"LeonardoCarvalho","ts":"2018-09-08T12:04:55.456Z"}
{"msg":"https://rfc.zeromq.org/spec:7/MDP/","username":"LeonardoCarvalho","ts":"2018-09-08T12:04:59.818Z"}
{"msg":"to deliver the messages to backend DEALER sockets, using IPC instead of TCP addresses","username":"LeonardoCarvalho","ts":"2018-09-08T12:05:38.753Z"}
{"msg":"the idea behind this is accept more than one TP on the same machine or even JVM","username":"LeonardoCarvalho","ts":"2018-09-08T12:06:11.401Z"}
{"msg":"to keep agnostic on naming conventions or configurations, the idea of using the ZMQ_PROBE_ROUTER flag looked like a very good fit to handle a faster handshake","username":"LeonardoCarvalho","ts":"2018-09-08T12:08:03.365Z"}
{"msg":"http://api.zeromq.org/4-1:zmq-setsockopt","username":"LeonardoCarvalho","ts":"2018-09-08T12:08:08.210Z"}
{"msg":"I've searched the server code and didn't manage to find a zero sized message on it, and changed the lines of code to implement the probing message, with success","username":"LeonardoCarvalho","ts":"2018-09-08T12:09:43.455Z"}
{"msg":"Since the implementation on clients talking to ROUTER sockets wouldn't be affected, since it's only triggered with the flag, I thought that the impact would be negligible","username":"LeonardoCarvalho","ts":"2018-09-08T12:11:58.766Z"}
{"msg":"Has joined the channel.","username":"cfzhang","ts":"2018-09-09T19:37:37.943Z","type":"uj"}
{"msg":"Has joined the channel.","username":"arsulegai","ts":"2018-09-11T18:55:46.066Z","type":"uj"}
{"msg":"Has joined the channel.","username":"adamgering","ts":"2018-09-14T19:28:56.568Z","type":"uj"}
{"msg":"Has joined the channel.","username":"kthblmfld","ts":"2018-09-17T16:13:34.232Z","type":"uj"}
{"msg":"@LeonardoCarvalho Hi. I am somewhat familiar with the Majordomo pattern and ROUTER-ROUTER in general. Currently we are using the ROUTER-DEALER request-reply pattern, which has been stabilized as part of the Transaction Processor API. If I understand, you are suggesting that we need ROUTER-ROUTER to support multiple TPs with a single validator. We have already added support for multiple TPs with a single validator at the application level, so using ROUTER-ROUTER for the TP API seems unnecessary.","username":"adamludvik","ts":"2018-09-18T15:22:12.691Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=MkxKiv33zZti9KEEs) @adamludvik No no, we don't *need*, but would be nice to give the capability to the TPs","username":"LeonardoCarvalho","ts":"2018-09-18T16:08:58.313Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=MkxKiv33zZti9KEEs","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=MkxKiv33zZti9KEEs","remote":true,"fileId":null,"fileName":null}]}
{"msg":"in my case, I got a very good boost of I/O using this pattern","username":"LeonardoCarvalho","ts":"2018-09-18T16:09:17.306Z"}
{"msg":"\"got a very good boost of I/O\" <- okay you have my attention :) ","username":"adamludvik","ts":"2018-09-18T16:16:05.380Z"}
{"msg":"Can you say a little more about where the backend DEALER sockets and what is using them? Are you suggesting we insert something between the validator and TPs to do routing?","username":"adamludvik","ts":"2018-09-18T16:17:21.432Z"}
{"msg":"@LeonardoCarvalho what sort of IO boost? What do you attribute that improvement to?","username":"jsmitchell","ts":"2018-09-18T16:27:01.984Z"}
{"msg":"I got, without too much changes in the code, a 4X improvement. The fact is, with that topology, the receiving socket got much less work to do, it only propagates to the backend. The backend receives the answers or requests and transmits to the front end","username":"LeonardoCarvalho","ts":"2018-09-18T22:18:41.767Z"}
{"msg":"In my feeling, the I/O got this boost merely reusing the threads in a more efficient way. See, the receiving and transmitting operations got totally decoupled.","username":"LeonardoCarvalho","ts":"2018-09-18T22:19:32.202Z"}
{"msg":"and, I think, the Reactive architecture must be related to this gain as well, I think the code got a better fit in it using the IPC backends","username":"LeonardoCarvalho","ts":"2018-09-18T22:24:40.820Z"}
{"msg":"Using a sawtooth server with the code change I've suggested, there's some code to evaluate the gains on my fork of the java-sdk project, feel very welcome to give any feedback","username":"LeonardoCarvalho","ts":"2018-09-18T23:54:22.476Z"}
{"msg":"I wouldn't have guessed the Java SDK was slow enough to be the bottleneck","username":"amundson","ts":"2018-09-19T00:03:13.397Z"}
{"msg":"It was, it could only work *one message a time* in the original version","username":"LeonardoCarvalho","ts":"2018-09-19T10:06:39.739Z"}
{"msg":"we don't see the 0MQ being a bottleneck in the other SDKs, though they do not consistently parallelize the requests currently. Go is probably the most correct in that respect.","username":"amundson","ts":"2018-09-19T16:12:10.034Z"}
{"msg":"Has joined the channel.","username":"wyatt-noise","ts":"2018-09-19T23:58:04.167Z","type":"uj"}
{"msg":"Has joined the channel.","username":"manju.ac","ts":"2018-09-20T08:54:36.574Z","type":"uj"}
{"msg":"Ah, well, I always think in high loads, and there was a ticket on JIRA about multi threading the java SDK, so...","username":"LeonardoCarvalho","ts":"2018-09-20T09:40:10.182Z"}
{"msg":"Hey All - I wanted to get some thoughts on how to coordinate Sawtooth feature planning moving forward. I had a conversation with @amundson a couple weeks ago who said that he was looking at point-to-point (Quorom style) private transactions. I know some other folks have also been looking at that as a feature","username":"kelly_","ts":"2018-09-20T15:04:04.100Z"}
{"msg":"Not sure if we should have some sort of living document where people detail what they are working on for the next couple months so we can look for overlap","username":"kelly_","ts":"2018-09-20T15:05:04.898Z"}
{"msg":"e.g. @LeonardoCarvalho could call out the JavaSDK to ensure that no one else was working on something in parallel, and if so they could connect to collaborate on it","username":"kelly_","ts":"2018-09-20T15:05:33.002Z"}
{"msg":"other options would be like a weekly call, or a combined community standup, etc.","username":"kelly_","ts":"2018-09-20T15:05:46.286Z"}
{"msg":"just looking for any feedback for what would be easiest/most preferable for the community members","username":"kelly_","ts":"2018-09-20T15:06:32.577Z"}
{"msg":"@kelly_ that's not how I would summarize the feature exactly, but it's close enough that if there are others doing similar work they should talk to me. we will submit an RFC when we know exactly what we are proposing.","username":"amundson","ts":"2018-09-20T15:10:27.870Z"}
{"msg":"ok, i'm less concerned about that specific feature than just how to keep the community aligned and make sure that too much thinking doesnt happen in isolation","username":"kelly_","ts":"2018-09-20T15:11:05.671Z"}
{"msg":"I'm not sure how to solve it, but the difficulty will almost certainly be that some of us don't like to advertise features until we can commit to them for sure. We are probably at an extreme right now in terms of being conservative about it.","username":"amundson","ts":"2018-09-20T15:13:23.815Z"}
{"msg":"(part of the reason we have RFC process is to help with that though)","username":"amundson","ts":"2018-09-20T15:14:00.664Z"}
{"msg":"Yea I don't think it's about committing to the feature, but more just raising awareness among the community participants on who is working on or investigating what","username":"kelly_","ts":"2018-09-20T15:14:38.548Z"}
{"msg":"as always this would be optional, so just looking for feedback on what works or doesnt work for people","username":"kelly_","ts":"2018-09-20T15:16:22.279Z"}
{"msg":"I think a living document is probably the easiest cause it's asynchronous","username":"kelly_","ts":"2018-09-20T15:16:55.391Z"}
{"msg":"if people want to put what they are working on great, if they don't feel comfortable, that's also their choice, but at least they would get the opportunity to see if someone else had called it out","username":"kelly_","ts":"2018-09-20T15:17:29.308Z"}
{"msg":"@kelly_ I recall from a conversation with the Indy team that they just solved this problem after experiencing a couple instances where two teams developed basically the same thing in isolation. It might be good to reach out to them and see if they have a solution that is working well.","username":"adamludvik","ts":"2018-09-20T15:25:56.449Z"}
{"msg":"@adamludvik thanks that is a great suggestion","username":"kelly_","ts":"2018-09-20T15:35:08.555Z"}
{"msg":"Some of us will be in Montreal. That's more of a one-off than a pattern for how we stay clear. I would like to take advantage of that time though.","username":"Dan","ts":"2018-09-20T15:36:25.184Z"}
{"msg":"yep, I'm booking my flight out there today","username":"kelly_","ts":"2018-09-20T15:38:53.375Z"}
{"msg":"\"@kelly_ We use a shared roadmap in the wiki where each team declares what they plan to work on:\nhttps://wiki.hyperledger.org/projects/indy/roadmap\nWe should probably do better at keeping that up to date. \nWe also have a monthly meeting were we discuss priorities together.\"","username":"kelly_","ts":"2018-09-20T16:18:19.202Z"}
{"msg":"^ @adamludvik that was what the Indy team said","username":"kelly_","ts":"2018-09-20T16:18:32.258Z"}
{"msg":"that seems pretty reasonable","username":"kelly_","ts":"2018-09-20T16:18:35.054Z"}
{"msg":"we could maybe even allocate 1 of the tech forums or app dev calls per month to that open discussion","username":"kelly_","ts":"2018-09-20T16:19:03.476Z"}
{"msg":"I think I am good with updating a public roadmap doc once a month. I'm not sure about using a wiki though, I've heard they tend to fall out of date.","username":"adamludvik","ts":"2018-09-20T16:30:33.971Z"}
{"msg":"I can't imagine where you heard that.","username":"Dan","ts":"2018-09-20T16:34:45.134Z"}
{"msg":"I think it was in a wiki somewhere","username":"adamludvik","ts":"2018-09-20T16:47:26.939Z"}
{"msg":"I had a google docs link for it but it got buried in the others.","username":"Dan","ts":"2018-09-20T17:29:21.509Z"}
{"msg":"I would go for google docs too as well","username":"kelly_","ts":"2018-09-20T17:32:57.452Z"}
{"msg":"","username":"boydjohnson","ts":"2018-09-20T18:04:53.965Z","attachments":[{"type":"file","title":"test_duplicates_dependencies_20_iter_branch.png","title_link":"/file-upload/myYAhRgEgsoF59x6u/test_duplicates_dependencies_20_iter_branch.png","image_url":"/file-upload/myYAhRgEgsoF59x6u/test_duplicates_dependencies_20_iter_branch.png","image_type":"image/png","image_size":2871346,"url":"/file-upload/myYAhRgEgsoF59x6u/test_duplicates_dependencies_20_iter_branch.png","remote":false,"fileId":"myYAhRgEgsoF59x6u","fileName":"test_duplicates_dependencies_20_iter_branch.png"}]}
{"msg":"@jsmitchell @adamludvik ^","username":"boydjohnson","ts":"2018-09-20T18:05:05.621Z"}
{"msg":"It is all signing and test framework.","username":"boydjohnson","ts":"2018-09-20T18:05:19.946Z"}
{"msg":"duplicates and dependencies?","username":"Dan","ts":"2018-09-20T18:12:04.959Z"}
{"msg":"@boydjohnson heh","username":"adamludvik","ts":"2018-09-20T18:16:24.808Z"}
{"msg":"@Dan we are trying to move more of our technical discussions to this channel, so that is carried over from another channel","username":"adamludvik","ts":"2018-09-20T18:16:53.696Z"}
{"msg":"So the fix seems to make no difference on performance?","username":"adamludvik","ts":"2018-09-20T18:17:16.338Z"}
{"msg":"SWEET","username":"jsmitchell","ts":"2018-09-20T18:18:33.462Z"}
{"msg":"Well that is the semi-optimized code. I can do another test with the naive-algorithm and beofre.","username":"boydjohnson","ts":"2018-09-20T18:18:46.424Z"}
{"msg":"nice work on getting that callgrind/viz stuff together @boydjohnson and @adamludvik ","username":"jsmitchell","ts":"2018-09-20T18:19:01.886Z"}
{"msg":"@boydjohnson definitely did all of the work on that","username":"adamludvik","ts":"2018-09-20T18:22:14.176Z"}
{"msg":":clap: ","username":"jsmitchell","ts":"2018-09-20T18:23:19.949Z"}
{"msg":"Yay!","username":"boydjohnson","ts":"2018-09-20T18:23:28.483Z"}
{"msg":"@boydjohnson is this cpu time or wall clock time?","username":"jsmitchell","ts":"2018-09-20T18:23:46.552Z"}
{"msg":"I am a little unsure. Is there a flag I would have to pass to get one or the other? I did `valgrind --tool=callgrind` on the binary.","username":"boydjohnson","ts":"2018-09-20T18:24:42.577Z"}
{"msg":"I think it is cpu time.","username":"boydjohnson","ts":"2018-09-20T18:26:55.384Z"}
{"msg":"@boydjohnson are all these being signed by the same key?","username":"jsmitchell","ts":"2018-09-20T18:30:15.328Z"}
{"msg":"you should definitely be caching the signing context","username":"jsmitchell","ts":"2018-09-20T18:30:25.860Z"}
{"msg":"Yes, I used the smallbank_workload iterator and passed it the same Signer.","username":"boydjohnson","ts":"2018-09-20T18:31:08.859Z"}
{"msg":"35% of the cpu time is being spent generating the public key during the signing operation","username":"jsmitchell","ts":"2018-09-20T18:31:12.352Z"}
{"msg":"Is that a misuse of the signing library in Rust SDK, or an inefficiency within it?","username":"boydjohnson","ts":"2018-09-20T18:32:52.266Z"}
{"msg":"probably a miss -- we had the same problem in the python lib and @Dan had added some caching","username":"jsmitchell","ts":"2018-09-20T18:33:22.152Z"}
{"msg":"@boydjohnson is this conclusive evidence that those spikes in execution time you were seeing earlier are a result of wating for the GIL?","username":"adamludvik","ts":"2018-09-20T18:34:46.418Z"}
{"msg":"@boydjohnson is this conclusive evidence that those spikes in execution time you were seeing earlier are a result of waiting for the GIL?","username":"adamludvik","ts":"2018-09-20T18:34:46.418Z"}
{"msg":"Maybe not conclusive yet. Those graphs were run on the pre-naive algorithm code, before this month. I am going to run this same callgrind on that code.","username":"boydjohnson","ts":"2018-09-20T18:35:50.270Z"}
{"msg":"i can't find info about wall clock time with callgrind, which is a bummer. Any waiting on locks is presumably going to be masked unless we can get wall clock time.","username":"jsmitchell","ts":"2018-09-20T18:36:27.969Z"}
{"msg":"A stackoverflow post I read said a statistical sampling profiler like oprofile would take into account the idling time around locks.","username":"boydjohnson","ts":"2018-09-20T18:39:32.707Z"}
{"msg":"that seems likely based on this profile data, actually","username":"jsmitchell","ts":"2018-09-20T18:41:58.855Z"}
{"msg":"we know from the smallbank workload generator that generating and signing batches is very fast","username":"jsmitchell","ts":"2018-09-20T18:42:21.849Z"}
{"msg":"looks like around 500k executions of that here","username":"jsmitchell","ts":"2018-09-20T18:42:41.042Z"}
{"msg":"so, while it's a high percentage of cpu time, it's probably not a big percentage of overall cpu time","username":"jsmitchell","ts":"2018-09-20T18:43:24.327Z"}
{"msg":"so, while it's a high percentage of cpu time, it's probably not a big percentage of overall clock time","username":"jsmitchell","ts":"2018-09-20T18:43:24.327Z"}
{"msg":"So it got called a ton of times is what you are saying.","username":"boydjohnson","ts":"2018-09-20T18:44:57.660Z"}
{"msg":"actually only ~160k executions","username":"jsmitchell","ts":"2018-09-20T18:45:42.613Z"}
{"msg":"well, no. what I'm saying is that if get_block_from_main_cache... for example is actually a much larger percentage of overall time based on waiting on locks, then that won't show up in these numbers","username":"jsmitchell","ts":"2018-09-20T18:46:42.912Z"}
{"msg":"because it's measuring time on the cpu","username":"jsmitchell","ts":"2018-09-20T18:46:58.182Z"}
{"msg":"so, because the signing stuff is cpu intensive, it will be overweighted on this picture","username":"jsmitchell","ts":"2018-09-20T18:47:18.020Z"}
{"msg":"how is this both validator and sawtooth_perf?","username":"amundson","ts":"2018-09-20T18:50:06.885Z"}
{"msg":"this is from a unit test or something?","username":"amundson","ts":"2018-09-20T18:51:38.991Z"}
{"msg":"@boydjohnson ^","username":"amundson","ts":"2018-09-20T18:52:02.680Z"}
{"msg":"Yes, I have a branch that brings in smallbank_workload (to create transactions), sawtooth_perf (to create batches), and a benchmark test that calls DuplicatesAndDependenciesValidation.validate_block a number of times.","username":"boydjohnson","ts":"2018-09-20T18:53:28.277Z"}
{"msg":"@boydjohnson so, that signing is client-side and really doesn't say anything about the validator code, right? or am I reading it incorrectly?","username":"amundson","ts":"2018-09-20T18:55:12.185Z"}
{"msg":"That is correct, it is sdk code.","username":"boydjohnson","ts":"2018-09-20T18:55:32.323Z"}
{"msg":"well, specifically, it has nothing to do with validator performance","username":"amundson","ts":"2018-09-20T18:55:46.241Z"}
{"msg":"quite the reverse, I think this suggests the validator code being tested is working quite well","username":"amundson","ts":"2018-09-20T18:56:14.408Z"}
{"msg":"Except this is only time on cpu.","username":"boydjohnson","ts":"2018-09-20T18:56:28.522Z"}
{"msg":"right, from a CPU perspective","username":"amundson","ts":"2018-09-20T18:57:46.746Z"}
{"msg":"the higher percent that client signing code has, the more efficient the validator code must be","username":"amundson","ts":"2018-09-20T18:58:14.645Z"}
{"msg":"For reference/context, the goal of this testing is to determine how the performance of that change checked when we removed the concurrency problem and whether we need to do additional optimization on that check.","username":"adamludvik","ts":"2018-09-20T18:59:04.277Z"}
{"msg":"So we still need the \"after we implemented the fix\" graphs to answer that question.","username":"adamludvik","ts":"2018-09-20T18:59:57.824Z"}
{"msg":"@boydjohnson did I get that right?","username":"adamludvik","ts":"2018-09-20T19:00:04.876Z"}
{"msg":"@adamludvik These graphs are after the fix. We need the pre-fix at least, and maybe the naive solution, too.","username":"boydjohnson","ts":"2018-09-20T19:02:50.427Z"}
{"msg":"I am working on getting graphs pre-fix.","username":"boydjohnson","ts":"2018-09-20T19:03:04.411Z"}
{"msg":"regarding feature roadmap, here is one example: https://wiki.postgresql.org/wiki/PostgreSQL11_Roadmap","username":"TomBarnes","ts":"2018-09-20T19:05:15.171Z"}
{"msg":"and... https://rust.facepunch.com/roadmap/","username":"TomBarnes","ts":"2018-09-20T19:08:18.403Z"}
{"msg":"looks like rust manages their roadmap through their RFC process - https://github.com/rust-lang/rfcs/blob/master/text/2314-roadmap-2018.md","username":"TomBarnes","ts":"2018-09-20T19:09:48.862Z"}
{"msg":"great links, thanks Tom","username":"kelly_","ts":"2018-09-20T19:10:51.996Z"}
{"msg":"http://www.brendangregg.com/FlameGraphs/offcpuflamegraphs.html This describes off-cpu flamegraphs.","username":"boydjohnson","ts":"2018-09-20T19:59:19.184Z"}
{"msg":"","username":"boydjohnson","ts":"2018-09-20T20:52:03.403Z","attachments":[{"type":"file","title":"test_duplicates_dependencies_prefix.png","title_link":"/file-upload/aLRFChJPchD8kYtm8/test_duplicates_dependencies_prefix.png","image_url":"/file-upload/aLRFChJPchD8kYtm8/test_duplicates_dependencies_prefix.png","image_type":"image/png","image_size":3134182,"url":"/file-upload/aLRFChJPchD8kYtm8/test_duplicates_dependencies_prefix.png","remote":false,"fileId":"aLRFChJPchD8kYtm8","fileName":"test_duplicates_dependencies_prefix.png"}]}
{"msg":"@adamludvik @jsmitchell @amundson ^","username":"boydjohnson","ts":"2018-09-20T20:52:25.981Z"}
{"msg":"Just to clarify, the first graph was after and this is before?","username":"adamludvik","ts":"2018-09-20T20:54:14.941Z"}
{"msg":"Yes.","username":"boydjohnson","ts":"2018-09-20T20:55:29.133Z"}
{"msg":"pretty significant difference","username":"jsmitchell","ts":"2018-09-20T21:19:03.918Z"}
{"msg":"Yeah, it seems like we did good.","username":"boydjohnson","ts":"2018-09-20T21:22:26.520Z"}
{"msg":"Has joined the channel.","username":"anandakumar.n","ts":"2018-09-21T13:39:58.337Z","type":"uj"}
{"msg":"Hi! i just want to know the reason ! why block header doesn't have time value!??\n\n \n","username":"anandakumar.n","ts":"2018-09-21T13:40:18.172Z"}
{"msg":"There's some dialog on that over in #sawtooth if you scroll up a bit.","username":"Dan","ts":"2018-09-21T18:19:31.237Z"}
{"msg":"I have updated the Consensus Engine API RFC to reflect changes made during implementation. Going to work on documentation next: https://github.com/hyperledger/sawtooth-rfcs/pull/4/commits/7355af743cd0c15674318a7fbd0e8b9112c440a4\n\nWould like to get a final round of feedback and then enter FCP.","username":"adamludvik","ts":"2018-09-21T20:29:10.319Z"}
{"msg":"Has joined the channel.","username":"acdam.bacdam","ts":"2018-09-23T12:07:10.762Z","type":"uj"}
{"msg":"I am new to sawtooth, read documentation and created application for simplewallet to deposit, withdraw and check balance for any account holder / User. I want an action to be implemented to fetch details of all the transaction happened for that user, or in other words when that user has deposited (including amount) and when withdrawl - something like a passbook to list all transaction details. So far I cam across context.setstate and getstate methods to fetch or set current state.\nCan anyone help here to fetch list of all transactions happened for provided user ?","username":"acdam.bacdam","ts":"2018-09-23T12:12:08.771Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=rMmNenbb4XTSnC7og) @anandakumar 1 Using timestamps in a distributed network is troublesome--mostly due to complex clock synchronization issues among peers. You could add a timestamp in your transaction family's transaction payload. If you want timestamps with blocks, refer to the BlockInfo Transaction Family. See: https://sawtooth.hyperledger.org/docs/core/releases/latest/transaction_family_specifications/blockinfo_transaction_family.html","username":"danintel","ts":"2018-09-24T16:45:04.383Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=rMmNenbb4XTSnC7og","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=rMmNenbb4XTSnC7og","remote":true,"fileId":null,"fileName":null}]}
{"msg":"@acdam.bacdam This is a good question for the #sawtooth channel.","username":"adamludvik","ts":"2018-09-24T16:50:39.965Z"}
{"msg":"@danintel @anandakumar 1 I believe there was a conversation related to this in the #sawtooth channel too.","username":"adamludvik","ts":"2018-09-24T16:51:31.968Z"}
{"msg":"Has joined the channel.","username":"VanC 7","ts":"2018-09-25T09:40:23.796Z","type":"uj"}
{"msg":"@pschwarz I was looking to see how much we were using the python lmdb library. @TomBarnes mentioned that it is no longer maintained. \nhttps://github.com/dw/py-lmdb/blob/master/README.md#py-lmdb-needs-a-maintainer\nFrom my quick search it looks like the blockstore and receipt store still use the python library... ```validator/sawtooth_validator/server/core.py\nvalidator/sawtooth_validator/server/state_verifier.py```\nBut all the state stuff (i.e. merkle trie) uses rust.\nDid I get that right?\n{block store, receipt store} <-- Python \n{state} <-- Rust","username":"Dan","ts":"2018-09-25T14:58:43.984Z"}
{"msg":"Slightly related, why do we have both of these.. they look very similar\n```.//validator/src/database/lmdb.rs\n.//adm/src/database/lmdb.rs\n```","username":"Dan","ts":"2018-09-25T15:13:50.696Z"}
{"msg":"@Dan I believe you summarized that correctly.\n\nI am already working on pulling out python lmdb from the blockstore: https://github.com/aludvik/sawtooth-core/commits/use-rust-blockstore\n\nThe receipt store is probably not too hard to do.\n\nThose are very similar because we copied the adm/ implementation to the validator/ package.","username":"adamludvik","ts":"2018-09-25T16:02:57.195Z"}
{"msg":"Do you recall why we don't have adm just use the validator's database code? Is it a functional difference or just dependency limitation?","username":"Dan","ts":"2018-09-25T16:05:34.173Z"}
{"msg":"I believe we wanted the packages to not depend on one another.","username":"adamludvik","ts":"2018-09-25T16:11:51.541Z"}
{"msg":"Has joined the channel.","username":"knkski","ts":"2018-09-25T16:13:48.738Z","type":"uj"}
{"msg":"Could I get another review on https://github.com/hyperledger/sawtooth-core/pull/1872?","username":"knkski","ts":"2018-09-25T16:14:47.611Z"}
{"msg":"@agunde @amundson ^","username":"adamludvik","ts":"2018-09-25T16:19:02.918Z"}
{"msg":"@knkski nice. I love the removal of that c code.","username":"amundson","ts":"2018-09-25T16:39:54.219Z"}
{"msg":":woo: ","username":"knkski","ts":"2018-09-25T17:35:58.518Z"}
{"msg":"the head field in the response to fetch_state is supposed to be the identity of the most recently committed block, right? ","username":"MicBowman","ts":"2018-09-26T22:37:52.081Z"}
{"msg":"i'm getting the same value for head no matter how many transactions are committed... using the developer validator","username":"MicBowman","ts":"2018-09-26T22:38:21.784Z"}
{"msg":"@MicBowman can you give more context?","username":"adamludvik","ts":"2018-09-27T00:13:48.034Z"}
{"msg":"Here's a video tutorial: https://www.youtube.com/watch?v=p85xwZ_OLX0","username":"Dan","ts":"2018-09-27T03:05:10.822Z"}
{"msg":"@Dan you are my hero","username":"adamludvik","ts":"2018-09-27T05:34:41.317Z"}
{"msg":"Has joined the channel.","username":"thou_shalt","ts":"2018-09-27T06:26:14.073Z","type":"uj"}
{"msg":"Hello, can somebody help with instructions how to write own consensus engine using pyhon sdk from sawtooth_sdk.consensus .Some simple example for instance .","username":"thou_shalt","ts":"2018-09-27T06:26:37.470Z"}
{"msg":"@thou_shalt good question for #sawtooth-consensus-dev \nin brief though, the only example is poet. poet is shimmed in from the approach that preceded engines so it's not a good example. The more recent examples are written in rust. This design doc may be of help to you:\nhttps://github.com/hyperledger/sawtooth-rfcs/pull/4/files ","username":"Dan","ts":"2018-09-27T12:11:11.025Z"}
{"msg":"what are people's thoughts on deprecating/stopping the publishing/posting of the 0.8 documentation?","username":"kelly_","ts":"2018-09-27T15:21:04.253Z"}
{"msg":"I've noticed that people reference it regularly in the #sawtooth channel, and also have noticed that it comes up on google searches sometimes which I think is adding confusion","username":"kelly_","ts":"2018-09-27T15:22:08.992Z"}
{"msg":"Add a header to it maybe? I wouldn't unpublish it.","username":"rjones","ts":"2018-09-27T15:22:52.790Z"}
{"msg":"Someone out there is stuck on 0.8 for the next five years ","username":"rjones","ts":"2018-09-27T15:23:31.304Z"}
{"msg":"I'm afraid we're going to have more people stuck if we keep it up :)","username":"kelly_","ts":"2018-09-27T15:35:57.714Z"}
{"msg":"but that's a good thought","username":"kelly_","ts":"2018-09-27T15:36:05.099Z"}
{"msg":"@adamludvik just looking at the head field in the response; it keeps coming up the same thing. i think, however, that it is in the section of my tests that are designed to fail so there might not actually be any transactions being sent (well.. txns that should be committed). this is part of some exploration on how to get the validator to sign the results for a get-state, get-transaction, get-block operations (through the rest-api)","username":"MicBowman","ts":"2018-09-27T16:31:38.635Z"}
{"msg":"@MicBowman are blocks being published? If no blocks are being published, then I wouldn't expect head to change.","username":"jsmitchell","ts":"2018-09-27T18:58:43.895Z"}
{"msg":"@jsmitchell i think it was just the section of failed tests... ","username":"MicBowman","ts":"2018-09-27T20:06:47.378Z"}
{"msg":"i'm trying to find a way to get the validator to sign the result of the get-state","username":"MicBowman","ts":"2018-09-27T20:07:06.464Z"}
{"msg":"so we can use it as an attestation of commit outside the ledger","username":"MicBowman","ts":"2018-09-27T20:07:21.646Z"}
{"msg":"could the client (the thing making the get call) sign it instead?","username":"jsmitchell","ts":"2018-09-27T20:14:56.432Z"}
{"msg":"if not, i think you'd need to extend the protocol","username":"jsmitchell","ts":"2018-09-27T20:34:37.428Z"}
{"msg":"the client is the one no one trusts","username":"MicBowman","ts":"2018-09-27T20:57:44.219Z"}
{"msg":"and, yes, it looks like there is no easy way to do this","username":"MicBowman","ts":"2018-09-27T20:57:59.962Z"}
{"msg":"the keys to sign don't exist in the rest_api","username":"MicBowman","ts":"2018-09-27T20:58:10.504Z"}
{"msg":"so it would have to be from the validator itself managing state","username":"MicBowman","ts":"2018-09-27T20:58:22.143Z"}
{"msg":"how are you deciding that the keys to sign are trustworthy?","username":"jsmitchell","ts":"2018-09-27T21:02:49.738Z"}
{"msg":"meaning, if the rest api did have its own keys, and you had a mechanism for registering/trusting them, then that would be a solution which is on the 'client side' (we consider the rest api an example, and have written several different rest apis with different behaviors which all talk the same set of protocol messages to the validator)","username":"jsmitchell","ts":"2018-09-27T21:16:06.152Z"}
{"msg":"@jsmitchell yup","username":"MicBowman","ts":"2018-09-27T23:19:10.544Z"}
{"msg":"trust in the keys will have to happen out of band... its not a good solution to our bigger problem (externalizing claims about the state of the *ledger* rather than the state of a *validator*)","username":"MicBowman","ts":"2018-09-27T23:39:22.828Z"}
{"msg":"but the out of band trust is a reasonable first step","username":"MicBowman","ts":"2018-09-27T23:39:35.503Z"}
{"msg":"frankly... i can probably get away with just adding a key to the rest api... that seems like a very low impact way to get *some* attestation","username":"MicBowman","ts":"2018-09-27T23:40:15.111Z"}
{"msg":"and its not obvious why i would trust the validator (in isolation) any more than the rest api","username":"MicBowman","ts":"2018-09-27T23:40:33.812Z"}
{"msg":"👍🏻","username":"jsmitchell","ts":"2018-09-28T00:16:30.654Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=mTdkL3ZGwzxvnXTdD) @Dan thanks a lot","username":"thou_shalt","ts":"2018-09-28T02:31:23.189Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=mTdkL3ZGwzxvnXTdD","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=mTdkL3ZGwzxvnXTdD","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Garbage Documentation","username":"danintel","ts":"2018-09-28T04:13:21.524Z","attachments":[{"type":"file","title":"Screenshot_2018-09-27-21-09-23.png","title_link":"/file-upload/H4ZX2KsBrRayDeHGS/Screenshot_2018-09-27-21-09-23.png","image_url":"/file-upload/H4ZX2KsBrRayDeHGS/Screenshot_2018-09-27-21-09-23.png","image_type":"image/png","image_size":141156,"url":"/file-upload/H4ZX2KsBrRayDeHGS/Screenshot_2018-09-27-21-09-23.png","remote":false,"fileId":"H4ZX2KsBrRayDeHGS","fileName":"Screenshot_2018-09-27-21-09-23.png"}]}
{"msg":"@kelly @rjones a sample of the pre-release  doc clutter we have","username":"danintel","ts":"2018-09-28T04:15:10.461Z"}
{"msg":"@MicBowman  I'm developing a little spring REST gateway that will do almost as you thinks...  I intend to use it to enroll external public keys and add them to the identity processor. The process will need an admin to approve the enrollment, and a key pair represents it.  After that, the gateway would use the identity to authorize or not access to itself, and the enrollment can be revoked by an admin anytime.","username":"LeonardoCarvalho","ts":"2018-09-28T10:53:59.515Z"}
{"msg":"@LeonardoCarvalho do you have more detail? that sounds promising","username":"MicBowman","ts":"2018-09-28T14:33:28.886Z"}
{"msg":"@boydjohnson @jsmitchell I have got unit tests and devmode liveness passing with a pure-rust block store.","username":"adamludvik","ts":"2018-09-28T19:45:43.436Z"}
{"msg":"Sweet work, @adamludvik .","username":"boydjohnson","ts":"2018-09-28T19:46:32.087Z"}
{"msg":"If I can get this through an LR run, then access to the blockstore database will be pure Rust from the block publisher/chain controller down.","username":"adamludvik","ts":"2018-09-28T19:47:19.860Z"}
{"msg":"i like that","username":"jsmitchell","ts":"2018-09-28T19:47:34.421Z"}
{"msg":"PR is up https://github.com/hyperledger/sawtooth-core/pull/1885, will want to do some stability/performance testing before merging though","username":"adamludvik","ts":"2018-09-28T20:15:43.456Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=hSc6MKgkhL6kLdQkB) @MicBowman I think tomorrow I can show a draft of my idea, is based on Cisco's Simple Certificate Enrollment Protocol and a micro service architecture I've deployed in the past using  Spring secutiry","username":"LeonardoCarvalho","ts":"2018-09-28T21:44:49.420Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=hSc6MKgkhL6kLdQkB","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=hSc6MKgkhL6kLdQkB","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=hSc6MKgkhL6kLdQkB) @MicBowman I think tomorrow I can show a draft of my idea, is based on Cisco's Simple Certificate Enrollment Protocol and a micro service architecture I've deployed in the past using  Spring security","username":"LeonardoCarvalho","ts":"2018-09-28T21:44:49.420Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=hSc6MKgkhL6kLdQkB","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=hSc6MKgkhL6kLdQkB","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Has joined the channel.","username":"resreassure","ts":"2018-09-28T21:55:44.489Z","type":"uj"}
{"msg":"@MicBowman , there's the 10000ft view:\n","username":"LeonardoCarvalho","ts":"2018-09-29T12:12:23.099Z"}
{"msg":"","username":"LeonardoCarvalho","ts":"2018-09-29T12:12:30.420Z","attachments":[{"type":"file","title":"Clipboard - September 29, 2018 9:12 AM","title_link":"/file-upload/mzaZYtCKXFquGgP4j/Clipboard%20-%20September%2029,%202018%209:12%20AM","image_url":"/file-upload/mzaZYtCKXFquGgP4j/Clipboard%20-%20September%2029,%202018%209:12%20AM","image_type":"image/png","image_size":41824,"url":"/file-upload/mzaZYtCKXFquGgP4j/Clipboard%20-%20September%2029,%202018%209:12%20AM","remote":false,"fileId":"mzaZYtCKXFquGgP4j","fileName":"Clipboard - September 29, 2018 9:12 AM"}]}
{"msg":"The particular problem I need to solve is that Brazil's main Cert Chain is off the mundial chains...","username":"LeonardoCarvalho","ts":"2018-09-29T12:13:23.211Z"}
{"msg":"And, since it's a little pricey for us (more than  US$ 150), I intend to put a mechanism to create local CAs based on user created keys, and probably PGP ones as well","username":"LeonardoCarvalho","ts":"2018-09-29T12:14:25.550Z"}
{"msg":"Using Spring's capabilities, a single executable (signed and/or encrypted) jar can be deployed almost anywhere","username":"LeonardoCarvalho","ts":"2018-09-29T12:15:43.137Z"}
{"msg":"the IETF draft is this:\nhttps://tools.ietf.org/html/draft-gutmann-scep-10","username":"LeonardoCarvalho","ts":"2018-09-29T12:21:32.452Z"}
{"msg":"Has joined the channel.","username":"phaniac","ts":"2018-10-01T18:18:15.812Z","type":"uj"}
{"msg":"Has joined the channel.","username":"wdmason","ts":"2018-10-02T09:06:34.995Z","type":"uj"}
{"msg":"Has joined the channel.","username":"Gerhardvd","ts":"2018-10-02T09:07:24.200Z","type":"uj"}
{"msg":"I have filed https://jira.hyperledger.org/browse/STL-1461 against sawtooth-raft, or at least that was my intention. Was the plain ol' Hyperledger Sawtooth JIRA the best place?","username":"kirkwood","ts":"2018-10-05T15:10:55.391Z"}
{"msg":"@kirkwood that looks fine.","username":"adamludvik","ts":"2018-10-05T15:17:28.530Z"}
{"msg":"Terrific. I like the `adhoc` stuff; makes this sort of testing very smooth.","username":"kirkwood","ts":"2018-10-05T15:24:28.230Z"}
{"msg":"Thanks!","username":"adamludvik","ts":"2018-10-05T15:49:05.845Z"}
{"msg":"@agunde @Dan @jsmitchell @amundson @pschwarz I have been giving some thought to\ndependency and duplicate transaction validation and I'd like to start a\ndiscussion around removing both checks from the core validator. Instead I'd\nlike to consider making these checks the responsibility of app developers. This\nis probably not realistic for the near future, but I think the tradeoffs are\ninteresting to consider.\n\nCurrently, the core validator is required to flag a transaction as invalid if\neither it has already been committed at some time in the past, or if one of the\ndependencies it explicitly calls out has not been committed. This requires\nmaintaining a space efficient data structure of all transactions ever committed\nindefinitely that is also efficient enough to query that it doesn't slow\nperformance. At 10 TPS this means keeping track of roughly a million new\ntransactions per day, and being able to check this list for duplicates for\nevery new transaction. I think this is a tall order over time.\n\nOther platforms I have researched have essentially avoided the issue altogether\nby tying transactions to some \"owned entity\". Bitcoin ties transactions to a\ncoin owned by some key. Ethereum ties transactions to an address and requires\nthe nonce to match, so that a duplicate transaction would fail the second time\naround. In other words, both of these platforms are able to leverage domain\nspecific knowledge to determine duplicate transactions are invalid. But domain\nspecific knowledge is something we don't have in the core validator.\n\nIn the case of transaction dependencies, I think we already do this validation\nin the application layer for many transaction types. Xo transactions depend on\na game being created before it can be played, and transactions are marked as\ninvalid if the game doesn't exist. Smallbank transactions depend on both\naccounts existing. Additionally, dependencies can be enforced by batching\ntransactions together.\n\nIn the case of duplicate transactions, this change would place an extra burden\non application developers to do this check somehow, but we do have some\nexamples already. The same Xo transaction cannot be applied twice, because the\nposition it attempts to take will already have been taken. Seth transactions\nuse the nonce strategy from Ethereum. Smallbank does not have this check, but\nmodifying it to include an account nonce or scheme similar to bitcoins seems\nsimple.\n\nThe other downside to this change is that the core platform would no longer be\nable to assume a transaction maps to at most one block.\n\nIn spite of the downsides, I think this change is still interesting to\nconsider and to gather more data on. I suspect that for a large network,\nperformance will be dragged down. I also suspect that removing these checks\nwill simplify and speed up block validation by offloading all transaction\nvalidation to the transaction processors (with the exception of signature and\nstructure).","username":"adamludvik","ts":"2018-10-05T15:49:26.077Z"}
{"msg":"what's your proposal for intkey that doesn't introduce some weird versioning/serialization smell?","username":"jsmitchell","ts":"2018-10-05T15:59:14.599Z"}
{"msg":"I think it is more interesting to collaborate on a higher level first to determine: 1. if our current solution actually works long term, 2. if moving this validation to the application layer improves performance or design simplicity, and 3. whether it is an unreasonable request of application developers to solve this problem.\n\nIntkey is a weird example because it is contrived to be simplistic and everyone owns everything, but I agree it needs to be considered if 1-3 show promising results. It also doesn't seem that outrageous for a contrived example to allow duplicate transactions and resubmitting the same transaction by other parties.","username":"adamludvik","ts":"2018-10-05T16:18:59.708Z"}
{"msg":"Primarily what I am looking for is whether this seems like an interesting idea to pursue, or a waste of time.","username":"adamludvik","ts":"2018-10-05T16:19:53.386Z"}
{"msg":"I don't think \"everything owns everything\" is the reason intkey is problematic. I think it's problematic because the operations are valid in any order, and certainly the same operation can happen twice (which is semantically the same as currency transfer operations from 'owned' accounts, unless something like utxo is adopted). The contract with the user is that when they sign a transaction it is executed no more than once. That's how we avoid double spend at the platform level. I agree that an existence check against an unbounded set is infeasible, but we need an answer on how we preserve key platform guarantees with any alternate proposal.","username":"jsmitchell","ts":"2018-10-05T16:27:37.378Z"}
{"msg":"Contract with which user? The application developer or the application user? I think the interesting question is \"Does avoiding double spend at the platform level force us to do existence checks against an unbounded set?\" I suspect the answer is yes, since the more efficient solutions I have come across so far all require domain specific knowledge (though I am still looking). I think it is worth explicitly considering the tradeoff between breaking this contract with the application developer at some far point in the future and committing to doing this inefficient check indefinitely.","username":"adamludvik","ts":"2018-10-05T16:45:18.983Z"}
{"msg":"the contract with the entity signing a transaction","username":"jsmitchell","ts":"2018-10-05T16:46:30.816Z"}
{"msg":"would a guarantee limited in time be an option? like, validator guarantees to keep a record of the transactions of the last year and after that the burden of protection against replay is at contract level. That would break noone, since noone has run sawtooth for more than a year ;)","username":"benoit.razet","ts":"2018-10-05T16:50:23.969Z"}
{"msg":"replay attacks are a real thing","username":"jsmitchell","ts":"2018-10-05T16:50:49.734Z"}
{"msg":"@adamludvik I don't think that moving the complexity into applications is good. First, we would end up with just a lot of apps that don't solve double-spend because you need to understand it before you can protect against it. But also, we could solve this in a much easier way by adding a field to batch which specifies a block_id which must be in the history no greater than, say, 1000 block back. then batches \"time out\" if they don't make it on the chain fast enough. if the depth is great enough, no one has to think about it much. however, it would require clients to consult the chain prior to putting together the batch which is not currently required.","username":"amundson","ts":"2018-10-05T19:00:16.519Z"}
{"msg":"this would seem to be important to solve in the context of checkpointing. so maybe it should just be the checkpoint_block_id (initially genesis block), and you solve the problem when you update to a new checkpoint block. would be awkward around checkpointing boundary though, which would have to be considered.","username":"amundson","ts":"2018-10-05T19:02:53.169Z"}
{"msg":"i think that would have to be done in the txn header, not the batch header","username":"jsmitchell","ts":"2018-10-05T19:39:38.495Z"}
{"msg":"but I like the properties of constraining the search space for duplicates to a small maximum and saying \"too old\" otherwise","username":"jsmitchell","ts":"2018-10-05T19:41:02.855Z"}
{"msg":"could be the txn header","username":"amundson","ts":"2018-10-05T20:00:04.485Z"}
{"msg":"yeah, would have to be","username":"amundson","ts":"2018-10-05T20:00:46.658Z"}
{"msg":"What @amundson suggested seems similar to what @benoit.razet suggested, except using block height as a timer instead of wall clock time.","username":"adamludvik","ts":"2018-10-05T20:31:00.066Z"}
{"msg":"You could also just define \"too old\" as after checkpointing","username":"adamludvik","ts":"2018-10-05T20:33:03.207Z"}
{"msg":"Putting an expiration on batches seems good","username":"adamludvik","ts":"2018-10-05T21:47:11.239Z"}
{"msg":"We could require including the current checkpoint block in the batch before submitting, and make all batches not committed expire after the checkpoint","username":"adamludvik","ts":"2018-10-06T02:40:10.858Z"}
{"msg":"Regardless of what you do at the batch level (optional) you must do it at the txn level to prevent someone from including an old txn in a new batch","username":"jsmitchell","ts":"2018-10-06T12:36:13.913Z"}
{"msg":"I think coupling it to checkpointing may introduce some undesirable effects, like a bunch of invalid txns immediately after a checkpoint. Since verification of existence requires the blockstore, not the global state, we can retrieve the required N blocks prior to the checkpoint without mandating that their state root hashes exist in global state.","username":"jsmitchell","ts":"2018-10-06T12:44:07.031Z"}
{"msg":"@adamludvik have you looked into sparse merkle trees?","username":"kelly_","ts":"2018-10-06T18:41:25.573Z"}
{"msg":"it may be a more efficient way to see if that transaction has been included","username":"kelly_","ts":"2018-10-06T18:41:43.174Z"}
{"msg":"A Sparse Merkle Tree is a really interesting variant of a Merkle Tree. It was first proposed by Google in tracking whether certificates have been revoked or not. https://www.links.org/files/RevocationTransparency.pdf.\n\nIt works by creating a massive, uncomputably large binary merkle tree composing of 2²⁵⁶ default leaves (if it’s assumed you are using 256 bit hash function, like sha256). Because most paths in the merkle tree (256 hashes down), has a default value, it’s possible to represent this data structure without having to keep it all in state. Different sizes can also be used. It doesn’t have to be 2²⁵⁶.\n\nThe reason why this is valuable is because you essentially will deterministically know what position in the tree any information will hold (like a token ID or the hash of any certificate). It will always be in the same position. So for Google, hashing a certificate will always mean it is at a specific leaf in the tree.\n\nIn Google’s case, each leaf is either zero or one, where one means, it has been revoked. Doing it this way means that when submitting a merkle root of the whole SMT means you not only show/include a cheap-to-verify proof of what certificates has been revoked, but you ALSO include proofs of certificates that have NOT been revoked (their leaf value is just zero).\n\nSo, by proving that a leaf exists or contains some data, is also a proof of non-inclusion of the rest of the state. ","username":"kelly_","ts":"2018-10-06T18:43:08.596Z"}
{"msg":"https://blog.ujomusic.com/a-plasma-cash-primer-27dcfd1d5ddc","username":"kelly_","ts":"2018-10-06T18:43:17.723Z"}
{"msg":"so just thinking from a query perspective, if the hash of a transaction is not in the sparse merkle tree than that is proof of non-inclusion","username":"kelly_","ts":"2018-10-06T18:45:22.188Z"}
{"msg":"a paper here - https://eprint.iacr.org/2016/683.pdf","username":"kelly_","ts":"2018-10-06T18:46:35.647Z"}
{"msg":"\"We show that our definitions enable efficient space-time trade-offs for different\ncaching strategies, and that *verifiable audit paths can be generated to\nprove (non-)membership in practically constant time (< 4 ms)* when\nusing SHA-512/256\"","username":"kelly_","ts":"2018-10-06T18:47:51.934Z"}
{"msg":"https://github.com/armaniferrante/sparse-merkle-tree/blob/master/src/lib.rs","username":"kelly_","ts":"2018-10-06T19:02:00.977Z"}
{"msg":"Well, Sawtooth uses this structure already:\nhttps://chat.hyperledger.org/channel/sawtooth?msg=7MK7Hq9GHbgr9NoKj","username":"LeonardoCarvalho","ts":"2018-10-06T19:35:40.958Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth?msg=7MK7Hq9GHbgr9NoKj","url":"https://chat.hyperledger.org/channel/sawtooth?msg=7MK7Hq9GHbgr9NoKj","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Has joined the channel.","username":"HandsomeRoger","ts":"2018-10-08T12:12:12.418Z","type":"uj"}
{"msg":"My apologies for potentially spamming the channel but I wanted to share some thoughts, related to the txn id membership pb, and based on my year of experience with Sawtooth and trying to understand where it stands compared to other blockchain platforms:\n\nI see Sawtooth as an interesting platform because a lot of the features that are set in stone in other blockchain solutions, are pluggable in Sawtooth. But this flexibility brings up a number of challenges for a deployed sawtooth network to stay manageable. Below is a list of pbs that are left open with barebone sawtooth-core but can be solved at various levels (operator level, app developer level, app framework level):\n- nondeterminism in transaction family that can impact the consensus of the network\n- txn unbounded runtime execution or inefficiencies in transaction family implementation that can impact the performance of the network\n- unbounded space consumption (set_state leak) can impact the performance of the network overtime because of space limitations\n- namespace restriction can impact the integrity of the global state store\n- tp maintenance for chain replay that can impact the auditability\n\nWhat’s common to all of them is that they can impact the performance/correctness of the platform as a whole, but still sawtooth-core leaves these problems unsolved. Now, compared to the txn replay pb that can definitely be solved at the application level, and keeping in mind that the txn replay attack can only impact the correctness of the app that does not prevent it, as a sawtooth user I’d be fine if sawtooth-core does not solve this pb, but if there exists a workable solution the better.\n\nRelated to the addition of a block_id field to the transaction protobuf: I consider Sawtooth as both a blockchain and a smart contract platform, the latter being arguably independent from the blockchain. To support this idea, the transaction protobuf does not refer to anything block related or global state related (like a merkle root hash). As a result, individual transactions are not tied to any particular blockchain instance, and could be executed in different deployed environments. The underlying feature here is that transactions are _portable_ between blockchains. Adding a block_id field in the transaction protobuf would break this property. I concede that the portability feature may not be commonly used but I would not neglect it because smart contracts are an interesting paradigm that need not be too closely coupled with blockchain.\n","username":"benoit.razet","ts":"2018-10-08T12:27:06.765Z"}
{"msg":"@benoit.razet do you agree that all those issues are mitigated when using seth, for example (because of the additional enforcement on contract storage/gas/limited opcodes from the evm interpreter)?","username":"jsmitchell","ts":"2018-10-08T13:09:12.102Z"}
{"msg":"completely agree, that's what I realized this we","username":"benoit.razet","ts":"2018-10-08T13:09:51.479Z"}
{"msg":"I feel like they are, which is an existence proof for being able to solve these problems at that layer","username":"jsmitchell","ts":"2018-10-08T13:10:01.454Z"}
{"msg":"without calcifying the core","username":"jsmitchell","ts":"2018-10-08T13:10:25.396Z"}
{"msg":"it would be nice to have an out-of-the-box tp with those features uncoupled to ethereum","username":"jsmitchell","ts":"2018-10-08T13:12:11.049Z"}
{"msg":"I had completely overlooked that seth fixed all these issues, instead I considered seth as just an effort to potentially attract eth aficionados to sawtooth","username":"benoit.razet","ts":"2018-10-08T13:13:03.595Z"}
{"msg":"it would nice if sabre would provide these guarantees too","username":"benoit.razet","ts":"2018-10-08T13:13:18.845Z"}
{"msg":"it would nice if sabre could provide these guarantees too","username":"benoit.razet","ts":"2018-10-08T13:13:18.845Z"}
{"msg":"that last point around block_id - not sure about portable between blockchains (I think that would need to be shown with a second blockchain impl), but we definitely plan to run smart contract TPs in different configurations that do not involve blocks","username":"amundson","ts":"2018-10-08T13:14:24.318Z"}
{"msg":"I think the more powerful idea is that those concepts can be enforced in the application domain","username":"jsmitchell","ts":"2018-10-08T13:14:32.425Z"}
{"msg":"which seth demonstrates","username":"jsmitchell","ts":"2018-10-08T13:14:39.705Z"}
{"msg":"@amundson maybe portable is too strong of a term, but I still think it has value. I'm not 100% sure, but bitcoin txns also have this property but it's a side effect of a transaction being the asset, and arguably Ethereum also has this property because the nonce in the txn is a monotonic counter linked to the account of the user, so it's more a local property and not a global one.","username":"benoit.razet","ts":"2018-10-08T13:26:03.975Z"}
{"msg":"I don't know how important the name is, but we could call it checkpoint_id or something instead of block_id. I'm aware of at least one place if not two where someone might want to run a TP outside of sawtooth proper.\nIf you have a sensor or some device with limited connectivity you might not want a requirement for too frequent of checking in with the blockchain. In those environments an infrequent checkpoint might be ok (with the caveat noted above that times around those checkpoints need some thought). ","username":"Dan","ts":"2018-10-08T13:34:23.734Z"}
{"msg":"I don't know how important the name is, but we could call it checkpoint_id or something instead of block_id. I'm aware of at least one place if not too where someone might want to run a TP outside of sawtooth proper.\nIf you have a sensor or some device with limited connectivity you might not want a requirement for too frequent of checking in with the blockchain. In those environments an infrequent checkpoint might be ok (with the caveat noted above that times around those checkpoints need some thought). ","username":"Dan","ts":"2018-10-08T13:34:23.734Z"}
{"msg":"@kelly_ SMTs look good, but they still grow unbounded with the length of the chain, which I think is a problem we want to address. I had considered using radix tree previously in a similar way. At the end of this article, they mention something called \"Plasma Cash\" that seems to be using it as a solution to the problem we discussed. https://medium.com/@kelvinfichter/whats-a-sparse-merkle-tree-acda70aeb837","username":"adamludvik","ts":"2018-10-08T15:55:53.993Z"}
{"msg":"@benoit.razet I agree that keeping transactions portable across deployments and/or implementations is a desirable feature and any changes should take this into consideration.","username":"adamludvik","ts":"2018-10-08T15:58:55.038Z"}
{"msg":"The academic paper on SMTs suggested that the expected case would be a balanced tree with a uniform distribution across the leaves. That seems like a worst case to me because then you've minimized the caching/pruning you can do. It went into some effort to talk about clustering as though that's bad .. I guess leading to an imbalanced tree. Maybe the cost of the proof is higher there because you can't list as many default values. But the overall cost of storing the structure seems better because you can represent more of the tree by defaults - so it's actually sparse.","username":"Dan","ts":"2018-10-08T16:04:05.150Z"}
{"msg":"I feel like I'm missing something.","username":"Dan","ts":"2018-10-08T16:04:14.445Z"}
{"msg":"if the value is default then you don't include it in the tree","username":"kelly_","ts":"2018-10-08T16:21:43.286Z"}
{"msg":"@adamludvik agree on the unbounded length. I don't believe plasma cash solves, the plasma cash tree is bounded to the number of tokens represented in the tree, so it isn't impacted by chain length","username":"kelly_","ts":"2018-10-08T16:22:34.873Z"}
{"msg":"@dan i think the assumption is uniform because the tree covers the entire namespace and hashes occur randomly across that namespace","username":"kelly_","ts":"2018-10-08T16:28:40.618Z"}
{"msg":"Yeah I guess my point was if you imagine the leaf nodes as a bit string\n11110000 implies you don't have anything to store for half the tree but \n10101010 implies you need to store (or reconstruct) all of the branches.","username":"Dan","ts":"2018-10-08T17:23:21.479Z"}
{"msg":"right","username":"kelly_","ts":"2018-10-08T18:13:04.854Z"}
{"msg":"... and 10101010 represents uniform distribution which seems worse than clustering.","username":"Dan","ts":"2018-10-08T20:16:20.490Z"}
{"msg":"Outlined a potential fix that seems to work in https://jira.hyperledger.org/browse/STL-1461; feedback welcome. Especially feedback of the form, \"no, don't do that.\"","username":"kirkwood","ts":"2018-10-11T18:05:11.803Z"}
{"msg":"Man, I keep meaning to put these messages in #sawtooth-consensus-dev . . .","username":"kirkwood","ts":"2018-10-11T18:19:45.839Z"}
{"msg":"awesome!! I'll do a little redirect over in the consensus channel.","username":"Dan","ts":"2018-10-11T18:24:32.987Z"}
{"msg":"Has joined the channel.","username":"bobonana","ts":"2018-10-11T18:50:38.894Z","type":"uj"}
{"msg":"is there any chance that we could get the sawtooth-rest-api package https://github.com/hyperledger/sawtooth-core/tree/master/rest_api available for installation through pip? it's available in APT as `python3-sawtooth-rest-api`","username":"bobonana","ts":"2018-10-11T18:53:47.761Z"}
{"msg":"Has left the channel.","username":"cuevrob","ts":"2018-10-11T21:11:21.569Z","type":"ul"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=nkNWtN7bhYfkDd6os) @bobonana I don't make that decision, butI would  file an issue at https://jira.hyperledger.org/projects/STL so others can hang their hat there and mention they need it too.","username":"danintel","ts":"2018-10-12T17:57:13.184Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=nkNWtN7bhYfkDd6os","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=nkNWtN7bhYfkDd6os","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Do we publish any wheels? I think we just publish debs.","username":"Dan","ts":"2018-10-12T20:03:13.329Z"}
{"msg":"@bobonana this was discussed briefly in next-directory chat. resolution is basically, don't import code from that sawtooth-rest-api, it's not a library.","username":"amundson","ts":"2018-10-13T02:54:39.102Z"}
{"msg":"Has joined the channel.","username":"MohitJuneja","ts":"2018-10-16T03:27:27.279Z","type":"uj"}
{"msg":"https://docs.google.com/document/d/1bQQGT8PKZXzhdceNVRIXoL9NQpdQCY8kGcOrUa-opFY/edit?usp=sharing","username":"kelly_","ts":"2018-10-16T16:47:28.538Z"}
{"msg":"^ blog detailing new 1.1 features and ecosystem growth/apps since 1.0 - would appreciate any feedback","username":"kelly_","ts":"2018-10-16T16:48:01.167Z"}
{"msg":"@adamludvik @achenette ","username":"kelly_","ts":"2018-10-16T16:48:29.232Z"}
{"msg":"@kelly_ Would we want to mention some of the apps built with Sawtooth that have presented at Tech Forum: the Remme folks, @FrankCastellucci's folks.","username":"boydjohnson","ts":"2018-10-16T17:02:14.515Z"}
{"msg":"@kelly_ how would you like feedback?","username":"adamludvik","ts":"2018-10-16T17:08:35.403Z"}
{"msg":"@adamludvik - comments on the doc would be preferred, if there are spelling or grammar mistakes just put track changes on an make them","username":"kelly_","ts":"2018-10-16T17:14:25.939Z"}
{"msg":"sounds good","username":"adamludvik","ts":"2018-10-16T17:14:42.495Z"}
{"msg":"@boydjohnson yea I've been thinking about linking to this: https://github.com/hyperledger/sawtooth-website/blob/0e8b4e181ea6deaae4f979a4dadef448c7c987a6/Users.md","username":"kelly_","ts":"2018-10-16T17:15:00.539Z"}
{"msg":"haven't had the time to make the wordwrap changes to get it merged","username":"kelly_","ts":"2018-10-16T17:15:35.305Z"}
{"msg":"linking to a PR seems like a bad practice from a longevity perspective. I guess I could just put it in a google doc and link to that","username":"kelly_","ts":"2018-10-16T17:15:56.282Z"}
{"msg":"Yeah, looks good, anyway.","username":"boydjohnson","ts":"2018-10-16T17:16:13.813Z"}
{"msg":"Looks good, couple minor comments.","username":"adamludvik","ts":"2018-10-16T17:19:25.734Z"}
{"msg":"@kelly_ - Nice blog post!  I added some comments/questions, plus a handful of wording and grammar tweaks as suggestions (I couldn't find a way to turn on \"tracked changes\").","username":"achenette","ts":"2018-10-16T20:09:21.383Z"}
{"msg":"Awesome thanks! @achenette ","username":"kelly_","ts":"2018-10-16T20:48:45.510Z"}
{"msg":"Has joined the channel.","username":"grapebaba","ts":"2018-10-17T01:43:35.441Z","type":"uj"}
{"msg":"hi guys, i am a newbie here, I have a question. I explore some tasks in JIRA, however I can't find some design docs attached on JIRA task","username":"grapebaba","ts":"2018-10-17T01:50:30.949Z"}
{"msg":"link?","username":"Dan","ts":"2018-10-17T12:45:36.310Z"}
{"msg":"@amundson from a rust conversion perspective what do you think is the right number? github stats on sawtooth core say ~25%, i remember looking at a validator block diagram and it was ~1/2 of the main components","username":"kelly_","ts":"2018-10-17T16:56:51.264Z"}
{"msg":"thats weird, don't know why that did a strikethrough","username":"kelly_","ts":"2018-10-17T16:57:06.948Z"}
{"msg":"oh cause i used ~","username":"kelly_","ts":"2018-10-17T16:57:26.189Z"}
{"msg":"is 40% a good number?","username":"kelly_","ts":"2018-10-17T16:58:48.893Z"}
{"msg":"@kelly_ the numbers on github are going to be skewed because they include a number of transaction families and utilities written in rust that are not the validator. roughly speaking, the architecture consists of the following layers: networking, handler/routing layer, journal, database, and transaction execution. So far, the journal and database layers have been mostly rewritten in Rust. Networking, handler/routing, and transaction execution are still Python. So if you want to say 40% of the architectural layers are in Rust, I think that would be pretty accurate. The layers are definitely not identical in size though, so without doing an actual line count its hard to come up with a verifiable percentage.","username":"adamludvik","ts":"2018-10-17T19:30:57.035Z"}
{"msg":"@adamludvik thanks I appreciate that, will change to 40%. it's not perfect but good high level indication","username":"kelly_","ts":"2018-10-17T19:41:18.594Z"}
{"msg":"also noted on github, on the flip side there are a bunch of tests that are written in python which may skew it the other way","username":"kelly_","ts":"2018-10-17T19:41:33.961Z"}
{"msg":"I think there is also some python code that is no longer fully used but is still in the repo","username":"jsmitchell","ts":"2018-10-17T19:41:43.557Z"}
{"msg":"@kelly_ You may want to mention in the `Users.md` list that it's not vetted or something like that.","username":"danintel","ts":"2018-10-17T22:22:55.166Z"}
{"msg":"yea good call @danintel ","username":"kelly_","ts":"2018-10-18T13:56:26.101Z"}
{"msg":"something like 'not an endorsement'","username":"kelly_","ts":"2018-10-18T13:56:37.568Z"}
{"msg":"@agunde thanks for update 1.1 sounds like it will be a nice release ","username":"silasdavis","ts":"2018-10-18T15:01:51.957Z"}
{"msg":"How vanilla (for want of a better word) PBFT implementation in terms of the original paper? ","username":"silasdavis","ts":"2018-10-18T15:02:31.147Z"}
{"msg":"There are a number of optimisations that most PBFT-likes make particular aeoun","username":"silasdavis","ts":"2018-10-18T15:03:01.408Z"}
{"msg":"@bridgerherman may be able to answer","username":"kelly_","ts":"2018-10-18T15:03:15.815Z"}
{"msg":"I belive that it was meant to follow the original pbft paper","username":"kelly_","ts":"2018-10-18T15:03:23.520Z"}
{"msg":"is there a tldr; on what aeoun does?","username":"kelly_","ts":"2018-10-18T15:03:40.132Z"}
{"msg":"Oops... Around worst case performance in particular ","username":"silasdavis","ts":"2018-10-18T15:03:51.377Z"}
{"msg":"oh ha","username":"kelly_","ts":"2018-10-18T15:03:59.171Z"}
{"msg":"got ya","username":"kelly_","ts":"2018-10-18T15:04:01.773Z"}
{"msg":"Haha sorry typing on phone ","username":"silasdavis","ts":"2018-10-18T15:04:05.497Z"}
{"msg":"That's interesting, in general I have seen optimizations for the optimistic scenario more so than around the worst-case","username":"kelly_","ts":"2018-10-18T15:04:57.972Z"}
{"msg":"@silasdavis here is the current introduction documentation for pbft https://github.com/hyperledger/sawtooth-pbft/blob/master/docs/source/introduction-to-sawtooth-pbft.rst You can see here that the implementation is based the 1999 paper with some adaptions for blockchain. Also here is a description of the work being done now in an effort to make it ready for production https://github.com/hyperledger/sawtooth-pbft/blob/master/docs/source/future-work.rst","username":"agunde","ts":"2018-10-18T15:09:20.442Z"}
{"msg":"Hi guys","username":"grapebaba","ts":"2018-10-18T15:38:43.494Z"}
{"msg":"the sabre project does not support smart contract transaction family right now?","username":"grapebaba","ts":"2018-10-18T15:40:02.537Z"}
{"msg":"Sabre is a smart contract transaction family","username":"zac","ts":"2018-10-18T15:46:17.546Z"}
{"msg":"@grapebaba We have a #sawtooth-sabre channel. ","username":"agunde","ts":"2018-10-18T15:48:15.012Z"}
{"msg":"@silasdavis it is quite vanilla","username":"adamludvik","ts":"2018-10-18T16:25:34.276Z"}
{"msg":"I am working on some basic stuff to mitigate the issues with worst-case performance, but long term we hope to implement additional algorithms with better worst-case performance. I view Sawtooth PBFT as kind of \"getting our feet wet\" in terms of proving out our new API and understanding the level of difficulty in implementing additional algorithms.","username":"adamludvik","ts":"2018-10-18T16:28:07.778Z"}
{"msg":"I am especially interested in the rBFT algorithm that Indy chose for situations where worst-case performance is important.","username":"adamludvik","ts":"2018-10-18T16:29:06.688Z"}
{"msg":"@adamludvik sounds good, if you are at all interested in porting the Tendermint consensus state machine I could approach people about that, they have a fairly good formal description on the way are are working on proving","username":"silasdavis","ts":"2018-10-19T11:45:01.447Z"}
{"msg":"@adamludvik sounds good, if you are at all interested in porting the Tendermint consensus state machine I could approach people about that, they have a fairly good formal description on the way are are working on machine proofs","username":"silasdavis","ts":"2018-10-19T11:45:01.447Z"}
{"msg":"snow white might be worth a look also","username":"silasdavis","ts":"2018-10-19T11:47:06.234Z"}
{"msg":"https://eprint.iacr.org/2016/919.pdf","username":"silasdavis","ts":"2018-10-19T11:47:16.253Z"}
{"msg":"We strongly considered Tendermint early on and I think I remember @Dan maybe having some interest in it? I have not heard of snow white, will take a look.","username":"adamludvik","ts":"2018-10-19T15:38:24.589Z"}
{"msg":"Yeah tendermint is interesting. The thing @adamludvik helped us understand is that the tendermint code itself draws a larger box than what we would draw around consensus .. i.e. it manages network layer etc.\nThe exercise of rewriting just the tendermint algorithm would be cool but not small.","username":"Dan","ts":"2018-10-19T15:46:04.758Z"}
{"msg":"I couldn't articulate off the top of my head what the advantages of tendermint are over pbft. Do you have those handy @silasdavis ","username":"Dan","ts":"2018-10-19T15:47:31.401Z"}
{"msg":"So given you are in the market for implementing PBFT yourselves - the core Tendermint algorithm (as opposed to Tendermint the project) should be reasonably approachable - a little more involved than PBFT - possibly - but not a lot. The layers on top to make it work well in a real system is obviously non-trivial.","username":"silasdavis","ts":"2018-10-19T16:11:53.566Z"}
{"msg":"But I was suggesting you might consider implementing the core in rust yourselves - you would not be behoven to their P2P layer or ABCI interface","username":"silasdavis","ts":"2018-10-19T16:12:36.552Z"}
{"msg":"here is a recent paper that should give a good summary: https://arxiv.org/pdf/1807.04938.pdf","username":"silasdavis","ts":"2018-10-19T16:12:47.372Z"}
{"msg":"they main difference is that they have a termination mechanism that means they have a single mode of operation and this can be less costly than the recovery phase in PBFT","username":"silasdavis","ts":"2018-10-19T16:13:36.423Z"}
{"msg":"There's obviously plenty of complexity around how you validate transactions and make sure the decision value you are using is up-to-date, and gossip etc. But I think they've refined down the core to something fairly nice in that recent paper","username":"silasdavis","ts":"2018-10-19T16:19:34.114Z"}
{"msg":"snow white: https://eprint.iacr.org/2016/919.pdf","username":"silasdavis","ts":"2018-10-19T16:19:51.461Z"}
{"msg":"@silasdavis any thoughts about honeybadger? I see they have a start on a rust implementation (https://github.com/rphmeier/honeybadger)","username":"amundson","ts":"2018-10-19T16:21:16.510Z"}
{"msg":"(like, a very minimal start, but at least there is some interest)","username":"amundson","ts":"2018-10-19T16:21:49.154Z"}
{"msg":"yeah I was actually going to suggest that, though I wasn't sure what your finality requirements are","username":"silasdavis","ts":"2018-10-19T16:39:00.208Z"}
{"msg":"it's in the fully async model and potentially has quite high latency","username":"silasdavis","ts":"2018-10-19T16:40:55.990Z"}
{"msg":"it's in the fully async model and potentially has quite high latency (i.e. convergence to a decision with probably 1, but not sure how it responds under various network conditions/attacks - probably better on large networks where law of large numbers can help)","username":"silasdavis","ts":"2018-10-19T16:40:55.990Z"}
{"msg":"but it would definitely be an interesting one to have in the mix","username":"silasdavis","ts":"2018-10-19T16:41:08.029Z"}
{"msg":"as would hashgraph though patent encumbered in US","username":"silasdavis","ts":"2018-10-19T16:41:21.113Z"}
{"msg":"incidentally I'm always going back to these notes: http://www.scs.stanford.edu/17au-cs244b/notes/","username":"silasdavis","ts":"2018-10-19T16:41:40.749Z"}
{"msg":"when trying to remember the tradeoffs, they're really succinct and actually have decent sketch proofs for some properties","username":"silasdavis","ts":"2018-10-19T16:42:15.011Z"}
{"msg":"e.g. for HoneyBadger: http://www.scs.stanford.edu/17au-cs244b/notes/honey-badger.txt","username":"silasdavis","ts":"2018-10-19T16:42:31.318Z"}
{"msg":"this is great stuff for #sawtooth-consensus-dev if we start to dive deeper","username":"amundson","ts":"2018-10-19T16:48:12.704Z"}
{"msg":"Has left the channel.","username":"kthblmfld","ts":"2018-10-19T18:40:56.973Z","type":"ul"}
{"msg":"Any suggestions / resources to help me with mocking hyper library to test server/client?","username":"arsulegai","ts":"2018-10-24T06:06:15.575Z"}
{"msg":"@arsulegai try in #sawtooth ","username":"Dan","ts":"2018-10-24T16:58:21.321Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=e4KT4KA9zJHCNoPTD) @Dan Sure, thanks","username":"arsulegai","ts":"2018-10-24T18:03:52.515Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=e4KT4KA9zJHCNoPTD","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=e4KT4KA9zJHCNoPTD","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Has joined the channel.","username":"MatthewRubino","ts":"2018-10-26T13:01:38.689Z","type":"uj"}
{"msg":"Has joined the channel.","username":"ApurvTandon","ts":"2018-10-28T20:13:14.721Z","type":"uj"}
{"msg":"@agunde Is the intent of the `unset` here  https://github.com/hyperledger/sawtooth-core/blame/d3bf28029090ae38a4d743d417c7ca15b6cd7e1e/protos/identity.proto#L24\nThat the transaction will fail unless the sender explicitly sets `permit` or `deny`?\n","username":"Dan","ts":"2018-10-29T15:37:35.700Z"}
{"msg":"Yes, that is standard for all enums protobuf we use. If you don't have an unset option set to 0, what ever you set to 0 will be the default. ","username":"agunde","ts":"2018-10-29T15:49:12.324Z"}
{"msg":"Which can cause some fun bugs. @Dan ","username":"agunde","ts":"2018-10-29T15:50:32.500Z"}
{"msg":"thx :)","username":"Dan","ts":"2018-10-29T16:00:57.399Z"}
{"msg":"Wanted to discuss on the Jira item - https://jira.hyperledger.org/browse/STL-1375\n\nThis has two parts to itfirst one is to allow ``context.get_state()`` (or depending on which language ``stateInstance.getState()``) accept partial addresses. If partial address is supplied then return the Map of key: address and value: state_data matching the prefix.\n\n--> I am planning to extend current SDK method to get this done. i.e. get_state() will now allow query by partial addresses.\n\n","username":"arsulegai","ts":"2018-10-31T09:38:29.413Z"}
{"msg":"Wanted open discussion on the Jira item - https://jira.hyperledger.org/browse/STL-1375\n\nThere are two parts to it\n*Part 1:* allow ``context.get_state()`` (or depending on which language ``stateInstance.getState()``) accept partial addresses. If partial address is supplied then return the Map of key: address and value: state_data matching the prefix.\n--> I am planning to extend current SDK method to get this done. i.e. get_state() will now allow query by partial addresses.\n\n*Part 2:* to get list of all addresses where there's non-empty data. I will introduce a new method something like ``context.list_data_addresses()``\n\nPlease feel free to comment / suggest your views","username":"arsulegai","ts":"2018-10-31T09:38:29.413Z"}
{"msg":"Wanted open discussion on the Jira item - https://jira.hyperledger.org/browse/STL-1375\n\nThere are two parts to it\n*Part 1:* allow ``context.get_state()`` (or depending on which language ``stateInstance.getState()``) accept partial addresses. If partial address is supplied then return the Map of key: address and value: state_data matching the prefix.\n--> I am planning to extend current SDK method to get this done. i.e. get_state() will now allow query by partial addresses.\n\n*Part 2:* to get list of all addresses where there's non-empty data. I will introduce a new method something like ``context.list_data_addresses()``\n\nPlease feel free to comment / suggest your views","username":"arsulegai","ts":"2018-10-31T09:38:29.413Z"}
{"msg":"@arsulegai I would wonder if this would be good for an RFC, https://github.com/hyperledger/sawtooth-rfcs, then there could be greater discussion of the various tradeoffs. ","username":"boydjohnson","ts":"2018-10-31T13:33:49.201Z"}
{"msg":"Has joined the channel.","username":"chainsaw","ts":"2018-10-31T14:29:05.312Z","type":"uj"}
{"msg":"@arsulegai I agree with @boydjohnson that we would need an RFC for this -- but first, maybe we should discuss it here. do you have some example use cases?  if you are reading across multiple state nodes, the first thought that occurs to me is that you may have defined the addressing scheme inefficiently.","username":"amundson","ts":"2018-10-31T15:59:52.988Z"}
{"msg":"That feature request was submitted by @yoni  and he will have better context on the motivations. Arun ( @arsulegai ) is looking at implementing it. I suggested we use jira for fleshing out this feature vs rfcs. I had a couple reasons in mind .. when the issue first arose the RFC process was still new. More importantly I'd like to explore whether for little features it's more efficient to do a little jira review and add the feature rather than a multi-month RFC process. ","username":"Dan","ts":"2018-10-31T16:06:22.505Z"}
{"msg":"I can see the usefulness of the 2nd part in the description of STL-1375 which is to determine presence or absence of data at an address. I would be interested to know the motivation to extend the get operation to a prefix instead of a full address since it breaks my mental computational model for sawtooth. Is this really a \"little feature\"? it looks like it would impact the parallel scheduler, and some protos like the state_context.proto.","username":"benoit.razet","ts":"2018-10-31T16:39:48.131Z"}
{"msg":"@Dan it changes the stable API surfaces (presumably, including the stable interface between the validator and TPs) and adds a degree of ongoing support for the overall team. an RFC is appropriate.","username":"amundson","ts":"2018-10-31T16:58:52.345Z"}
{"msg":"I don't have a strong opinion on this feature yet - the JIRA isn't enough to justify changing the API surface, IMO - but, that's what we can flush out here (an understanding of why its useful)","username":"amundson","ts":"2018-10-31T17:05:31.466Z"}
{"msg":"the existence of data at addresses isn't completely sufficient for any use case that handles hash collision (if addressing is done via hashing). you can have an index node, though that is not good from a parallelization perspective. maybe the addressing scheme which makes these features interesting is thus not hashing-based?","username":"amundson","ts":"2018-10-31T17:30:50.653Z"}
{"msg":"for example, if I did an existence check on the settings namespace, that's not very informative because of the addressing scheme","username":"amundson","ts":"2018-10-31T17:35:55.402Z"}
{"msg":"@amundson do you mean an existence check from a prefix or a full address?","username":"benoit.razet","ts":"2018-10-31T17:43:49.780Z"}
{"msg":"the use-case I have in mind is having a contract raise an InvalidTransaction when it finds unexpectedly data at an address. For example if the address is the result of the hash of a uid, then it would be up to the client to resbumit a transaction with a different uid to avoid collision.  ","username":"benoit.razet","ts":"2018-10-31T17:49:12.933Z"}
{"msg":"that could just be a flag on the set operation to abort if there is already data present though too, if you were going for efficiency","username":"amundson","ts":"2018-10-31T18:07:04.046Z"}
{"msg":"but what I mean is, if you get the existence check/list of everything set in the settings namespace, you still have to take the setting name, hash it, and compare. you can't do the reverse, so it won't tell you what settings exist. doesn't seem useful at all with that addressing scheme.","username":"amundson","ts":"2018-10-31T18:08:43.959Z"}
{"msg":"if you however had an addressing scheme that wasn't hashing, then maybe that existence list would have more meaning and value for the TP - i.e. give you an index without needing to write an index manually to a specific node (which involves write contention, which is bad)","username":"amundson","ts":"2018-10-31T18:11:01.041Z"}
{"msg":"if that part of the tree that you were doing that existence list on had a lot of state nodes present, that would turn into quite a few reads within the validator though, which might make it less efficient overall than storing the index and incurring the write penalty","username":"amundson","ts":"2018-10-31T18:15:49.460Z"}
{"msg":"abstractly, it would be easy to estimate the number of reads if you had a use case and knew the estimated number of state nodes. if there were N state nodes, then at worst something like 32*N reads to do that scan (assuming a normal size prefix for state addressing, because we would exclude that).  you could potentially exclude the read of the actual data node too, so maybe 31*N worst case. some nodes in the tree would overlap so it would be less than 31*N in practice.","username":"amundson","ts":"2018-10-31T18:21:39.376Z"}
{"msg":"In the longer run - a breaking change, for sure - would be to modify the messages to actually deal with no-set versus empty data, which are possibly two separate states","username":"pschwarz","ts":"2018-10-31T20:23:27.113Z"}
{"msg":"@benoit.razet I think the use case is currently supported, as long as you're not writing empty data","username":"pschwarz","ts":"2018-10-31T20:25:00.722Z"}
{"msg":"@benoit.razet I think your use case is currently supported, as long as you're not writing empty data","username":"pschwarz","ts":"2018-10-31T20:25:00.722Z"}
{"msg":"@amundson a flag on the get operation to indicate to return a boolean for presence of data would not hurt in addition to the flag on the set operation ;) I'm fine with the interface as it is today, it works for my use-case no problem @pschwarz , I was just thinking of what extension could save transfer of data between the validator and tp, but I can always burn one more address containing exclusively this boolean. ","username":"benoit.razet","ts":"2018-11-01T12:26:03.707Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=pSuMPrta9ifoqttYr) @benoit.razet Yes, there'll be new addition to proto file for second part. However, isn't parallel scheduling dependent on input/output addresses of transaction header? (I couldn't understand how context.get_state() will impact scheduling)\n\nPartial prefix can be in input addresses of transaction header, so TP has access to read data at addresses having these prefix. Please correct me if I misunderstood something here.","username":"arsulegai","ts":"2018-11-01T13:47:01.387Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=pSuMPrta9ifoqttYr","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=pSuMPrta9ifoqttYr","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=F8fz6ih3GhajpL6sR) @amundson Agree,\nQuestion extending this use case what would be efficient way to know how many setting entries are present?","username":"arsulegai","ts":"2018-11-01T13:55:56.679Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=F8fz6ih3GhajpL6sR","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=F8fz6ih3GhajpL6sR","remote":true,"fileId":null,"fileName":null}]}
{"msg":"There is no index, so you'd have to count them","username":"jsmitchell","ts":"2018-11-01T14:12:04.564Z"}
{"msg":"@benoit.razet yeah, I don't see any downside to the set-if-not-set boolean/and was-set return flag other than maybe just making the api bigger, so if it was useful. in most of the apps we have done though, we using hashing and handle hash collisions so neither are useful because you have to do a read and unpack a list.","username":"amundson","ts":"2018-11-01T15:06:16.974Z"}
{"msg":"@arsulegai the point about interference with the parallel scheduler was, I think, commentary on setting input/output to prefixes instead of specific nodes. if you set input to a prefix, any write to a node in that prefix will cause serialization because you have contention between the transactions. similar but worse if you set output to a prefix. it's a feature but also a trade-off.","username":"amundson","ts":"2018-11-01T15:11:21.840Z"}
{"msg":"@arsulegai If the goal is to allow searching or iterating through a set of state nodes then we would probably want to use an iterator-style pattern and not a list-all-the-addresses pattern. something that can handle the large address space available (2^(8*35)?), or a fair chunk of it.","username":"amundson","ts":"2018-11-01T15:24:46.424Z"}
{"msg":"@arsulegai thoughts on the use case for this?","username":"amundson","ts":"2018-11-01T15:25:48.320Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=fc7f3a8b-62b2-4e05-8472-604df2d945df) @arsulegai No, it would not tell you how many settings entries are present because there may be multiple settings stored at any given node due to hash collisions. (Also, not interesting to know the number of settings set.)","username":"amundson","ts":"2018-11-01T15:27:34.545Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=fc7f3a8b-62b2-4e05-8472-604df2d945df","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=fc7f3a8b-62b2-4e05-8472-604df2d945df","remote":true,"fileId":null,"fileName":null}]}
{"msg":"for a sparse tree, a depth first search iterator would be fine, and I believe one is already present in the merkle trie implementation. It would just be a question of exposing the interface. Once you got above a certain number of leaf nodes or a certain overall response size (in bytes), you'd probably want to bail out of the call (or do something like cursor/pagination).","username":"jsmitchell","ts":"2018-11-01T15:30:07.203Z"}
{"msg":"what do you do with transactions that take forever to run, because they are scanning the state tree? I'm not sure we have anything protecting against that currently. Probably we should add something that causes transactions that make more than X number of iterations calls fail if we add this so its deterministically capped.","username":"amundson","ts":"2018-11-01T15:33:56.861Z"}
{"msg":"even without this iterator, from a sabre point-of-view, capping the number of requests would be good.","username":"amundson","ts":"2018-11-01T15:35:51.357Z"}
{"msg":"@agunde ^","username":"amundson","ts":"2018-11-01T15:36:32.182Z"}
{"msg":"@yoni if you are around can you comment here or in the jira (preferably in the jira) on the motivating use case? (https://jira.hyperledger.org/browse/STL-1375)","username":"Dan","ts":"2018-11-01T16:48:49.481Z"}
{"msg":"Has left the channel.","username":"MatthewRubino","ts":"2018-11-02T13:20:21.676Z","type":"ul"}
{"msg":"I haven't run tests locally in forever. I've been leaning on jenkins. Saw there was a maillist question though and I can repeat that failure on my system. Is anyone successful with bin/run_tests locally? \n```Aborting on container exit...\nERROR:__main__:Test error in UNIT-CLI\nERROR:__main__:Command '['docker-compose', '-p', 'latest', '-f', './cli/tests/unit_cli.yaml', 'up', '--abort-on-container-exit']' returned non-zero exit status 1.\nTraceback (most recent call last):\n  File \"/Users/dcmiddle/project/stl/sawtooth-core/bin/run_docker_test\", line 126, in main\n    timeout=timer.remaining())\n  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/subprocess.py\", line 418, in run\n    output=stdout, stderr=stderr)\nsubprocess.CalledProcessError: Command '['docker-compose', '-p', 'latest', '-f', './cli/tests/unit_cli.yaml', 'up', '--abort-on-container-exit']' returned non-zero exit status 1.\nINFO:__main__:Container latest_unit-cli_1 ran image cli-tests:latest with install-type \nINFO:__main__:Shutting down with: ['docker-compose', '-p', 'latest', '-f', './cli/tests/unit_cli.yaml', 'down', '--remove-orphans', '--volumes']\nRemoving latest_unit-cli_1 ... done\nRemoving network latest_default\nERROR:__main__:Test UNIT-CLI failed\n```","username":"Dan","ts":"2018-11-02T14:34:37.697Z"}
{"msg":"I believe if you do `./bin/run_tests` locally from a clean system, it will build all the docker images you need automatically for you, but this build time gets counted as part of the test time, so the test can time out before it actually starts. @rbuysse can you confirm?","username":"adamludvik","ts":"2018-11-02T17:33:00.531Z"}
{"msg":"I can deny","username":"rbuysse","ts":"2018-11-02T18:12:02.360Z"}
{"msg":"you noticed that behavior a while ago and I did a wicked good PR to fix https://github.com/hyperledger/sawtooth-core/commit/e8f1749ad390dd5b8db9de9333fe3da82791a6d7#diff-6c20dc43cd4f6ca422048e2a848211d9","username":"rbuysse","ts":"2018-11-02T18:12:24.061Z"}
{"msg":"I did build then up then run tests...\n```\ndocker-compose -f docker/compose/sawtooth-build.yaml build\ndocker-compose -f docker/compose/sawtooth-build.yaml up\n\n```","username":"Dan","ts":"2018-11-02T18:57:08.785Z"}
{"msg":"I did build then up then run tests...\n```\ndocker-compose -f docker/compose/sawtooth-build.yaml build\ndocker-compose -f docker/compose/sawtooth-build.yaml up\nbin/run_tests\n```","username":"Dan","ts":"2018-11-02T18:57:08.785Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=XzgM8W6MkacNhFAdG) @amundson  hmm, I agree to this. But as such SDK API to read several addresses (as long as transaction header in batch list allows it) at once would not affect scheduler was my point earlier.","username":"arsulegai","ts":"2018-11-03T10:17:11.954Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=XzgM8W6MkacNhFAdG","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=XzgM8W6MkacNhFAdG","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=bQxzBQyqeahHe9jtA) @amundson I would also request @yoni to comment on this.","username":"arsulegai","ts":"2018-11-03T10:18:25.494Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=bQxzBQyqeahHe9jtA","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=bQxzBQyqeahHe9jtA","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Has joined the channel.","username":"Isaiah_Kim","ts":"2018-11-03T14:31:59.584Z","type":"uj"}
{"msg":"Has joined the channel.","username":"eugene-babichenko","ts":"2018-11-05T10:14:41.631Z","type":"uj"}
{"msg":"Hello, I would like to have a discussion about one thing regarding working with seeds/peers. Our development team want to have the possibility to add peers manually (for example, by invoking a REST API method). If the core team likes the feature I would create a pull request to the core repository with the implementation of this functionality.","username":"eugene-babichenko","ts":"2018-11-05T10:17:43.800Z"}
{"msg":"Has joined the channel.","username":"ddhulla","ts":"2018-11-05T10:46:00.205Z","type":"uj"}
{"msg":"I think that's an interesting idea. In terms of administration, we have the `sawadm` CLI which effects the local filesystem. The `sawnet` command requests from multiple nodes (but does not change them) .. kind of a monitoring feature. The sawtooth processes are controlled (in ubuntu at least) using the OS mechanisms (systemd, systemctl,..)\nWhere do you think a remote call to change local peers would be implemented?\nAs far as general process for adding a feature: after gathering feedback here you probably need to write-up the approach as an RFC to gain wider feedback. That's usually the case for changing established APIs or significant new feature sets. \nSee: https://github.com/hyperledger/sawtooth-rfcs\nAnd any of the PRs (open and/or closed) on that repo.","username":"Dan","ts":"2018-11-05T19:16:40.837Z"}
{"msg":"@amundson @jsmitchell motivation is updated by @yoni in https://jira.hyperledger.org/browse/STL-1375","username":"arsulegai","ts":"2018-11-06T03:44:38.673Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=wk4rG3rGHhE5PoJMm) @Dan Thank you for the feedback! I think that the overall idea of the implementation would be the following. We already have the method `Gossip.add_candidate_peer_endpoints` and I think it is suitable for implementation of such feature (I can be wrong). Then I will add a new protobuf definitions with something like `AddPeersRequest` (containing the list of peers to be added) and `AddPeersResponse`. With that I should be able to implement a corresponding handler in `sawtooth_validator.state.client_handlers`. With that handler it will be fairly easy to add `POST /peers` to the REST API and implement `sawnet peers add` on top of that method.","username":"eugene-babichenko","ts":"2018-11-06T07:54:32.237Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=wk4rG3rGHhE5PoJMm","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=wk4rG3rGHhE5PoJMm","remote":true,"fileId":null,"fileName":null}]}
{"msg":"who would have rights to add a peer? ","username":"Dan","ts":"2018-11-06T14:04:16.478Z"}
{"msg":"Any REST API user I think. This is acceptable for us because we do not expose the REST API and use it only internally. This should not be a problem for Sawtooth too, because the documentation suggests using proxy servers to restrict access to a publicly exposed REST API server.","username":"eugene-babichenko","ts":"2018-11-06T15:02:24.442Z"}
{"msg":"That's probably too permissive. In the existing system, you need administrative access to alter the validator process including it's local configuration and peer assignment. If this was wide open then anyone within your intranet could kill your validator.","username":"Dan","ts":"2018-11-06T15:26:59.847Z"}
{"msg":"I think this kind of feature would be good to add to a management console. Just need to think through some things like the appropriate security policies.","username":"Dan","ts":"2018-11-06T15:28:13.200Z"}
{"msg":"Ok, I got your point. Maybe it should be based on key permissioning with signed requests? Following such approach we can just add a role called `admin`, use it for off-chain permissioning on `POST /peers` method and work with it as described here https://sawtooth.hyperledger.org/docs/core/nightly/master/sysadmin_guide/configuring_permissions.html#transactor-roles-label","username":"eugene-babichenko","ts":"2018-11-06T16:20:10.044Z"}
{"msg":"Ok, I got your point. Maybe it should be based on key permissioning with signed requests? Following such approach we can just add a role called `admin`, use it for off-chain permissioning on `POST /peers` method and work with it as described here https://sawtooth.hyperledger.org/docs/core/nightly/master/sysadmin_guide/configuring_permissions.html","username":"eugene-babichenko","ts":"2018-11-06T16:20:10.044Z"}
{"msg":"yeah that sounds like the right direction... extending the off-chain permissioning from transactors to validator-admins or something like that. I'm not sure whether the / a rest service should be cognizant of that or whether that decision is solely evaluated at the validator process. I'm inclined to think that this permissioning would be defined solely at the validator and that securing the rest endpoint would be a separate matter through separate means.. defense in depth etc. \nThere should also be some discussion about whether this functionality would be added to the example REST API. That service gets treated like a default component by many users, while others deploy only custom rest services.\nYou might see if others chime in on this hear over the next few days. You could also consider summarizing the discussion for the mail list for those who don't monitor this channel. Once you feel like you have a good sense of the problem and solution you can put up the RFC.","username":"Dan","ts":"2018-11-06T18:50:01.781Z"}
{"msg":"I noticed this inconsistency in the validator tp api and a difference in the Rust and Python SDKs around empty state addresses. ```\n Validator TP Interface\n \ttransaction has wildcarded inputs\n \t\tGet_State and the address is not in state\n \t\t\tentries: []\n \t\t\t\n \ttransaction has full addresses as inputs\n \t\tGet_State and the address is not in state\n \t\t\tentries: [Entry(address, data='')]\n \t\n \t\nPython Sdk\n\tentries: [] or [Entry(address, data='')]\n\t\tthen entries: []\n\t\t\nRust Sdk\n\tentries: []\n\t\tthen Err(ContextError::ResponseAttributeError)\n\tentries: [Entry(address, data='')]\n\t\tthen Ok(None)\n```","username":"boydjohnson","ts":"2018-11-07T21:08:28.533Z"}
{"msg":"@eugene-babichenko seems like a good feature. I assume this would only apply when using static peering?","username":"amundson","ts":"2018-11-08T15:15:06.857Z"}
{"msg":"not sure about whether it's appropriate for the REST API, we don't otherwise use it for administration","username":"amundson","ts":"2018-11-08T15:16:51.416Z"}
{"msg":"@agunde any thoughts on this? ^","username":"amundson","ts":"2018-11-08T15:20:17.174Z"}
{"msg":"I like the idea. The goal is essentially to be able to add new peers to at static network without needing to stop a node and edit the config file? (or command line) It does seem like a good candidate for expanding the permissioning. I would suggest coming up with a more specific role then `admin` (as this will need to be checked by the validator itself). Possible `admin.peers` which would open up other such use cases. Another thing to keep in mind is that off-chain permissioning is only local to that specific validator, so it would be good to think about if there is a use case that it you may want to put this setting on chain (using the Identity transaction family) so that all validators have the same permissioning.","username":"agunde","ts":"2018-11-08T15:34:39.840Z"}
{"msg":"I am thinking of the batch injection issue. In the Python validator, a batch injector implements a Python ABC, and the batch injector factory does dynamic imports of the python module. I am wondering what thoughts there are of loading a share library that uses a Rust interface to do batch injection. That will decouple the batch injector from the validator. It could be similar to Redis with its modules system in Redis 4. Or postgresql and modules like Postgis and pgrouting.","username":"boydjohnson","ts":"2018-11-08T16:24:12.300Z"}
{"msg":"@ltseeley fyi on my local system getting a unit test failure on your backport PR branch. ","username":"Dan","ts":"2018-11-08T21:17:22.740Z"}
{"msg":"Has joined the channel.","username":"ltseeley","ts":"2018-11-08T21:17:22.864Z","type":"uj"}
{"msg":"```ERROR:__main__:Test error in TEST-PEER-LIST\nERROR:__main__:Command '['docker-compose', '-p', 'latest', '-f', '/Users/dcmiddle/project/stl/sawtooth-core/integration/sawtooth_integration/docker/test_peer_list.yaml', 'up', '--abort-on-container-exit']' returned non-zero exit status 127.\n```","username":"Dan","ts":"2018-11-08T21:17:52.268Z"}
{"msg":"might be a build failure on my end.","username":"Dan","ts":"2018-11-08T21:18:28.892Z"}
{"msg":"```devmode-1_1       | /project/sawtooth-core/sdk/examples/devmode_rust/bin/devmode-rust: error while loading shared libraries: libssl.so.1.0.0: cannot open shared object file: No such file or directory\n```","username":"Dan","ts":"2018-11-08T21:19:50.704Z"}
{"msg":"Yeah, that test works for me locally","username":"ltseeley","ts":"2018-11-08T21:20:36.408Z"}
{"msg":"do you have sawtooth-devmode and sawtooth-devmode-images?","username":"rbuysse","ts":"2018-11-08T22:08:55.229Z"}
{"msg":"do you have sawtooth-devmode and sawtooth-devmode-local images?","username":"rbuysse","ts":"2018-11-08T22:08:55.229Z"}
{"msg":"```$ docker image list '*devmode*'\nREPOSITORY                    TAG                 IMAGE ID            CREATED             SIZE\nsawtooth-devmode-rust-local   latest              34fde9f29896        27 minutes ago      1.22GB\nsawtooth-devmode-local        latest              5fdf70ec2c81        10 days ago         1.18GB```","username":"Dan","ts":"2018-11-08T22:09:20.244Z"}
{"msg":"FWIW I got a clean build and test pass locally on Logan & Boyd's backport branch. Just confirming what Jenkins already produced. ","username":"Dan","ts":"2018-11-09T19:29:00.482Z"}
{"msg":"I guess the more meaningful thing is to test the poet repo against those binaries.  That poet build is still :runner_tone5: ","username":"Dan","ts":"2018-11-09T19:35:19.997Z"}
{"msg":"I think test-dynamic-network is passing but I do see protobuf related errors. The liveness test is failing and I see the same errors there: \n```poet-0_1                        | [2018-11-09 23:04:43.049 DEBUG    engine] Received message: CONSENSUS_NOTIFY_PEER_CONNECTED\npoet-0_1                        | [2018-11-09 23:04:43.050 ERROR    engine] Unknown type tag: CONSENSUS_NOTIFY_PEER_CONNECTED\npoet-0_1                        | [2018-11-09 23:04:43.299 DEBUG    engine] Received message: CONSENSUS_NOTIFY_PEER_CONNECTED\npoet-0_1                        | [2018-11-09 23:04:43.299 ERROR    engine] Unknown type tag: CONSENSUS_NOTIFY_PEER_CONNECTED\n```\nThat message type has been around for 7 months so I don't know what's up there. ","username":"Dan","ts":"2018-11-10T00:31:16.630Z"}
{"msg":"Ok so that's probably a red herring (gray/blue herring for reference: :fish: )\nPoet engine should probably just ignore those messages. (in fact I can't see where that message is used by any consensus).","username":"Dan","ts":"2018-11-10T01:33:23.070Z"}
{"msg":"Ok so that's probably a red herring (gray herring for reference: :fish: )\nPoet engine should probably just ignore those messages. (in fact I can't see where that message is used by any consensus).","username":"Dan","ts":"2018-11-10T01:33:23.070Z"}
{"msg":"https://pastebin.com/eCbTPB0n","username":"Dan","ts":"2018-11-10T15:32:57.070Z"}
{"msg":"validator-0_1                   | thread 'PublisherThread' panicked at 'BlockInjector.block_start failed: PyErr { ptype: <class 'TypeError'>, pvalue: Some(\"a bytes-like object is required, not 'BlockHeader'\"), ptraceback: Some(<traceback object at 0x7fda0bb254c8>) }', libcore/result.rs:1009:5","username":"Dan","ts":"2018-11-10T15:33:32.810Z"}
{"msg":"@amundson Yes, this is to manage a system with static peering without having to restart a node. @agunde Not sure if this permissioning should be on-chain. I think I will prepare an RFC to discuss that further.","username":"eugene-babichenko","ts":"2018-11-12T09:39:50.315Z"}
{"msg":"@eugene-babichenko sounds good","username":"amundson","ts":"2018-11-12T15:52:22.571Z"}
{"msg":"Would anyone from the Sawtooth community care to comment on this indy-hipe that changes our \"rust-like rfc\" process to try to make it easier? https://github.com/hyperledger/indy-hipe/pull/56/files I'm hoping we can have an emerging consensus on how to best handle these repos to ease cross-project collaborations at Hyperledger, and am looking for perspectives from outside Indy before we make substantial changes.","username":"nage","ts":"2018-11-12T16:55:49.877Z"}
{"msg":"@nage for the numbering, we use the PR number; kind of nice because after the PR is created you know the number immediately","username":"amundson","ts":"2018-11-13T02:48:58.682Z"}
{"msg":"oh, I was initially missing the anti-PR piece","username":"amundson","ts":"2018-11-13T02:52:03.131Z"}
{"msg":"@nage my initial thought is that the feedback mechanism would be worse with the proposed change","username":"amundson","ts":"2018-11-13T02:58:23.423Z"}
{"msg":"and since the entire point is to gather feedback and respond to it, probably not worth the trade-off","username":"amundson","ts":"2018-11-13T02:59:02.675Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=h9HvGfMhdCuCvTfA8) @amundson @jsmitchell any thoughts on comment updated by @yoni ?","username":"arsulegai","ts":"2018-11-13T03:32:38.182Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=h9HvGfMhdCuCvTfA8","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=h9HvGfMhdCuCvTfA8","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Has joined the channel.","username":"socoboy","ts":"2018-11-13T07:29:03.456Z","type":"uj"}
{"msg":"Hi everyone, I'm using the latest version of Sawtooth from commit at Nov 1 - 8a366ad2\nI'm having issue which I don't know root cause and how to fix it, When I sent a fail transaction (which would be rejected by Transaction Processor), the transaction is sent continuously to transaction processor, like it stucked in a loop, until another succes transaction verified","username":"socoboy","ts":"2018-11-13T07:32:25.235Z"}
{"msg":"If anyone know how to fix it, please help me. Thank you so much","username":"socoboy","ts":"2018-11-13T07:32:37.533Z"}
{"msg":"If it is generating an InternalError it will be retried. In most cases InternalErrors should not be raised in the TransactionProcessor and should instead return an InvalidTransaction. @socoboy Are you using your own TransactionProcessor? Do you see InternalError logs?","username":"agunde","ts":"2018-11-13T13:32:20.297Z"}
{"msg":"@arsulegai it does not cover most of the questions I had asked here","username":"amundson","ts":"2018-11-13T14:10:17.501Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=miuJGpqA4Cvb5ttk7) @amundson Hmm.. ok, thanks","username":"arsulegai","ts":"2018-11-13T14:38:29.974Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=miuJGpqA4Cvb5ttk7","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=miuJGpqA4Cvb5ttk7","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=he9uJD9vuHaDH9DFY) @amundson Thanks.  I'll add these comments to the PR","username":"nage","ts":"2018-11-13T15:49:18.624Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=he9uJD9vuHaDH9DFY","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=he9uJD9vuHaDH9DFY","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=jjjLdx3YgwNi8ZZG7) @agunde Hi @agunde , I just return an InvalidTransactionError like this\n```\n\tif createAccountData.UserPublicAddress == \"\" {\n\t\treturn &processor.InvalidTransactionError{Msg: \"Public address must not be empty\"}\n\t}\n```\nLet me check on the log and let you know more detaily","username":"socoboy","ts":"2018-11-14T04:55:37.154Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=jjjLdx3YgwNi8ZZG7","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=jjjLdx3YgwNi8ZZG7","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Hi @agunde, Here are the logs on our TP:\n```\n\nsawtooth-fruitchain-tp-go-default | 2018/11/14 04:59:25.790211 handler.go:64: [DEBUG] fruitchain txn 6562a688a43e7192a046ff8a74731333e8961eac10952f67eb7bed6e307db7c90f1b4b9b3cff39b5d402158ef0d5574df359f6865230e279c66967ceefd24073: type CREATE_PERMISSION\nsawtooth-fruitchain-tp-go-default | 2018/11/14 04:59:25.790239 handler.go:67: [DEBUG] public key 024540fea32947158680192ab7997fd0145b011a3fc27ec56354ea77e6fe763ca1\nsawtooth-fruitchain-tp-go-default | 2018/11/14 04:59:25.790258 handler.go:136: [DEBUG] fruitchain txn create permission permission_public_address:“027878bbcf9223c3701c25035b5454338dae4adce0da329740e2b59d96e9ab36cb” permission_types:BACKEND\nsawtooth-fruitchain-tp-go-default | 2018/11/14 04:59:25.793109 worker.go:74: [WARN] (411f561f-5dae-43f9-ae61-02f29b335417 <nil>) Invalid transaction: User is not allowed to create permission\nsawtooth-fruitchain-tp-go-default | 2018/11/14 04:59:26.794135 handler.go:64: [DEBUG] fruitchain txn 6562a688a43e7192a046ff8a74731333e8961eac10952f67eb7bed6e307db7c90f1b4b9b3cff39b5d402158ef0d5574df359f6865230e279c66967ceefd24073: type CREATE_PERMISSION\nsawtooth-fruitchain-tp-go-default | 2018/11/14 04:59:26.794164 handler.go:67: [DEBUG] public key 024540fea32947158680192ab7997fd0145b011a3fc27ec56354ea77e6fe763ca1\nsawtooth-fruitchain-tp-go-default | 2018/11/14 04:59:26.794182 handler.go:136: [DEBUG] fruitchain txn create permission permission_public_address:“027878bbcf9223c3701c25035b5454338dae4adce0da329740e2b59d96e9ab36cb” permission_types:BACKEND\nsawtooth-fruitchain-tp-go-default | 2018/11/14 04:59:26.797418 worker.go:74: [WARN] (387e6a09-e1aa-439d-a148-9bc4c9a45ace <nil>) Invalid transaction: User is not allowed to create permission\n```\n\nI return an InvalidTransactionError","username":"socoboy","ts":"2018-11-14T07:04:08.440Z"}
{"msg":"And it continuously verify the transaction ","username":"socoboy","ts":"2018-11-14T07:04:27.263Z"}
{"msg":"Any clues from the validator logs?","username":"agunde","ts":"2018-11-14T14:08:35.119Z"}
{"msg":"Also which version of sawtooth are you useng?","username":"agunde","ts":"2018-11-14T14:12:23.584Z"}
{"msg":"Also which version of sawtooth are you using?","username":"agunde","ts":"2018-11-14T14:12:23.584Z"}
{"msg":"Has joined the channel.","username":"anoopc444","ts":"2018-11-15T07:01:58.020Z","type":"uj"}
{"msg":"Hi All, i am pretty new to the sawtooth development, Could anyone guide me the required system configuration to start the sawtooth setup and development based on your prior experience?","username":"anoopc444","ts":"2018-11-15T07:03:07.375Z"}
{"msg":"@anoopc444, this is a question for the 'sawtooth' channel. You can find the info here: https://sawtooth.hyperledger.org/docs/core/releases/latest/app_developers_guide.html. No special system requirements except Ubuntu 16.04, docker, docker-compose etc.","username":"amolk","ts":"2018-11-15T10:32:48.711Z"}
{"msg":"Has joined the channel.","username":"JayeshJawale2","ts":"2018-11-19T09:11:10.343Z","type":"uj"}
{"msg":"Hi. I was able to start a single node sawtooth network by following the steps mentioned in the docs. Following is specified in the documentation:\n\"Any work done in this environment will be lost once the container exits. To keep your work, you would need to take additional steps, such as mounting a host directory into the container. See the Docker documentation for more information.\"\n\nI looked into Docker guide and in order to use volumes to share date between container/host you have to specify the target file/directory within the container. Here is how my validator looks like:\n`validator:\n\timage:  docker.io/hyperledger/sawtooth-validator\n\tentrypoint: \"bash -c \\\"\\\n\t\t\t\t\tsawadm keygen && \\\n\t\t\t\t\tsawtooth keygen my_key && \\\n\t\t\t\t\tsawset genesis -k /root/.sawtooth/keys/my_key.priv && \\\n\t\t\t\t\tsawadm genesis config-genesis.batch && \\\n\t\t\t\t\tsawtooth-validator -vv \\\n\t\t\t\t\t--endpoint tcp://validator:8800 \\\n\t\t\t\t\t--bind component:tcp://eth0:4004 \\\n\t\t\t\t\t--bind network:tcp://eth0:8800 \\\"\"                \n\tports:\n\t\t- \"5000:4004\"\n\tnetworks:\n\tbackend:\n\tvolumes:\n\t\t- /sawtooth-data:/var/lib/sawtooth`\n\t\t\t\t  \nAfter container starts /sawtooth-data populates with files, such as:\n`-rw-r--r-- 1 root root 1099511627776 Nov 23 10:18 block-00.lmdb\n-rw-r--r-- 1 root root          8192 Nov 23 10:18 block-00.lmdb-lock\n-rw-r--r-- 1 root root           128 Nov 23 10:18 block-chain-id\n-rw-r--r-- 1 root root 1099511627776 Nov 23 10:18 merkle-00.lmdb\n-rw-r--r-- 1 root root          8192 Nov 23 10:18 merkle-00.lmdb-lock\n-rw-r--r-- 1 root root 1099511627776 Nov 23 10:18 txn_receipts-00.lmdb\n-rw-r--r-- 1 root root          8192 Nov 23 10:18 txn_receipts-00.lmdb-lock +`\n\n\nAt the moment, when container stops and starts again data is not persisted even tough valume is mapped as suggested.\n\nCan you please provie your thoughts regarding this? Maybe target /var/lib/sawtooth is not the one which needs to be mapped, other settings may be required, etc.\n\nThank you.","username":"ZorbaGrue","ts":"2018-11-23T09:47:57.243Z"}
{"msg":"There's an error on line 100 of python/sawtooth_sdk/processor/context.py\naddresses = [e.address for e in state_entries]\nthere is no address property, address is the key value of the state_entries dictionary\n\nAlso, it wouldn't tell you the specific address you weren't authorized to write to, although that's let of an issue than returning the correct error message:\n\n            raise AuthorizationException(\n                'Tried to set unauthorized address: {}'.format(addresses))\n\nShould I open a ticket on JIRA?","username":"adamgering","ts":"2018-11-25T23:58:17.365Z"}
{"msg":"There's an error on line 100 of python/sawtooth_sdk/processor/context.py\naddresses = [e.address for e in state_entries]\nthere is no address attribute, address is the key value of the state_entries dictionary\n\nAlso, it wouldn't tell you the specific address you weren't authorized to write to, although that's let of an issue than returning the correct error message:\n\n            raise AuthorizationException(\n                'Tried to set unauthorized address: {}'.format(addresses))\n\nShould I open a ticket on JIRA?","username":"adamgering","ts":"2018-11-25T23:58:17.365Z"}
{"msg":"There's an error on line 100 of python/sawtooth_sdk/processor/context.py\naddresses = [e.address for e in state_entries]\nthere is no address attribute, address is the key value of the state_entries dictionary\n\nAlso, it wouldn't tell you the specific address you weren't authorized to write to, although that's less of an issue than returning the correct error message:\n\n            raise AuthorizationException(\n                'Tried to set unauthorized address: {}'.format(addresses))\n\nShould I open a ticket on JIRA?","username":"adamgering","ts":"2018-11-25T23:58:17.365Z"}
{"msg":"Presently it returns <<AttributeError: 'str' object has no attribute 'address'>>","username":"adamgering","ts":"2018-11-26T00:06:32.178Z"}
{"msg":"Has joined the channel.","username":"bochuxt","ts":"2018-11-26T07:11:28.885Z","type":"uj"}
{"msg":"Has joined the channel.","username":"nishanthkp","ts":"2018-11-26T10:14:12.959Z","type":"uj"}
{"msg":"@adamgering JIRA and/or PR welcome","username":"amundson","ts":"2018-11-26T18:21:09.518Z"}
{"msg":"Has joined the channel.","username":"aedigix","ts":"2018-11-27T04:53:14.419Z","type":"uj"}
{"msg":"Has left the channel.","username":"kdenhartog","ts":"2018-11-27T19:52:24.172Z","type":"ul"}
{"msg":"Has joined the channel.","username":"agoops","ts":"2018-11-28T23:16:35.559Z","type":"uj"}
{"msg":"Hi, just curious about how does the RFC process usually take?","username":"eugene-babichenko","ts":"2018-11-30T14:03:44.025Z"}
{"msg":"@pschwarz @amundson @Dan @jsmitchell @adamludvik Can we get some reviews on @eugene-babichenko  rfc pr https://github.com/hyperledger/sawtooth-rfcs/pull/32","username":"agunde","ts":"2018-11-30T14:10:29.212Z"}
{"msg":"@kodonnel you may also be interested in ^","username":"Dan","ts":"2018-11-30T14:14:38.198Z"}
{"msg":"@amundson do we have an expected path for the sawtooth 1.1 release notes? would like to link to them in the blog","username":"kelly_","ts":"2018-12-04T17:24:07.322Z"}
{"msg":"oh nevermind i see the pull request","username":"kelly_","ts":"2018-12-04T17:31:39.039Z"}
{"msg":"@adamludvik - do you know what the URL will be when the bumper notes request gets merged on sawtooth-website","username":"kelly_","ts":"2018-12-04T17:31:55.770Z"}
{"msg":"looks liek https://sawtooth.hyperledger.org/release/bumper/ maybe?","username":"kelly_","ts":"2018-12-04T17:33:17.389Z"}
{"msg":"one second while I rewind my brain","username":"adamludvik","ts":"2018-12-04T17:33:57.941Z"}
{"msg":"or https://sawtooth.hyperledger.org/release/bumper/notes.html","username":"kelly_","ts":"2018-12-04T17:34:38.547Z"}
{"msg":"ok thanks :)","username":"kelly_","ts":"2018-12-04T17:34:41.989Z"}
{"msg":"I believe https://sawtooth.hyperledger.org/release/bumper/notes.html should work, the permalink specified is https://sawtooth.hyperledger.org/release/bumper/. Trying to verify this by rebuilding the website locally.","username":"adamludvik","ts":"2018-12-04T17:39:49.440Z"}
{"msg":"Okay, verified locally that you want https://sawtooth.hyperledger.org/release/bumper/","username":"adamludvik","ts":"2018-12-04T17:40:23.530Z"}
{"msg":"awesome, thanks adam!","username":"kelly_","ts":"2018-12-04T17:40:32.354Z"}
{"msg":"There will also be a new \"Releases\" tab in the banner at the top of the site.","username":"adamludvik","ts":"2018-12-04T17:40:56.142Z"}
{"msg":"@amundson - i assume you've seen this: https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html","username":"kelly_","ts":"2018-12-06T18:55:36.666Z"}
{"msg":"Has joined the channel.","username":"kthblmfld","ts":"2018-12-09T02:40:24.757Z","type":"uj"}
{"msg":"Folks, I was examining the core code and I noticed that there are folders `sdk`, `protos`, `processor`.  I am considering buidling TP in Go but having seen the sawtooth-sdk-go, I notice that there are also `protos` and `processor` folders. It seemed somewhat confusing as to which to us. The stuff in the core code or the independent sdk repos?\n\nAlso I presumed protos is meant to be the shared across multiple SDKs. I was wondering won't it better for it to be only be in core and not copied across multiple repos?","username":"paul.sitoh","ts":"2018-12-09T13:31:08.928Z"}
{"msg":"Yeah having a single repo for protos would have been another way to go.\nThe SDKs that remain in core are those necessary for core. The other languages were all split out. So if you want to work with go you can work exclusively with the go repo.","username":"Dan","ts":"2018-12-09T16:18:48.108Z"}
{"msg":"Has joined the channel.","username":"JSSilva","ts":"2018-12-10T14:43:29.975Z","type":"uj"}
{"msg":"Has joined the channel.","username":"DatNguyen","ts":"2018-12-11T07:22:05.018Z","type":"uj"}
{"msg":"Thought: How about moving consensus SDK related code out of sawtooth-core/sdk/rust or sawtooth-core/sdk/python to something like sawtooth-core/consensus/sdk/rust.\nAlso move sawtooth-core/sdk/examples/devmode_rust to sawtooth-core/consensus/examples/devmode_rust?","username":"arsulegai","ts":"2018-12-15T04:09:39.373Z"}
{"msg":"there have been suggestions to move the SDKs out of the core repo altogether","username":"rbuysse","ts":"2018-12-15T20:02:13.411Z"}
{"msg":"Oh, yeah! Moving rust and python SDK out of sawtooth-core is good option too","username":"arsulegai","ts":"2018-12-16T15:19:21.146Z"}
{"msg":"@arsulegai curious about the motivation. how does this help you? splitting the consensus sdk out of the primary sdk would be possible but it seems fine to have them combined too.","username":"amundson","ts":"2018-12-17T00:36:47.610Z"}
{"msg":"@amundson no problems or no hard thoughts on current structure, but it's just these following things made me think there's scope for improvement\n1. Give logical partition for application developers from consensus development (more of framework side)\n2. Having both SDK in same cargo project ties their version. In most cases changes in consensus part may not require us to upgrade application development SDK.\n3. It's rare that one uses modules from both consensus and application SDK.","username":"arsulegai","ts":"2018-12-17T19:25:36.540Z"}
{"msg":"@arsulegai I agree with all those points. the counter-point is its more work to maintain another SDK, which is why it is were it is currently, and there are few (if any) technical downsides to it being in one SDK.","username":"amundson","ts":"2018-12-17T20:44:18.255Z"}
{"msg":"there are quite a few negatives for the sdk to remain in the core repo though","username":"amundson","ts":"2018-12-17T20:44:35.610Z"}
{"msg":"Has joined the channel.","username":"Eddiwar","ts":"2018-12-17T23:56:09.198Z","type":"uj"}
{"msg":"FYI @arsulegai @manojgop and rajeev (sorry I can't find his handle here) reported validator crashes while testing PoET2. It's unclear whether it's instability in validator master, the rust consensus SDK, or the poet2 code. From the sound of it I would guess it's related to the validator. The crash happens after thousands of blocks somewhere in the scheduler after it crosses an FFI boundary. There's logs and more details to be shared here. My info is ~1 day old at this point so I'll rely on Arun et al to update here.\nIs anyone running LR on master with a rust consensus?","username":"Dan","ts":"2018-12-19T15:01:28.659Z"}
{"msg":"Has joined the channel.","username":"manojgop","ts":"2018-12-19T15:01:28.839Z","type":"uj"}
{"msg":"^ @rranjan3 ","username":"arsulegai","ts":"2018-12-19T18:58:27.528Z"}
{"msg":"Has joined the channel.","username":"rranjan3","ts":"2018-12-19T18:58:27.643Z","type":"uj"}
{"msg":"Is PoET2 examining past state at all?  ","username":"pschwarz","ts":"2018-12-19T21:29:45.400Z"}
{"msg":"I'm just wondering if its in a situation where it's walking back too far relative to state pruning","username":"pschwarz","ts":"2018-12-19T21:30:42.599Z"}
{"msg":"I'm just wondering if it's in a situation where it's walking back too far relative to state pruning","username":"pschwarz","ts":"2018-12-19T21:30:42.599Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=Jr6cydrmdNWbjYy2B) @pschwarz No @pschwarz this is not being examined in PoET2","username":"rranjan3","ts":"2018-12-20T13:09:33.753Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=Jr6cydrmdNWbjYy2B","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=Jr6cydrmdNWbjYy2B","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=BEt7pf8rDxf6z58P3) @pschwarz [ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=Jr6cydrmdNWbjYy2B) @pschwarz No this is not being examined in PoET2","username":"rranjan3","ts":"2018-12-20T13:09:33.753Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=BEt7pf8rDxf6z58P3","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=BEt7pf8rDxf6z58P3","remote":true,"fileId":null,"fileName":null},{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=Jr6cydrmdNWbjYy2B","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=Jr6cydrmdNWbjYy2B","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=Jr6cydrmdNWbjYy2B) No this is not being examined in PoET2","username":"rranjan3","ts":"2018-12-20T13:09:33.753Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=Jr6cydrmdNWbjYy2B","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=Jr6cydrmdNWbjYy2B","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=BEt7pf8rDxf6z58P3) @pschwarz This is possible but then there are no errors in the validator logs(debug enabled) in this line. Another thing is that this issue has been hit for a run with low number of blocks as well(~200 ) which is less than the default *state_pruning_block_depth* of 1000. ","username":"rranjan3","ts":"2018-12-20T13:38:27.996Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=BEt7pf8rDxf6z58P3","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=BEt7pf8rDxf6z58P3","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=BEt7pf8rDxf6z58P3) @pschwarz This is possible but then there are no errors in the validator logs(debug enabled) in this line. Another thing is that this issue has been hit for a run with low number of blocks as well(~200 ) which is less than the default *state_pruning_block_depth* of 1000. But yes at all other times, the number of committed blocks in the chain are to the tune of few thousands(3k-15k).","username":"rranjan3","ts":"2018-12-20T13:38:27.996Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=BEt7pf8rDxf6z58P3","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=BEt7pf8rDxf6z58P3","remote":true,"fileId":null,"fileName":null}]}
{"msg":"what's the error?","username":"jsmitchell","ts":"2018-12-20T15:31:07.116Z"}
{"msg":"No error is seen in the validator logs. The docker container would get killed after printing the last log as - \n[23:58:40.246 [Dummy-30] (unknown file) DEBUG] [src/journal/block_scheduler.rs: 166] Adding block 7c2aaabe0875d65e090ccdaa8bdfdd67646bcfc5a4cc193ea5af8fddaabb9579105cc60e9880f31ca0f1af85a85d54a2b317bdcd80118716aa6d3940abcdd1e3 for processing","username":"rranjan3","ts":"2018-12-20T15:55:31.876Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=bmYv4gSupcm3GQcwd) @jsmitchell No error is seen in the validator logs. The docker container would get killed after printing the last log as - \n_[23:58:40.246 [Dummy-30] (unknown file) DEBUG] [src/journal/block_scheduler.rs: 166] Adding block 7c2aaabe0875d65e090ccdaa8bdfdd67646bcfc5a4cc193ea5af8fddaabb9579105cc60e9880f31ca0f1af85a85d54a2b317bdcd80118716aa6d3940abcdd1e3 for processing_","username":"rranjan3","ts":"2018-12-20T15:56:10.017Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=bmYv4gSupcm3GQcwd","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=bmYv4gSupcm3GQcwd","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Tried adding custom logs to drill down. The last traces then could be seen was in state validation - https://github.com/hyperledger/sawtooth-core/blob/master/validator/src/scheduler/py_scheduler.rs#L67","username":"rranjan3","ts":"2018-12-20T16:07:25.528Z"}
{"msg":"is the validator dumping core? have you taken a look at the backtraces in the core file?","username":"jsmitchell","ts":"2018-12-20T16:07:26.022Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=WmJZh3HCYYKJDLhLh) @jsmitchell There are other one-off issues where I have seen it run into some Segmentation fault and then dump core but not yet in this case. ","username":"rranjan3","ts":"2018-12-20T17:12:48.299Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=WmJZh3HCYYKJDLhLh","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=WmJZh3HCYYKJDLhLh","remote":true,"fileId":null,"fileName":null}]}
{"msg":"well, there is something happening to cause the validator process to exit","username":"jsmitchell","ts":"2018-12-20T17:24:45.380Z"}
{"msg":"Another observation worth sharing is that with default input rates( for intkey workload it is 1 tps), setups have survived for pretty long. Over 60k blocks is what I have observed in this case for a network running for beyond 36 hours only to fail with this same issue.  ","username":"rranjan3","ts":"2018-12-20T17:48:04.200Z"}
{"msg":"Another observation worth sharing is that with default input rates( for intkey workload it is 1 tps), setups have survived for pretty long. Over 60k blocks is what I have observed in this case for a network running for beyond 36 hours only to fail with this same issue.  ","username":"rranjan3","ts":"2018-12-20T17:48:04.200Z"}
{"msg":"Another observation worth sharing is that with default input rates( for intkey workload it is 1 tps), setups have survived for pretty long. Over 60k blocks is what I have observed in this case for a network running for beyond 36 hours only to fail with this same issue.  \n\nWe are able to pull down this time to 5-10 hours or 3-15k blocks by increasing the input rates(just as much that backpressure is not hit).\n\nHaven't been profiling system resources but random checks haven't suggested any issue from that perspective.","username":"rranjan3","ts":"2018-12-20T17:48:04.200Z"}
{"msg":"Has joined the channel.","username":"merq","ts":"2018-12-22T03:39:41.143Z","type":"uj"}
{"msg":"Hi guys, did the commit about the [ZMQ Probe|https://github.com/hyperledger/sawtooth-core/commit/0d43a5079904909086148c53201459117c7b4829] made it to the v1.1 branch ?\nLooks like not.","username":"LeonardoCarvalho","ts":"2018-12-26T10:28:12.342Z"}
{"msg":"Can you add a link to the original PR for that?  We can use that as reference for discussing adding it to the backport list","username":"pschwarz","ts":"2018-12-26T18:41:52.080Z"}
{"msg":"Sure, here it is","username":"LeonardoCarvalho","ts":"2018-12-29T17:08:09.745Z"}
{"msg":"https://github.com/hyperledger/sawtooth-core/pull/1858","username":"LeonardoCarvalho","ts":"2018-12-29T17:08:10.348Z"}
{"msg":"And I did find an interesting site, https://safecurves.cr.yp.to/","username":"LeonardoCarvalho","ts":"2018-12-29T17:08:27.290Z"}
{"msg":"Where it claims that secp256k1 is vulnerable to some widely known attacks, what do you all think ?","username":"LeonardoCarvalho","ts":"2018-12-29T17:09:33.927Z"}
{"msg":"Has joined the channel.","username":"rstrauck","ts":"2019-01-04T16:35:36.213Z","type":"uj"}
{"msg":"I ran sawooth raft  on a 3 node network. After running for 3-4 hours I get below \"NO respose\" message in one of the validator nodes and it removes the connection as per the below logs. I guess this is ZMQ connection loss. Any idea why this happens","username":"manojgop","ts":"2019-01-08T14:25:35.965Z"}
{"msg":"I ran sawooth raft  on a 3 node network. After running for 3-4 hours I get below \"NO respose\" message in one of the validator nodes and it removes the connection as per the below logs. I guess this is ZMQ connection loss. Any idea why this happens {\"log\":\"\\u001b[32m[2019-01-07 17:46:19.733 INFO     interconnect]\\u001b[0m \\u001b[37mNo response from c47c22595d0785568099d6e58bd263131ef3f7e9c5e8f0a8536c115f5aaedd2c28a0bb5efcbaed61fc6168116a3ef0ac758f67e59960556cca08dd6a9d50e9ca in 582.5916867256165 seconds - removing connection.\\u001b[0m\\n\",\"stream\":\"stderr\",\"time\":\"2019-01-07T17:46:19.791210358Z\"}\n\n{\"log\":\"\\u001b[32m[2019-01-07 17:46:19.828 INFO     interconnect]\\u001b[0m \\u001b[37mNo response from OutboundConnectionThread-tcp://5b09efec6fbc:8800 in 1546882597.113996 seconds - removing connection.\\u001b[0m\\n\",\"stream\":\"stderr\",\"time\":\"2019-01-07T17:46:19.868576709Z\"}\n\n{\"log\":\"\\u001b[36m[2019-01-07 17:46:19.917 DEBUG    dispatch]\\u001b[0m \\u001b[37mRemoved send_message function for connection OutboundConnectionThread-tcp://5b09efec6fbc:8800\\u001b[0m\\n\",\"stream\":\"stderr\",\"time\":\"2019-01-07T17:46:19.918195517Z\"}\n\n{\"log\":\"\\u001b[36m[2019-01-07 17:46:20.720 DEBUG    gossip]\\u001b[0m \\u001b[37mEndpoint has not completed authorization in 10 seconds: tcp://5b09efec6fbc:8800\\u001b[0m\\n\",\"stream\":\"stderr\",\"time\":\"2019-01-07T17:46:20.730162981Z\"}\n","username":"manojgop","ts":"2019-01-08T14:25:35.965Z"}
{"msg":"I ran sawooth raft  on a 3 node network. After running for 3-4 hours I get below \"No response\" message in one of the validator nodes and it removes the connection as per the below logs. I guess this is ZMQ connection loss. Any idea why this happens   --->  \"{\"log\":\"\\u001b[32m[2019-01-07 17:46:19.733 INFO     interconnect]\\u001b[0m \\u001b[37mNo response from c47c22595d0785568099d6e58bd263131ef3f7e9c5e8f0a8536c115f5aaedd2c28a0bb5efcbaed61fc6168116a3ef0ac758f67e59960556cca08dd6a9d50e9ca in 582.5916867256165 seconds - removing connection.\\u001b[0m\\n\",\"stream\":\"stderr\",\"time\":\"2019-01-07T17:46:19.791210358Z\"}\n\n{\"log\":\"\\u001b[32m[2019-01-07 17:46:19.828 INFO     interconnect]\\u001b[0m \\u001b[37mNo response from OutboundConnectionThread-tcp://5b09efec6fbc:8800 in 1546882597.113996 seconds - removing connection.\\u001b[0m\\n\",\"stream\":\"stderr\",\"time\":\"2019-01-07T17:46:19.868576709Z\"}\n\n{\"log\":\"\\u001b[36m[2019-01-07 17:46:19.917 DEBUG    dispatch]\\u001b[0m \\u001b[37mRemoved send_message function for connection OutboundConnectionThread-tcp://5b09efec6fbc:8800\\u001b[0m\\n\",\"stream\":\"stderr\",\"time\":\"2019-01-07T17:46:19.918195517Z\"}\n\n{\"log\":\"\\u001b[36m[2019-01-07 17:46:20.720 DEBUG    gossip]\\u001b[0m \\u001b[37mEndpoint has not completed authorization in 10 seconds: tcp://5b09efec6fbc:8800\\u001b[0m\\n\",\"stream\":\"stderr\",\"time\":\"2019-01-07T17:46:20.730162981Z\"}\n","username":"manojgop","ts":"2019-01-08T14:25:35.965Z"}
{"msg":"I ran sawooth raft  on a 3 node network in docker mode. After running for 3-4 hours I get below \"No response\" message in one of the validator nodes and it removes the connection as per the below logs. I guess this is ZMQ connection loss.  are still Any idea why this happens   --->  \"{\"log\":\"\\u001b[32m[2019-01-07 17:46:19.733 INFO     interconnect]\\u001b[0m \\u001b[37mNo response from c47c22595d0785568099d6e58bd263131ef3f7e9c5e8f0a8536c115f5aaedd2c28a0bb5efcbaed61fc6168116a3ef0ac758f67e59960556cca08dd6a9d50e9ca in 582.5916867256165 seconds - removing connection.\\u001b[0m\\n\",\"stream\":\"stderr\",\"time\":\"2019-01-07T17:46:19.791210358Z\"}\n\n{\"log\":\"\\u001b[32m[2019-01-07 17:46:19.828 INFO     interconnect]\\u001b[0m \\u001b[37mNo response from OutboundConnectionThread-tcp://5b09efec6fbc:8800 in 1546882597.113996 seconds - removing connection.\\u001b[0m\\n\",\"stream\":\"stderr\",\"time\":\"2019-01-07T17:46:19.868576709Z\"}\n\n{\"log\":\"\\u001b[36m[2019-01-07 17:46:19.917 DEBUG    dispatch]\\u001b[0m \\u001b[37mRemoved send_message function for connection OutboundConnectionThread-tcp://5b09efec6fbc:8800\\u001b[0m\\n\",\"stream\":\"stderr\",\"time\":\"2019-01-07T17:46:19.918195517Z\"}\n\n{\"log\":\"\\u001b[36m[2019-01-07 17:46:20.720 DEBUG    gossip]\\u001b[0m \\u001b[37mEndpoint has not completed authorization in 10 seconds: tcp://5b09efec6fbc:8800\\u001b[0m\\n\",\"stream\":\"stderr\",\"time\":\"2019-01-07T17:46:20.730162981Z\"}\n","username":"manojgop","ts":"2019-01-08T14:25:35.965Z"}
{"msg":"@manojgop have you checked the Raft logs to see if there was a failure there?","username":"ltseeley","ts":"2019-01-08T17:56:19.444Z"}
{"msg":"*Editorial comment:* I strongly recommend not changing CLI names after release. For example, `devmode-engine-rust` in release 1.1.x (latest, bumper) is `devmode-rust` in release 1.2.x (nightly)","username":"danintel","ts":"2019-01-10T00:34:21.835Z"}
{"msg":"*Editorial comment:* I strongly recommend not changing CLI names after release. For example, `devmode-engine-rust` in release 1.1.x (latest, bumper) is `devmode-rust` in release 1.2.x (nightly)\n\nP.S., I could use a documentation review, PR #1997 https://github.com/hyperledger/sawtooth-core/pull/1997","username":"danintel","ts":"2019-01-10T00:34:21.835Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=wFjjepzdNbPJa3N9f) @ltseeley @ltseeley I debugged it further and found that after couple of hours the hearbeat message from Leader takes longer time (4sec +) to reach the follower. By default, heartbeat is set as 200ms and election time out as 2 sec. But since heartbeat from leader took long time to reach the follower (reason is unkown), the follower times out and starts new election process. And once this happens the process repeats again frequently and leader election will not be stable and during this period no one is publishing the block and we get queue full error. As I understand the consensus engine do not send messages to its peer directly and the communication is routed via validator ZMQ.  And all communication between validators (blocks, messages form consensus engine etc) happen via single network interconnect between validators. So looks like there is some delay in communication or processing at validator end. The ZmqService::send_to() function in consensus SDK is sometime taking long time to send the heart beat. Looks like the sync_channel() used for communication is betting blocked (may be due to buffer full and validator slow in processing messages ??). Let me know if you have any thoughts on why the messages send from one consensus engine is getting delayed.","username":"manojgop","ts":"2019-01-11T08:47:00.591Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=wFjjepzdNbPJa3N9f","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=wFjjepzdNbPJa3N9f","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=wFjjepzdNbPJa3N9f) @ltseeley @ltseeley I debugged raft issue further and found that after couple of hours the hearbeat message from Leader takes longer time (4sec +) to reach the follower. By default, heartbeat is set as 200ms and election time out as 2 sec. But since heartbeat from leader took long time to reach the follower (reason is unkown), the follower times out and starts new election process. And once this happens the process repeats again frequently and leader election will not be stable and during this period no one is publishing the block and we get queue full error. As I understand the consensus engine do not send messages to its peer directly and the communication is routed via validator ZMQ.  And all communication between validators (blocks, messages form consensus engine etc) happen via single network interconnect between validators. So looks like there is some delay in communication or processing at validator end. The ZmqService::send_to() function in consensus SDK is sometime taking long time to send the heart beat. Looks like the sync_channel() used for communication is betting blocked (may be due to buffer full and validator slow in processing messages ??). Let me know if you have any thoughts on why the messages send from one consensus engine is getting delayed.","username":"manojgop","ts":"2019-01-11T08:47:00.591Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=wFjjepzdNbPJa3N9f","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=wFjjepzdNbPJa3N9f","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=wFjjepzdNbPJa3N9f) @ltseeley I debugged raft issue further and found that after couple of hours the hearbeat message from Leader takes longer time (4sec +) to reach the follower. By default, heartbeat is set as 200ms and election time out as 2 sec. But since heartbeat from leader took long time to reach the follower (reason is unkown), the follower times out and starts new election process. And once this happens the process repeats again frequently and leader election will not be stable and during this period no one is publishing the block and we get queue full error. As I understand the consensus engine do not send messages to its peer directly and the communication is routed via validator ZMQ.  And all communication between validators (blocks, messages from consensus engine etc) happen via single network interconnect between validators. So looks like there is some delay in communication or processing at validator end. The ZmqService::send_to() function in consensus SDK is sometime taking long time to send the message (heart beat msg in case of Raft). Looks like the sync_channel() used for communication is betting blocked (may be due to buffer full and validator slow in processing messages ??). Let me know if you have any thoughts on why the messages send from consensus engine is getting delayed to reach peer consensus engine.","username":"manojgop","ts":"2019-01-11T08:47:00.591Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=wFjjepzdNbPJa3N9f","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=wFjjepzdNbPJa3N9f","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=wFjjepzdNbPJa3N9f) @ltseeley I debugged raft issue further and found that after couple of hours the hearbeat message from Leader takes longer time (4sec +) to reach the follower. By default, heartbeat is set as 200ms and election time out as 2 sec. But since heartbeat from leader took long time to reach the follower (reason is unkown), the follower times out and starts new election process. And once this happens the process repeats again frequently and leader election will not be stable and during this period no one is publishing the block and we get queue full error. As I understand the consensus engine do not send messages to its peer directly and the communication is routed via validator ZMQ.  And all communication between validators (blocks, messages from consensus engine etc) happen via single network interconnect between validators. So looks like there is some delay in communication or processing at validator end. The ZmqService::send_to() function in consensus SDK is sometime taking long time to send the message (heart beat msg in case of Raft). Looks like the zmq socket used for communication (in zmq_stream.rs) is betting blocked for some reason . Let me know if you have any thoughts on why the messages send from consensus engine is getting delayed to reach peer consensus engine.","username":"manojgop","ts":"2019-01-11T09:19:49.731Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=wFjjepzdNbPJa3N9f","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=wFjjepzdNbPJa3N9f","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=wFjjepzdNbPJa3N9f) @ltseeley I debugged raft issue further and found that after couple of hours the *hearbeat message from Leader takes longer time (4sec +) to reach the follower*. By default, heartbeat is set as 200ms and election time out as 2 sec. But since heartbeat from leader took long time to reach the follower (reason is unkown), the follower times out and starts new election process. And once this happens the process repeats again frequently and leader election will not be stable and *during this period no one is publishing the block and we get queue full error*. As I understand the consensus engine do not send messages to its peer directly and the communication is routed via validator ZMQ.  And all communication between validators (blocks, messages from consensus engine etc) happen via single network interconnect between validators. So looks like there is some delay in communication . *The ZmqService::send_to() function in consensus SDK is sometime taking long time to send the message (heart beat msg in case of Raft)*. Looks like the zmq socket used for communication (in zmq_stream.rs) is getting blocked for some reason . Let me know if you have any thoughts on why the messages send from consensus engine is getting delayed to reach peer consensus engine.","username":"manojgop","ts":"2019-01-11T09:19:49.731Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=wFjjepzdNbPJa3N9f","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=wFjjepzdNbPJa3N9f","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Has joined the channel.","username":"muniyaraj","ts":"2019-01-11T11:53:47.906Z","type":"uj"}
{"msg":"@danintel the intent are that they both be devmode-engine-rust. so either there is an issue in master or you have something cached? Should be pretty easy to fix if it's wrong.","username":"amundson","ts":"2019-01-11T18:28:27.549Z"}
{"msg":"@amundson That is good to hear--so it's just a temporary issue I can workaround. I have Sawtooth nightly 1.2.1.dev171 on Xenial, and apparently nightly packages are no longer produced for Xenial. \nI'd prefer to use Bionic, but I have never been able to install Sawtooth on it  (due to the missing PoET packages).","username":"danintel","ts":"2019-01-11T18:35:19.706Z"}
{"msg":"@danintel Our (Bitwise) intent is to focus on bionic moving forward. @rbuysse put in a change which makes it possible to support multiple distributions but it would stretch testing resources thin to support both. (If others want to step up there, great.) As far as the PoET packages, PoET is not stable enough on 1.2+bionic currently to pass PR checks and thus the patches @rbuysse has for producing those packages haven't been merged. Definitely an opportunity for someone to step up and debug that issue.","username":"amundson","ts":"2019-01-11T18:46:15.124Z"}
{"msg":"I don't expect backporting nightly to Xenial, but it would be nice to be able to at least install Sawtooth packages on Bionic. Currently, there is a dependency of Sawtooth packages on 5 `python3-sawtooth-poet-*` packages. Could this dependency be removed temporarily? Here is the install error on Bionic:\n```$ sudo apt-get install -y sawtooth\n. . . Some packages could not be installed. This may mean that you have\nrequested an impossible situation or if you are using the unstable\ndistribution that some required packages have not yet been created\nor been moved out of Incoming.\nThe following information may help to resolve the situation:\nThe following packages have unmet dependencies:\n sawtooth : Depends: python3-sawtooth-poet-cli but it is not installable . . .```","username":"danintel","ts":"2019-01-11T19:18:50.109Z"}
{"msg":"that's just for the meta-package","username":"rbuysse","ts":"2019-01-11T19:29:59.516Z"}
{"msg":"you should be able to install individual packages ","username":"rbuysse","ts":"2019-01-11T19:30:09.473Z"}
{"msg":"Thanks--so package `sawtooth` is not needed.  This subset seems to work OK:\n`sudo apt-get install python3-sawtooth-cli python3-sawtooth-integration python3-sawtooth-rest-api python3-sawtooth-sdk python3-sawtooth-settings python3-sawtooth-signing python3-sawtooth-validator sawtooth-devmode-engine-rust`","username":"danintel","ts":"2019-01-11T20:15:48.126Z"}
{"msg":"Has joined the channel.","username":"nanspro","ts":"2019-01-12T10:08:26.047Z","type":"uj"}
{"msg":"Hi all, I getting Registration of [chair 1.0] failed","username":"muniyaraj","ts":"2019-01-13T15:57:49.158Z"}
{"msg":"pls help me","username":"muniyaraj","ts":"2019-01-13T15:57:54.491Z"}
{"msg":"@manojgop it could be that the network is just backed up at that point; we have seen that happen under a very high workload.","username":"ltseeley","ts":"2019-01-14T15:13:50.679Z"}
{"msg":"@ltseeley This high network load is also impacting the heatbeat messages between validators and I can see \"No response from peer validator\" in the logs and validators eventually removing the connection with  the peers. I'll reduce the hearbeat messages between raft consensus engine (which is also going through validator network interconnect) and check  the behaviour. By default raft is sending heart beat messages every 200ms. I'll increase it to 2 sec and check","username":"manojgop","ts":"2019-01-14T15:42:11.709Z"}
{"msg":"if anyone has any updates they'd like to get into the next Hyperledger Sawtooth TSC, please @ me and let me know! https://wiki.hyperledger.org/groups/tsc/project-updates/sawtooth-2019-jan","username":"kelly_","ts":"2019-01-15T00:32:51.187Z"}
{"msg":"thanks!","username":"kelly_","ts":"2019-01-15T00:32:52.955Z"}
{"msg":"Has joined the channel.","username":"renex","ts":"2019-01-17T15:24:42.529Z","type":"uj"}
{"msg":"Has joined the channel.","username":"abgomez","ts":"2019-01-18T22:09:42.229Z","type":"uj"}
{"msg":"Has joined the channel.","username":"youngerjo","ts":"2019-01-22T04:09:21.018Z","type":"uj"}
{"msg":"Has joined the channel.","username":"rbnaraujo","ts":"2019-01-25T12:23:46.157Z","type":"uj"}
{"msg":"Has joined the channel.","username":"Behzad 2","ts":"2019-01-26T20:40:14.026Z","type":"uj"}
{"msg":"Has joined the channel.","username":"moulika","ts":"2019-01-28T11:04:14.423Z","type":"uj"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=9W7gdSbPqetevrBYP) I tried increasing the Raft heartbeat to 4 sec. But I still observer the same behavior after running for about 30+ hours.  If we increase the TPS rate to 50 or 100 then we can observe it sooner. So looks like lot of messages are getting queued to be processed in the validator (which includes both consensus engine and validator gossip peer messages). I also tried using a very light weight TP which just returns success from apply method in TP handler without doing any real processing just to rule out any TP bottleneck in processing.```\nHave you tested and profiled validator with higher TPS or run Raft for longer duration? Any validator issues which are already known for these scenarios ?\n``` ","username":"manojgop","ts":"2019-01-28T17:22:47.937Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=9W7gdSbPqetevrBYP","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=9W7gdSbPqetevrBYP","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=9W7gdSbPqetevrBYP) @ltseeley @amundson  I tried increasing the Raft heartbeat to 4 sec. But I still observer the same behavior after running for about 30+ hours.  If we increase the TPS rate to 50 or 100 then we can observe it sooner. So looks like lot of messages are getting queued to be processed in the validator (which includes both consensus engine and validator gossip peer messages). I also tried using a very light weight TP which just returns success from apply method in TP handler without doing any real processing just to rule out any TP bottleneck in processing.```\nHave you tested and profiled validator with higher TPS or run Raft for longer duration? Any validator issues which are already known for these scenarios ?\n``` ","username":"manojgop","ts":"2019-01-28T17:22:47.937Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=9W7gdSbPqetevrBYP","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=9W7gdSbPqetevrBYP","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=9W7gdSbPqetevrBYP) @ltseeley @amundson  I tried increasing the Raft heartbeat to 4 sec. But I still observe the same behavior after running for about 30+ hours.  If we increase the TPS rate to 50 or 100 then we can observe the issue sooner. So looks like lot of messages are getting queued to be processed in the validator (which includes both consensus engine and validator gossip peer messages). I also tried using a very light weight TP which just returns success from apply method in TP handler without doing any real processing just to rule out any TP bottleneck in processing.```\nHave you tested and profiled validator with higher TPS or run Raft for longer duration? Any validator issues which are already known for these scenarios ?\n``` ","username":"manojgop","ts":"2019-01-28T17:22:47.937Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=9W7gdSbPqetevrBYP","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=9W7gdSbPqetevrBYP","remote":true,"fileId":null,"fileName":null}]}
{"msg":"@manojgop interesting. Have you characterized what types of messages predominate?","username":"jsmitchell","ts":"2019-01-28T17:24:49.654Z"}
{"msg":"if you are running the metrics stuff, message type is one of the tags collected for the counters","username":"jsmitchell","ts":"2019-01-28T17:25:11.042Z"}
{"msg":"I've not enabled metrics yet. Is grafana metrics supported if run the nodes in docker mode ? After running for long hours, from Raft engine side I've seen the block commit message response from Validator taking long time after Raft calls block_commit(). Also Raft follower nodes takes long time to get Heartbeat request from leader and then there will be reelections multiple times where there is no leader getting elected as message processing is getting slower at validator end. Also I notice lot of Missing batch request from follower nodes  which means the gossip message also takes lot of time to send batches to peers.  So once  the message processing in validator gets slower (Dispatch incoming queue  size in validator also logs > 10/20 messages consistently), things go haywire. ","username":"manojgop","ts":"2019-01-28T17:37:10.836Z"}
{"msg":"@jsmitchell I've not enabled metrics yet. Is grafana metrics supported if run the nodes in docker mode ? After running for long hours, from Raft engine side I've seen the block commit message response from Validator taking long time after Raft calls block_commit(). Also Raft follower nodes takes long time to get Heartbeat request from leader and then there will be reelections multiple times where there is no leader getting elected as message processing is getting slower at validator end. Also I notice lot of Missing batch request from follower nodes  which means the gossip message also takes lot of time to send batches to peers.  So once  the message processing in validator gets slower (Dispatch incoming queue  size in validator also logs > 10/20 messages consistently), things go haywire.","username":"manojgop","ts":"2019-01-28T17:37:10.836Z"}
{"msg":"@jsmitchell I've not enabled metrics yet. Is grafana metrics supported if we run the validator in docker mode ? After running for long hours, from Raft engine side I've seen the block commit message response from Validator taking long time after Raft calls block_commit(). Also Raft follower nodes takes long time to get Heartbeat request from leader and then there will be reelections multiple times where there is no leader getting elected as message processing is getting slower at validator end. Also I notice lot of Missing batch request from follower nodes  which means the gossip message also takes lot of time to send batches to peers.  So once  the message processing in validator gets slower (Dispatch incoming queue  size in validator also logs > 10/20 messages consistently), things go haywire.","username":"manojgop","ts":"2019-01-28T17:37:10.836Z"}
{"msg":"yes, you can deliver metrics to influxdb/grafana from a validator running inside docker","username":"jsmitchell","ts":"2019-01-28T17:38:57.278Z"}
{"msg":"there should be an example compose file with the relevant containers and the command line args required","username":"jsmitchell","ts":"2019-01-28T17:39:12.285Z"}
{"msg":"we might get some clues if we see an unusual type of message dominate","username":"jsmitchell","ts":"2019-01-28T17:41:14.702Z"}
{"msg":"for example, we've seen problems in the past with the GET_BATCH_BY_TRANSACTION_ID message for dependency resolution","username":"jsmitchell","ts":"2019-01-28T17:41:55.204Z"}
{"msg":"I'll enable metrics and run it again","username":"manojgop","ts":"2019-01-28T17:43:00.066Z"}
{"msg":"But in Sawtooth Raft, a leader can commit a block without ensuring the batches in the blocks have reached the follower. We are only storing block id in the Raft log entry. I guess the assumption here is follower will receive the batches in the block via gossip network from its peers before leader commits the block. After running raft for more than 24 hrs I've seen the follower nodes sending too many batch requests and leader node responding to batch request","username":"manojgop","ts":"2019-01-28T17:48:59.321Z"}
{"msg":"In sawtooth are all the messages from the peer validator(gossip messages) and consensus engine messages processed using same queue ?","username":"manojgop","ts":"2019-01-28T17:50:13.555Z"}
{"msg":"two separate queues, iirc","username":"jsmitchell","ts":"2019-01-28T17:50:26.962Z"}
{"msg":"But the consensus messages are also going via Validator ZMQ right ?","username":"manojgop","ts":"2019-01-28T17:51:04.536Z"}
{"msg":"yeah, but it's a separate instance running on a different thread and managed by a different threadpool","username":"jsmitchell","ts":"2019-01-28T17:51:34.884Z"}
{"msg":"Leader consensus <-> Leader validator <-> Follower Validator <-> Follower consensus  where <-> = ZMQ","username":"manojgop","ts":"2019-01-28T17:51:56.537Z"}
{"msg":"oh, yes - the peer messages are always exchanged via gossip","username":"jsmitchell","ts":"2019-01-28T17:52:27.111Z"}
{"msg":"even if they are consensus messages","username":"jsmitchell","ts":"2019-01-28T17:52:33.892Z"}
{"msg":"i thought you were referring to the engine<->validator messages","username":"jsmitchell","ts":"2019-01-28T17:52:47.594Z"}
{"msg":"\"Dispatch incoming queue size\" in the validator logs corresponds to all the messages which dispatch handler eventually dispatches to different threadpool ?","username":"manojgop","ts":"2019-01-28T17:53:53.301Z"}
{"msg":"yes, the depth of the incoming message queue","username":"jsmitchell","ts":"2019-01-28T17:54:32.264Z"}
{"msg":"I meant all the peer messaging between consensus engines also go via validator ZMQ which is the same path used by gossip messages too","username":"manojgop","ts":"2019-01-28T17:55:01.624Z"}
{"msg":"yes, correct","username":"jsmitchell","ts":"2019-01-28T17:55:10.851Z"}
{"msg":"So consenus engine messages like heart beat may get slowed down if there is lot of gossip messages and vice versa. We can't assign any priority for messages or is it FIFO based ?","username":"manojgop","ts":"2019-01-28T17:56:11.334Z"}
{"msg":"So consenus engine messages like heart beat may get slowed down if there are lot of gossip messages and vice versa. We can't assign any priority for messages or is it FIFO based ?","username":"manojgop","ts":"2019-01-28T17:56:11.334Z"}
{"msg":"there is a mechanism for priority","username":"jsmitchell","ts":"2019-01-28T17:57:18.979Z"}
{"msg":"it's been a long long time since I looked at that code","username":"jsmitchell","ts":"2019-01-28T17:57:26.449Z"}
{"msg":"Even the commit_block() message from consensus to validator may get slowed.  I've seen validator sometimes taking lot of time responding to commit_block(). I don't see any option to set message priority using consensus SDK","username":"manojgop","ts":"2019-01-28T17:59:10.509Z"}
{"msg":"https://github.com/hyperledger/sawtooth-core/blob/master/validator/sawtooth_validator/networking/dispatch.py#L145","username":"jsmitchell","ts":"2019-01-28T18:02:41.844Z"}
{"msg":"https://github.com/hyperledger/sawtooth-core/blob/master/validator/sawtooth_validator/server/consensus_handlers.py","username":"jsmitchell","ts":"2019-01-28T18:05:50.241Z"}
{"msg":"those add_handler calls look like they are defaulting to priority=None","username":"jsmitchell","ts":"2019-01-28T18:07:35.814Z"}
{"msg":"@ltseeley @pschwarz ^","username":"jsmitchell","ts":"2019-01-28T18:08:55.983Z"}
{"msg":"may have further thoughts","username":"jsmitchell","ts":"2019-01-28T18:09:22.647Z"}
{"msg":"I wonder if those should be at least medium","username":"pschwarz","ts":"2019-01-28T18:23:45.996Z"}
{"msg":"They default to NONE, because the priority can be set separately.  For example, if a group of handlers is configured for a particular message type, the priority is set once for that message type","username":"pschwarz","ts":"2019-01-28T18:25:58.342Z"}
{"msg":"Most of the MEDIUM level messages are for peering initialization","username":"pschwarz","ts":"2019-01-28T18:26:33.333Z"}
{"msg":"Everything else is default priority","username":"pschwarz","ts":"2019-01-28T18:26:46.487Z"}
{"msg":"Ping Responses are HIGH, so connections aren't dropped, but they're the only ones","username":"pschwarz","ts":"2019-01-28T18:27:20.217Z"}
{"msg":"I was not aware that there was a priority mechanism for handlers. Seems useful though","username":"ltseeley","ts":"2019-01-28T18:32:08.821Z"}
{"msg":"do you guys have some suggestions for @manojgop about what specific message types he should raise the priority of? All the consensus messages? Seems like a good opportunity for some testing since he's able to recreate this issue.","username":"jsmitchell","ts":"2019-01-28T19:02:09.974Z"}
{"msg":"Hmm, bumping up the priority of the peer (engine-to-engine) consensus messages might be interesting; if that works well, it might prevent new elections occuring in Raft. Might also be interesting to try increasing priority of all consensus messages (or even just block commits, since those seem to be slowed down).","username":"ltseeley","ts":"2019-01-28T19:19:45.776Z"}
{"msg":"hi all, Can you please tell how to use sawtooth explorer\n\nHave any guidance for that?","username":"muniyaraj","ts":"2019-01-30T08:42:07.982Z"}
{"msg":"1858","username":"LeonardoCarvalho","ts":"2019-01-30T10:54:05.825Z"}
{"msg":"Guys, any news on backporting https://github.com/hyperledger/sawtooth-core/pull/1858 ?","username":"LeonardoCarvalho","ts":"2019-01-30T10:54:05.825Z"}
{"msg":"Have you created a backport PR for it?","username":"pschwarz","ts":"2019-01-30T16:15:28.334Z"}
{"msg":"Create a branch against 1-1, and cherry pick the commit.  When you submit the PR, title it as \"BACKPORT 1-1: <Specific title>\" and reference the original PR in the description","username":"pschwarz","ts":"2019-01-30T16:16:27.265Z"}
{"msg":"It will get it in the review process","username":"pschwarz","ts":"2019-01-30T16:16:39.387Z"}
{"msg":"ok, thank you!","username":"LeonardoCarvalho","ts":"2019-01-30T22:29:41.310Z"}
{"msg":"@LeonardoCarvalho if the backport is merged prior to next Tuesday, you could request a release on Tuesday in #sawtooth-release for the following Thursday. I think we have one other fix too that is likely to justify a point release.","username":"amundson","ts":"2019-01-31T16:32:21.475Z"}
{"msg":"Has left the channel.","username":"rjones","ts":"2019-01-31T19:00:26.054Z","type":"ul"}
{"msg":"Ok, I'll start learning the procedure.","username":"LeonardoCarvalho","ts":"2019-02-01T10:58:28.183Z"}
{"msg":"@rbuysse and I are considering merging the python signing library into the python sdk","username":"amundson","ts":"2019-02-01T14:58:00.969Z"}
{"msg":"All the Jenkins builds of sawtooth-core seem to be failing.  I see this error in my log and other logs:\n``` validator/sawtooth_validator/networking/interconnect.py:31:0: E0611: No name 'asyncio' in module 'zmq.auth' (no-name-in-module)```\nhttps://build.sawtooth.me/job/Sawtooth-Hyperledger/job/sawtooth-core/job/PR-2012/4/console\nFile interconnect.py changed 2 months ago, so something else is missing or changed.","username":"danintel","ts":"2019-02-01T16:52:48.613Z"}
{"msg":"@danintel this is something @pschwarz and others have been looking into","username":"amundson","ts":"2019-02-01T17:32:00.711Z"}
{"msg":"Thanks! CI is great for preventing regression. It seems fragile though. I don't know if it's a Jenkins thing. Travis also seems fragile. Needs a lot of care and feeding.","username":"danintel","ts":"2019-02-01T17:44:44.979Z"}
{"msg":"in no way is it a problem with CI","username":"amundson","ts":"2019-02-01T17:53:38.178Z"}
{"msg":"The Intel team also has a couple of PRs that they are looking to move forward into a point release.","username":"TomBarnes","ts":"2019-02-01T17:55:11.229Z"}
{"msg":"do you know which?","username":"amundson","ts":"2019-02-01T17:56:45.580Z"}
{"msg":"@amundson #1995 in sawtooth-core, #6 in cxx sdk, #4 in rust sdk","username":"TomBarnes","ts":"2019-02-01T18:15:54.400Z"}
{"msg":"we generally only backport bug fixes and doc updates, so 1995 is probably destined for 1.2 and not a 1.1.x point release","username":"amundson","ts":"2019-02-01T18:23:04.604Z"}
{"msg":"I dont think this breaks backward compatability, and I see other non-breaking api changes in past sawtooth point releases","username":"TomBarnes","ts":"2019-02-01T18:27:35.385Z"}
{"msg":"that were new features?","username":"amundson","ts":"2019-02-01T18:33:23.885Z"}
{"msg":"AFAIK, these proto APIs haven't even changed since v1.0","username":"amundson","ts":"2019-02-01T18:33:45.629Z"}
{"msg":"Extension of existing APIs.","username":"TomBarnes","ts":"2019-02-01T18:33:50.295Z"}
{"msg":"which backports?","username":"amundson","ts":"2019-02-01T18:34:04.299Z"}
{"msg":"for exmaple in 1.0.4 \"Added `client_max_size` to Sawtooth Rest API Configuration for controlling the size of batches submitted\"","username":"TomBarnes","ts":"2019-02-01T18:34:25.280Z"}
{"msg":"My interpretation of that was that it fixed a bug around the unintentional 1MB limit and then added a config option so you could set it to get the previous behavior if you wished. But, I don't equate REST API configuration changes to TP protocol changes in any case.","username":"amundson","ts":"2019-02-01T18:43:22.858Z"}
{"msg":"its a non-breaking change thats tranparent to the user","username":"TomBarnes","ts":"2019-02-01T18:45:00.202Z"}
{"msg":"i think thats the key point","username":"TomBarnes","ts":"2019-02-01T18:45:16.854Z"}
{"msg":"Well, within 1.x, we aren't breaking the API -- we won't even consider that prior to 2.0. So your argument holds and that's why we would even allow it into master (and thus 1.2) in the first place. But when we add features, we increment the minor number (1.1->1.2), so that you can write code against 1.1 and it will work with any 1.1.x validator.","username":"amundson","ts":"2019-02-01T18:50:37.228Z"}
{"msg":"how urgent is this capability for you?","username":"amundson","ts":"2019-02-01T18:51:40.276Z"}
{"msg":"(to be in a release)","username":"amundson","ts":"2019-02-01T18:52:56.710Z"}
{"msg":"This one and RFC #34 have significant business urgency.  Unless we anticipated a 1.2 release in Q1, waiting for a 1.2 release would create difficulties. ","username":"TomBarnes","ts":"2019-02-01T18:54:48.648Z"}
{"msg":"RFC 34 doesn't seem to have much support yet. It is problematic for reasons describe in the RFC commentary.","username":"amundson","ts":"2019-02-01T19:04:46.518Z"}
{"msg":"re:1.2 in Q1 - haven't really considered it yet. In theory it shouldn't be as heavy-weight process-wise as 1.1 was (which took a lot of effort), but master has some bugs in it that would need to be squashed and a LR7 passed.","username":"amundson","ts":"2019-02-01T19:07:17.642Z"}
{"msg":"poet doesn't pass w/master currently, maybe because of a block manager ref counting bug (that's the current theory), though there could be poet-specific bugs too.","username":"amundson","ts":"2019-02-01T19:09:33.648Z"}
{"msg":"RFC #34 can be worked around, based on feedback in that RFC, if it has business urgency","username":"pschwarz","ts":"2019-02-01T19:29:31.051Z"}
{"msg":"Just created my PR : https://github.com/hyperledger/sawtooth-core/pull/2014","username":"LeonardoCarvalho","ts":"2019-02-04T11:33:12.726Z"}
{"msg":"@jsmitchell @pschwarz @agunde @boydjohnson we plan to extend the TP protocol slightly with this PR - https://github.com/hyperledger/sawtooth-core/pull/1995 - in the comments, I raise a concern we would like to get more input on, which is namely how we get TPs using the new protocol to be rejected by previous validators that only talk the old protocol. For example, here we could have a TP requesting RAW and older validators would ignore it an behave incorrectly (well, behave without knowledge of the new protocol elements). We planned for this in our PeerRegisterRequest but apparently not with TPs. Thoughts on implementing a protocol_version for TpRegisterRequest (which would only help if we backported it, this time) or some other possible approaches?","username":"amundson","ts":"2019-02-04T22:36:49.740Z"}
{"msg":"@arsulegai ^","username":"amundson","ts":"2019-02-04T22:41:25.356Z"}
{"msg":"* It would probably be TpRegisterResponse to address this concern ^","username":"arsulegai","ts":"2019-02-05T03:02:07.886Z"}
{"msg":"Guys, any feedback for this PR?","username":"arsulegai","ts":"2019-02-06T00:45:33.260Z"}
{"msg":"@amundson to handle current TPs that do not provide this protocal_version, would we default them to the old protocal? And then TPs that need Raw would only work with a validator using tp protocol version 2, otherwise the connection will be closed? That sounds fine to me.","username":"agunde","ts":"2019-02-06T15:18:53.202Z"}
{"msg":"@amundson to handle current TPs that do not provide this protocol_version, would we default them to the old protocol? And then TPs that need Raw would only work with a validator using tp protocol version 2, otherwise the connection will be closed? That sounds fine to me.","username":"agunde","ts":"2019-02-06T15:18:53.202Z"}
{"msg":"This will effect the way Sabre handles smart contracts as well, a thing to keep in mind.","username":"agunde","ts":"2019-02-06T15:20:08.228Z"}
{"msg":"Has left the channel.","username":"nanspro","ts":"2019-02-06T15:26:30.430Z","type":"ul"}
{"msg":"I think that we probably need protocol_version on the request and response. if the validator does not send back the same protocol version that was requested, the sdk could panic, shutting down the tp.","username":"amundson","ts":"2019-02-07T02:54:17.760Z"}
{"msg":"My views\n1. How about graceful \"unregister\" procedure initiated from SDK instead of panic?\n2. Having protocol_version in request message would be redundant, would it be fine if hard coded values are allowed at both SDK & Validator?\n\nComing to the question asked by @agunde , I see version specified as ^0.1 and others may also have followed similar approach, would that mean SDK version needs to change to 0.2?\nRef: https://github.com/hyperledger/sawtooth-sabre/blob/74788358f4fc3b5b93d6aa9ced9e8ddc81131b72/tp/Cargo.toml#L28","username":"arsulegai","ts":"2019-02-07T03:12:31.311Z"}
{"msg":"My views\n1. How about graceful \"unregister\" procedure initiated from SDK instead of panic?\n2. Having protocol_version in request message would be redundant, would it be fine if hard coded values are allowed at both SDK & Validator?","username":"arsulegai","ts":"2019-02-07T03:12:31.311Z"}
{"msg":"re:1 - it could be graceful if the field is empty, because that is \"protocol 0\" (the current protocol) and we know how to unregister. this is the only actual case there should ever be a mismatch between request and response.","username":"amundson","ts":"2019-02-07T04:16:00.665Z"}
{"msg":"re:2 - we need it in the request message, because the validator should determine if it can handle that protocol version. if it can not, it should reject the registration - at a minimum, refusing to send any processing requests to the TP.","username":"amundson","ts":"2019-02-07T04:17:22.100Z"}
{"msg":"within sawtooth 1.x, we should keep compatibility back to protocol version 0, and for 2.0 we can figure out what we want to do","username":"amundson","ts":"2019-02-07T04:21:13.021Z"}
{"msg":"Ok, thanks","username":"arsulegai","ts":"2019-02-07T04:24:06.499Z"}
{"msg":"@arsulegai for the sdk-side of things, it should unpack and fill in all the fields in the protobuf (I haven't looked back at the RFC, but I wonder if that's what we intended there) before sending it on to apply(). I have some code I'll add soon to the rust SDK (master) which will remove protobuf objects from the API and this will get more elegant after that change. @boydjohnson also has some slight API-breaking changes for the Rust SDK so we will try and do the changes close together.","username":"amundson","ts":"2019-02-07T04:34:43.160Z"}
{"msg":"Ok, I was planning to make use of protobuf \"oneof\" to fill either header/header_bytes to save extra bytes. Introducing oneof would make it irreversible. SDK is making use of extracted header fields to identify handler to make a apply() call so there'll be need to de-serialize header at SDK in case raw header format is requested. I'll monitor master branch of rust SDK and follow your leads.","username":"arsulegai","ts":"2019-02-07T04:58:46.562Z"}
{"msg":"we've avoided oneof in the past","username":"amundson","ts":"2019-02-07T05:08:39.358Z"}
{"msg":"do you have a diff that shows how you were planning to sue it?","username":"amundson","ts":"2019-02-07T05:09:26.974Z"}
{"msg":"do you have a diff that shows how you were planning to use it?","username":"amundson","ts":"2019-02-07T05:09:26.974Z"}
{"msg":"Yes, in my work in progress dev branch https://github.com/arsulegai/sawtooth-core/commit/3bb2a0faccc7b72380322c3fe8bb8b77196442de#diff-05cadfb3661c6c964d6a6b910205d654R99","username":"arsulegai","ts":"2019-02-07T05:11:16.597Z"}
{"msg":"that makes me nervous without a lot of backwards-compatibility tests","username":"amundson","ts":"2019-02-07T05:27:40.485Z"}
{"msg":"I was under the impression that empty fields were not in the serialized form, and so this would not actually save any space. we could test that.","username":"amundson","ts":"2019-02-07T05:28:58.762Z"}
{"msg":"I am afraid of this too, you are correct there's no saving space with just empty fields.","username":"arsulegai","ts":"2019-02-07T05:39:03.870Z"}
{"msg":"we won't have our changes into the SDK immediately, so if you want to just remove the oneof and fill in the empty fields on the SDK-side when RAW is used, that should work fine. the changes from us are possible sometime next week.","username":"amundson","ts":"2019-02-07T05:41:45.313Z"}
{"msg":"the approach is going to be to convert from the protobuf to another struct. I do have some code to do that, but it is currently targetting sawtooth 2.0 and does a bunch of string->bytes conversion which might need to be redone to put it into the sawtooth sdk.","username":"amundson","ts":"2019-02-07T05:44:09.151Z"}
{"msg":"Ok, sounds good. I will go back to sending header_bytes with empty header if RAW is requested.","username":"arsulegai","ts":"2019-02-07T05:45:10.383Z"}
{"msg":"we plan to start doing contributor meetings soon, @mfford will schedule them starting sometime after we have started the similar grid meetings.","username":"amundson","ts":"2019-02-07T15:39:04.673Z"}
{"msg":"That would be super helpful.","username":"amolk","ts":"2019-02-07T16:34:33.633Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=PCM2Q9eQnqWgEoSrn) @jsmitchell @ltseeley @pschwarz @amundson I tried running Raft by enabling the metrics. ```\n*Issue 1:*\n``` What I observe is whenever total memory occupied by the validator process gets close to max system memory a disk I/O will happen . This looks to be LMDB writing to the disk.  Disk /O is in order of TBps. At this point the TP processing gets slow and message processing time also increases (can be seen in the grafana graph). Since the int-tp client workload is also running this will queue in batches and we eventually get queue full error. So the LMDB disk I/O is slowing the system down. The TP processing is also blocked at this time since TP calls get/set state on LMDB merkle tree.```\n\n``` ","username":"manojgop","ts":"2019-02-08T15:57:32.662Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=PCM2Q9eQnqWgEoSrn","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=PCM2Q9eQnqWgEoSrn","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=PCM2Q9eQnqWgEoSrn) @jsmitchell @ltseeley @pschwarz @amundson I tried running Raft by enabling the metrics. ```\n*Issue 1:* ``` What I observe is whenever total memory occupied by the validator process gets close to max system memory a disk I/O will happen . This looks to be LMDB writing to the disk.  Disk /O is in order of TBps. At this point the TP processing gets slow and message processing time also increases (can be seen in the grafana graph). Since the int-tp client workload is also running this will queue in batches and we eventually get queue full error. So the LMDB disk I/O is slowing the system down. The TP processing is also blocked at this time since TP calls get/set state on LMDB merkle tree.```\n\n``` ","username":"manojgop","ts":"2019-02-08T15:57:32.662Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=PCM2Q9eQnqWgEoSrn","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=PCM2Q9eQnqWgEoSrn","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=PCM2Q9eQnqWgEoSrn) @jsmitchell @ltseeley @pschwarz @amundson I tried running Raft by enabling the metrics.  *Issue 1:*  - What I observe is whenever total memory occupied by the validator process gets close to max system memory a disk I/O will happen . This looks to be LMDB writing to the disk.  Disk /O is in order of TBps. At this point the TP processing gets slow and message processing time also increases (can be seen in the grafana graph). Since the int-tp client workload is also running this will queue in batches and we eventually get queue full error. So the LMDB disk I/O is slowing the system down. The TP processing is also blocked at this time since TP calls get/set state on LMDB merkle tree.\n\n*Issue 2:* - When Raft leader nodes rejects batches forwarded follower nodes since leader queue if full, these batches will remain in follower queue forever (till leader changes) since leader only add publishes the blocks and add batches in leader queue. May be there should be a mechanism for clearing the batches in the  validator queue if its doesn't get processed after certain configurable number of blocks.","username":"manojgop","ts":"2019-02-08T15:57:32.662Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=PCM2Q9eQnqWgEoSrn","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=PCM2Q9eQnqWgEoSrn","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=PCM2Q9eQnqWgEoSrn) @jsmitchell @ltseeley @pschwarz @amundson I tried running Raft by enabling the metrics.  *Issue 1:*  - What I observe is whenever total memory occupied by the validator process gets close to max system memory a disk I/O will happen . This looks to be LMDB writing to the disk.  Disk /O is in order of TBps. At this point the TP processing gets slow and message processing time also increases (can be seen in the grafana graph). Since the int-tp client workload is also running this will queue in batches and we eventually get queue full error. So the LMDB disk I/O is slowing the system down. The TP processing is also blocked at this time since TP calls get/set state on LMDB merkle tree.\n\n*Issue 2:* - When Raft leader nodes rejects batches forwarded follower nodes since leader queue if full, these batches will remain in follower queue forever (till leader changes) since leader only add publishes the blocks and add batches in leader queue. May be there should be a mechanism for clearing the batches in the  validator queue if its doesn't get processed after certain configurable number of blocks.","username":"manojgop","ts":"2019-02-08T15:57:32.662Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=PCM2Q9eQnqWgEoSrn","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=PCM2Q9eQnqWgEoSrn","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=PCM2Q9eQnqWgEoSrn) @jsmitchell @ltseeley @pschwarz @amundson I tried running Raft by enabling the metrics.  *Issue 1:*  - What I observe is whenever total memory occupied by the validator process gets close to max system memory a disk I/O will happen . This looks to be LMDB writing to the disk.  Disk /O is in order of TBps. At this point the TP processing gets slow and message processing time also increases (can be seen in the grafana graph). Since the int-tp client workload is also running this will queue in batches and we eventually get queue full error. So the LMDB disk I/O is slowing the system down. The TP processing is also blocked at this time since TP calls get/set state on LMDB merkle tree.\n\n*Issue 2:* - When Raft leader nodes rejects batches forwarded follower nodes since leader queue if full, these batches will remain in follower queue forever (till leader changes) since leader only add publishes the blocks and add batches in leader queue. May be there should be a mechanism for clearing the batches in the  validator queue if its doesn't get processed after certain configurable number of blocks.","username":"manojgop","ts":"2019-02-08T15:57:32.662Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=PCM2Q9eQnqWgEoSrn","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=PCM2Q9eQnqWgEoSrn","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=PCM2Q9eQnqWgEoSrn) @jsmitchell @ltseeley @pschwarz @amundson I tried running Raft by enabling the metrics.  *Issue 1:*  - What I observe is whenever total memory occupied by the validator process gets close to max system memory a disk I/O will happen . This looks to be LMDB writing to the disk.  Disk /O is in order of TBps. At this point the TP processing gets slow and message processing time also increases (can be seen in the grafana graph). Since the int-tp client workload is also running this will queue in batches and we eventually get queue full error. So the LMDB disk I/O is slowing the system down. The TP processing is also blocked at this time since TP calls get/set state on LMDB merkle tree.\n\n*Issue 2:* - When Raft leader nodes rejects batches forwarded follower nodes since leader queue if full, these batches will remain in follower queue forever (till leader changes) since leader only  publishes the blocks with contain batches in leader queue. May be there should be a mechanism for clearing the batches in the  validator queue if its doesn't get processed after certain configurable number of blocks.","username":"manojgop","ts":"2019-02-08T15:57:32.662Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=PCM2Q9eQnqWgEoSrn","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=PCM2Q9eQnqWgEoSrn","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=PCM2Q9eQnqWgEoSrn) @jsmitchell @ltseeley @pschwarz @amundson I tried running Raft by enabling the metrics.  *Issue 1:*  - What I observe is whenever total memory occupied by the validator process gets close to max system memory a disk I/O will happen . This looks to be LMDB writing to the disk.  Disk /O is in order of TBps. At this point the TP processing gets slow and message processing time also increases (can be seen in the grafana graph). Since the int-tp client workload is also running this will queue in batches and we eventually get queue full error. So the LMDB disk I/O is slowing the system down. The TP processing is also blocked at this time since TP calls get/set state on LMDB merkle tree.\n\n*Issue 2:* - When Raft leader nodes rejects batches forwarded follower nodes since leader queue if full, these batches will remain in follower queue forever (till leader changes) since leader only  publishes the blocks with contain batches in leader queue. May be there should be a mechanism for clearing the batches in the validator queue if it doesn't get processed after a configurable number of blocks.","username":"manojgop","ts":"2019-02-08T15:57:32.662Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=PCM2Q9eQnqWgEoSrn","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=PCM2Q9eQnqWgEoSrn","remote":true,"fileId":null,"fileName":null}]}
{"msg":"What do you mean “TBps”?","username":"jsmitchell","ts":"2019-02-08T16:04:24.241Z"}
{"msg":"","username":"manojgop","ts":"2019-02-08T16:04:43.742Z","attachments":[{"type":"file","title":"grafana_metrics_lmdb.JPG","title_link":"/file-upload/BF8uXYqhXPQFQ94mQ/grafana_metrics_lmdb.JPG","image_url":"/file-upload/BF8uXYqhXPQFQ94mQ/grafana_metrics_lmdb.JPG","image_type":"image/jpeg","image_size":130938,"url":"/file-upload/BF8uXYqhXPQFQ94mQ/grafana_metrics_lmdb.JPG","remote":false,"fileId":"BF8uXYqhXPQFQ94mQ","fileName":"grafana_metrics_lmdb.JPG"}]}
{"msg":"TeraByes/sec","username":"manojgop","ts":"2019-02-08T16:04:56.777Z"}
{"msg":"Tera Bytes/sec","username":"manojgop","ts":"2019-02-08T16:04:56.777Z"}
{"msg":"LMDB size is 1 TB","username":"manojgop","ts":"2019-02-08T16:05:31.513Z"}
{"msg":"Yeah, as a sparse file...","username":"jsmitchell","ts":"2019-02-08T16:05:41.264Z"}
{"msg":"yes","username":"manojgop","ts":"2019-02-08T16:05:47.806Z"}
{"msg":"What filesystem are you running this on?","username":"jsmitchell","ts":"2019-02-08T16:05:51.181Z"}
{"msg":"Is Windows involved at all?","username":"jsmitchell","ts":"2019-02-08T16:06:18.304Z"}
{"msg":"I'm using a Ubuntu VM. I'll rerun this on Intel NUC. No windows","username":"manojgop","ts":"2019-02-08T16:06:33.096Z"}
{"msg":"I'm using a Ubuntu VM. I'll rerun this on Intel NUC with SSD. No windows","username":"manojgop","ts":"2019-02-08T16:06:33.096Z"}
{"msg":"Ubuntu VM on what?","username":"jsmitchell","ts":"2019-02-08T16:06:46.022Z"}
{"msg":"Linux server Virtualization","username":"manojgop","ts":"2019-02-08T16:08:45.079Z"}
{"msg":"BTW to reproduce the issue quickly I limited the docker container  memory to 70M. I run 5TPS int key workload","username":"manojgop","ts":"2019-02-08T16:09:39.603Z"}
{"msg":"with think after 5-6 mins  the container memory gets full and disk I/O happens. If I don't set any container memory limit, then disk I/O happens only after validator process consume most of system memory.","username":"manojgop","ts":"2019-02-08T16:11:43.413Z"}
{"msg":"After 5-6 mins  the container memory gets full and disk I/O happens. If I don't set any container memory limit, then disk I/O happens only after validator process consume most of system memory.","username":"manojgop","ts":"2019-02-08T16:11:43.413Z"}
{"msg":"After 5-6 mins  the container memory gets full and disk I/O happens. ","username":"manojgop","ts":"2019-02-08T16:11:43.413Z"}
{"msg":"You can notice from the graph Read/Write IOPS peaks","username":"manojgop","ts":"2019-02-08T16:12:18.802Z"}
{"msg":"This issue can be reproduced consistently and quickly if we limit the validator docker container memory","username":"manojgop","ts":"2019-02-08T16:12:59.907Z"}
{"msg":"But if I use a system with 8 GB RAM then we will notice this issue only after running for more than 8 days with 5TPS since its take long for system memory to get consumed","username":"manojgop","ts":"2019-02-08T16:14:30.256Z"}
{"msg":"We regularly run long running tests. The behavior we see is regular write IO and almost no read IO until Linux fscache pages fill up available memory. At that point there will be a small, steady amount of read IO to fetch pages off of disk that are not in the cache. We don’t see the spikes you are seeing.","username":"jsmitchell","ts":"2019-02-08T16:17:52.967Z"}
{"msg":"Which is the disk type you use ? SSD, HDD ?","username":"manojgop","ts":"2019-02-08T16:18:57.412Z"}
{"msg":"@jsmitchell @ltseeley One more issue with Raft consensus and validator is , when Raft leader nodes rejects batches forwarded follower nodes since leader queue if full, these batches will remain in follower queue forever (till leader changes) since leader only publishes the blocks with contain batches in leader queue. May be there should be a mechanism for clearing the batches in the validator queue if it doesn't get processed after a configurable number of blocks. This can also increase memory consumption in validator nodes (follower nodes)","username":"manojgop","ts":"2019-02-08T16:18:57.412Z"}
{"msg":"SSD. The write workload is intensive — 1k-4k iops depending on how hard you are pushing state","username":"jsmitchell","ts":"2019-02-08T16:32:54.710Z"}
{"msg":"HDD won’t cut it","username":"jsmitchell","ts":"2019-02-08T16:33:07.495Z"}
{"msg":"But that still should not result in those enormous IO spikes","username":"jsmitchell","ts":"2019-02-08T16:33:35.302Z"}
{"msg":"Has joined the channel.","username":"circlespainter","ts":"2019-02-09T10:27:22.091Z","type":"uj"}
{"msg":"I experimented above experiments on a machine with SSD support","username":"arsulegai","ts":"2019-02-11T16:52:37.237Z"}
{"msg":"I experimented above experiments on a machine with SSD","username":"arsulegai","ts":"2019-02-11T16:52:37.237Z"}
{"msg":"Result is same","username":"arsulegai","ts":"2019-02-11T16:52:45.847Z"}
{"msg":"I experimented above scenario on a machine with SSD, there were no IO spikes but the outcome is same","username":"arsulegai","ts":"2019-02-11T16:55:25.797Z"}
{"msg":"I experimented above scenario on a machine with SSD, there were no sudden IO spikes but the outcome is same","username":"arsulegai","ts":"2019-02-11T16:55:25.797Z"}
{"msg":"Coming to observation from logs:\n1. All Raft engines have same log entry, leader engine has published a new block and is waiting for follower nodes to confirm Raft log entry to proceed.\n2. Input tps remained constant, so I see queue full and batches rejected. Machine's memory was used to the full capacity.\n3. Follower nodes too printed that they received the block and they validated from their end.\n4. Dispatcher queue is full and memory usage is maximum, then there's no activity in the network other than heartbeat.","username":"arsulegai","ts":"2019-02-11T17:15:17.303Z"}
{"msg":"","username":"arsulegai","ts":"2019-02-11T17:22:26.340Z","attachments":[{"type":"file","title":"Experiment - limited memory in machine, IO to SSD","title_link":"/file-upload/XCecbm7LZv2ybcRhE/Experiment%20-%20limited%20memory%20in%20machine,%20IO%20to%20SSD","image_url":"/file-upload/XCecbm7LZv2ybcRhE/Experiment%20-%20limited%20memory%20in%20machine,%20IO%20to%20SSD","image_type":"image/png","image_size":276073,"url":"/file-upload/XCecbm7LZv2ybcRhE/Experiment%20-%20limited%20memory%20in%20machine,%20IO%20to%20SSD","remote":false,"fileId":"XCecbm7LZv2ybcRhE","fileName":"Experiment - limited memory in machine, IO to SSD"}]}
{"msg":"Machines were limited to maximum of 70MB","username":"arsulegai","ts":"2019-02-11T17:23:11.868Z"}
{"msg":"My initial suspicion is that propose() from leader is lost due to no space left in follower nodes, leader has advanced and hence is unable to send proposal again\nIt could be wrong as well, there's no definite way to prove it without more logging. Any suggestions?","username":"arsulegai","ts":"2019-02-11T17:42:54.007Z"}
{"msg":"Need to understand the nature of that read IO. What’s causing it?","username":"jsmitchell","ts":"2019-02-11T17:43:23.706Z"}
{"msg":"It probably has nothing to do with the lmdb. At 70mb, you are probably running into swap thrashing just with stack+heap on the validator process.","username":"jsmitchell","ts":"2019-02-11T17:44:54.885Z"}
{"msg":"I am used to seeing the validator process use 800MB-1.2GB of ram. Why would we expect it to run within 70MB?","username":"jsmitchell","ts":"2019-02-11T17:45:39.784Z"}
{"msg":"It was only to get to the issue scenario sooner, which otherwise we were seeing after days of running","username":"arsulegai","ts":"2019-02-11T17:47:13.318Z"}
{"msg":"How much memory was available to the process in those machines (where you saw issues after days of running)? What did memory consumption look like when the issue occurred? Did that coincide with the increased read IO?","username":"jsmitchell","ts":"2019-02-11T17:49:50.970Z"}
{"msg":"If you are saying that one of the sawtooth processes is consuming most of 8GB of ram for stack+heap (NOT fscache), then that sounds like a memory leak.","username":"jsmitchell","ts":"2019-02-11T17:55:57.122Z"}
{"msg":"Will continue more experiments on it and report here, we have other tests still running","username":"arsulegai","ts":"2019-02-11T18:01:33.947Z"}
{"msg":"A random thought: Would it sound good if even the peer validators can decide  priority of consensus engine messages. i.e. Use a new message type (not the Gossip message as it is sending today) for sending consensus messages to peers and increase chances of handling those messages by raising priority?","username":"arsulegai","ts":"2019-02-11T18:09:28.023Z"}
{"msg":"I had a conversation with @ltseeley about that very thing last week","username":"jsmitchell","ts":"2019-02-11T18:12:08.057Z"}
{"msg":"I think I had similar comment to one of his PR in sawtooth-core in another context","username":"arsulegai","ts":"2019-02-11T18:13:04.292Z"}
{"msg":"But, that is probably separate from a possible memory leak as a root cause discussion. (I.e if the machine starts swapping, the node is toast regardless if it is handling consensus messages with higher priority or not)","username":"jsmitchell","ts":"2019-02-11T18:13:49.430Z"}
{"msg":"Agree","username":"arsulegai","ts":"2019-02-11T18:14:02.412Z"}
{"msg":"Has joined the channel.","username":"Mr-zohaibkhalid","ts":"2019-02-11T19:36:22.243Z","type":"uj"}
{"msg":"When Raft leader nodes rejects batches forwarded follower nodes since leader queue if full, these batches will remain in follower queue forever (till leader changes) since leader only publishes the blocks with contain batches in leader queue. May be there should be a mechanism for clearing the batches in the validator queue if it doesn't get processed after a configurable number of blocks. This can also lead to memory consumption in validator nodes (follower nodes in case of Raft)","username":"manojgop","ts":"2019-02-13T04:33:47.973Z"}
{"msg":"@jsmitchell @ltseeley One more issue with validator memory during Raft consensus is when Raft leader nodes rejects batches forwarded follower nodes since leader queue if full, these batches will remain in follower queue forever (till leader changes) since leader only publishes the blocks with contain batches in leader queue. May be there should be a mechanism for clearing the batches in the validator queue if it doesn't get processed after a configurable number of blocks. This can also lead to memory consumption in validator nodes (follower nodes in case of Raft)","username":"manojgop","ts":"2019-02-13T04:33:47.973Z"}
{"msg":"@jsmitchell @ltseeley One more issue with validator memory during Raft consensus is when Raft leader nodes rejects batches forwarded follower nodes since leader queue if full, these batches will remain in follower queue forever (till leader changes) since leader only publishes the blocks with contain batches in leader queue. May be there should be a mechanism for clearing the batches in the validator queue if it doesn't get processed after a long time (for example after configurable number of blocks.) This can also lead to memory consumption in validator nodes (follower nodes in case of Raft)","username":"manojgop","ts":"2019-02-13T04:33:47.973Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4) @amundson @amundson in case of consensus algorithms like Raft , the transactions sent by clients to the follower nodes will remain in queue for ever if the leader node rejects the batches sent by follower node via gossip (when leader queue if full temporarily) or unless follower nodes becomes a leader and inserts those transaction in a block.  These transactions are actually valid but will remain in the follower node queue till the follower node becomes the leader.  So could we use the time-in-queue or block horizon approach to clear the pending valid transactions in queue ?","username":"manojgop","ts":"2019-02-13T04:33:47.973Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Since we are talking about possible improvements, there are few other things to help us in addition to what @manojgop mentioned\n1. Possibly the current trace of dispatcher queue full can slightly be altered or a new trace can be introduced which states whether validator has capacity to accept new messages. Current trace will print dispatcher queue is full if there are more than 10 messages but in reality it might not have enough space left.\n2. Name dispatcher queue so that it's identifiable from logs which of the interface messages are getting lost due to lack of memory. This is just to bring in more clarity in logs.\n3. Possibility of moving dispatcher part of code from python to rust.","username":"arsulegai","ts":"2019-02-13T06:59:21.639Z"}
{"msg":"Has joined the channel.","username":"jaypersanchez","ts":"2019-02-13T11:29:32.634Z","type":"uj"}
{"msg":"Hello everyone.  How can I start to contribute to Sawtooth?","username":"jaypersanchez","ts":"2019-02-13T11:30:49.971Z"}
{"msg":"@jaypersanchez do you have a particular area of interest?","username":"amundson","ts":"2019-02-13T18:56:19.475Z"}
{"msg":"Fork to new discussion: @jsmitchell @pschwarz @boydjohnson @amundson This is regarding the patch to remove invalid transactions and avoid potential loop over invalid transactions https://github.com/hyperledger/sawtooth-core/pull/1994 .\nCurrent solution provided here appears to be fine for a node creating block but not for nodes which do not participate in creating blocks. Can we think of breaking this into smaller chunks and target solving one problem at a time?","username":"arsulegai","ts":"2019-02-14T08:22:35.143Z"}
{"msg":"@arsulegai what do you propose? Current thoughts I’ve heard are some kind of time horizon based mechanism for purging the pending queue.","username":"jsmitchell","ts":"2019-02-14T15:38:37.447Z"}
{"msg":"The reason I am not inclined towards time bound mechanism is because consensus engine decides when to create the block. Validator may not be right candidate to apply such logic, there's possibility that transactions may get removed even before they are properly scheduled.","username":"arsulegai","ts":"2019-02-14T15:43:17.207Z"}
{"msg":"How about number of blocks committed since the time of arrival of transaction? This is something in control of administrator and validator cannot be solely responsible for losing transactions.","username":"arsulegai","ts":"2019-02-14T15:48:44.917Z"}
{"msg":"I think I am diverging again, we can classify discussion into 2 categories\n1. Periodic purging of pending batches and make sure transactions are not stalled in queue forever.\n2. Clearing up invalid transaction even if there's no block created when processor has executed it and marked as invalid.","username":"arsulegai","ts":"2019-02-14T15:53:12.559Z"}
{"msg":"for (1), do you mean invalid transactions?","username":"amundson","ts":"2019-02-14T16:22:46.214Z"}
{"msg":"removing valid transactions at any point could have BFT implications we would need to thing through","username":"amundson","ts":"2019-02-14T16:23:26.527Z"}
{"msg":"I'm ok with periodic execution of pending transactions and removal of only invalid transactions. But executing transactions just to remove invalid ones will increase number of times a transaction may get executed by a validator to 3.","username":"arsulegai","ts":"2019-02-14T16:33:44.387Z"}
{"msg":"Hmm, agree that removal of valid transactions with above proposal is not a good idea.","username":"arsulegai","ts":"2019-02-14T16:34:33.437Z"}
{"msg":"hmm, that is an interesting idea","username":"amundson","ts":"2019-02-14T16:38:06.403Z"}
{"msg":"well, you could calculate a time-in-queue for each transaction, and then periodically run it to see if it has become invalid without worrying about the execution overhead, because it would be done so seldom.","username":"amundson","ts":"2019-02-14T16:39:06.492Z"}
{"msg":"i.e. don't test a transaction for validity if it has been in the queue for less than N minutes","username":"amundson","ts":"2019-02-14T16:39:46.708Z"}
{"msg":"I'm wary of defining period here with respect to time or even number of blocks since transaction's arrival.","username":"arsulegai","ts":"2019-02-14T16:44:25.129Z"}
{"msg":"Adding to the proposal, this idea can be extended to all validators irrespective of commands from their consensus engine.","username":"arsulegai","ts":"2019-02-14T16:46:39.840Z"}
{"msg":"@arsulegai as @jsmitchell mentioned, a block horizon would be a good metric for periodically testing validity of pending transactions. And it could be configured by the administrator.","username":"amolk","ts":"2019-02-15T09:18:13.835Z"}
{"msg":"Block horizon sounds better than time horizon :)","username":"arsulegai","ts":"2019-02-15T09:23:38.531Z"}
{"msg":"Yep, Time Horizon reminds me of Black Holes...","username":"LeonardoCarvalho","ts":"2019-02-15T14:20:18.799Z"}
{"msg":"Then we can call it Event Horizon 🙂","username":"danintel","ts":"2019-02-15T16:35:30.657Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4) @amundson @amundson in case of consensus algorithms like Raft, the transactions sent by client to follower node will remain in the follower queue for ever if the leader rejects these transaction sent via gossip (if leader queue if full temporarily) or unless the follower nodes becomes leader at later point and commits these transactions in a block. These are actually valid transactions but can remain in follower node queue in above scenario. Can we use time-in-queue or block horizon approach to remove these pending transactions ?","username":"manojgop","ts":"2019-02-16T07:57:46.729Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4) @amundson @jsmitchell in case of consensus algorithms like Raft, the transactions sent by client to follower node will remain in the follower queue for ever if the leader rejects these transaction sent via gossip (if leader queue if full temporarily) or unless the follower nodes becomes leader at later point and commits these transactions in a block. These are actually valid transactions but can remain in follower node queue in above scenario. Can we use time-in-queue or block horizon approach to remove these pending transactions ?","username":"manojgop","ts":"2019-02-16T07:57:46.729Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4) @amundson in case of consensus algorithms like Raft, the transactions sent by client to follower node will remain in the follower queue for ever if the leader rejects these transaction sent via gossip (if leader queue if full temporarily) or unless the follower nodes becomes leader at later point and commits these transactions in a block. These are actually valid transactions but can remain in follower node queue in above scenario. Can we use time-in-queue or block horizon approach to remove these pending transactions ?","username":"manojgop","ts":"2019-02-16T07:57:46.729Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4) @amundson in case of consensus algorithms like Raft, the transactions sent by client to follower node will remain in the follower queue for ever if the leader rejects these transaction sent via gossip (if leader queue if full temporarily) or unless the follower nodes becomes leader at later point and insets these transactions in a block and commits it. These are actually valid transactions but can remain in follower node queue in above scenario. Can we use time-in-queue or block horizon approach to remove these pending transactions ?","username":"manojgop","ts":"2019-02-16T07:57:46.729Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4) @amundson in case of consensus algorithms like Raft, the transactions sent by client to follower node will remain in the follower queue for ever if the leader rejects these transaction sent via gossip (if leader queue is full temporarily) or unless the follower nodes becomes leader at later point and insets these transactions in a block and commits it. These are actually valid transactions but can remain in follower node queue in above scenario. Can we use time-in-queue or block horizon approach to remove these pending transactions ?","username":"manojgop","ts":"2019-02-16T07:57:46.729Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4) @amundson in case of consensus algorithms like Raft, the transactions sent by client to follower node will remain in the follower queue for ever if the leader rejects these transaction sent via gossip (if leader queue is full temporarily) or unless the follower nodes becomes leader at later point and adds these transactions in a block and commits it. These are actually valid transactions but can remain in follower node queue in above scenario. Can we use time-in-queue or block horizon approach to remove these pending transactions ?","username":"manojgop","ts":"2019-02-16T07:57:46.729Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4) @amundson in case of consensus algorithms like Raft, the transactions sent by client to follower node will remain in the follower queue for ever if the leader rejects these transaction sent via gossip (if leader queue is full temporarily) or unless the follower nodes becomes leader at later point and adds these transactions in a block and commits it. These are actually valid transactions but can remain in follower node queue for long time in above scenario. Can we use time-in-queue or block horizon approach to remove these pending transactions ?","username":"manojgop","ts":"2019-02-16T07:57:46.729Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4) @amundson in case of consensus algorithms like Raft, the transactions sent by client to follower node will remain in the follower queue for ever if the leader rejects these transaction sent via gossip (if leader queue is full temporarily) or unless the follower nodes becomes leader at later point and adds these transactions in a block and commits it. These are actually valid transactions but can remain in follower node queue for long time in above scenario. Can we use time-in-queue or block horizon approach to remove these pending valid transactions ?","username":"manojgop","ts":"2019-02-16T07:57:46.729Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=4yMgtnckaYRH7PsB4","remote":true,"fileId":null,"fileName":null}]}
{"msg":"I would recommend invalid transactions be purged and valid transactions broadcast once again. ","username":"amolk","ts":"2019-02-16T09:38:27.571Z"}
{"msg":"There is already a mechanism to handle duplicate valid transactions by a validator so a re-broadcast by a follower of a transaction already in a leaders queue won't be harmful. ","username":"amolk","ts":"2019-02-16T09:55:02.065Z"}
{"msg":"valid transactions could be re-broadcast, that would be safe","username":"amundson","ts":"2019-02-17T02:15:21.780Z"}
{"msg":"the correct behavior for PBFT (and probably Raft) is to cause a new leader election if the leader is (apparently) refusing to add valid transactions to blocks. the validator should never, ever, drop a valid transaction.","username":"amundson","ts":"2019-02-17T02:18:02.639Z"}
{"msg":"I think you might want some randomness in determining whether to do the re-broadcast to prevent all non-leader nodes from broadcasting. With a little more work, it could be turned into send-to-leader instead of broadcast. (this would certainly require Consensus API modifications though)","username":"amundson","ts":"2019-02-17T02:21:25.778Z"}
{"msg":"Not sure if there is a better channel for this, since it is a build issue.  We run regular builds of the core (currently 1.1.3 tag) and sawtooth-poet(currently 1.1.2 tag) with no divergences.  Up until today the unit tests were passing, but today the test_config and test_genesis in sawtooth-core, and test_genesis in sawtooth-power have failed with a module import error vs the protobufs.  My first guess without digging in is that this would be because of an sdk pulled in that has changed.  Two questions a) is this the right channel for that sort of note, if not where? b) any pointers to where exactly I might find that dependency before I dive in to see what can be done to avoid this sort of thing in the future - I'd expect a tagged build to say as stable as it was when tagged and not change day by day.","username":"kodonnel","ts":"2019-02-20T14:33:42.817Z"}
{"msg":"Since the builds between core and poet are so similar I'd presume its about the same place in each.","username":"kodonnel","ts":"2019-02-20T14:35:55.628Z"}
{"msg":"@rbuysse ^","username":"jsmitchell","ts":"2019-02-20T14:39:37.647Z"}
{"msg":"@kodonnel yes, this is a good channel for that discussion","username":"amundson","ts":"2019-02-20T14:43:28.732Z"}
{"msg":"cool.  I'm mid long meeting.  Hopefully will get a chance to dig into it today. ","username":"kodonnel","ts":"2019-02-20T14:46:05.743Z"}
{"msg":"For the record and brevities sake, a snippet of the error I am looking at `unit-poet-cli_1  |     from sawtooth_poet_common.validator_registry_view.validator_registry_view \\\nunit-poet-cli_1  |   File \"/project/sawtooth-poet/common/sawtooth_poet_common/validator_registry_view/validator_registry_view.py\", line 17, in <module>\nunit-poet-cli_1  |     from sawtooth_poet_common.protobuf.validator_registry_pb2 import ValidatorInfo\nunit-poet-cli_1  | ImportError: No module named 'sawtooth_poet_common.protobuf'`","username":"kodonnel","ts":"2019-02-20T15:03:07.370Z"}
{"msg":"For the record and brevities sake, a snippet of the error I am looking at `unit-poet-cli_1  |     from sawtooth_poet_common.validator_registry_view.validator_registry_view \\\nunit-poet-cli_1  |   File \"/project/sawtooth-poet/common/sawtooth_poet_common/validator_registry_view/validator_registry_view.py\", line 17, in <module>\nunit-poet-cli_1  |     from sawtooth_poet_common.protobuf.validator_registry_pb2 import ValidatorInfo\nunit-poet-cli_1  | ImportError: No module named 'sawtooth_poet_common.protobuf'`\n","username":"kodonnel","ts":"2019-02-20T15:03:07.370Z"}
{"msg":" `unit-poet-cli_1  |     from sawtooth_poet_common.validator_registry_view.validator_registry_view \\\nunit-poet-cli_1  |   File \"/project/sawtooth-poet/common/sawtooth_poet_common/validator_registry_view/validator_registry_view.py\", line 17, in <module>\nunit-poet-cli_1  |     from sawtooth_poet_common.protobuf.validator_registry_pb2 import ValidatorInfo\nunit-poet-cli_1  | ImportError: No module named 'sawtooth_poet_common.protobuf'`\nFor the record and brevities sake a snippet of the error I am looking at.","username":"kodonnel","ts":"2019-02-20T15:03:07.370Z"}
{"msg":" `unit-poet-cli_1  |     from sawtooth_poet_common.validator_registry_view.validator_registry_view \\\nunit-poet-cli_1  |   File \"/project/sawtooth-poet/common/sawtooth_poet_common/validator_registry_view/validator_registry_view.py\", line 17, in <module>\nunit-poet-cli_1  |     from sawtooth_poet_common.protobuf.validator_registry_pb2 import ValidatorInfo\nunit-poet-cli_1  | ImportError: No module named 'sawtooth_poet_common.protobuf'`\nFor the record and brevity's sake a snippet of the error I am looking at.","username":"kodonnel","ts":"2019-02-20T15:03:07.370Z"}
{"msg":"and a demonstration of failed formatting :)","username":"kodonnel","ts":"2019-02-20T15:04:05.524Z"}
{"msg":"@amundson @jsmitchell Do we have away to disable gossip broadcast in sawtooth-core for a fully connected and statically peered network like RAFT.  This is to avoid rebroadcast of batches and blocks in case of fully connected network.  Would it make sense to enable it via some sawtooth settings (meant for admin tasks)","username":"manojgop","ts":"2019-02-20T17:02:04.415Z"}
{"msg":"@ltseeley ^","username":"jsmitchell","ts":"2019-02-20T17:04:57.285Z"}
{"msg":"@manojgop this is something we've had some conversations about and would like to implement somehow. I see two possibilities for accomplishing this: 1) using settings (likely one or more settings in the `sawtooth.consensus.algorithm` namespace), or 2) consensus engine providing some information when it registers with the validator (similar to how it reports its name and version).","username":"ltseeley","ts":"2019-02-20T17:14:24.962Z"}
{"msg":"@pschwarz ^","username":"ltseeley","ts":"2019-02-20T17:14:42.951Z"}
{"msg":"My initial thoughts are that settings seem like a nice option because it wouldn't require changes to APIs/SDKs. However, it might be useful for these decisions to be made by the consensus engine and not an administrator. But I suppose the peering configuration (static vs. dynamic, the list of peers) is required to be setup by the admin already, so maybe that wouldn't be as big of a deal.","username":"ltseeley","ts":"2019-02-20T17:20:53.895Z"}
{"msg":"I don't think it's a setting or even an option for gossip. you just want a new call that is a straight broadcast. don't change the behavior of gossip, just don't use it.","username":"amundson","ts":"2019-02-20T17:28:22.755Z"}
{"msg":"I don't think it's a setting or even an option for gossip. you just want a new call that is a straight broadcast. don't change the behavior of gossip, just don't use it.","username":"amundson","ts":"2019-02-20T17:28:22.755Z"}
{"msg":"ic - the piece not controlled by consensus at all currently? the hint from the consensus engine seems better.","username":"amundson","ts":"2019-02-20T17:31:44.904Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=WdRSCQRmyLmJ8Jf43) So I believe I have zeroed in on the issue here, and it isn't a stray dynamic dependency as I suspected.  More just a confusing aspect of the build process which happens to be common in core and poet.  Just waiting for a good build to confirm.","username":"kodonnel","ts":"2019-02-20T17:46:50.807Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=WdRSCQRmyLmJ8Jf43","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=WdRSCQRmyLmJ8Jf43","remote":true,"fileId":null,"fileName":null}]}
{"msg":"It definitely seems like a hint is better, since the behaviour is very dependent on the consensus engine that is active","username":"pschwarz","ts":"2019-02-20T17:49:51.617Z"}
{"msg":"what if the nodes are supposed to usually be fully connected, but there is a network problem preventing that from being the case? would removing gossip break CFT or BFT expectations?","username":"amundson","ts":"2019-02-20T17:51:03.546Z"}
{"msg":"Sorry to interrupt: isn't the broadcast issue in the ambit of validator than consensus engine?","username":"arsulegai","ts":"2019-02-20T17:56:01.970Z"}
{"msg":"the consensus is what provides those guarantees. If the consensus requires a certain topology, then asserting that topology is a complex problem.","username":"jsmitchell","ts":"2019-02-20T17:56:21.442Z"}
{"msg":"Network administrator makes the decision of having fully connected or not when setting up validators.","username":"arsulegai","ts":"2019-02-20T17:57:25.852Z"}
{"msg":"they are related @arsulegai - the decision not to re-broadcast is only possible due to the fully-connected nature of the network","username":"jsmitchell","ts":"2019-02-20T17:57:39.112Z"}
{"msg":"I agree that dynamic switching of consensus would require consensus knowledge.","username":"arsulegai","ts":"2019-02-20T17:58:03.472Z"}
{"msg":"furthermore, no node knows that the topology is fully connected","username":"jsmitchell","ts":"2019-02-20T17:58:34.302Z"}
{"msg":"Agree. Probably I was not clear with my question.","username":"arsulegai","ts":"2019-02-20T17:59:35.533Z"}
{"msg":"I'm trying to map this with re-broadcast of batch and block which are received over gossip.","username":"arsulegai","ts":"2019-02-20T18:00:15.963Z"}
{"msg":"If the node knew the topology, it could make smarter decisions about when to rebroadcast","username":"jsmitchell","ts":"2019-02-20T18:00:30.968Z"}
{"msg":"on a gradient from 0% of the time (fully connected) to some stochastic max","username":"jsmitchell","ts":"2019-02-20T18:00:48.952Z"}
{"msg":"i.e. if a node is an 'bridge' node to a poorly connected neighborhood of nodes, it should broadcast to that peer 100% of the time, probably","username":"jsmitchell","ts":"2019-02-20T18:02:10.086Z"}
{"msg":"whereas if a node knows that the network is fully connected, it never needs to rebroadcast","username":"jsmitchell","ts":"2019-02-20T18:02:36.991Z"}
{"msg":"Ok, so you're saying that since consensus engine now mandates certain network topology (such as in raft it's must to have fully connected network). A hint from consensus engine will let validator decide not to re-broadcast.","username":"arsulegai","ts":"2019-02-20T18:03:54.215Z"}
{"msg":"that way, the behavior is a consequence of the shape of the network, rather than a directive by the consensus engine","username":"jsmitchell","ts":"2019-02-20T18:04:08.821Z"}
{"msg":"no, i am saying decouple the assertion on the shape of the network from the gossip behavior based on the shape of the network","username":"jsmitchell","ts":"2019-02-20T18:04:43.508Z"}
{"msg":"RAFT can assert that the network needs to be fully connected. That occurs via some magic mechanism (probably human action). The networking piece recognizes that the network is fully connected and chooses not to rebroadcast.","username":"jsmitchell","ts":"2019-02-20T18:05:27.244Z"}
{"msg":"Ah! That's where I was heading to. My initial question was to ask why are we trying to tie consensus engine's hint. Because I saw discussions on that.","username":"arsulegai","ts":"2019-02-20T18:06:33.814Z"}
{"msg":"I guess I'm in sync with your thoughts.","username":"arsulegai","ts":"2019-02-20T18:06:47.965Z"}
{"msg":"easier said than done :)","username":"jsmitchell","ts":"2019-02-20T18:07:19.319Z"}
{"msg":"i'm not sure it's even practical","username":"jsmitchell","ts":"2019-02-20T18:08:26.904Z"}
{"msg":"especially when you factor in the need to deal with byzantine responses from peers","username":"jsmitchell","ts":"2019-02-20T18:09:10.706Z"}
{"msg":"nodes would probably need to sign a message listing who they are peered with and distribute it around the network","username":"jsmitchell","ts":"2019-02-20T18:10:48.049Z"}
{"msg":"on a fairly frequent basis","username":"jsmitchell","ts":"2019-02-20T18:10:55.218Z"}
{"msg":"so that all nodes can keep an up to date model of the shape of the network","username":"jsmitchell","ts":"2019-02-20T18:11:06.968Z"}
{"msg":"A parallel chain concept?","username":"arsulegai","ts":"2019-02-20T18:12:00.186Z"}
{"msg":"no, it's a graph","username":"jsmitchell","ts":"2019-02-20T18:12:08.076Z"}
{"msg":"and it's not validated like blocks or state","username":"jsmitchell","ts":"2019-02-20T18:12:24.182Z"}
{"msg":"we'd just check signatures to make sure that bad nodes aren't lying about the shape of the network","username":"jsmitchell","ts":"2019-02-20T18:12:43.312Z"}
{"msg":"when you receive a message from a peer, you'd look at the current shape of the network and determine the likelihood that your peers would already be receiving the message via an alternate path","username":"jsmitchell","ts":"2019-02-20T18:13:29.259Z"}
{"msg":"in a fully connected network, this would always be a 100% probability","username":"jsmitchell","ts":"2019-02-20T18:13:43.597Z"}
{"msg":"so, above some threshold, say 90%, you would not retransmit","username":"jsmitchell","ts":"2019-02-20T18:13:59.892Z"}
{"msg":"Ok, that would be too frequent I guess. For example in raft we'll end up having more node discovery messages along with consensus heartbeat messages.","username":"arsulegai","ts":"2019-02-20T18:14:04.946Z"}
{"msg":"well, you could decide the frequency of the topology annoucements","username":"jsmitchell","ts":"2019-02-20T18:14:23.687Z"}
{"msg":"It needs careful modelling","username":"arsulegai","ts":"2019-02-20T18:14:28.936Z"}
{"msg":"Yeah","username":"arsulegai","ts":"2019-02-20T18:14:30.466Z"}
{"msg":"yes, it's complex","username":"jsmitchell","ts":"2019-02-20T18:14:34.142Z"}
{"msg":"@amundson @ltseeley @pschwarz ^","username":"jsmitchell","ts":"2019-02-20T18:15:50.499Z"}
{"msg":"@jsmitchell is this a use case that's actually been discussed before?","username":"ltseeley","ts":"2019-02-20T18:17:18.009Z"}
{"msg":"in broad generalities","username":"jsmitchell","ts":"2019-02-20T18:17:27.100Z"}
{"msg":"the behavior of the gossip layer is far from ideal, currently","username":"jsmitchell","ts":"2019-02-20T18:18:00.059Z"}
{"msg":"we have certainly discussed stochastic broadcast before","username":"jsmitchell","ts":"2019-02-20T18:18:13.006Z"}
{"msg":"LIke is there some barrier that would prevent a consortium from setting up a realiably fully peered network?","username":"ltseeley","ts":"2019-02-20T18:18:29.737Z"}
{"msg":"Like is there some barrier that would prevent a consortium from setting up a realiably fully peered network?","username":"ltseeley","ts":"2019-02-20T18:18:29.737Z"}
{"msg":"this represents more of a complete soultion to the problem","username":"jsmitchell","ts":"2019-02-20T18:18:38.253Z"}
{"msg":"@ltseeley like firewalls? sure","username":"jsmitchell","ts":"2019-02-20T18:18:53.807Z"}
{"msg":"there are going to be static intentional barriers (like firewall settings), and dynamic unintentional barriers (like nodes going offline, network segmentation, etc)","username":"jsmitchell","ts":"2019-02-20T18:19:45.495Z"}
{"msg":"it would be really keen if the design of the gossip piece properly took those things into consideration and behaved optimally","username":"jsmitchell","ts":"2019-02-20T18:20:33.697Z"}
{"msg":"i.e. for a fully connected network, recognize that the chance of delivery is 100% and not rebroadcast, but for a 'linked list' connectivity, the need is to rebroadcast 100% of the time","username":"jsmitchell","ts":"2019-02-20T18:21:28.675Z"}
{"msg":"because the node recognizes that its rebroadcast is the _only_ way this peer is going to receive the message","username":"jsmitchell","ts":"2019-02-20T18:21:54.733Z"}
{"msg":"Well if a consortium is going to setup a network running PBFT, for instance, is there a reason they wouldn't be willing to configure the firewall to allow communication with all the other nodes? Is there some other factor that would prevent them from wanting to connect to some other organization's node(s)? And the \"dynamic unintentional barriers\" are supposed to be solved by the algorithm to some extent (Raft has CFT when up to 1/2 nodes are unavailable, PBFT when 1/3 are unavailable).","username":"ltseeley","ts":"2019-02-20T18:24:01.822Z"}
{"msg":"this is more a discussion about gossip doing the right thing than consensus","username":"jsmitchell","ts":"2019-02-20T18:24:35.022Z"}
{"msg":"consensus kind of runs as a virtual layer on top of the gossip network","username":"jsmitchell","ts":"2019-02-20T18:24:55.236Z"}
{"msg":"it is more efficient if it is fully connected","username":"jsmitchell","ts":"2019-02-20T18:25:04.877Z"}
{"msg":"but, that is not a hard and fast requirement","username":"jsmitchell","ts":"2019-02-20T18:25:10.734Z"}
{"msg":"GOt it","username":"ltseeley","ts":"2019-02-20T18:25:31.150Z"}
{"msg":"Got it","username":"ltseeley","ts":"2019-02-20T18:25:31.150Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=fvDDvFWjSas2WePJo) So the problem was self-created in the end.  We disabled the lint related steps for the moment, in particular for sawtooth-poet.  Which in there has an explicit build of poet-common (not installed) which the unit tests use.  Caught us by surprise.  So our fault, but I'm not in love with how tangled the builds, and build steps are. Just sayin' :grin: ","username":"kodonnel","ts":"2019-02-20T18:30:40.773Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=fvDDvFWjSas2WePJo","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=fvDDvFWjSas2WePJo","remote":true,"fileId":null,"fileName":null}]}
{"msg":"@rbuysse ^","username":"jsmitchell","ts":"2019-02-20T18:32:37.129Z"}
{"msg":"So it sounds like a non-relaying broadcast call on the consensus API and consensus hints would both be incomplete solutions, because neither really take into consideration the actually topology of the network (they assume that the actual topology matches the expected topology). Am I understanding that correctly?","username":"ltseeley","ts":"2019-02-20T18:41:15.822Z"}
{"msg":"yes","username":"jsmitchell","ts":"2019-02-20T18:44:59.938Z"}
{"msg":"@amundson @pschwarz thoughts on above discussion?","username":"jsmitchell","ts":"2019-02-20T22:32:56.026Z"}
{"msg":"a lot of that makes sense, in that you are suggesting the network layer should be good enough that consensus shouldn't need to worry about it","username":"amundson","ts":"2019-02-21T00:17:04.214Z"}
{"msg":"but, I wonder if it's odd that we are doing any gossip activity at all with PBFT/Raft","username":"amundson","ts":"2019-02-21T00:17:33.587Z"}
{"msg":"Well, the argument would be that we wouldn’t be doing any gossip on a fully-connected network. Whether we would allow PBFT/Raft to run on a temporarily or permanently non-fully connected network seems like a somewhat different question.","username":"jsmitchell","ts":"2019-02-21T00:48:45.388Z"}
{"msg":"But, it feels like something that can behave correctly in a fully connected case, and is resilient to temporary non fully connected states would be a nice benefit","username":"jsmitchell","ts":"2019-02-21T00:50:25.409Z"}
{"msg":"@jsmitchell @amundson @ltseeley @pschwarz Can we have a temporary solution (eg: sawtooth settings ) introduced to avoid gossip message rebroadcast for a fully connected network like Raft. In case of Raft we observer queue full issue and batch rejections when we increased the TPS to 10 on a 5 node network. But with gossip msg rebroadcast disabled we are able to run with 10 TPS for more than 24 hours and its still running without any batch rejections. We are yet to verify the max TPS supported in Raft with gossip rebroadcast disabled.  Meanwhile if you have some suggestions to improve the TPS for Raft let me know. ","username":"manojgop","ts":"2019-02-21T10:57:39.042Z"}
{"msg":"@jsmitchell @amundson @ltseeley @pschwarz Can we have a temporary solution (eg: sawtooth settings ) introduced to avoid gossip message rebroadcast for a fully connected network like Raft. In case of Raft we observe queue full issue and batch rejections when we increased the TPS to 10 on a 5 node network. But with gossip msg rebroadcast disabled we are able to run with 10 TPS for more than 24 hours and its still running without any batch rejections. We are yet to verify the max TPS supported in Raft with gossip rebroadcast disabled.  Meanwhile if you have some suggestions to improve the TPS for Raft let me know. ","username":"manojgop","ts":"2019-02-21T10:57:39.042Z"}
{"msg":"@jsmitchell @amundson @ltseeley @pschwarz Can we have a temporary solution (eg: sawtooth settings ) introduced to avoid gossip message rebroadcast for a fully connected network like Raft. In case of Raft we observe queue full issue and batch rejections when we increased the TPS to 10 on a 5 node network. But with gossip msg rebroadcast disabled we are able to run with 10 TPS for more than 24 hours and its still running without any batch rejections. I'm yet to verify the max TPS supported in Raft with gossip rebroadcast disabled.  Meanwhile if you have some suggestions to improve the TPS for Raft let me know. ","username":"manojgop","ts":"2019-02-21T10:57:39.042Z"}
{"msg":"I saw a setting \"sawtooth.gossip.time_to_live\" in gossip.py. Is it possible to set this to 0 to avoid gossip rebroadcast ?","username":"manojgop","ts":"2019-02-21T11:16:36.303Z"}
{"msg":"I saw a setting \"sawtooth.gossip.time_to_live\" in https://github.com/hyperledger/sawtooth-core/blob/1a1e7eb19c32d00bcadb49d5bdfac939c323d852/validator/sawtooth_validator/gossip/gossip.py#L272. Is it possible to set this to 0 to avoid gossip rebroadcast ?","username":"manojgop","ts":"2019-02-21T11:16:36.303Z"}
{"msg":"I saw a setting \"sawtooth.gossip.time_to_live\" in https://github.com/hyperledger/sawtooth-core/blob/1a1e7eb19c32d00bcadb49d5bdfac939c323d852/validator/sawtooth_validator/gossip/gossip.py#L272. \\\\ Is it possible to set this to 0 to avoid gossip rebroadcast ?","username":"manojgop","ts":"2019-02-21T11:16:36.303Z"}
{"msg":"I saw a setting \"sawtooth.gossip.time_to_live\" in https://github.com/hyperledger/sawtooth-core/blob/1a1e7eb19c32d00bcadb49d5bdfac939c323d852/validator/sawtooth_validator/gossip/gossip.py#L272. \\Is it possible to set this to 0 to avoid gossip rebroadcast ? \\","username":"manojgop","ts":"2019-02-21T11:16:36.303Z"}
{"msg":"I saw a setting \"sawtooth.gossip.time_to_live\" in https://github.com/hyperledger/sawtooth-core/blob/1a1e7eb19c32d00bcadb49d5bdfac939c323d852/validator/sawtooth_validator/gossip/gossip.py#L272. \\\\ Is it possible to set this to 0 to avoid gossip rebroadcast ? \\","username":"manojgop","ts":"2019-02-21T11:16:36.303Z"}
{"msg":"I saw a setting \"sawtooth.gossip.time_to_live\" in https://github.com/hyperledger/sawtooth-core/blob/1a1e7eb19c32d00bcadb49d5bdfac939c323d852/validator/sawtooth_validator/gossip/gossip.py#L272. \\newline Is it possible to set this to 0 to avoid gossip rebroadcast ? \\","username":"manojgop","ts":"2019-02-21T11:16:36.303Z"}
{"msg":"I saw a setting \"sawtooth.gossip.time_to_live\" in https://github.com/hyperledger/sawtooth-core/blob/1a1e7eb19c32d00bcadb49d5bdfac939c323d852/validator/sawtooth_validator/gossip/gossip.py#L272. \\newline Is it possible to set this to 0 to avoid gossip rebroadcast ? \\","username":"manojgop","ts":"2019-02-21T11:16:36.303Z"}
{"msg":"I saw a setting \"sawtooth.gossip.time_to_live\" in https://github.com/hyperledger/sawtooth-core/blob/1a1e7eb19c32d00bcadb49d5bdfac939c323d852/validator/sawtooth_validator/gossip/gossip.py#L272. _\\newline_ Is it possible to set this to 0 to avoid gossip rebroadcast ? \\","username":"manojgop","ts":"2019-02-21T11:16:36.303Z"}
{"msg":"I saw a setting \"sawtooth.gossip.time_to_live\" in https://github.com/hyperledger/sawtooth-core/blob/1a1e7eb19c32d00bcadb49d5bdfac939c323d852/validator/sawtooth_validator/gossip/gossip.py#L272. ```\n\n``` Is it possible to set this to 0 to avoid gossip rebroadcast ? ","username":"manojgop","ts":"2019-02-21T11:16:36.303Z"}
{"msg":"I saw a setting \"sawtooth.gossip.time_to_live\" in https://github.com/hyperledger/sawtooth-core/blob/1a1e7eb19c32d00bcadb49d5bdfac939c323d852/validator/sawtooth_validator/gossip/gossip.py#L272. \n\n Is it possible to set this to 0 to avoid gossip rebroadcast ? ","username":"manojgop","ts":"2019-02-21T11:16:36.303Z"}
{"msg":"I saw a setting \"sawtooth.gossip.time_to_live\" in https://github.com/hyperledger/sawtooth-core/blob/1a1e7eb19c32d00bcadb49d5bdfac939c323d852/validator/sawtooth_validator/gossip/gossip.py#L272. \n Is it possible to set this to 0 to avoid gossip rebroadcast ? ","username":"manojgop","ts":"2019-02-21T11:16:36.303Z"}
{"msg":"I don't think that's going to avoid it. You can comment out the broadcast handler for local testing. I doubt we would entertain a band-aid PR.","username":"jsmitchell","ts":"2019-02-21T16:17:51.295Z"}
{"msg":"But as per code it appears to be that setting this value to 1 or 0 would stop re-broadcast. What was the other reason to have this setting?","username":"arsulegai","ts":"2019-02-21T16:28:15.464Z"}
{"msg":"But as per code it appears to be that setting this value to a value lesser than or equal to 1 would stop re-broadcast. What was the other reason to have this setting?","username":"arsulegai","ts":"2019-02-21T16:28:15.464Z"}
{"msg":"i mean, go ahead and give it a try","username":"jsmitchell","ts":"2019-02-21T16:36:05.035Z"}
{"msg":"Yeah, in current run I've commented out block and batch re-broadcast. Gossip messages of consensus was just being notified to engine even though it's handled by broadcast handler, so didn't touch that part.","username":"arsulegai","ts":"2019-02-21T16:42:37.326Z"}
{"msg":"So, really, it sounds like we should be implementing a stochastic gossip layer, which","username":"pschwarz","ts":"2019-02-21T16:48:53.992Z"}
{"msg":"yeah, i raised that with @ltseeley, @arsulegai. The consensus message handling in there is totally inappropriate.","username":"jsmitchell","ts":"2019-02-21T16:49:13.427Z"}
{"msg":"There's a PR to update it. Can you take a look, @jsmitchell? https://github.com/hyperledger/sawtooth-core/pull/2019","username":"ltseeley","ts":"2019-02-21T16:49:45.864Z"}
{"msg":"@arsulegai @manojgop seems to me like setting TTL to 1 should do what we want it to. If you try it out, let me know how it goes.","username":"ltseeley","ts":"2019-02-21T16:52:42.689Z"}
{"msg":"What's the minimum number of nodes for Raft to behave in a sane way? 3? 2? 1?","username":"danintel","ts":"2019-02-21T16:53:39.935Z"}
{"msg":"iirc it should work with 1","username":"ltseeley","ts":"2019-02-21T16:54:44.149Z"}
{"msg":"Just elects itself","username":"ltseeley","ts":"2019-02-21T16:55:07.245Z"}
{"msg":"left a couple of comments @ltseeley ","username":"jsmitchell","ts":"2019-02-21T16:55:11.256Z"}
{"msg":"Responded","username":"ltseeley","ts":"2019-02-21T17:09:08.457Z"}
{"msg":"Can someone please explain how blockpublisher is selected? How candidate blocks are composed? Thanks","username":"neewy","ts":"2019-02-25T11:03:05.021Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=G76PfvnWnQ7T3ZvaW) @ltseeley It doesn't work. Probably @jsmitchell had foreseen this. Consensus messages will get ignored even with fully connected network. Your pending PR needs to go in, let's plan for it. Immediate next step could be to bring in separate message type for consensus gossip broadcasting, so that priority can be set when processing them.","username":"arsulegai","ts":"2019-02-25T13:29:56.640Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=G76PfvnWnQ7T3ZvaW","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=G76PfvnWnQ7T3ZvaW","remote":true,"fileId":null,"fileName":null}]}
{"msg":"@neewy I didn't understand what you mean by how block publisher is selected. Candidate block is composed when consensus engine requests validator node to create the block.","username":"arsulegai","ts":"2019-02-25T13:31:42.690Z"}
{"msg":"@arsulegai did you try setting it to 1, or 0? ","username":"ltseeley","ts":"2019-02-25T14:10:18.863Z"}
{"msg":"In either case, consensus message isn't passed to consensus engine","username":"arsulegai","ts":"2019-02-25T14:19:11.880Z"}
{"msg":"Ah yes, I see. With that PR, it should work.","username":"ltseeley","ts":"2019-02-25T15:05:13.536Z"}
{"msg":"PR looks ok to me - aim is to have separate handler, other discussions in that review can be in their own PRs.","username":"arsulegai","ts":"2019-02-25T16:25:18.253Z"}
{"msg":"Has joined the channel.","username":"cliveb","ts":"2019-02-25T18:35:46.785Z","type":"uj"}
{"msg":"Has joined the channel.","username":"rjones","ts":"2019-02-25T19:22:10.250Z","type":"uj"}
{"msg":"Hi! The internship program has been extended a week, and we don't have any Sawtooth applications. If you want some free-ish developers: https://wiki.hyperledger.org/display/INTERN/2019+Projects","username":"rjones","ts":"2019-02-25T19:23:00.141Z"}
{"msg":"Hello, \nI am curious about this block of code in `SyncBlockPublisher.on_chain_updated`: https://github.com/hyperledger/sawtooth-core/blob/c65462ea57e07671d5eb217fb3fa5a68057ed18d/validator/src/journal/publisher.rs#L185-L189 \n\n","username":"agoops","ts":"2019-02-26T00:06:45.176Z"}
{"msg":"Hello,\nI am curious about this block of code in `SyncBlockPublisher.on_chain_updated`: https://github.com/hyperledger/sawtooth-core/blob/c65462ea57e07671d5eb217fb3fa5a68057ed18d/validator/src/journal/publisher.rs#L185-L189\nIt seems that it checks if there was a `candidate_block` already being built, then it cancels that block, and calls `self.initialize_block` to begin building a new candidate_block. However, it builds this \"new\" candidate block off of the same `previous_block_id` that the deleted candidate_block was being built off of. \nWhy is this the case?\nI would assume that since `on_chain_updated` is called with a `chain_head`, any subsequent building of candidate_blocks should be *off the new chain_head*. \nAny help in understanding this piece would be greatly appreciated.\n","username":"agoops","ts":"2019-02-26T00:10:48.619Z"}
{"msg":"Hello,\nI am curious about this block of code in `SyncBlockPublisher.on_chain_updated`: https://github.com/hyperledger/sawtooth-core/blob/c65462ea57e07671d5eb217fb3fa5a68057ed18d/validator/src/journal/publisher.rs#L185-L189\nIt seems that it checks if there was a `candidate_block` already being built, then it cancels that block, and calls `self.initialize_block` to begin building a new candidate_block. However, it builds this \"new\" candidate block off of the same `previous_block_id` that the deleted candidate_block was being built off of. \nWhy is this the case?\nI would assume that since `on_chain_updated` is called with a `chain_head`, any subsequent building of candidate_blocks should be *off the new chain_head*. \nAny help in understanding this piece, and why it isn't built off the given chain_head, would be greatly appreciated.\n","username":"agoops","ts":"2019-02-26T00:10:48.619Z"}
{"msg":"Hello,\nI am curious about this block of code in `SyncBlockPublisher.on_chain_updated`: https://github.com/hyperledger/sawtooth-core/blob/c65462ea57e07671d5eb217fb3fa5a68057ed18d/validator/src/journal/publisher.rs#L185-L189\nIt seems that it checks if there was a `candidate_block` already being built, then it cancels that block, and calls `self.initialize_block` to begin building a new candidate_block. However, it builds this \"new\" candidate block off of the same `previous_block_id` that the deleted candidate_block was being built off of. \nWhy is this the case?\nI would assume that since `on_chain_updated` is called with a `chain_head`, any subsequent building of candidate_blocks should be *off the new chain_head*. \nAny help in understanding this piece, and why it isn't built off the given chain_head, would be greatly appreciated.\n","username":"agoops","ts":"2019-02-26T00:10:48.619Z"}
{"msg":"Hello,\nI am interested in learning about how blocks become committed in sawtooth-core, and how that affects the building of a new candidate block. I had a handful of questions, which I hope I could get some help with!\nI am curious about this block of code in `SyncBlockPublisher.on_chain_updated`: https://github.com/hyperledger/sawtooth-core/blob/c65462ea57e07671d5eb217fb3fa5a68057ed18d/validator/src/journal/publisher.rs#L185-L189\nIt seems that it checks if there was a `candidate_block` already being built, then it cancels that block, and calls `self.initialize_block` to begin building a new candidate_block. However, it builds this \"new\" candidate block off of the same `previous_block_id` that the deleted candidate_block was being built off of. \nWhy is this the case?\nI would assume that since `on_chain_updated` is called with a `chain_head`, any subsequent building of candidate_blocks should be off the new chain_head. \nAre there reasons that a validator may keep building off of the previous block like that? \nAny help in understanding this piece would be greatly appreciated!\n","username":"agoops","ts":"2019-02-26T00:10:48.619Z"}
{"msg":"Has joined the channel.","username":"Lotus","ts":"2019-02-26T14:57:57.592Z","type":"uj"}
{"msg":"@amundson @mfford I am interested in sawtooth-core contributor meetings, could you please let us know when are we planning for it?","username":"arsulegai","ts":"2019-02-27T03:10:20.311Z"}
{"msg":"@arsulegai Thanks for checking in on this. We will communicate scheduling details to the whole community once they are firm, so stay tuned!","username":"mfford","ts":"2019-02-27T15:35:40.839Z"}
{"msg":"Hi @jsmitchell , I am curious if you can point me in the right direction regarding my question^. Is there a better channel to post questions like this?","username":"agoops","ts":"2019-02-27T17:54:53.150Z"}
{"msg":"Has joined the channel.","username":"wkatsak","ts":"2019-02-28T18:24:22.852Z","type":"uj"}
{"msg":"Hello everyone","username":"wkatsak","ts":"2019-02-28T18:24:32.519Z"}
{"msg":"i'm finding myself in need of building debs for 1.1.4","username":"wkatsak","ts":"2019-02-28T18:24:43.536Z"}
{"msg":"(or, insert version here)","username":"wkatsak","ts":"2019-02-28T18:24:51.207Z"}
{"msg":"whats the quickest way to do this?","username":"wkatsak","ts":"2019-02-28T18:25:02.439Z"}
{"msg":"im looking at BUILD.md","username":"wkatsak","ts":"2019-02-28T18:25:14.936Z"}
{"msg":"but this is giving me a version mismatch error if i check out 1.1.4","username":"wkatsak","ts":"2019-02-28T18:25:24.152Z"}
{"msg":"Any help would be greatly appreciated","username":"wkatsak","ts":"2019-02-28T18:44:00.702Z"}
{"msg":"@wkatsak we recommend you use the published debs - any reason that isn't working for you?","username":"amundson","ts":"2019-02-28T18:59:32.082Z"}
{"msg":"@agoops huh, that does look a little weird. @pschwarz what do you think? (about one screen up)","username":"jsmitchell","ts":"2019-02-28T20:11:21.544Z"}
{"msg":"The main reason why it builds off the previously used `previous_block_id` is that the consensus engine explicitly tells the validator what block to build a new block on top of.  The commit message will most likely be paired with a cancel block message, but it still needs to handle the case where the publishing is in progress.  It cancels and restarts the block in order to remove any batches that may have been included in the committed block.","username":"pschwarz","ts":"2019-02-28T20:56:47.136Z"}
{"msg":"@amundson we need to make some small patches and want to be able to deploy to test, without doing packaging manually","username":"wkatsak","ts":"2019-02-28T21:21:40.128Z"}
{"msg":"@amundson In particular, ZMQ disables ipv6 support by default. I think we've found a workaround, but we need to patch.","username":"wkatsak","ts":"2019-02-28T21:22:06.101Z"}
{"msg":"@rbuysse ^","username":"amundson","ts":"2019-02-28T21:39:02.642Z"}
{"msg":"@wkatsak Can you post the exact error you're getting?","username":"rbuysse","ts":"2019-02-28T21:40:19.242Z"}
{"msg":"I was running `docker build -f validator/Dockerfile-installed .`","username":"wkatsak","ts":"2019-02-28T21:42:16.070Z"}
{"msg":"\"VERSION file and (bumped?) git describe versions differ:\"","username":"wkatsak","ts":"2019-02-28T21:44:11.006Z"}
{"msg":"what do you see if you run `git tag`","username":"rbuysse","ts":"2019-02-28T21:45:40.556Z"}
{"msg":"`v0.6.0\nv0.6.1\nv0.7.0\nv0.7.1\nv0.8.0\nv0.8.1\nv0.8.10\nv0.8.11\nv0.8.12\nv0.8.13\nv0.8.2\nv0.8.3\nv0.8.4\nv0.8.5\nv0.8.6\nv0.8.7\nv0.8.8\nv0.8.9\nv0.9.0\nv1.0.0\nv1.0.0rc1\nv1.0.0rc2\nv1.0.0rc3\nv1.0.0rc4\nv1.0.0rc5\nv1.0.0rc6\nv1.0.0rc7\nv1.0.1\nv1.0.2\nv1.0.3\nv1.0.4\nv1.0.5\nv1.1.0\nv1.1.1\nv1.1.2\nv1.1.3\nv1.1.4\nv1.2.0`","username":"wkatsak","ts":"2019-02-28T21:45:56.947Z"}
{"msg":"interestingly, i was futzing with my forked branch, and now i can't reproduce it","username":"wkatsak","ts":"2019-02-28T21:46:20.989Z"}
{"msg":"lol","username":"wkatsak","ts":"2019-02-28T21:46:21.521Z"}
{"msg":"maybe you can explain how the build works.    what does the VERSION envvar passed to that container do?","username":"wkatsak","ts":"2019-02-28T21:46:37.902Z"}
{"msg":"is that just for tagging?","username":"wkatsak","ts":"2019-02-28T21:46:43.059Z"}
{"msg":"or does it check out the code at some tag or branch?","username":"wkatsak","ts":"2019-02-28T21:46:50.028Z"}
{"msg":"that's just for versioning the build artifacts","username":"rbuysse","ts":"2019-02-28T21:47:26.844Z"}
{"msg":"so, it will build whatever is checked out?","username":"wkatsak","ts":"2019-02-28T21:47:57.196Z"}
{"msg":"the dockerfile runs ./bin/get_version so the .debs can be versioned properly","username":"rbuysse","ts":"2019-02-28T21:48:01.408Z"}
{"msg":"yeah","username":"rbuysse","ts":"2019-02-28T21:48:03.427Z"}
{"msg":"ah ok, thanks, that helps","username":"wkatsak","ts":"2019-02-28T21:50:01.724Z"}
{"msg":"and then, you just extract the debs from the container image?","username":"wkatsak","ts":"2019-02-28T21:50:11.166Z"}
{"msg":"from sawtooth-core/ run `docker-compose -f docker-compose-installed.yaml build validator`","username":"rbuysse","ts":"2019-02-28T21:50:52.682Z"}
{"msg":"would be nice if that was a little more flexible actually.  the AUTO_STRICT deep down in there can be a bit of a pain, don't get me wrong I like it over all  ","username":"kodonnel","ts":"2019-02-28T21:51:28.543Z"}
{"msg":"then run `docker-compose -f docker/compose/copy-debs.yaml up validator`","username":"rbuysse","ts":"2019-02-28T21:51:49.635Z"}
{"msg":"@kodonnel we've been talking about ways to improve it","username":"rbuysse","ts":"2019-02-28T21:52:44.597Z"}
{"msg":"don't know if I have any better ideas, really, but I've been bitten by it in the past alot.  ","username":"kodonnel","ts":"2019-02-28T21:53:16.493Z"}
{"msg":"@wkatsak after you run copy-debs, your deb file will be in build/debs","username":"rbuysse","ts":"2019-02-28T21:53:46.939Z"}
{"msg":"who runs copy-debs?","username":"wkatsak","ts":"2019-02-28T22:02:15.684Z"}
{"msg":"i can run inside the container?","username":"wkatsak","ts":"2019-02-28T22:02:21.732Z"}
{"msg":"@rbuysse only ideas I've had on it, aren't particularly compatible with the rust/cargo semantic versioning which is fairly strict.  It's all pretty smooth if you are working at the leading version, but if you experimenting with HEAD-1 then it gets tricky.  Actually not tricky so much as you find out you made the mistake an hour after you made it. an early cheap gating check before the heart of the build would probably go a long way reduce frustration a bit, and a little guide maybe","username":"kodonnel","ts":"2019-02-28T22:14:23.142Z"}
{"msg":"@rbuysse Whats the right way to run copy-debs?","username":"wkatsak","ts":"2019-02-28T22:24:58.910Z"}
{"msg":"@rbuysse Sorry, my mind glossed over what you copy-pasted","username":"wkatsak","ts":"2019-02-28T23:53:44.668Z"}
{"msg":"looks like i got it working","username":"wkatsak","ts":"2019-02-28T23:53:48.508Z"}
{"msg":"awesome!","username":"rbuysse","ts":"2019-02-28T23:58:27.954Z"}
{"msg":"We are trying to patch to enable IPv6","username":"wkatsak","ts":"2019-03-01T00:00:25.312Z"}
{"msg":"we have a pure v6 testnet","username":"wkatsak","ts":"2019-03-01T00:00:30.078Z"}
{"msg":"I don't think there is any fundamental problem, just some \"bad\" assumptions made in certain places","username":"wkatsak","ts":"2019-03-01T00:01:06.211Z"}
{"msg":"@wkatsak cool","username":"amundson","ts":"2019-03-01T14:30:03.446Z"}
{"msg":"@wkatsak What did you have to do to enable IPv6? Patch and rebuild ZMQ? Or was it some simpler?","username":"danintel","ts":"2019-03-01T16:23:56.207Z"}
{"msg":"@danintel We are still working on bringing it up, but so far I've patched the validator socket setup to call setsockopts with the ZMQ ipv6 flag","username":"wkatsak","ts":"2019-03-01T19:05:35.619Z"}
{"msg":"@danintel and in the rest API, the code that parses the config breaks on an address like [::]","username":"wkatsak","ts":"2019-03-01T19:05:58.282Z"}
{"msg":"we patched that as well","username":"wkatsak","ts":"2019-03-01T19:06:02.491Z"}
{"msg":"@wkatsak Maybe you can file a PR or at least a JIRA ticket with your exact changes when you are done.","username":"danintel","ts":"2019-03-01T19:08:41.251Z"}
{"msg":"Yes, once I have it all working, we will find some way to get it back","username":"wkatsak","ts":"2019-03-01T19:08:58.478Z"}
{"msg":"Has joined the channel.","username":"Quasso","ts":"2019-03-06T12:04:25.263Z","type":"uj"}
{"msg":"Looks like something has changed in the rustup-init script  `Removing intermediate container 8099f9266063\n ---> 46a362b29524\nStep 7/15 : RUN curl https://sh.rustup.rs -sSf > /usr/bin/rustup-init  && chmod +x /usr/bin/rustup-init  && rustup-init -y\n ---> Running in cc48bc90b286\n/usr/bin/rustup-init: line 18: RUSTUP_UPDATE_ROOT: unbound variable\nService 'validator' failed to build: The command '/bin/sh -c curl https://sh.rustup.rs -sSf > /usr/bin/rustup-init  && chmod +x /usr/bin/rustup-init  && rustup-init -y' returned a non-zero code: 1\nP`","username":"kodonnel","ts":"2019-03-06T15:01:30.668Z"}
{"msg":"Looks like something has changed in the rustup-init script  `Removing intermediate container 8099f9266063\n ---> 46a362b29524\nStep 7/15 : RUN curl https://sh.rustup.rs -sSf > /usr/bin/rustup-init  && chmod +x /usr/bin/rustup-init  && rustup-init -y\n ---> Running in cc48bc90b286\n/usr/bin/rustup-init: line 18: RUSTUP_UPDATE_ROOT: unbound variable\nService 'validator' failed to build: The command '/bin/sh -c curl https://sh.rustup.rs -sSf > /usr/bin/rustup-init  && chmod +x /usr/bin/rustup-init  && rustup-init -y' returned a non-zero code: 1\nP`","username":"kodonnel","ts":"2019-03-06T15:01:30.668Z"}
{"msg":"Looks like something has changed in the rustup-init script  ```\n\n``` `Removing intermediate container 8099f9266063\n ---> 46a362b29524\nStep 7/15 : RUN curl https://sh.rustup.rs -sSf > /usr/bin/rustup-init  && chmod +x /usr/bin/rustup-init  && rustup-init -y\n ---> Running in cc48bc90b286\n/usr/bin/rustup-init: line 18: RUSTUP_UPDATE_ROOT: unbound variable\nService 'validator' failed to build: The command '/bin/sh -c curl https://sh.rustup.rs -sSf > /usr/bin/rustup-init  && chmod +x /usr/bin/rustup-init  && rustup-init -y' returned a non-zero code: 1\nP`","username":"kodonnel","ts":"2019-03-06T15:01:30.668Z"}
{"msg":"Looks like something has changed in the rustup-init script  ```\n\n Removing intermediate container 8099f9266063\n ---> 46a362b29524\nStep 7/15 : RUN curl https://sh.rustup.rs -sSf > /usr/bin/rustup-init  && chmod +x /usr/bin/rustup-init  && rustup-init -y\n ---> Running in cc48bc90b286\n/usr/bin/rustup-init: line 18: RUSTUP_UPDATE_ROOT: unbound variable\nService 'validator' failed to build: The command '/bin/sh -c curl https://sh.rustup.rs -sSf > /usr/bin/rustup-init  && chmod +x /usr/bin/rustup-init  && rustup-init -y' returned a non-zero code: 1\n ```","username":"kodonnel","ts":"2019-03-06T15:01:30.668Z"}
{"msg":"getting that in several of the project builds today","username":"kodonnel","ts":"2019-03-06T15:03:00.478Z"}
{"msg":"weird, I don't see why that error should occur based on the script, also don't see how any of last nights rustup changes should cause that.","username":"kodonnel","ts":"2019-03-06T15:12:10.955Z"}
{"msg":"oh i see it now","username":"kodonnel","ts":"2019-03-06T15:13:40.865Z"}
{"msg":"https://github.com/rust-lang/rustup.rs/issues/1684","username":"kodonnel","ts":"2019-03-06T15:21:17.679Z"}
{"msg":"Has joined the channel.","username":"satelander","ts":"2019-03-06T15:21:50.418Z","type":"uj"}
{"msg":"@kodonnel Thanks for looking into this, we were just trying to figure out what was happening as well. ","username":"agunde","ts":"2019-03-06T15:24:24.959Z"}
{"msg":"There is a PR up to fix it now https://github.com/rust-lang/rustup.rs/pull/1683/files","username":"agunde","ts":"2019-03-06T15:25:31.650Z"}
{"msg":"there's an interim fix up and live now.  ","username":"kodonnel","ts":"2019-03-06T15:42:39.015Z"}
{"msg":"Has joined the channel.","username":"pankajcheema","ts":"2019-03-07T05:50:14.378Z","type":"uj"}
{"msg":"Has joined the channel.","username":"Keegan-Lee","ts":"2019-03-07T19:48:16.133Z","type":"uj"}
{"msg":"Has left the channel.","username":"rohitkhatri","ts":"2019-03-08T10:46:39.692Z","type":"ul"}
{"msg":"Has joined the channel.","username":"MarcVauclairNXP","ts":"2019-03-12T13:59:03.607Z","type":"uj"}
{"msg":"Hello, does anyone know how to reach the Hyperledger Sawtooth documentation maintainer? Goal: reporting improvements to the documentation","username":"MarcVauclairNXP","ts":"2019-03-12T13:59:19.746Z"}
{"msg":"^ @achenette ","username":"arsulegai","ts":"2019-03-12T15:01:51.244Z"}
{"msg":"Thanks, arsulegai!  @MarcVauclairNXP - I work on the documentation for Hyperledger Sawtooth (and other projects). I would be happy to see your suggestions, in this channel or #sawtooth or in a direct message.","username":"achenette","ts":"2019-03-12T15:05:06.435Z"}
{"msg":"Thank you both. I have send my suggestions in a direct message to you @achenette .","username":"MarcVauclairNXP","ts":"2019-03-12T15:14:24.426Z"}
{"msg":"Mic is looking for support on the identity whitepaper. Can someone familiar with Pike drop a line or two in there? https://docs.google.com/document/d/10D0WgbMV91YBPzKTutc5TNirDC1RRzB_8GSF84hv4l4/edit#","username":"Dan","ts":"2019-03-14T02:50:54.177Z"}
{"msg":"(search for Pike in the doc to take you to a place to put it.)","username":"Dan","ts":"2019-03-14T02:51:18.667Z"}
{"msg":"Ever seen such traces?\nvalidator-0: [32m[2019-03-14 15:21:45.659 INFO     interconnect][0m [37mNo response from OutboundConnectionThread-tcp://validator-1:8800 in 1552569580.1803834 seconds - removing connection.","username":"arsulegai","ts":"2019-03-15T15:12:16.110Z"}
{"msg":"Have you seen such traces?\nvalidator-0: [32m[2019-03-14 15:21:45.659 INFO     interconnect][0m [37mNo response from OutboundConnectionThread-tcp://validator-1:8800 in 1552569580.1803834 seconds - removing connection.","username":"arsulegai","ts":"2019-03-15T15:12:16.110Z"}
{"msg":"Interesting part is the time in seconds printed in the log","username":"arsulegai","ts":"2019-03-15T15:12:35.141Z"}
{"msg":"^ @danintel ","username":"arsulegai","ts":"2019-03-15T18:59:57.546Z"}
{"msg":"Has joined the channel.","username":"mgkm","ts":"2019-03-15T21:27:40.994Z","type":"uj"}
{"msg":"No I have not seen that error. It seems like a network connectivity issue, with garbage values in the error message.","username":"danintel","ts":"2019-03-15T23:29:58.646Z"}
{"msg":"Connection was removed in 2 sec. So I think variables getting garbage value is a problem","username":"arsulegai","ts":"2019-03-16T03:20:45.593Z"}
{"msg":"^ @pschwarz @agunde @ltseeley  Have you seen such cases? Can this be an issue?","username":"arsulegai","ts":"2019-03-17T04:57:10.719Z"}
{"msg":" Is there a Sawtooth contributors' meeting this week?","username":"amolk","ts":"2019-03-18T09:58:49.812Z"}
{"msg":"@arsulegai  I haven't seen that particular message. There might have been some incorrect math, by the look of it.  Perhaps the original time marked was lost (and therefore `0`).","username":"pschwarz","ts":"2019-03-18T13:25:27.165Z"}
{"msg":"Thanks @pschwarz the reason for this is unknown yet, it didn't appear again. But it looks to be serious if for some reason time value was marked as 0.","username":"arsulegai","ts":"2019-03-18T14:40:21.780Z"}
{"msg":"@jsmitchell @amundson There was a discussion on periodic execution pending batches and rebroadcast, if batches for some reason do not get added to a block even after waiting for long. Do you consider this a feature going in for the next Sawtooth 1.2 release?","username":"arsulegai","ts":"2019-03-18T15:16:17.051Z"}
{"msg":"@amolk next week I think - today was the Grid contributor meeting","username":"amundson","ts":"2019-03-18T15:48:40.320Z"}
{"msg":"@arsulegai As long as it is stable w/PBFT and we do not have any obvious regressions, I think we should proceed with the release. Currently we know there are some regressions that need to be address (re: PoET liveness tests).","username":"amundson","ts":"2019-03-18T15:57:54.356Z"}
{"msg":"We could pick a feature  cut-off date, say the end of the month, to get in any new features.","username":"amundson","ts":"2019-03-18T15:58:36.504Z"}
{"msg":"@amolk The HL Sawtooth Contributor Meeting was just added to the HL Community Calendar for Monday, March 25th: https://wiki.hyperledger.org/display/HYP/Calendar+of+Public+Meetings","username":"mfford","ts":"2019-03-18T16:11:15.493Z"}
{"msg":"Thanks @amundson , there are few other issues in validator such as instability of validator connections due to \"maximum-peer-connectivity\"","username":"arsulegai","ts":"2019-03-19T14:32:15.836Z"}
{"msg":"Solving them could be beneficial for PBFT as well","username":"arsulegai","ts":"2019-03-19T14:32:43.826Z"}
{"msg":"@arsulegai Are you suggesting that there is a regression since 1.1 for that?","username":"amundson","ts":"2019-03-19T14:36:12.545Z"}
{"msg":"I don't know if it's in 1.1 as well, at least I find that issue in latest master","username":"arsulegai","ts":"2019-03-19T15:47:03.728Z"}
{"msg":"The poet2 master branch has lint errors because of a change in pylint.","username":"amundson","ts":"2019-03-19T17:09:56.792Z"}
{"msg":"Has joined the channel.","username":"Nonj","ts":"2019-03-21T17:18:21.559Z","type":"uj"}
{"msg":"Hi folks, I'm currently on the sawtooth/NEXT project and we are looking to upgrade our sawtooth_sdk to version 1.1.4 from 1.0.5. The issue I'm currently running into is that I see that the protobuf package in 1.1.4 got replaced by a package called \"consensus\" in 1.0.5. Can anyone confirm that? Or am I missing something crucial?","username":"Nonj","ts":"2019-03-21T17:20:50.434Z"}
{"msg":"@nonj when you say 'package', do you mean in terms of python or ubuntu?","username":"amundson","ts":"2019-03-21T19:09:07.136Z"}
{"msg":"@Nonj  when you say 'package', do you mean in terms of python or ubuntu?","username":"amundson","ts":"2019-03-21T19:09:07.136Z"}
{"msg":"sorry, python","username":"Nonj","ts":"2019-03-21T19:32:27.642Z"}
{"msg":"I also just checked, the python package seems to come with sawtooth_sdk in v1.1.3","username":"Nonj","ts":"2019-03-21T21:39:07.251Z"}
{"msg":"We need to solve this proxy support another way than putting it within the Dockerfiles, or drop support for proxies. An ideal solution would require no support within a Dockerfile. Maybe folks behind a proxy should just use VMs instead of docker. Thoughts?","username":"amundson","ts":"2019-03-22T03:56:35.959Z"}
{"msg":"@Nonj it may not be intentional. will require some research.","username":"amundson","ts":"2019-03-22T03:58:49.057Z"}
{"msg":"Has left the channel.","username":"st","ts":"2019-03-22T08:39:23.356Z","type":"ul"}
{"msg":"Another reminder that our first Hyperledger Sawtooth Contributor Meeting is Monday, March 25th at 10am CDT. \n\nThe meeting information can be found on the Hyperledger Community Meetings Calendar located here: https://wiki.hyperledger.org/display/HYP/Calendar+of+Public+Meetings\n\nYou can still add topics to the agenda for this meeting. If you have an appropriate topic you would like to discuss and facilitate, please add it to the agenda, located in \nthe wiki here: https://wiki.hyperledger.org/pages/viewpage.action?pageId=6427754\n\nLooking forward to seeing everyone at our first meeting!\n-Mark","username":"mfford","ts":"2019-03-22T14:13:26.915Z"}
{"msg":"Have we considered moving the basic protobuf definitions out of the SDK packages?  Seems like having copies of that all over the various repositories is asking for trouble.","username":"kodonnel","ts":"2019-03-26T14:38:01.164Z"}
{"msg":"@kodonnel the separation is intentional. the contract between the components is the serialized format, not the proto definition. if we rename or add something to the proto definition in core, the SDKs and ohter components can adopt it on their own timeline (often requiring code changes and/or support for the updates).","username":"amundson","ts":"2019-03-26T18:46:17.082Z"}
{"msg":"that said, I think we need to remove use of the protobuf objects from our APIs entirely so it's not leaking out (and so that we can provide better (more natural) APIs than the protobuf APIs provide)","username":"amundson","ts":"2019-03-26T18:47:44.466Z"}
{"msg":"in other words, make it an implementation detail","username":"amundson","ts":"2019-03-26T18:47:59.374Z"}
{"msg":"I'd second that last.  But to your point about serialized format not proto - is the format formally defined/documented anywhere apart from the protobufs? ","username":"kodonnel","ts":"2019-03-26T18:52:01.156Z"}
{"msg":"the protobufs are a formal definition. the serialization format is defined by protobuf.","username":"amundson","ts":"2019-03-26T18:53:50.593Z"}
{"msg":"OK so then that's legal splitting hairs then.  Still seems like it would be not a terrible idea to split that definition out.  I get the individual sdk's and what have you should be free to move along that timeline according to their schedule.  But you've effectively got a dependency there which isn't explicit, since it is just expressed by whether or not the most recent protobufs were copied into source or not. Maybe not \"just\" but significantly.","username":"kodonnel","ts":"2019-03-26T18:58:33.150Z"}
{"msg":"OK so then that's legal splitting hairs then.:)  Still seems like it would be not a terrible idea to split that definition out.  I get the individual sdk's and what have you should be free to move along that timeline according to their schedule.  But you've effectively got a dependency there which isn't explicit, since it is just expressed by whether or not the most recent protobufs were copied into source or not. Maybe not \"just\" but significantly.","username":"kodonnel","ts":"2019-03-26T18:58:33.150Z"}
{"msg":"I'm not sure what you are suggesting in a concrete form. Maybe pick a small subset and create the definition you have in mind.","username":"amundson","ts":"2019-03-26T19:06:43.396Z"}
{"msg":"what I'm thinking about is not custom TP's or any TP specific protobufs, but the core protos (CLIENT_BATCH_*, CONSENSUS_*, TP_*, etc ).  So what's in, for example : https://github.com/hyperledger/sawtooth-core/tree/master/protos, https://github.com/hyperledger/sawtooth-sdk-java/tree/master/protos, https://github.com/hyperledger/sawtooth-sdk-rust/tree/master/protos, et al.  The latter two are copies of the first (at some point in time).  Wouldn't it be better and more explicit if the protos were split out and maintained separately?  and then tagged versions pulled in by the SDK's at build time.  Otherwise seems like there is a an opening there to get unintentional drift.  ","username":"kodonnel","ts":"2019-03-26T19:20:45.534Z"}
{"msg":"It's a theoretical problem, I'll grant you.  But I've seen stuff go haywire like that before.","username":"kodonnel","ts":"2019-03-26T19:21:57.880Z"}
{"msg":"Topic: Discussion on how to handle pending batches queue","username":"arsulegai","ts":"2019-03-26T19:46:31.564Z"}
{"msg":"We've discussed few solutions where we talked about re-broadcasting pending transactions to other validators if it's waiting for too long in the queue","username":"arsulegai","ts":"2019-03-26T19:47:59.289Z"}
{"msg":"@kodonnel no, for the reasons I said above","username":"amundson","ts":"2019-03-26T19:48:11.562Z"}
{"msg":"And probably execute it once, before re-broadcasting to other nodes","username":"arsulegai","ts":"2019-03-26T19:48:24.584Z"}
{"msg":"How about another proposal where all batches including the failed ones be part of block getting constructed?","username":"arsulegai","ts":"2019-03-26T19:49:28.268Z"}
{"msg":"Another option would be to expire it and let the client re-submit","username":"amundson","ts":"2019-03-26T19:49:40.047Z"}
{"msg":"But problem with such approaches is that each validator has it's own timer to expire, from client's point of view it's difficult to know which of the validator to trust","username":"arsulegai","ts":"2019-03-26T19:50:47.862Z"}
{"msg":"I don't see how the validator vs. client resubmitting changes that trust.","username":"amundson","ts":"2019-03-26T19:52:17.669Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=w6WREshp746hQzK9a) @amundson Perhaps I'm being thick, but I'm not seeing how that suggestion conflicts with the intent of those reasons.","username":"kodonnel","ts":"2019-03-26T19:53:11.811Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=w6WREshp746hQzK9a","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=w6WREshp746hQzK9a","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=w6WREshp746hQzK9a) @amundson Perhaps I'm being thick, but I'm not seeing how the suggestion conflicts with the intent of those reasons.","username":"kodonnel","ts":"2019-03-26T19:53:11.811Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=w6WREshp746hQzK9a","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=w6WREshp746hQzK9a","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Making failed transactions part of the block would allow for some additional denial of service attacks which we would then have to mitigate. Currently failed transactions increase CPU on the validator but don't cause additional network traffic.","username":"amundson","ts":"2019-03-26T19:54:23.091Z"}
{"msg":"Let's say one of the validator asked client to retry - but before the client could retry another validator committed it into the block.","username":"arsulegai","ts":"2019-03-26T19:55:32.870Z"}
{"msg":"@kodonnel the tagging would help mitigate it, but there is no point since avoiding the duplication is optimizing for problem that doesn't exist. the real problems we need to solve is reducing dependencies, not adding them.","username":"amundson","ts":"2019-03-26T19:56:18.739Z"}
{"msg":"it's already possible to pull those files from tagged versions of core, if you like","username":"amundson","ts":"2019-03-26T19:57:01.635Z"}
{"msg":"hmm! I agree in cases like PoET there will be increased network because each validator would have removed these invalid transactions from their queue. Probably there's a way to mitigate it by storing invalid transaction status in txn receipts?","username":"arsulegai","ts":"2019-03-26T19:57:24.915Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=tLEa9noq5Nqr5YH3K) @amundson Honestly that's actually more palatable than the way the SDK's keep copies in source.","username":"kodonnel","ts":"2019-03-26T19:58:03.025Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=tLEa9noq5Nqr5YH3K","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=tLEa9noq5Nqr5YH3K","remote":true,"fileId":null,"fileName":null}]}
{"msg":"there should be one source of truth for that serialization format.  ","username":"kodonnel","ts":"2019-03-26T19:58:58.002Z"}
{"msg":"@arsulegai well, it is a reasonable thing to send receipts along with the block, IMO. but I don't think we should do invalid receipts along with it. what problem are you trying to solve?","username":"amundson","ts":"2019-03-26T19:59:10.640Z"}
{"msg":"@kodonnel I'd probably agree if it didn't come with a huge downside of an additional dependency, making it completely undesirable in practice. The copies could contain a comment within indicating where they were copied from, if tracking it back is the problem. (Though, commit message may do this just as well.)","username":"amundson","ts":"2019-03-26T20:01:23.917Z"}
{"msg":"I am thinking of a case where we may need to scale the application and handle requests from multiple clients, from different locations, each of them connecting to different validators.","username":"arsulegai","ts":"2019-03-26T20:01:48.786Z"}
{"msg":"Let's consider cookiejar example,\nInitially: Cookies available  -  100\n(Following clients requests simultaneously)\nPerson 1 Eat: 70\nPerson 2 Eat: 25\nPerson 3 Eat 25\nPerson 4 Bake 25","username":"arsulegai","ts":"2019-03-26T20:03:52.637Z"}
{"msg":"@amundson The dependency is really there already, its just not explicit.","username":"kodonnel","ts":"2019-03-26T20:03:59.500Z"}
{"msg":"Person 1 through 4 are all connected to different validators, through different clients, they are not aware of each other","username":"arsulegai","ts":"2019-03-26T20:04:28.718Z"}
{"msg":"The transaction done by Person 3 purely depends on whether his/her request was considered before Person 4 or not.","username":"arsulegai","ts":"2019-03-26T20:05:21.446Z"}
{"msg":"@kodonnel by dependency I meant within the build system","username":"amundson","ts":"2019-03-26T20:10:18.221Z"}
{"msg":"@arsulegai is that the end of our example, or is there more?","username":"amundson","ts":"2019-03-26T20:11:05.286Z"}
{"msg":"@arsulegai is that the end of your example, or is there more?","username":"amundson","ts":"2019-03-26T20:11:05.286Z"}
{"msg":"It is end of my example, I am thinking of describing what would happen in this scenario case by case with each consensus engines we have","username":"arsulegai","ts":"2019-03-26T20:12:31.350Z"}
{"msg":"The problem would be same, without ordering the batches considered. Validator needs a way to communicate to other validators, the list of considered batches.","username":"arsulegai","ts":"2019-03-26T20:21:44.827Z"}
{"msg":"@arsulegai if person 3's txn is based on person 4's, they should wait until they have high confidence that person 4's txn is committed (which will vary based on consensus algo and questions of connectivity), and then submit their txn listing person 4's txn as a dependency.","username":"jsmitchell","ts":"2019-03-26T21:13:25.735Z"}
{"msg":"otherwise, the only thing the network guarantees is consistent ordering, state agreement, and validity/invalidity of transactions in that context","username":"jsmitchell","ts":"2019-03-26T21:14:37.728Z"}
{"msg":"the universe does not owe anyone a valid transaction","username":"jsmitchell","ts":"2019-03-26T21:14:51.123Z"}
{"msg":"Has left the channel.","username":"rjones","ts":"2019-03-26T21:43:18.558Z","type":"ul"}
{"msg":"Right, that's the problem I'm worrying about","username":"arsulegai","ts":"2019-03-26T21:54:38.637Z"}
{"msg":"If Person 3's transaction is rejected because Person 4's transaction has not reached yet, then it should be ok. This is debatable as long as it is consistently rejected in all the nodes.","username":"arsulegai","ts":"2019-03-26T21:56:01.955Z"}
{"msg":"However there shouldn't be a case that one node accepts it as valid and other node accepting as invalid.","username":"arsulegai","ts":"2019-03-26T21:56:30.895Z"}
{"msg":"Coming to DoS, we've permissioning and there's way to control it. I believe we can address this inconsistency without worrying about it.","username":"arsulegai","ts":"2019-03-26T21:59:04.566Z"}
{"msg":"@arsulegai if by \"accepts\" you mean it becoming part of the current chain, consensus is what handles that problem, in agreeing on the current head of the chain (which is a pointer to a block)","username":"amundson","ts":"2019-03-26T22:44:05.546Z"}
{"msg":"I feel like you might be solving for problems in a non-BFT manner because you are currently using Raft, while the solutions currently in place (and some additional features that have been suggested) are focused on solving these things in a BFT-compatible way. Or, just as likely, I am misinterpreting how you would expect the \"invalid transaction\" information to be consumed by the other nodes.","username":"amundson","ts":"2019-03-26T22:47:59.314Z"}
{"msg":"For removing invalid transactions, each node should run through and determine that they are invalid independently. I really think that it will be performant enough to do this periodically by running the pending queue through a scheduler on top of the current chain (independent of publishing cadence). I don't think you really gain much by sending hints from the leader on what is (potentially) invalid (and there are DoS issues with doing that).","username":"amundson","ts":"2019-03-26T22:58:39.626Z"}
{"msg":"Ah! Let's take the above example with Raft as consensus algorithm. The leader node rejects transaction and leadership changes to another node after executing Person 4's transaction.","username":"arsulegai","ts":"2019-03-27T03:26:51.406Z"}
{"msg":"Even with periodic cleaning of pending batches, we may not completely solve this inconsistency.","username":"arsulegai","ts":"2019-03-27T03:28:02.946Z"}
{"msg":"Person 3's transaction will get accepted this time. Even with periodic cleaning of pending batches, we may not completely solve this inconsistency.","username":"arsulegai","ts":"2019-03-27T03:28:02.946Z"}
{"msg":"A transaction which was rejected may be few moments ago is now accepted.","username":"arsulegai","ts":"2019-03-27T03:29:49.994Z"}
{"msg":"This is not only the issue with Raft, it's possible even in PoET or PBFT. Let's say there's limit of number of batches considered in a block. Person 4's transaction is before Person 3's transaction in validator 1. But in validator 2 it's reverse. Block from validator 1 thinks Person 3's transaction is valid, but block from validator 2 thinks Person 3's transaction is invalid.","username":"arsulegai","ts":"2019-03-27T03:33:19.064Z"}
{"msg":"If concern is about block processing/DoS, probably good time to bringing in state checkpoint feature?","username":"arsulegai","ts":"2019-03-27T10:02:16.944Z"}
{"msg":"Has joined the channel.","username":"duncanjw","ts":"2019-03-27T13:15:52.041Z","type":"uj"}
{"msg":"^ @amundson ","username":"arsulegai","ts":"2019-03-27T17:37:18.784Z"}
{"msg":"^ @amundson @jsmitchell ","username":"arsulegai","ts":"2019-03-27T17:37:18.784Z"}
{"msg":"How about one more exception introduced?\n1. Validator rejecting transaction which is not retried.\n2. TP rejecting transaction which is not retried.\n3. Invalid error which is retried.\n\nTransactions rejected for case 1 are not added to the block. But transactions rejected for case 2 are added to the block.","username":"arsulegai","ts":"2019-03-27T20:12:34.313Z"}
{"msg":"This will avoid DoS and help in letting other validators know list of transactions considered to build the block.","username":"arsulegai","ts":"2019-03-27T20:13:38.241Z"}
{"msg":"Why don’t you like the simpler approach of just processing the pending queue periodically?","username":"amundson","ts":"2019-03-27T21:42:29.264Z"}
{"msg":"Periodic cleanup will not solve the issue I'm talking about, we will not solve the issue of one validator rejecting a transaction and other validator accepting it later point in me.","username":"arsulegai","ts":"2019-03-28T06:32:26.972Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=RraQcEyrDQKZ89AQe) @jsmitchell Consistent ordering is not taken care of in case of invalid transactions!","username":"arsulegai","ts":"2019-03-28T07:10:11.685Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=RraQcEyrDQKZ89AQe","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=RraQcEyrDQKZ89AQe","remote":true,"fileId":null,"fileName":null}]}
{"msg":"If there are clients from multiple locations, connected to different validators and sending requests we do not have ordering!","username":"arsulegai","ts":"2019-03-28T07:10:47.227Z"}
{"msg":"But generally thinking for a Blockchain framework, this kind of distributed input scenario is common.","username":"arsulegai","ts":"2019-03-28T07:11:22.306Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=RhGtmfncdmXyhP8ku) @amundson No. The problem I discussed exists in all the consensus.","username":"arsulegai","ts":"2019-03-28T07:13:42.100Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=RhGtmfncdmXyhP8ku","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=RhGtmfncdmXyhP8ku","remote":true,"fileId":null,"fileName":null}]}
{"msg":"@arsulegai  has a point, I did a study on a bet system, and that issue arose. ","username":"LeonardoCarvalho","ts":"2019-03-28T10:17:36.041Z"}
{"msg":"I think it is completely unnecessary and irrelevant to order _invalid_ transactions.","username":"amundson","ts":"2019-03-28T13:09:34.995Z"}
{"msg":"invalid transactions result in no state transitions within the system, and thus are completely irrelevant for reconstructing state. The _only_ purpose of transactions, consensus, and TPs in Sawtooth is the generate agreement on the list of transactions which modify state.","username":"amundson","ts":"2019-03-28T13:11:50.021Z"}
{"msg":"TPs should also be stateless","username":"amundson","ts":"2019-03-28T13:16:34.113Z"}
{"msg":"furthermore, the only thing that makes a decision about transaction validity is the block publishing/validation process. The only place where a user would see a locally different answer (i.e. a transaction being considered valid by being included in a block and made the chain head) would be in a consensus which doesn't provide finality. Eventual consistent ordering at the network level is achieved at some level of confidence at a certain block depth. This is inherent in the design of the consensus algorithms and there is lots of literature on this. If you want to avoid this condition, use a consensus that provides finality guarantees and is well behaved wrt cliques.","username":"jsmitchell","ts":"2019-03-28T13:17:42.636Z"}
{"msg":"@arsulegai I'm trying to understand what is driving this desire. Do you have a TP that is stateful, and you are trying to run the exact sequence of transactions through it?","username":"amundson","ts":"2019-03-28T13:19:17.476Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=vc7HjscNQmNMr8RvH) The system is designed to provide global ordering of valid transactions. If you care about the ordering of invalid transactions, recast them as valid transactions and track your application level validity within state.","username":"jsmitchell","ts":"2019-03-28T13:20:44.693Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=vc7HjscNQmNMr8RvH","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=vc7HjscNQmNMr8RvH","remote":true,"fileId":null,"fileName":null}]}
{"msg":"It is important to understand that a 'invalid transaction: reason' answer from the validator you submitted a client transaction to is an answer 'local' to that validator and is only evaluated as part of block publishing. Before that happens, that transaction will already have been distributed to the network. At some point in the future, it may be considered valid and included in a block due to some other state change which makes it valid.","username":"jsmitchell","ts":"2019-03-28T13:48:13.611Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=HSpbJNirTnyDmRHtx) @amundson Yeah! I mean even in the case of Cookiejar example I told you it is stateful application. Result of request depends on the number of cookies available currently.","username":"arsulegai","ts":"2019-03-29T04:02:20.560Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=HSpbJNirTnyDmRHtx","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=HSpbJNirTnyDmRHtx","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=dGPHMWfPdHA3BtYjM) @jsmitchell The merkle tree may grow to large size. How about considering TP rejections separate from validator's rejections? Propagate TP rejected transactions in the block and let all other validators try.","username":"arsulegai","ts":"2019-03-29T04:04:59.819Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=dGPHMWfPdHA3BtYjM","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=dGPHMWfPdHA3BtYjM","remote":true,"fileId":null,"fileName":null}]}
{"msg":"@jsmitchell @amundson Looking through suggestions, I think you have understood the concern. There's a possibility as Mitchel mentioned to consider all invalid transactions as valid, store their status somewhere in global state. Wouldn't that be a workaround solution, that masks ordering issue of the block?","username":"arsulegai","ts":"2019-03-29T04:07:22.143Z"}
{"msg":"And as I explained earlier, this issue occurs with all the consensus engines we have. I'm open for your comments and suggestions.","username":"arsulegai","ts":"2019-03-29T04:09:19.351Z"}
{"msg":"Maybe a 2 phase validation mechanism ?","username":"LeonardoCarvalho","ts":"2019-03-29T10:26:19.114Z"}
{"msg":"@arsulegai a stateful application is not the same as a stateful TP. (All sawtooth apps are stateful, that's kind of the point.) A stateful TP would be one that stores state outside of the validator and attempts to predict validator behavior to manage it rather than implementing a clean state transition function. That is explicitly not supported or desirable. The order of transactions given to the TPs for processing is also not guarenteed to be the same as contained within a block, in the case of the parallel scheduler. There is also no guarentee a transaction will be executed only one time. Some of this can be mitigated by selection of consensus (finality helps a bit), or addition of explicit dependencies, but such an app design will always be sensitive to changes in the validator.","username":"amundson","ts":"2019-03-29T14:09:45.135Z"}
{"msg":"Ok, I'll take back the word ordering. I didn't understand the comment on stateful TP. The case I was talking about is where TP stores state in validator/global state.","username":"arsulegai","ts":"2019-03-29T19:28:05.596Z"}
{"msg":"TP executing transaction at arbitrary point in time is fine. But how do you comment that there should not be multiple result for single input?","username":"arsulegai","ts":"2019-03-29T19:33:59.082Z"}
{"msg":"TP executing transaction at arbitrary point in time is fine. But how do you comment for the question that there should not be multiple result for single input?","username":"arsulegai","ts":"2019-03-29T19:33:59.082Z"}
{"msg":"I see this issue even in PBFT. There's no consensus engine currently available, that addresses this issue. Looking at the problem statement, to me it is validator issue and not related to consensus engines.","username":"arsulegai","ts":"2019-03-29T19:38:30.304Z"}
{"msg":"@amundson ^","username":"arsulegai","ts":"2019-03-31T06:15:21.502Z"}
{"msg":"Has joined the channel.","username":"GiorgosT","ts":"2019-03-31T14:57:45.350Z","type":"uj"}
{"msg":"@arsulegai do you mean how to prevent the transaction from executing twice?","username":"amundson","ts":"2019-04-01T01:40:34.343Z"}
{"msg":"Yes, prevent execution second time (which could end up having different result) without storing the status of transaction in global state. Storing status explicitly from TP seems to be workaround to me.","username":"arsulegai","ts":"2019-04-01T05:01:28.679Z"}
{"msg":"One more thing to note why ordering within a block wouldn't be an issue, input and output addresses will refer to the same global state address. Hence there won't an issue with parallel scheduling you referred to.","username":"arsulegai","ts":"2019-04-01T09:50:54.696Z"}
{"msg":"why 'without storing the status of the transaction in global state'? That solves the problem you are describing at the application layer. That way, applications which are sensitive to this condition can make the choice to do this, while not enforcing it on every possible use case.","username":"jsmitchell","ts":"2019-04-01T14:37:41.664Z"}
{"msg":"Reason 1:  The number of transactions may grow big. If history is required, it'll be too much to maintain at application layer.\nReason 2: Almost all applications need this application layer workaround. Let it be cookiejar, let it be smallbank or intkey for that matter.\n3. With state checkpoints, we can mitigate Blockchain growing big.","username":"arsulegai","ts":"2019-04-01T15:21:27.468Z"}
{"msg":"Reason 1:  The number of transactions may grow big. If history is required, it'll be too much to maintain at application layer.\nReason 2: Almost all applications need this application layer workaround. Let it be cookiejar, let it be smallbank or intkey for that matter.\nReason 3. With state checkpoints, we can mitigate Blockchain growing big.","username":"arsulegai","ts":"2019-04-01T15:21:27.468Z"}
{"msg":"you are talking about recordkeeping the 'invalid' transactions one way or another","username":"jsmitchell","ts":"2019-04-01T15:25:09.696Z"}
{"msg":"also, state checkpointing is completely unrelated to this. That would allow transfer and more rapid catchup for newly joined nodes or nodes which have been disconnected for some time. The size of current state is still the size of current state, whether or not we support state checkpointing. If you remove addresses from state or overwrite prior versions of address in the new version of state, we already have support for purging old entries (past a block horizon).","username":"jsmitchell","ts":"2019-04-01T15:30:39.362Z"}
{"msg":"I understand, state checkpoint would help to speedy catch-up. But because of the reason you mentioned that state will grow large, it becomes workaround for application to handle. I'm worried that every application relying on global state would end up implementing this.","username":"arsulegai","ts":"2019-04-01T16:04:48.639Z"}
{"msg":"if you recordkeep the list of invalid transactions, they need to be stored somewhere, whether it's the blockstore or state. Growth of either of these is the same class of issue.","username":"jsmitchell","ts":"2019-04-01T16:15:59.682Z"}
{"msg":"requiring all the validators to process invalid transactions to validate a block is a complete non-starter","username":"amundson","ts":"2019-04-01T16:18:34.523Z"}
{"msg":"A transaction is not invalid unless TP on that validator executes","username":"arsulegai","ts":"2019-04-01T16:24:19.272Z"}
{"msg":"That's when I brought up proposal of splitting validator rejections vs TP rejections","username":"arsulegai","ts":"2019-04-01T16:24:43.366Z"}
{"msg":"yes, I understand the distinction you are making, but structurally-invalid transactions/batches are already rejected very early on by the validator and don't make it as far as gossiping or the pending queue.","username":"amundson","ts":"2019-04-01T16:31:21.313Z"}
{"msg":"They are executed when either the block is constructed or getting validated right?","username":"arsulegai","ts":"2019-04-01T16:33:10.154Z"}
{"msg":"I agree with you that it's somewhat structural change. But it's worth exploring and beneficial.","username":"arsulegai","ts":"2019-04-01T16:35:57.114Z"}
{"msg":"Moving a conversation from #sawtooth-pr-review ... @danintel has a PR up for seth - https://github.com/hyperledger/sawtooth-seth/pull/95/files - that uses curl to pull down the necessary apt keys. The advantage of this, if I understand correctly, is that because curl behaves properly with respect to proxy variables, we can reduce/avoid the proxy variable stuff we are currently maintaining.","username":"amundson","ts":"2019-04-01T18:14:56.411Z"}
{"msg":"I think if we can avoid the huge blocks of proxy steps in Dockerfiles by taking this approach, it seems like the most appealing approach suggested thus far. Any additional thoughts?","username":"amundson","ts":"2019-04-01T18:17:36.535Z"}
{"msg":"apparently that approach doesn't work for npm ","username":"rbuysse","ts":"2019-04-01T18:36:59.924Z"}
{"msg":"@Nonj We just published a 1.1.4.post1 version of the python sawtooth-sdk to fix the protobuf issue. Sorry you were impacted!","username":"rbuysse","ts":"2019-04-01T20:15:47.654Z"}
{"msg":"Has joined the channel.","username":"kumble","ts":"2019-04-02T01:20:32.726Z","type":"uj"}
{"msg":"@rbuysse  thanks a ton!","username":"Nonj","ts":"2019-04-02T01:50:35.231Z"}
{"msg":"@rbuysse what's the error with npm?","username":"arsulegai","ts":"2019-04-02T03:20:58.350Z"}
{"msg":"@amundson Wanted a conclusion for earlier topic, do we consider a potential solution to solve it?","username":"arsulegai","ts":"2019-04-02T03:23:33.811Z"}
{"msg":"Has joined the channel.","username":"Mohit_Python","ts":"2019-04-02T04:39:07.916Z","type":"uj"}
{"msg":"@arsulegai I'm not sure what the issue is. @danintel was looking at it","username":"rbuysse","ts":"2019-04-02T18:10:21.436Z"}
{"msg":"What do we want out of Ursa? Here's my starter list in order of tractability more than priority:\n1. painless update (to edwards curve) for faster signature operations\n2. aggregated signatures for use with PBFT c.f. https://github.com/hyperledger/sawtooth-rfcs/pull/30\n3. Confidential transactions - by which I mean that the contents or some field of the contents is somehow hidden (encrypted, committed to, etc.), but can still be meaningfully verified in TP logic (e.g. range proofs).\n4. Private transactions - by which I mean concealing the identity of the participants. (I don't know that there is any mechanism for this.)\n\nThere are plans for anonymous credentials, e.g. proving you possess some attribute like are a member of a bank or carry a certain credit line. I don't know where that capability factors into priorities for the rest of you.","username":"Dan","ts":"2019-04-02T21:19:42.761Z"}
{"msg":"@Dan anonymous credentials are interesting for Grid. would like to see a hello world.","username":"amundson","ts":"2019-04-02T21:25:32.788Z"}
{"msg":"For signing, I think the highest priority has to be support for all the languages sawtooth uses. Without that, we can't achieve your #1, because we can't adopt Ursa without major caveats.","username":"amundson","ts":"2019-04-02T21:30:44.403Z"}
{"msg":"How would aggregated signatures enhance the PBFT approach in that RFC? That would mostly seem to be a problem of network communication, not a signing library problem.","username":"amundson","ts":"2019-04-02T21:32:41.590Z"}
{"msg":"#3 and #4 on your list probably require architectural discussion for Sawtooth before we would know what we need from Ursa?","username":"amundson","ts":"2019-04-02T21:36:08.355Z"}
{"msg":"Hello, I have a question regarding a possible bug in Sawtooth validator. We emailed that several times to the team, but haven't received any response on that, so I guess I might receive it faster here. Now we are trying to do memory profiling of the validator to see what is actually going on when the issue occurs. Hoping for your cooperation on that issue.\nBelow is the text of our report. I am also curious if it might be related to this issue https://jira.hyperledger.org/browse/STL-1505.\n\n================================================================================\nSteps to reproduce:\n\n Spin up a network of Sawtooth nodes with the settings provided below.\nEmulate any network connectivity problem on one of the nodes. This can be done by simply disabling the network connection or by bringing other nodes down.\nAfter that a node will start attempts to reconnect to its peers.\nWhile attempting to reconnect a node starts to consume more and more memory over time. In the last case the memory loss was about 5 MB per hour.\nAfter a successful reconnect memory is not being freed.\n\nAnother issue with such configuration is that a node will keep only the number of peers provided in `minimum_peer_connectivity` and is having trouble finding more peers, but this may be a networking or our old development setup issue, we will investigate it further.\n\nThe validator configuration:\n\n```\npeering = \"dynamic\"\nminimum_peer_connectivity = 3\nscheduler = \"parallel\"\n```\n\nWe also provide at least 3 seeds.\n\nOur environment\n\nWe run the validator in a Docker container based on Ubuntu Xenial with the valdator installed from the Bumper repository (version 1.1.4). The Python version is 3.5.2\n\nOur assumptions\n\nWe assume that this issue is related to the the process of reconnection attempts (as it is creates a lot of OutboundConnection instances) but we haven’t found the exact point where the memory leaks yet. Probably some of the objects are not collected by the Python GC or memory is leaking from the unsafe Rust part of the application.","username":"eugene-babichenko","ts":"2019-04-03T08:45:28.833Z"}
{"msg":"@eugene-babichenko I don't think it is necessarily the same as STL-1505, because that was filed due to apparent memory leaks occurring over a longer period of time on an otherwise stable network.","username":"amundson","ts":"2019-04-03T14:09:22.675Z"}
{"msg":"I doubt this is rust code. All the connection attempts are handled in python, currently.","username":"jsmitchell","ts":"2019-04-03T14:14:44.802Z"}
{"msg":"Has joined the channel.","username":"Kirill_Vusik","ts":"2019-04-03T15:23:04.844Z","type":"uj"}
{"msg":"Thank you for the responses. Running vprof on that code showed me that after 4 hours of work on an unstable network there is around 6000 instances of `sawtooth_validator.networking.future.Future`. Also there are objects that are probably related to that, like `TimerContext`, `deque` and `threading.Condition` (also 5k-6k instances for each). I guess that those futures are still referenced from somewhere or are ignored by the GC for some reason.","username":"eugene-babichenko","ts":"2019-04-03T15:30:18.003Z"}
{"msg":"Thank you for the responses. Running vprof on that code showed me that after 4 hours of work on an unstable network there is around 6000 instances of `sawtooth_validator.networking.future.Future`. Also there are objects that are probably related to that, like `TimerContext`, `deque` and `threading.Condition` (also 5k-6k instances for each). I guess that those futures are still referenced from somewhere or are ignored by the GC for some reason. Now I'm taking a deeper look into that.","username":"eugene-babichenko","ts":"2019-04-03T15:30:18.003Z"}
{"msg":"they are almost certainly the futures associated with the connection attempts and are never being resolved due to the lack of a response from the other side. They probably need timeouts added so that they can be removed.","username":"jsmitchell","ts":"2019-04-03T16:10:24.485Z"}
{"msg":"@rberg2 I think you just fixed this in another repo right? I don't recall which one tho and I'd like to cross check the syntax. https://github.com/hyperledger/sawtooth-poet/pull/26","username":"Dan","ts":"2019-04-03T19:43:53.846Z"}
{"msg":"yes! I have added that back to a few repos","username":"rberg2","ts":"2019-04-03T19:46:11.880Z"}
{"msg":"here is one https://github.com/hyperledger/sawtooth-sabre/commit/cfe050bb0d542ec4911cc40b2ce1d86bb336873a","username":"rberg2","ts":"2019-04-03T19:47:53.805Z"}
{"msg":"Hey all! I'm currently trying to update to sawtooth 1.1.4 for the NEXT hyperdirectory project. After updating the sawtooth-validator image from 1.0.5 to 1.1.4, it seems as though I need to fix some configurations as well. Is there an upgrade checklist somewhere that I can check out to see what else I need to modify? Thank you in advance!","username":"Nonj","ts":"2019-04-05T21:55:06.740Z"}
{"msg":"@Nonj See #sawtooth channel for an answer. This channel is for Sawtooth core development.","username":"danintel","ts":"2019-04-05T23:03:26.862Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi) @amundson @amundson @jsmitchell What's your suggestion for a client using sawtooth block chain  to solve the issue where multiple clients gets different status of transaction (as valid or invalid) based on which validator endpoint they are sending the transaction (via rest api). Since in certain scenarios (as @arsulegai mentioned above in cookie jar example) clients cannot depend on other clients for transaction ordering.  This is independent of the consensus mechanism we use. Do you think we can support this by making changes to sawtooth validator or is it the responsibility of clients should handle this ? How are other block chain frameworks handling this scenario ? ","username":"manojgop","ts":"2019-04-06T10:24:49.723Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi) @amundson @jsmitchell What's your suggestion for a client using sawtooth block chain  to solve the issue where multiple clients gets different status of transaction (as valid or invalid) based on which validator endpoint they are sending the transaction (via rest api). Since in certain scenarios (as @arsulegai mentioned above in cookie jar example) clients cannot depend on other clients for transaction ordering.  This is independent of the consensus mechanism we use. Do you think we can support this by making changes to sawtooth validator or is it the responsibility of clients should handle this ? How are other block chain frameworks handling this scenario ? ","username":"manojgop","ts":"2019-04-06T10:24:49.723Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi) @amundson @jsmitchell What's your suggestion for a client using sawtooth to solve the issue where multiple clients gets different status of transaction (as valid or invalid) based on which validator endpoint clients are sending the transaction (via rest api). Since in certain scenarios (as @arsulegai mentioned above in cookie jar example) clients cannot depend on other clients for transaction ordering.  This is independent of the consensus mechanism we use. Do you think we can support this by making changes to sawtooth validator or is it the responsibility of clients should handle this ? How are other block chain frameworks handling this scenario ? ","username":"manojgop","ts":"2019-04-06T10:24:49.723Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi) @amundson @jsmitchell What's your suggestion for a client using sawtooth to solve the issue where multiple clients gets different status of transaction (as valid or invalid) based on which validator endpoint clients are sending the transaction (via rest api). Since in certain scenarios (as @arsulegai mentioned above in cookie jar example) clients cannot depend on other clients for transaction ordering.  This is independent of the consensus mechanism we use. Do you think we can support this by making changes to sawtooth validator or is it the responsibility of client to handle this ? How are other block chain frameworks handling this scenario ? ","username":"manojgop","ts":"2019-04-06T10:24:49.723Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi) @amundson @jsmitchell What's your suggestion for a client using sawtooth to solve the issue where multiple clients gets different status of transaction (as valid or invalid) based on which validator endpoint clients are sending the transaction (via rest api). Since in certain scenarios (as @arsulegai mentioned above in cookie jar example) clients cannot depend on other clients for transaction ordering.  Since order of execution of transactions in a block is not fixed in sawtooth different validator can get different execution status for the transaction (from TP). This is independent of the consensus mechanism we use. Do you think we can support this by making changes to sawtooth validator or is it the responsibility of client to handle this ? How are other block chain frameworks handling this scenario ? ","username":"manojgop","ts":"2019-04-06T10:24:49.723Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi) @amundson @jsmitchell What's your suggestion for a client using sawtooth to solve the issue where multiple clients gets different status of transaction (as valid or invalid) based on which validator endpoint clients are sending the transaction (via rest api). Since in certain scenarios (as @arsulegai mentioned above in cookie jar example) clients cannot depend on other clients for transaction ordering.  Since order of execution of transactions in a block is not fixed in sawtooth different validator can get different execution status for the transaction (from TP). This is independent of the consensus mechanism we use.       \n1) Do you think we can support this  by making changes to sawtooth validator or is it the responsibility of client to handle this ? 2) How are other block chain frameworks handling this scenario ? ","username":"manojgop","ts":"2019-04-06T10:24:49.723Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi) @amundson @jsmitchell What's your suggestion for a client using sawtooth to solve the issue where multiple clients gets different status of transaction (as valid or invalid) based on which validator endpoint clients are sending the transaction (via rest api). Since in certain scenarios (as @arsulegai mentioned above in cookie jar example) clients cannot depend on other clients for transaction ordering.  Since order of execution of transactions in a block is not fixed in sawtooth different validator can get different execution status for the transaction (from TP). This is independent of the consensus mechanism we use. ```\n\n```       \n1) Do you think we can support this  by making changes to sawtooth validator or is it the responsibility of client to handle this ? 2) How are other block chain frameworks handling this scenario ? ","username":"manojgop","ts":"2019-04-06T10:24:49.723Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi) @amundson @jsmitchell What's your suggestion for a client using sawtooth to solve the issue where multiple clients gets different status of transaction (as valid or invalid) based on which validator endpoint clients are sending the transaction (via rest api). Since in certain scenarios (as @arsulegai mentioned above in cookie jar example) clients cannot depend on other clients for transaction ordering.  Since order of execution of transactions in a block is not fixed in sawtooth different validator can get different execution status for the transaction (from TP). This is independent of the consensus mechanism we use. \n1) Do you think we can support this  by making changes to sawtooth validator or is it the responsibility of client to handle this ? \n2) How are other block chain frameworks handling this scenario ? ","username":"manojgop","ts":"2019-04-06T10:24:49.723Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi) @amundson @jsmitchell What's your suggestion for a client using sawtooth to solve the issue where multiple clients gets different status of transaction (as valid or invalid) based on which validator endpoint clients are sending the transaction (via rest api). Since in certain scenarios (as @arsulegai mentioned above in cookie jar example) clients cannot depend on other clients for transaction ordering.  Since order of execution of transactions in a block is not fixed in sawtooth, different validator can get different execution status for the transaction (from TP). This is independent of the consensus mechanism we use. \n1) Do you think we can support this by making changes to sawtooth validator or is it the responsibility of client to handle this ? For example, use serial ordering for execution of transactions in a block that is published by nodes.\n2) How are other block chain frameworks handling this scenario ? ","username":"manojgop","ts":"2019-04-06T10:24:49.723Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi) @amundson @jsmitchell What's your suggestion for a client using sawtooth to solve the issue where multiple clients gets different status of transaction (as valid or invalid) based on which validator endpoint clients are sending the transaction (via rest api). Since in certain scenarios (as @arsulegai mentioned above in cookie jar example https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=tLdPedmukKFTNh7do) clients cannot depend on other clients for transaction ordering.  Since order of execution of transactions in a block is not fixed in sawtooth, different validator can get different execution status for the transaction (from TP). This is independent of the consensus mechanism we use. \n1) Do you think we can support this by making changes to sawtooth validator or is it the responsibility of client to handle this ? For example, use serial ordering for execution of transactions in a block that is published by nodes.\n2) How are other block chain frameworks handling this scenario ? ","username":"manojgop","ts":"2019-04-06T10:24:49.723Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi","remote":true,"fileId":null,"fileName":null},{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=tLdPedmukKFTNh7do","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=tLdPedmukKFTNh7do","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi) @amundson @jsmitchell What's your suggestion for a client using sawtooth to solve the issue where multiple clients gets different status of transaction (as valid or invalid) based on which validator endpoint clients are sending the transaction (via rest api). Since in certain scenarios (as @arsulegai mentioned above in cookie jar example https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=tLdPedmukKFTNh7do) clients cannot depend on other clients for transaction ordering.  Since order of execution of transactions in a block is not fixed in sawtooth, different validator can get different execution status for the transaction (from TP). This is independent of the consensus mechanism we use. \n1) Do you think we can support this by making changes to sawtooth validator or is it the responsibility of client to handle this ? For example, use serial ordering for execution of transactions in a block that is published by nodes. or let client application handle it by sending all requests from other clients to a batcher which can order the transactions in a batch before sending it to validator ?\n2) How are other block chain frameworks handling this scenario ? ","username":"manojgop","ts":"2019-04-06T10:24:49.723Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=TpwZ4TRCosjDGeKWi","remote":true,"fileId":null,"fileName":null},{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=tLdPedmukKFTNh7do","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=tLdPedmukKFTNh7do","remote":true,"fileId":null,"fileName":null}]}
{"msg":"@manojgop The expectation is that the submitting client will query the validator that it used to submit the batch. The idea that multiple clients are coordinating to know the batch id to request status across the network seems contrived, because the  coordination implies sideband communication. If you have sideband communication, you also have a way to talk about validity sideband.","username":"amundson","ts":"2019-04-06T13:01:16.960Z"}
{"msg":"There is a lot more complexity in batch status than the topics we have discussed here, and at least with a forking consensus like poet there are edge cases. Some of those exist with any consensus, such as a validator restart potentially causing the loss of information about a batch because it was either invalid or in the pending queue. That makes batch status unknowable without complete network knowledge (and if you have complete access to all validators on the network, it doesn’t sound like a blockchain use case)","username":"amundson","ts":"2019-04-06T13:14:29.725Z"}
{"msg":"One idea to help develop or experiment with some more enhancements would be to create the ability to subscribe to a stream of transaction/batch state transitions. An app could persist this information to help solve the restart issue. So, a sample “event” on that stream might be (batch-id-a, old-status, new-status).","username":"amundson","ts":"2019-04-06T13:19:10.945Z"}
{"msg":"@amundson Are you suggesting to handle this issue at application level ?. I was thinking even if client uses event subscription mechanism, some clients may get valid status for a txn/batch where as other might get invalid status based on order of execution of transactions. This happens because each client is sending transactions independently of other clients and if there is no batcher client present to order these transactions and if each validator executes transactions in any arbitrary order (parallel execution) then block chain framework can't guarantee the status of transaction.  So from client perspective the logic becomes complex.","username":"manojgop","ts":"2019-04-06T15:27:01.669Z"}
{"msg":"Do you see this as a generic problem with any block chain framework which is distributed/decentralized. Hence this has be taken care by application ? Or can we do some changes in validator to handle transaction execution and status in a more deterministic way ","username":"manojgop","ts":"2019-04-06T15:28:41.848Z"}
{"msg":"Do you see this as a generic problem with any block chain framework which is distributed/decentralized. Hence this has be handled at application layer ? Or can we do some changes in validator to handle transaction execution and status in a more deterministic way ","username":"manojgop","ts":"2019-04-06T15:28:41.848Z"}
{"msg":"I have already suggested a solution to this that you can use today. Use a consensus that supports finality like PBFT and treat all your transactions as valid at the blockchain level. If they are “invalid” at the app level, record their result differently in state.","username":"jsmitchell","ts":"2019-04-06T15:54:11.731Z"}
{"msg":"Transactions are only processed when included in a block. By declaring all transactions as “valid”, you ensure they will always be included in the block they are first considered in. The use of a finality-supporting consensus ensures that there is no disagreement about chain head (i.e. no forks which might have a different ordering)","username":"jsmitchell","ts":"2019-04-06T16:08:21.558Z"}
{"msg":"You're right @jsmitchell a class of probable statements are handled in finality based consensus engines like PBFT / Raft. Still the issue we're discussing persist in PBFT. Concern is not about ordering transactions within a block, rather transactions considered while constructing the blocks.","username":"arsulegai","ts":"2019-04-06T17:46:37.572Z"}
{"msg":"You're right @jsmitchell a class of problem statements are handled in finality based consensus engines like PBFT / Raft. Still the issue we're discussing here persist in PBFT. Concern is not about ordering transactions within a block, rather transactions considered while constructing the blocks.","username":"arsulegai","ts":"2019-04-06T17:46:37.572Z"}
{"msg":"A transaction is decided as 'valid'/'invalid' by particular validator, in case of finality based consensus engine all other validators are also supposed to give same result as the validator which is proposing the block.","username":"arsulegai","ts":"2019-04-06T17:49:04.647Z"}
{"msg":"Storing status of transaction in global state instead of rejecting is a potential solution to the problem. I'm not denying that and it works perfect.","username":"arsulegai","ts":"2019-04-06T17:52:49.412Z"}
{"msg":"Question however is, this is a problem in all applications. Do we go with such a strong need to the Sawtooth application developers? Or if possible can we consider a solution from framework itself?","username":"arsulegai","ts":"2019-04-06T17:55:15.447Z"}
{"msg":"@amundson ^","username":"arsulegai","ts":"2019-04-06T18:05:34.845Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=Q6uVf9yWvJNSSfA9Uv) @ These problems can be considered in a separate discussion. With a client that has retry ability, validator restart scenarios could be mitigated. However if pending batches are not cleared over long period, they can be re-broadcasted to other validators. If other validators have these transactions, they'll ignore duplicate entry.","username":"arsulegai","ts":"2019-04-06T18:24:58.959Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=Q6uVf9yWvJNSSfA9Uv","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=Q6uVf9yWvJNSSfA9Uv","remote":true,"fileId":null,"fileName":null}]}
{"msg":"You are understanding half of my suggestion @arsulegai ","username":"jsmitchell","ts":"2019-04-06T19:39:34.046Z"}
{"msg":"I have offered a solution that involves considering transactions for publication once and only once. It requires both finality-supporting consensus and making a single decision on inclusion of transactions.","username":"jsmitchell","ts":"2019-04-06T19:46:08.800Z"}
{"msg":"Sawtooth is going to continue to support forking consensus, so it is not going to be able to provide the guarantees you are talking about to the client. Even if we communicated information about invalid transactions considered along with a block, that block itself could be on a fork that is abandoned in the future. End result is a changing answer to the client.","username":"jsmitchell","ts":"2019-04-06T19:52:17.021Z"}
{"msg":"@jsmitchell  So are you suggesting this solution as a temporary or permanent approach that can be adopted by all clients (i.e. to treat all transactions as valid at block chain level  and If they are “invalid” at the app level, record their result differently in state). \nDo you mean making any generic changes at sawtooth core level to give deterministic behavior for transaction status to clients is not feasible since sawtooth has to support both forking and non-forking/finality based consensus ? I'm trying to understand is this issue something specific to sawtooth design or is it applicable for all block chain frameworks which is decentralized and distributed","username":"manojgop","ts":"2019-04-07T03:38:00.091Z"}
{"msg":"@jsmitchell  So are you suggesting this solution as a temporary or permanent approach that can be adopted by all clients (i.e. to treat all transactions as valid at block chain level  and If they are “invalid” at the app level, record their result differently in state). \nDo you mean making any generic changes at sawtooth core level to give deterministic behavior for transaction status to clients is not feasible since sawtooth has to support both forking and non-forking/finality based consensus ? I'm trying to understand is this issue something specific to sawtooth design and/or is it applicable for all block chain frameworks (which is decentralized and distributed) and which uses non-forking/finality consensus like PBTF.","username":"manojgop","ts":"2019-04-07T03:38:00.091Z"}
{"msg":"@jsmitchell  So are you suggesting this solution as a temporary or permanent approach that can be adopted by all clients (i.e. to treat all transactions as valid at block chain level  and If they are “invalid” at the app level, record their result differently in state). \nDo you mean making any generic changes at sawtooth core level to give deterministic behavior for transaction status to clients is not feasible since sawtooth has to support both forking and non-forking/finality based consensus ? I'm trying to understand is this issue something specific to sawtooth design and/or is it applicable for all block chain frameworks (which is decentralized and distributed) and which uses non-forking/finality consensus like PBFT.","username":"manojgop","ts":"2019-04-07T03:38:00.091Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=GWLyv2qMGbv83ySc34) @jsmitchell Thanks it works, almost all applications will require such solution.","username":"arsulegai","ts":"2019-04-07T06:07:26.884Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=GWLyv2qMGbv83ySc34","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=GWLyv2qMGbv83ySc34","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=GWLyv2qMGbv83ySc34) @jsmitchell Thanks it works, almost all applications will require such solution.","username":"arsulegai","ts":"2019-04-07T06:07:30.867Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=GWLyv2qMGbv83ySc34","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=GWLyv2qMGbv83ySc34","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=vdttBmpoMVFooYJifW) @jsmitchell Forking consensus engines will have this issue anyway. How about making it possible for non forking engines?","username":"arsulegai","ts":"2019-04-07T06:08:48.114Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=vdttBmpoMVFooYJifW","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=vdttBmpoMVFooYJifW","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Only you can see this message","username":"pankajcheema","ts":"2019-04-07T08:21:37.266Z"}
{"msg":"I am getting this message at the time of posting in sawtooth channel any suggestion please","username":"pankajcheema","ts":"2019-04-07T08:22:13.764Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=tpiPdp6EvJk5HM85t) @pankajcheema I've replied to your question in #sawtooth channel","username":"arsulegai","ts":"2019-04-07T10:29:04.837Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=tpiPdp6EvJk5HM85t","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=tpiPdp6EvJk5HM85t","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=a4f4c4b9-1557-479b-989a-6fbe332c0571) @arsulegai @arsulegai @jsmitchell I think the method proposed works only if we use serial scheduling. In case of parallel scheduling, different Validator/TP can update the state differently. A transaction can be marked as  valid in the state by one validator/TP and another validator/TP can mark it as invalid based on the order in which transaction is executed in the batch.  In this cookie jar example,  the clients are not adding any transaction dependency. So if we expect validator to give a deterministic result , we need to use serial scheduling.","username":"manojgop","ts":"2019-04-09T04:25:51.093Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=a4f4c4b9-1557-479b-989a-6fbe332c0571","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=a4f4c4b9-1557-479b-989a-6fbe332c0571","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=a4f4c4b9-1557-479b-989a-6fbe332c0571) @arsulegai @jsmitchell I think the method proposed works only if we use serial scheduling. In case of parallel scheduling, different Validator/TP can update the state differently. A transaction can be marked as  valid in the state by one validator/TP and another validator/TP can mark it as invalid based on the order in which transaction is executed in the batch.  In this cookie jar example,  the clients are not adding any transaction dependency. So if we expect validator to give a deterministic result , we need to use serial scheduling.","username":"manojgop","ts":"2019-04-09T04:25:51.093Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=a4f4c4b9-1557-479b-989a-6fbe332c0571","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=a4f4c4b9-1557-479b-989a-6fbe332c0571","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=a4f4c4b9-1557-479b-989a-6fbe332c0571) @arsulegai @jsmitchell I think the method proposed works only if we use serial scheduling. In case of parallel scheduling, different Validator/TP can update the state differently. A transaction can be marked as  valid in the state by one validator/TP and another validator/TP can mark it as invalid based on the order in which transaction is executed in the batch.  In cookie jar example,  the clients are not adding any transaction dependency when they submit transactions/batch. So if we expect all validators/TP to give a deterministic result , we need to use serial scheduling.","username":"manojgop","ts":"2019-04-09T04:25:51.093Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=a4f4c4b9-1557-479b-989a-6fbe332c0571","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=a4f4c4b9-1557-479b-989a-6fbe332c0571","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Not true. The parallel scheduler preserves context ordering based on overlaps of inputs/outputs. Contexts provided are identical, and state transition is therefore 100% deterministic. Nothing can flip from being valid to invalid or vise versa.","username":"jsmitchell","ts":"2019-04-09T11:16:14.694Z"}
{"msg":"Hmm, then we can think of solution for the scenario, for non forking consensus engines.","username":"arsulegai","ts":"2019-04-09T13:34:45.949Z"}
{"msg":"@arsulegai @manojgop given the amount of discussion here and confusion (in particular, on how things currently work and what you can/can't do w/BFT and forking consensus), I think we will need RFCs to move forward. @ltseeley @jsmitchell and myself will probably submit a couple of RFCs short-term related to these discussions. That should help us capture a lot of this discussion and iterate on it until we agree on how to proceed.","username":"amundson","ts":"2019-04-09T15:59:58.570Z"}
{"msg":"Awesome! Thanks","username":"arsulegai","ts":"2019-04-09T16:17:09.584Z"}
{"msg":"Topic: Allowing batch with empty transaction in a block.","username":"arsulegai","ts":"2019-04-10T06:53:16.016Z"}
{"msg":"I've question here, do we need to allow batches with empty transaction list be put in a block? If so, what's the use case?","username":"arsulegai","ts":"2019-04-10T06:53:53.249Z"}
{"msg":"I've a question here, do we need to allow batches with empty transaction list be put in a block? If so, what's the use case?","username":"arsulegai","ts":"2019-04-10T06:53:53.249Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=ZAXzuHLXFA3JPs2Xg) @amundson Wonderful !!. That will help","username":"manojgop","ts":"2019-04-10T08:33:18.232Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=ZAXzuHLXFA3JPs2Xg","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=ZAXzuHLXFA3JPs2Xg","remote":true,"fileId":null,"fileName":null}]}
{"msg":"My takeaway from the invalid transaction discussion was that 1) it is satisfiable with application design using the sawtooth as-is. 2) it may be an easier app-developer experience if we added features.\nFeatures such as TP can return \"Rejected Transaction\" and the transaction will be handled by sawtooth like a valid transaction in terms of block creation. That would satisfy the risk around an invalid transaction being reconsidered at some point in the future when it is no longer desireable. It may also satisfy the client application need for a response but I understand that problem less.\nAdding another response type would create other issues that I won't ramble about here, but I do think it's worth considering how easy our app developer experience is. ","username":"Dan","ts":"2019-04-10T17:45:54.852Z"}
{"msg":"@jsmitchell ^ I've another interesting question, it's regarding block with batch, batch having no transactions.","username":"arsulegai","ts":"2019-04-10T18:10:18.437Z"}
{"msg":"@arsulegai we probably shouldn't allow empty transaction lists in batches","username":"amundson","ts":"2019-04-10T18:59:50.153Z"}
{"msg":"I think the basis for that question is keeping blocks flowing when there's no Txns for e.g. poet2? Might be a way to use something like blockinfo to generate an automatic transaction. Or issue a transaction from consensus. \nAs far as an empty transaction, I recall discussion a long time ago about having transactions that were successful but did not write anything back to state. I don't recall if there is anything which enables/prevents that.","username":"Dan","ts":"2019-04-10T19:14:54.775Z"}
{"msg":"or just allow empty blocks","username":"amundson","ts":"2019-04-10T19:18:29.168Z"}
{"msg":"the question though was about batches with empty transactions list","username":"amundson","ts":"2019-04-10T19:19:03.380Z"}
{"msg":"Right @Dan that would have been my next topic/question, if there's a way to create empty block to keep the flow in PoET2?\nCurrent question was to understand the validator's behavior and see what it has to offer. We observed a case where blocks are added with batches, but they had no transactions in them.","username":"arsulegai","ts":"2019-04-11T02:38:32.346Z"}
{"msg":"what does the consensus rfc say about initiating a block? Does it place any requirements on their being batches/transactions to be processed?","username":"Dan","ts":"2019-04-11T15:26:32.542Z"}
{"msg":"it shouldn't say anything about that","username":"jsmitchell","ts":"2019-04-11T15:38:51.145Z"}
{"msg":"in my opinion, an empty block should be valid, as should the possibility of creating a block which causes injection (e.g. blockinfo) where the only batches/txns in the block would be injected contents.","username":"jsmitchell","ts":"2019-04-11T15:40:18.229Z"}
{"msg":"empty batches are a bug","username":"jsmitchell","ts":"2019-04-11T15:40:32.080Z"}
{"msg":"@arsulegai that JIRA issue you just commented on - Adam is no longer contributing to the project, so feel free to take ownership of the bug","username":"jsmitchell","ts":"2019-04-11T16:00:30.029Z"}
{"msg":"@Dan consensus rfc says if finalize_block is successful a new block sent out","username":"arsulegai","ts":"2019-04-11T16:18:46.346Z"}
{"msg":"@jsmitchell I guess current behavior makes validator consider it as error scenario and empty block is not created. Did I miss something or is there a way to do it?","username":"arsulegai","ts":"2019-04-11T16:19:31.614Z"}
{"msg":"Wait! I didn't check what if there's BatchInfo injector batches in it","username":"arsulegai","ts":"2019-04-11T16:21:15.506Z"}
{"msg":"block publishing is driven by consensus based on the presence of work in the pending queue. If there are no valid items in the pending queue a block won't be produced. This is a different question than \"are empty blocks valid?\". When I said \"in my opinion\" above, I was expressing how I think the system should work, not describing how it does work. Again, in my opinion, consensus should be in complete control of the decision to publish a block, even if there aren't batches in the pending queue.","username":"jsmitchell","ts":"2019-04-11T16:22:04.462Z"}
{"msg":"I agree with you. A possible missing thing to make it look complete could be ability to dynamically decide what batches are to be added into the block. Something like making consensus engine be able to add batches when summarizing or making batch injection as a separate component.","username":"arsulegai","ts":"2019-04-11T16:34:14.261Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=mkdbGsWWgxQDXC3ns) @jsmitchell @ltseeley a quick question on this: what is maximum_peer_connectivity introduced for?\n\nIs it tracking total number of peering connections or is it tracking total number of peers itself?\nExample: if P1, P2, P3 are the only validators in the network then do we say maximum_peer_connectivity can be set to 2?","username":"arsulegai","ts":"2019-04-11T16:58:26.650Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=mkdbGsWWgxQDXC3ns","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=mkdbGsWWgxQDXC3ns","remote":true,"fileId":null,"fileName":null}]}
{"msg":"If you have outstanding PR on sawtooth-core, you will need to rebase, to pick up some linting-related fixes that will be unrelated to your code.","username":"pschwarz","ts":"2019-04-12T18:20:46.714Z"}
{"msg":"@arsulegai I can't say for sure what the _intended_ purpose of the setting is, but what it _does_ is track the number of connections.","username":"ltseeley","ts":"2019-04-12T18:30:40.838Z"}
{"msg":"I'm thinking to make it maximum number of peers supported","username":"arsulegai","ts":"2019-04-12T19:40:51.876Z"}
{"msg":"As it sounds","username":"arsulegai","ts":"2019-04-12T19:41:10.363Z"}
{"msg":"Would that be ok?","username":"arsulegai","ts":"2019-04-12T19:41:29.463Z"}
{"msg":"You mean you are trying to document the meaning? Or you want to make a change to its functionality?","username":"Dan","ts":"2019-04-12T21:00:00.324Z"}
{"msg":"Has joined the channel.","username":"rjones","ts":"2019-04-13T00:07:40.249Z","type":"uj"}
{"msg":"Could I ask Sawtooth maintainers to please join https://lists.hyperledger.org/g/maintainers ? I'd appreciate it.","username":"rjones","ts":"2019-04-13T00:07:49.627Z"}
{"msg":"@Dan The variable is either not fully documented or doesn't follow meaning. I'm thinking to make a code change. Is it allowed?\n\nMany got confused to know that it's not just total number of peers.","username":"arsulegai","ts":"2019-04-13T04:42:12.748Z"}
{"msg":"Has joined the channel.","username":"jimbarritt","ts":"2019-04-13T13:13:41.911Z","type":"uj"}
{"msg":"I think it is implemented correctly, but might not be clearly explained. The idea is to cap the number of a connections that your server will accept. If you imagine your server gets widely advertised across a 100 node network, your server could get overwhelmed. This parameter caps the connections so that it will never connect to more than n other nodes.\nThe comment in the gossip.py file compliments the sysadmin guide, but maybe this explanation makes the definition more clear.\ngossip.py: \n```            maximum_peer_connectivity (int): The validator will reject                              \n                new peer requests if the number of connected peers                                  \n                reaches this threshold.     ```\nvalidator_configuration_file.rst:\n```The maximum number of peers that will be accepted.```\nImplicitly, but perhaps not clearly, that means the max number of peers that will be accepted _by this validator_.","username":"Dan","ts":"2019-04-13T20:33:39.877Z"}
{"msg":"We are working on a HL project proposal for a new transation execution library (tentatively called Transact). Sawtooth and Grid will use this library. Anyone interested, please review - https://docs.google.com/document/d/13d0cMReGOhK13BbdgMOFZy_prUzqWBXWc4nlI7mehpY/edit","username":"amundson","ts":"2019-04-15T14:16:11.638Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=REnDyaXe92iF5NbF7) @Dan Confusion comes because there can be multiple connections with same peer. This variable considers them distinct, for example there are cases where a validator V1 connects to validator V2 3 times, but ignores connection request from V3.","username":"arsulegai","ts":"2019-04-16T03:35:10.961Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=REnDyaXe92iF5NbF7","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=REnDyaXe92iF5NbF7","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Should we consider multiple connections to same peer as one and allow other peers to join this validator was my question.","username":"arsulegai","ts":"2019-04-16T03:35:57.093Z"}
{"msg":"Multiple connections between peers in either direction should be considered a bug ","username":"jsmitchell","ts":"2019-04-16T04:02:07.906Z"}
{"msg":"Thanks for the clarification @jsmitchell @Dan ","username":"arsulegai","ts":"2019-04-16T04:12:41.727Z"}
{"msg":"Has joined the channel.","username":"sah","ts":"2019-04-16T04:24:51.553Z","type":"uj"}
{"msg":"How do these peering variables work with raft and pbft which expect fully connected networks? Do they just get overridden or does the admin need to know to set them for a fully connected network?","username":"Dan","ts":"2019-04-16T12:44:40.759Z"}
{"msg":"Admin needs to explicitly set peers such that exactly one peering request is established, and all peers are connected.\n\nExample: if validator V1 starts first, validator V2 shall specify V1 as peer, validator V3 will have V1 & V2 as peers.\n\nMultiple peering issue is seen if there's peers list marking other way round along with these. i.e. if V1 also lists V2 or V3 as peer or if V2 also lists V3 as peer.","username":"arsulegai","ts":"2019-04-16T13:27:31.604Z"}
{"msg":"Admin needs to explicitly set peers such that exactly one peering request is established, and all peers are connected to each other.\n\nExample: if validator V1 starts first, validator V2 shall specify V1 as peer, validator V3 will have V1 & V2 as peers.\n\nMultiple peering issue is seen if there's peers list marking other way round along with these. i.e. if V1 also lists V2 or V3 as peer or if V2 also lists V3 as peer.","username":"arsulegai","ts":"2019-04-16T13:27:31.604Z"}
{"msg":"Admin needs to explicitly set peers such that exactly one peering connection is established between two nodes, and all peers are connected to each other.\n\nExample: if validator V1 starts first, validator V2 shall specify V1 as peer, validator V3 will have V1 & V2 as peers.\n\nMultiple peering issue is seen if there's peers list marking other way round along with these. i.e. if V1 also lists V2 or V3 as peer or if V2 also lists V3 as peer.","username":"arsulegai","ts":"2019-04-16T13:27:31.604Z"}
{"msg":"But this above still doesn't explain why sometimes 3 peering connections are seen between 2 validators.","username":"arsulegai","ts":"2019-04-16T13:30:31.564Z"}
{"msg":"I agree with @jsmitchell that multiple connections between peers is not the intended design","username":"amundson","ts":"2019-04-16T14:08:46.807Z"}
{"msg":"I think this was \"hidden\" when we were only using PoET because we used dynamic peering more often than static.","username":"amundson","ts":"2019-04-16T14:10:47.573Z"}
{"msg":"@amundson That's right. If we take example of Raft with static peering for fully connected network, if we follow peering approach as per the Raft documentation then we don't get multiple connections. For example, to startup a 3 node network where the nodes have endpoints alpha, beta, and gamma, you would do the following:\nStartup the alpha validator with no peers specified (but --peering static should still be used)\nStartup the beta validator with --peers tcp://alpha:8800\nStartup the gamma validator with --peers tcp://alpha:8800,tcp://beta:8800","username":"manojgop","ts":"2019-04-17T17:58:06.603Z"}
{"msg":"But if we do peering as  alpha --peers beta, gamma;  beta --peers alpha, gamma and gamma --peers alpha, beta, then we get multiple peer connections","username":"manojgop","ts":"2019-04-17T18:00:33.119Z"}
{"msg":"But if we do peering as  alpha --peers beta, gamma;  beta --peers alpha, gamma and gamma --peers alpha, beta, then we get multiple peer connections between validators","username":"manojgop","ts":"2019-04-17T18:00:33.119Z"}
{"msg":"So is the suggestion to fix the code so only single connection is made between validators irrespective of how static peering is configured which gives more flexibility in making peering configuration (for example in docker compose file) or to document it more clearly and leave the code as it is.","username":"manojgop","ts":"2019-04-17T18:04:21.278Z"}
{"msg":"@manojgop duplicate peers should be a bug. Alpha should only have at most one connection with Beta. ","username":"Dan","ts":"2019-04-17T18:11:45.338Z"}
{"msg":"maybe not technically a bug since it's working as intended, but certainly we should fix it with an enhancement","username":"amundson","ts":"2019-04-17T19:03:52.612Z"}
{"msg":"I'm probably overloading 'intended' there","username":"amundson","ts":"2019-04-17T19:05:24.096Z"}
{"msg":"at an architectural level, it was the intent to have only one; what was developed was slightly different, but its not buggy per-se, it's just missing a feature to avoid the duplication.","username":"amundson","ts":"2019-04-17T19:06:46.157Z"}
{"msg":"i haven't looked at that code in a long time. I seem to recall it made an attempt to avoid duplicates, so maybe there is a race condition there with the handshake or something else. Probably a bug.","username":"jsmitchell","ts":"2019-04-17T19:07:32.821Z"}
{"msg":"PRs to make it work properly per the described intent would be welcomed","username":"jsmitchell","ts":"2019-04-17T19:08:23.558Z"}
{"msg":"_it's not a bug. it just needs more features to make it work right._","username":"Dan","ts":"2019-04-17T20:08:54.378Z"}
{"msg":"I just looked at the code. There is some light checking at the network 'connection' level which only allows \"inbound\" connections identified by the connection id if there's not already an \"outbound\" connection with that identifier.","username":"jsmitchell","ts":"2019-04-17T20:09:50.037Z"}
{"msg":"@jsmitchell where is that?","username":"amundson","ts":"2019-04-17T21:38:59.149Z"}
{"msg":"https://github.com/hyperledger/sawtooth-core/blob/master/validator/sawtooth_validator/networking/handlers.py#L148","username":"jsmitchell","ts":"2019-04-17T21:46:17.953Z"}
{"msg":"in the ConnectHandler","username":"jsmitchell","ts":"2019-04-17T21:46:42.223Z"}
{"msg":"I suspect that either the connection id naming is not consistent inbound/outbound, or there are timing issues. In any case, it's not robust.","username":"jsmitchell","ts":"2019-04-17T21:48:00.727Z"}
{"msg":"I don't think that's what that code is trying to do. #notabugjustneedafeature","username":"amundson","ts":"2019-04-17T23:56:06.233Z"}
{"msg":"Wouldn't you have to do this at a level where you know the peer id?","username":"amundson","ts":"2019-04-17T23:57:07.336Z"}
{"msg":"which is in the \"gossip\" code","username":"amundson","ts":"2019-04-17T23:57:24.200Z"}
{"msg":"@Dan I'm not saying this happened, but I could see someone in the past having argued that static peering should do what the user tells it to do and not get too clever.","username":"amundson","ts":"2019-04-18T00:00:51.321Z"}
{"msg":"Hello everyone,\n\nI would like to start contributing in Sawtooth source (and in Sawtooth Core in particular). I noticed that there is a *help-wanted* label in Jira, but the last task with that label was created last October. Is this label relevant, may start working an unassigned without this label?","username":"Kirill_Vusik","ts":"2019-04-18T09:23:44.564Z"}
{"msg":"Hello everyone,\n\nI would like to start contributing in Sawtooth source (and in Sawtooth Core in particular). I noticed that there is a *help-wanted* label in Jira, but the last task with that label was created last October. Is this label relevant? May start working on an unassigned task without this label?","username":"Kirill_Vusik","ts":"2019-04-18T09:23:44.564Z"}
{"msg":"Hello everyone,\n\nI would like to start contributing in Sawtooth source (and in Sawtooth Core in particular). I noticed that there is a *help-wanted* label in Jira, but the last task with that label was created last October. Is this label relevant? May I start working on an unassigned task without this label?","username":"Kirill_Vusik","ts":"2019-04-18T09:23:44.564Z"}
{"msg":"hi all, if the guys at DAML are interested in a contractor, please let me now... ;)","username":"LeonardoCarvalho","ts":"2019-04-18T12:32:13.890Z"}
{"msg":"@Kirill_Vusik great to have your involvement!\nIt is possible some of those issues are getting too old. Also very likely they just haven't been fixed yet because they are lower priority. We should scrub them soon. You are welcome to work on any Jira item though. Probably just a good idea to note in Jira that you are working on it and/or signal people here. That way we won't have two people solving the same problem.","username":"Dan","ts":"2019-04-18T12:49:27.145Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=ZWNaw8ByTEAPMchSK) @Dan Got it, thank you","username":"Kirill_Vusik","ts":"2019-04-18T13:26:09.353Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=ZWNaw8ByTEAPMchSK","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=ZWNaw8ByTEAPMchSK","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Let's say at some point I want to start a new chain by seeding it with the state of a different chain. Or I want to just excise off history for storage reasons. What would you call flattening state history? I don't think that's checkpointing. And it's probably more than 'pruning'.","username":"Dan","ts":"2019-04-18T13:46:41.240Z"}
{"msg":"definitely in the same neighborhood as checkpointing. the decision to 'start a new chain' makes a substantial difference in approach.","username":"jsmitchell","ts":"2019-04-18T15:03:44.229Z"}
{"msg":"a crazy idea might be asserting the existence of a given state root hash at genesis","username":"jsmitchell","ts":"2019-04-18T15:04:57.647Z"}
{"msg":"for this 'start a new chain' concept","username":"jsmitchell","ts":"2019-04-18T15:05:41.338Z"}
{"msg":"a more conventional way to think about it would be a set of transactions that preload the trie","username":"jsmitchell","ts":"2019-04-18T15:06:05.075Z"}
{"msg":"but that might be massive","username":"jsmitchell","ts":"2019-04-18T15:06:10.957Z"}
{"msg":"so like exporting state into a set of 'raw' transactions like `set(addy:123abc, value:b'fdc321')` for a genesis batch as opposed to literally replaying the whole blockchain.\nI'm also thinking about catastrophic recovery thing that's not thought out enough to articulate. Thought I'd look around literature but couldn't think of a correct term for this history culling checkpointing.","username":"Dan","ts":"2019-04-18T15:22:32.347Z"}
{"msg":"checkpointing for a running chain is probably a lot more dynamic than you are thinking","username":"jsmitchell","ts":"2019-04-18T15:25:05.420Z"}
{"msg":"but shares some properties with the 'crazy idea' above","username":"jsmitchell","ts":"2019-04-18T15:25:41.101Z"}
{"msg":"capabilities including the transfer and hash validation of portions/all of state and using that as a base context for the validation of the next block based on that state","username":"jsmitchell","ts":"2019-04-18T15:26:49.660Z"}
{"msg":"@Kirill_Vusik we will have more entered into JIRA soon; in the meantime, there are quite a few things that could be worked on related to the rust transition. if you want something relatively easy, working on rewriting the CLI in rust would be good. if you want something a bit harder, rewriting the REST API in rust using actix would be great (it would allow us to optionally compile it into the validator itself or the grid daemon). help with the transact library would be great (for example, we need a parallel scheduler and additional execution adapters (https://github.com/bitwiseio/transact (warning - bleeding edge)); if you want a super deep/hard problem, we need to prototype compiling PBFT consensus directly into the validator (by deep, I mean rewrite a chunk of the validator); if you want a research-level topic, there are features that could be put into PBFT. There is also endless things around the core, like enhancing the SDKs. For example, the Rust SDK's threading model needs to be enhanced. ","username":"amundson","ts":"2019-04-18T17:04:47.916Z"}
{"msg":"working to move RFC #32 along. I have commented on the open question about endpoints. I don't want to fracture the dialog into chat, but drawing attention to the update so you can comment there: https://github.com/hyperledger/sawtooth-rfcs/pull/32","username":"Dan","ts":"2019-04-18T18:47:34.085Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=BHsQpYjp7yTpKgXmf) @amundson thank you for the clarification, I will think it over","username":"Kirill_Vusik","ts":"2019-04-18T18:51:28.165Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=BHsQpYjp7yTpKgXmf","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=BHsQpYjp7yTpKgXmf","remote":true,"fileId":null,"fileName":null}]}
{"msg":"I remember someone commenting on why Rust was favored over Go fort Sawtooth. Both are similar--compiled languages with strict checking, extensive libraries, and works well in a concurrent environment. So why Rust > Go?","username":"danintel","ts":"2019-04-18T20:30:59.984Z"}
{"msg":"I remember someone commenting on why Rust was favored over Go for Sawtooth. Both are similar--compiled languages with strict checking, extensive libraries, and works well in a concurrent environment. So why Rust > Go?","username":"danintel","ts":"2019-04-18T20:30:59.984Z"}
{"msg":"rust's design provides extensive guarantees regarding memory safety, which are enforced at compile time. Rust's memory management is extremely predictable based on ownership rules and lifetimes, to the extent that the compiler can insert explicit allocation/deallocation instructions. Go uses a garbage collector and provides no such guarantees.","username":"jsmitchell","ts":"2019-04-18T20:39:08.381Z"}
{"msg":"the go toolchain/build process is also not great","username":"jsmitchell","ts":"2019-04-18T20:39:53.574Z"}
{"msg":"downsides of rust are that it can be challenging to learn and that it takes hours to compile hello world","username":"jsmitchell","ts":"2019-04-18T20:40:34.368Z"}
{"msg":"lol","username":"Dan","ts":"2019-04-18T21:02:19.612Z"}
{"msg":"someone joked at one point that Go is where programmers go when they can't handle Rust, and that's why all the Rust crates are of better quality","username":"amundson","ts":"2019-04-18T21:04:27.165Z"}
{"msg":"I don't think Rust is actually that hard though","username":"amundson","ts":"2019-04-18T21:04:45.836Z"}
{"msg":"You just have to learn some new patterns that you should have probably been using before","username":"amundson","ts":"2019-04-18T21:05:32.920Z"}
{"msg":"the compiler, and required syntax, and warnings have also improved substantially over the last several years","username":"jsmitchell","ts":"2019-04-18T21:06:07.974Z"}
{"msg":"so, it's a lot easier than it used to be","username":"jsmitchell","ts":"2019-04-18T21:06:19.093Z"}
{"msg":"yes, that's why","username":"amundson","ts":"2019-04-18T21:06:36.598Z"}
{"msg":"basically it's \"My First Rust\" now","username":"jsmitchell","ts":"2019-04-18T21:06:55.725Z"}
{"msg":"for babies","username":"jsmitchell","ts":"2019-04-18T21:06:58.174Z"}
{"msg":"now the compiler does stuff like this:","username":"jsmitchell","ts":"2019-04-18T21:13:10.259Z"}
{"msg":"","username":"jsmitchell","ts":"2019-04-18T21:13:13.987Z","attachments":[{"type":"file","title":"Clipboard - April 18, 2019 4:13 PM","title_link":"/file-upload/XGtXTSa97zPntQ73u/Clipboard%20-%20April%2018,%202019%204:13%20PM","image_url":"/file-upload/XGtXTSa97zPntQ73u/Clipboard%20-%20April%2018,%202019%204:13%20PM","image_type":"image/png","image_size":145691,"url":"/file-upload/XGtXTSa97zPntQ73u/Clipboard%20-%20April%2018,%202019%204:13%20PM","remote":false,"fileId":"XGtXTSa97zPntQ73u","fileName":"Clipboard - April 18, 2019 4:13 PM"}]}
{"msg":"which is pretty damn cool, because it's the implication of a parse error","username":"jsmitchell","ts":"2019-04-18T21:14:41.765Z"}
{"msg":"(parenthesis are your friend)","username":"danintel","ts":"2019-04-18T23:47:22.587Z"}
{"msg":"Hello everyone! I am trying to implement the `block_end` batch injector (which was not implemented in 1.1.4 from what I can see). It works fine for some time, but at a random point of time validator stops to accept batches and they end up in the unknown status. What I am trying to is to call the `block_end` method from the `CandidateBlock::summarize` and add batches to the scheduler. So, before this line (https://github.com/hyperledger/sawtooth-core/blob/v1.1.4/validator/src/journal/candidate_block.rs#L346) I do the following:\n```rust\nlet batches_by_block_end = self.poll_injectors(|injector: &cpython::PyObject| {\n    // ...here comes a long boilerplate copied from add_batch\n}\nfor b in batches_by_block_end {\n    let batch_id = b.header_signature.clone();\n    self.pending_batches.push(b.clone());\n    self.pending_batch_ids.insert(batch_id.clone());\n\n    self.scheduler.add_batch(b, None, true).unwrap();\n}\n```\n\nBefore the validator stops accepting new batches it also outputs the following log entry: `[2019-04-19 14:29:17.236 DEBUG    scheduler_parallel] Removed 8 incomplete batches from the schedule`\n\nDo you have any suggestions about that?","username":"eugene-babichenko","ts":"2019-04-19T14:39:22.423Z"}
{"msg":"what consensus are you using @eugene-babichenko ? how many nodes?","username":"jsmitchell","ts":"2019-04-19T16:27:32.884Z"}
{"msg":"@jsmitchell We are using our own engine and this is a single node setup.","username":"eugene-babichenko","ts":"2019-04-19T16:37:16.677Z"}
{"msg":"It can be reproduced on a larger network though","username":"eugene-babichenko","ts":"2019-04-19T16:37:45.005Z"}
{"msg":"ok, so I believe that message means that the consensus engine instructed the block publisher to publish a block. When this happens, the publisher finalizes the schedule which aborts any uncompleted transactions in flight (thus, 'removed 8 incomplete batches from the schedule').","username":"jsmitchell","ts":"2019-04-19T16:38:29.033Z"}
{"msg":"if the result is a schedule with 0 valid batches, i believe the publisher will abandon the block, which ultimately is probably the wrong thing to do","username":"jsmitchell","ts":"2019-04-19T16:39:25.978Z"}
{"msg":"you will need to think about this in the context of injecting a batch at the end","username":"jsmitchell","ts":"2019-04-19T16:39:51.643Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=awzuaReBGLfjvAQPM) @jsmitchell Exactly. What confuses me is that all batches I post after that go to the UNKNOWN state.","username":"eugene-babichenko","ts":"2019-04-19T16:40:06.208Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=awzuaReBGLfjvAQPM","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=awzuaReBGLfjvAQPM","remote":true,"fileId":null,"fileName":null}]}
{"msg":"what probably needs to happen is that the schedule needs to be finalized, and then added to with that injected transaction, which will require some changes","username":"jsmitchell","ts":"2019-04-19T16:40:39.022Z"}
{"msg":"I don't know why this should affect submitting new batches","username":"jsmitchell","ts":"2019-04-19T16:41:36.352Z"}
{"msg":"i would think that it would continue to try to publish blocks based on the presence of batches in the pending queue, per the rules of consensus","username":"jsmitchell","ts":"2019-04-19T16:41:59.522Z"}
{"msg":"That might related to our own modules (API, consensus) somehow. I will retry that with the devmode on a local setup to see how it goes.","username":"eugene-babichenko","ts":"2019-04-19T16:42:30.103Z"}
{"msg":"good idea","username":"jsmitchell","ts":"2019-04-19T16:42:38.472Z"}
{"msg":"you might want to set the inter block time for devmode so it has a chance to include some transactions, but you will need to handle that case of zero valid transactions from the pending queue for injection","username":"jsmitchell","ts":"2019-04-19T16:43:19.258Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=a9jYwKfkA9JEKpY8a) @jsmitchell So basically what I need to do is:\n1. Finalize the schedule\n2. Add injected batches to the end of the schedule via some new method\n3. Wait for execution results\n\nDid I get the idea?","username":"eugene-babichenko","ts":"2019-04-19T16:44:41.105Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=a9jYwKfkA9JEKpY8a","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=a9jYwKfkA9JEKpY8a","remote":true,"fileId":null,"fileName":null}]}
{"msg":"yes I think so. That is a material change to how it behaves currently, so it may be worth a short RFC to pad out the injection feature, if you are willing. At the very least, worth a discussion with others here @amundson @pschwarz @agunde etc","username":"jsmitchell","ts":"2019-04-19T16:46:17.220Z"}
{"msg":"I think that I will be able to prepare an RFC a week later or so. Now I just need to make it work on my local fork :)","username":"eugene-babichenko","ts":"2019-04-19T16:47:28.700Z"}
{"msg":"other related feature areas are giving the consensus engine appropriate complete control over block publishing (i.e. don't make an 'empty' block a special case), and coming up with sdk/protocol support for defining and loading injector code","username":"jsmitchell","ts":"2019-04-19T16:48:18.083Z"}
{"msg":"I would be happy to work on some of those once I have enough time. Especially on batch injectors","username":"eugene-babichenko","ts":"2019-04-19T16:49:32.994Z"}
{"msg":"very cool :)","username":"jsmitchell","ts":"2019-04-19T16:49:48.638Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=oHbXgzCNhytLmAD2R) @Dan I've read references to that as \"sharding\", and I think it would be a good addition tp the tool set. An endpoint can receive some data (hashes, signatures, etc) to validate the state passed as valid for it's genesis, with a \"remote trusting\" that ought to be revalidated at some points in time...","username":"LeonardoCarvalho","ts":"2019-04-19T19:09:19.044Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=oHbXgzCNhytLmAD2R","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=oHbXgzCNhytLmAD2R","remote":true,"fileId":null,"fileName":null}]}
{"msg":"i've normally seen sharding to mean partitioning the database so some nodes handle some keys and other nodes handle other keys. ","username":"Dan","ts":"2019-04-19T19:10:18.240Z"}
{"msg":"and that's the case, if you can abstract enough. :)","username":"LeonardoCarvalho","ts":"2019-04-19T19:12:08.615Z"}
{"msg":"Has joined the channel.","username":"maksimb","ts":"2019-04-22T12:39:46.777Z","type":"uj"}
{"msg":"Hello. Experienced another panic in the validator (1.1): ` thread 'ChainThread:CommitReceiver' panicked at 'No method cancel on python scheduler: PyErr { ptype: <class 'KeyError'>, pvalue: Some(KeyError('Value was not found',)), ptraceback: Some(<traceback object at 0x7b3e86b24f88>) }'`\n\nUnfortunately, I cannot provide the exact conditions to reproduce that, but maybe someone here can suggest why it happens?","username":"eugene-babichenko","ts":"2019-04-24T16:29:56.018Z"}
{"msg":"@pschwarz have you seen stuff like this before across the rust/python boundary? ^","username":"amundson","ts":"2019-04-24T16:32:22.503Z"}
{"msg":"Has joined the channel.","username":"artem.frantsiian","ts":"2019-04-24T16:33:06.674Z","type":"uj"}
{"msg":"I have not seen that","username":"pschwarz","ts":"2019-04-24T16:33:53.677Z"}
{"msg":"I wonder if it similar to some of that weird stack corruption we were seeing in the 100% python days","username":"pschwarz","ts":"2019-04-24T16:34:25.443Z"}
{"msg":"s/similar/related","username":"pschwarz","ts":"2019-04-24T16:34:54.584Z"}
{"msg":"What was the issue with stack corruption?","username":"eugene-babichenko","ts":"2019-04-24T16:35:28.522Z"}
{"msg":"There would be times when the the python interpreter would crash complaining that methods were missing from objects that clearly should be there","username":"pschwarz","ts":"2019-04-24T16:38:14.615Z"}
{"msg":"I think there might be an old Jira ticket for that :thinking: ","username":"pschwarz","ts":"2019-04-24T16:38:27.950Z"}
{"msg":"i think @Dan closed that ticket recently","username":"jsmitchell","ts":"2019-04-24T16:39:01.210Z"}
{"msg":"Oh","username":"pschwarz","ts":"2019-04-24T16:40:21.034Z"}
{"msg":"That explains why I can't find it","username":"pschwarz","ts":"2019-04-24T16:40:27.226Z"}
{"msg":"Was it fixed anywhere? I guess I can just incorporate the fix to my fork (I am still on 1.1.4)","username":"eugene-babichenko","ts":"2019-04-24T16:41:21.928Z"}
{"msg":"I don't think so - it certainly was a motivating factor in the rust rewrite, though","username":"pschwarz","ts":"2019-04-24T16:42:40.566Z"}
{"msg":"But I'd have to look through the ticket notes, if I can find it","username":"pschwarz","ts":"2019-04-24T16:43:01.182Z"}
{"msg":"STL-1019","username":"jsmitchell","ts":"2019-04-24T16:44:57.520Z"}
{"msg":"https://jira.hyperledger.org/browse/STL-1019","username":"jsmitchell","ts":"2019-04-24T16:45:20.699Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=Bi6amdC6NLwvF5nYH) @eugene-babichenko What can you suggest us to solve this problem, we will run a public testnet on sawtooth now and want to make sure that the network will fully operational?","username":"artem.frantsiian","ts":"2019-04-24T16:56:25.509Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=Bi6amdC6NLwvF5nYH","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=Bi6amdC6NLwvF5nYH","remote":true,"fileId":null,"fileName":null}]}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=Bi6amdC6NLwvF5nYH) @jsmitchell @pschwarz  What can you suggest us to solve this problem, we will run a public testnet on sawtooth now and want to make sure that the network will fully operational?","username":"artem.frantsiian","ts":"2019-04-24T16:56:25.509Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=Bi6amdC6NLwvF5nYH","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=Bi6amdC6NLwvF5nYH","remote":true,"fileId":null,"fileName":null}]}
{"msg":"restarting the node is effective","username":"pschwarz","ts":"2019-04-24T18:47:02.106Z"}
{"msg":"yeah that wouldn't take down the whole network. it would be a single node that could be restarted.","username":"Dan","ts":"2019-04-24T19:05:42.137Z"}
{"msg":"@pschwarz feel free to reopen that if you think it's relevant. I saw no activity incl. reproducers on it and assumed it was dead.","username":"Dan","ts":"2019-04-24T19:06:14.556Z"}
{"msg":"\"Steps to reproduce\" were certainly an issue with that ticket.","username":"pschwarz","ts":"2019-04-24T19:11:42.093Z"}
{"msg":"we'll try to provide actual steps to reproduce","username":"artem.frantsiian","ts":"2019-04-24T20:49:02.344Z"}
{"msg":"Has joined the channel.","username":"DavidAEdwards","ts":"2019-04-25T13:10:00.987Z","type":"uj"}
{"msg":"Has joined the channel.","username":"ruffsl","ts":"2019-04-26T21:33:46.775Z","type":"uj"}
{"msg":"daml","username":"ruffsl","ts":"2019-04-26T21:34:18.644Z"}
{"msg":"Folks, I was wondering, if I were to replace the REST API with a client to talk directly to the  validator, what the messaging zmq model is? Is it PUB/SUB or something else?","username":"paul.sitoh","ts":"2019-04-28T19:41:46.067Z"}
{"msg":"@paul.sitoh You can use ROUTER/DEALER in zmq","username":"arsulegai","ts":"2019-04-29T02:59:57.392Z"}
{"msg":"Ok thanks","username":"paul.sitoh","ts":"2019-04-29T07:20:08.458Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=9M5yrkLgZCSQkPyHB) @arsulegai Thanks","username":"paul.sitoh","ts":"2019-04-29T07:20:26.593Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=9M5yrkLgZCSQkPyHB","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=9M5yrkLgZCSQkPyHB","remote":true,"fileId":null,"fileName":null}]}
{"msg":"@arsulegai or others when we route a message to a validator, is there any particular socket `address` we should push to?","username":"paul.sitoh","ts":"2019-04-30T08:35:58.431Z"}
{"msg":"@arsulegai or others when we route a message, via the ROUNTER/DEALER model, to a validator, is there any particular socket `address` we should push to?","username":"paul.sitoh","ts":"2019-04-30T08:35:58.431Z"}
{"msg":"For example ```socket.send(address, ZMQ.SNDMORE);\n      socket.send(\"This is the payload.\".getBytes(), NOFLAGS);```","username":"paul.sitoh","ts":"2019-04-30T08:55:53.390Z"}
{"msg":"For example ```socket.send(address, ZMQ.SNDMORE);socket.send(\"This is the payload.\".getBytes(), NOFLAGS);```","username":"paul.sitoh","ts":"2019-04-30T08:55:53.390Z"}
{"msg":"[11:49:20.397 node-1-testnet.remme.io [Thread-18] handlers WARNING] Connecting peer provided an invalid endpoint: tcp://:8800; Ignoring connection request.\n[11:49:20.398 node-1-testnet.remme.io [Thread-18] dispatch WARNING] Sending hang-up in reply to NETWORK_CONNECT to connection f2e7abf91a8701602233c8f63169e2e2116e5fbb49bc391e660d4699a5eb1ad52dc7ce2c79246886f71447746b068d4277c4a26b1497f8efa5e88efca31c97e3\n[11:49:23.412 node-1-testnet.remme.io [Thread-8] handlers WARNING] Connecting peer provided an invalid endpoint: tcp://:8800; Ignoring connection request.\n[11:49:23.412 node-1-testnet.remme.io [Thread-8] dispatch WARNING] Sending hang-up in reply to NETWORK_CONNECT to connection c0e26df110b2a22effea302d29151d4256efc8e28f79c80bf25e627f9f7c8acd8ffb7fb076a24f2ad563760288a923d84b49f1688a6c5bdf208f337c4a38fd8f\n[11:49:26.428 node-1-testnet.remme.io [Thread-23] handlers WARNING] Connecting peer provided an invalid endpoint: tcp://:8800; Ignoring connection request.\n[11:49:26.429 node-1-testnet.remme.io [Thread-23] dispatch WARNING] Sending hang-up in reply to NETWORK_CONNECT to connection fa69c2f2a5622076d5ec631dd62f489884cca22c088345d0f821779d77d110241a003525805883e0bcd5cfa250ae886b337fd6b22b7ac5cd31905f65d1aac33c\n[11:49:29.442 node-1-testnet.remme.io [Thread-21] handlers WARNING] Connecting peer provided an invalid endpoint: tcp://:8800; Ignoring connection request.\n[11:49:29.442 node-1-testnet.remme.io [Thread-21] dispatch WARNING] Sending hang-up in reply to NETWORK_CONNECT to connection 4505fe3a7b50dc218d51a50ca6dec8a24a7439f99c7a1d84a90b7c084985af29978fcf14f2909434dd197fc440725645457a619f1e43a39db558596e760da95e\n[11:49:32.459 node-1-testnet.remme.io [Thread-23] handlers WARNING] Connecting peer provided an invalid endpoint: tcp://:8800; Ignoring connection request.\n[11:49:32.459 node-1-testnet.remme.io [Thread-23] dispatch WARNING] Sending hang-up in reply to NETWORK_CONNECT to connection 228d3418ecfbd9ca2e094218c67b0ba74925ab081b810b30f685942e80fab034ae215d1cf7bde2892f9fe33835440d5d3977f96b7e960e986ca6fd721e9c200a\n","username":"artem.frantsiian","ts":"2019-05-02T12:02:02.357Z"}
{"msg":"Hello, why i can get this in my logs?\n[11:49:20.397 node-1-testnet.remme.io [Thread-18] handlers WARNING] Connecting peer provided an invalid endpoint: tcp://:8800; Ignoring connection request.\n[11:49:20.398 node-1-testnet.remme.io [Thread-18] dispatch WARNING] Sending hang-up in reply to NETWORK_CONNECT to connection f2e7abf91a8701602233c8f63169e2e2116e5fbb49bc391e660d4699a5eb1ad52dc7ce2c79246886f71447746b068d4277c4a26b1497f8efa5e88efca31c97e3\n[11:49:23.412 node-1-testnet.remme.io [Thread-8] handlers WARNING] Connecting peer provided an invalid endpoint: tcp://:8800; Ignoring connection request.\n[11:49:23.412 node-1-testnet.remme.io [Thread-8] dispatch WARNING] Sending hang-up in reply to NETWORK_CONNECT to connection c0e26df110b2a22effea302d29151d4256efc8e28f79c80bf25e627f9f7c8acd8ffb7fb076a24f2ad563760288a923d84b49f1688a6c5bdf208f337c4a38fd8f\n[11:49:26.428 node-1-testnet.remme.io [Thread-23] handlers WARNING] Connecting peer provided an invalid endpoint: tcp://:8800; Ignoring connection request.\n[11:49:26.429 node-1-testnet.remme.io [Thread-23] dispatch WARNING] Sending hang-up in reply to NETWORK_CONNECT to connection fa69c2f2a5622076d5ec631dd62f489884cca22c088345d0f821779d77d110241a003525805883e0bcd5cfa250ae886b337fd6b22b7ac5cd31905f65d1aac33c\n[11:49:29.442 node-1-testnet.remme.io [Thread-21] handlers WARNING] Connecting peer provided an invalid endpoint: tcp://:8800; Ignoring connection request.\n[11:49:29.442 node-1-testnet.remme.io [Thread-21] dispatch WARNING] Sending hang-up in reply to NETWORK_CONNECT to connection 4505fe3a7b50dc218d51a50ca6dec8a24a7439f99c7a1d84a90b7c084985af29978fcf14f2909434dd197fc440725645457a619f1e43a39db558596e760da95e\n[11:49:32.459 node-1-testnet.remme.io [Thread-23] handlers WARNING] Connecting peer provided an invalid endpoint: tcp://:8800; Ignoring connection request.\n[11:49:32.459 node-1-testnet.remme.io [Thread-23] dispatch WARNING] Sending hang-up in reply to NETWORK_CONNECT to connection 228d3418ecfbd9ca2e094218c67b0ba74925ab081b810b30f685942e80fab034ae215d1cf7bde2892f9fe33835440d5d3977f96b7e960e986ca6fd721e9c200a\n\n\n\n","username":"artem.frantsiian","ts":"2019-05-02T12:02:02.357Z"}
{"msg":"Hello, why I can get this in my logs?\n[11:49:20.397 node-1-testnet.remme.io [Thread-18] handlers WARNING] Connecting peer provided an invalid endpoint: tcp://:8800; Ignoring connection request.\n[11:49:20.398 node-1-testnet.remme.io [Thread-18] dispatch WARNING] Sending hang-up in reply to NETWORK_CONNECT to connection f2e7abf91a8701602233c8f63169e2e2116e5fbb49bc391e660d4699a5eb1ad52dc7ce2c79246886f71447746b068d4277c4a26b1497f8efa5e88efca31c97e3\n[11:49:23.412 node-1-testnet.remme.io [Thread-8] handlers WARNING] Connecting peer provided an invalid endpoint: tcp://:8800; Ignoring connection request.\n[11:49:23.412 node-1-testnet.remme.io [Thread-8] dispatch WARNING] Sending hang-up in reply to NETWORK_CONNECT to connection c0e26df110b2a22effea302d29151d4256efc8e28f79c80bf25e627f9f7c8acd8ffb7fb076a24f2ad563760288a923d84b49f1688a6c5bdf208f337c4a38fd8f\n[11:49:26.428 node-1-testnet.remme.io [Thread-23] handlers WARNING] Connecting peer provided an invalid endpoint: tcp://:8800; Ignoring connection request.\n[11:49:26.429 node-1-testnet.remme.io [Thread-23] dispatch WARNING] Sending hang-up in reply to NETWORK_CONNECT to connection fa69c2f2a5622076d5ec631dd62f489884cca22c088345d0f821779d77d110241a003525805883e0bcd5cfa250ae886b337fd6b22b7ac5cd31905f65d1aac33c\n[11:49:29.442 node-1-testnet.remme.io [Thread-21] handlers WARNING] Connecting peer provided an invalid endpoint: tcp://:8800; Ignoring connection request.\n[11:49:29.442 node-1-testnet.remme.io [Thread-21] dispatch WARNING] Sending hang-up in reply to NETWORK_CONNECT to connection 4505fe3a7b50dc218d51a50ca6dec8a24a7439f99c7a1d84a90b7c084985af29978fcf14f2909434dd197fc440725645457a619f1e43a39db558596e760da95e\n[11:49:32.459 node-1-testnet.remme.io [Thread-23] handlers WARNING] Connecting peer provided an invalid endpoint: tcp://:8800; Ignoring connection request.\n[11:49:32.459 node-1-testnet.remme.io [Thread-23] dispatch WARNING] Sending hang-up in reply to NETWORK_CONNECT to connection 228d3418ecfbd9ca2e094218c67b0ba74925ab081b810b30f685942e80fab034ae215d1cf7bde2892f9fe33835440d5d3977f96b7e960e986ca6fd721e9c200a","username":"artem.frantsiian","ts":"2019-05-02T12:02:02.357Z"}
{"msg":"You should probably ask that in #sawtooth, this channel is reserved for core dev discussions. Less so for troubleshooting.","username":"DavidAEdwards","ts":"2019-05-02T12:03:32.225Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=ebCzqCbstHt6qapo5) @DavidAEdwards thanks","username":"artem.frantsiian","ts":"2019-05-02T12:04:29.576Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=ebCzqCbstHt6qapo5","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=ebCzqCbstHt6qapo5","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Could somebody help? We get next logs from validator container:\nhttps://gist.github.com/ArtemFrantsiian/97e79c8bf0c13dab7e259250809cbf61","username":"artem.frantsiian","ts":"2019-05-02T14:54:54.016Z"}
{"msg":"@artem.frantsiian looks like you have modified the validator/build process?","username":"jsmitchell","ts":"2019-05-02T14:58:49.992Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=HNrbfGZastf9icLPQ) @jsmitchell The validator was modified a bit. The build process remains unchanged.","username":"eugene-babichenko","ts":"2019-05-02T15:01:47.516Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=HNrbfGZastf9icLPQ","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=HNrbfGZastf9icLPQ","remote":true,"fileId":null,"fileName":null}]}
{"msg":"I don't think anyone's going to be able to interpret that backtrace for you. If such a thing were happening to me, I'd make sure to build with debug symbols and use a version of gdb that's capable of decoding python stack frames","username":"jsmitchell","ts":"2019-05-02T15:04:52.766Z"}
{"msg":"the set_merkle_root prior to the ffi boundary is probably a clue, but I don't want to speculate","username":"jsmitchell","ts":"2019-05-02T15:06:23.828Z"}
{"msg":"https://stackoverflow.com/questions/54372292/sawtooth-1-1-2-getting-rejected-due-to-invalid-predecessor-when-adding-block-t\nOver in sawtooth-next-directory we're getting the same behavior, a `rejected due to invalid predecessor` error when attempting to add a new block to the genesis block. The cause seems non-deterministic, we can follow the same deployment steps on the same server after removing all images, containers, volumes, etc. and restarting the docker daemon between builds. it's not happening often but also prevents us from adding new blocks when it does happen. This all started happening after our upgrade from sawtooth v1.0 to v1.1","username":"bobonana","ts":"2019-05-02T18:47:08.354Z"}
{"msg":"https://stackoverflow.com/questions/54372292/sawtooth-1-1-2-getting-rejected-due-to-invalid-predecessor-when-adding-block-t\nOver in sawtooth-next-directory we're getting the same behavior, a `rejected due to invalid predecessor` error when attempting to add a new block to the genesis block. The cause seems non-deterministic, we can follow the same deployment steps on the same server after removing all images, containers, volumes, etc. and restarting the docker daemon between builds. it's not happening often but also prevents us from adding new blocks when it does happen. This all started happening after our upgrade from sawtooth v1.0 to v1.1\n\nis this expected behavior and is there a preferred way to recover from it, or prevent it entirely?","username":"bobonana","ts":"2019-05-02T18:47:08.354Z"}
{"msg":"https://stackoverflow.com/questions/54372292/sawtooth-1-1-2-getting-rejected-due-to-invalid-predecessor-when-adding-block-t\nOver in sawtooth-next-directory we're getting the same behavior, a `rejected due to invalid predecessor` error when attempting to add a new block to the genesis block. The cause seems non-deterministic, we can follow the same deployment steps on the same server after removing all images, containers, volumes, etc. and restarting the docker daemon between builds. It's repeating, just not consistently. it's not happening often but also prevents us from adding new blocks when it does happen. This all started happening after our upgrade from sawtooth v1.0 to v1.1\n\nis this expected behavior and is there a preferred way to recover from it, or prevent it entirely?","username":"bobonana","ts":"2019-05-02T18:47:08.354Z"}
{"msg":"https://stackoverflow.com/questions/54372292/sawtooth-1-1-2-getting-rejected-due-to-invalid-predecessor-when-adding-block-t\nOver in sawtooth-next-directory we're getting the same behavior, a `rejected due to invalid predecessor` error when attempting to add a new block to the genesis block. The cause seems non-deterministic, we can follow the same deployment steps on the same server after removing all images, containers, volumes, etc. and restarting the docker daemon between builds. It's repeating, just not consistently. it's not happening often but also prevents us from adding new blocks when it does happen. This all started happening after our upgrade from sawtooth v1.0 to v1.1\n\nis this expected behavior and is there a preferred way to recover from it, or prevent it entirely?\n\nwe're running in developer mode with the devmode-engine image","username":"bobonana","ts":"2019-05-02T18:47:08.354Z"}
{"msg":"On a separate note, we ran some performance tests and noticed that 500 transactions took around 1.3 minutes to be processed using v1.0, but with the switch to v1.1 those same 500 transactions now take around 9.3 minutes to be processed. Is this performance hit expected with the update?","username":"bobonana","ts":"2019-05-02T18:52:43.213Z"}
{"msg":"@bobonana I don't know of a performance hit. Witch what consensus? (if you are using DevMode, don't use it to measure performance.","username":"danintel","ts":"2019-05-02T21:35:29.094Z"}
{"msg":"@bobonana I don't know of a performance hit. Witch what consensus? (if you are using DevMode, don't use it to measure performance.)","username":"danintel","ts":"2019-05-02T21:35:29.094Z"}
{"msg":"@danintel the performance hit is with DevMode, it's not a big deal then since it won't affect prod, but out of curiosity do you know the cause of the performance hit in DevMode (and that other consensus algos weren't similarly affected)?","username":"bobonana","ts":"2019-05-02T21:54:55.228Z"}
{"msg":"@bobonana No I do not. Good question for #sawtooth-consensus-dev. I know that DevMode tries to publish blocks as fast as possible and is more fragile than the other \"real\" consensus engines.","username":"danintel","ts":"2019-05-02T22:01:30.134Z"}
{"msg":"@danintel ah, that makes sense. I'll check in that room too. thanks! \n\non a side note. is there a preferred method of setting a docker healthcheck for the sawtooth, settings-tp, and validator images? Is it possible that attempting to add to the chain before either component is ready would cause the error?","username":"bobonana","ts":"2019-05-02T22:12:28.712Z"}
{"msg":"Submitted transactions just sit there in the validator until the TP is up and running.","username":"danintel","ts":"2019-05-02T22:16:43.117Z"}
{"msg":"@danintel really? our TP seems to be functioning fine, the validator just gives a `rejected due to invalid predecessor` and stops processing transactions alltogether after. when it does happen it only seems to happen during the addition of a block to the genesis block (this is when we bootstrap our local admin user which results in a message being submitted to the validator, and happens right after everything initializes). waiting doesn't seem to help, we've had to restart the application up until now (tho I'll try restarting just the TP image next time and see if that works)","username":"bobonana","ts":"2019-05-02T22:28:33.914Z"}
{"msg":"hello, I tried to get settings of my network by sawtooth cli and got next error:\n```root@node-genesis-testnet-dev:/# sawtooth settings list --url http://localhost:8008\nTraceback (most recent call last):\n  File \"/usr/lib/python3/dist-packages/sawtooth_cli/main.py\", line 174, in main_wrapper\n    main()\n  File \"/usr/lib/python3/dist-packages/sawtooth_cli/main.py\", line 162, in main\n    do_settings(args)\n  File \"/usr/lib/python3/dist-packages/sawtooth_cli/settings.py\", line 86, in do_settings\n    _do_settings_list(args)\n  File \"/usr/lib/python3/dist-packages/sawtooth_cli/settings.py\", line 110, in _do_settings_list\n    setting.ParseFromString(decoded)\ngoogle.protobuf.message.DecodeError: Error parsing message\nroot@node-genesis-testnet-dev:/#```","username":"artem.frantsiian","ts":"2019-05-03T11:11:02.888Z"}
{"msg":"@bobonana not sure, but possible that is being caused by something non-deterministic in your transaction processor","username":"amundson","ts":"2019-05-03T14:53:06.347Z"}
{"msg":"could possibly explain the performance issue too, if the TP is causing random published blocks to be marked invalid","username":"amundson","ts":"2019-05-03T14:54:30.940Z"}
{"msg":"@artem.frantsiian can you report that in JIRA so we can track it?","username":"amundson","ts":"2019-05-03T14:55:43.044Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=A9gqHDn2g778rsAps) @amundson yes, I'll report you soon","username":"artem.frantsiian","ts":"2019-05-03T15:16:01.264Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=A9gqHDn2g778rsAps","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=A9gqHDn2g778rsAps","remote":true,"fileId":null,"fileName":null}]}
{"msg":"@amundson we're using the default validator image, how could I check if there's somethign non-deterministic?","username":"bobonana","ts":"2019-05-03T22:11:26.468Z"}
{"msg":"Hi all...was trying to play around with sawtooth on a 32bit machine and I had to update lmdb.rs as follows to get it to compile...\n-const DEFAULT_SIZE: usize = 1 << 40; // 1024 ** 4\n+//const DEFAULT_SIZE: usize = 1 << 32; // 1024 ** 4\n+const DEFAULT_SIZE: usize = <usize>::max_value(); // 1024 ** 4\n","username":"wchang","ts":"2019-05-04T05:49:29.192Z"}
{"msg":"so I had 2 questions:\n1. What is the strategy for sawtooth once the database/blockchain approaches the limit?  Is forking the way to go?","username":"wchang","ts":"2019-05-04T05:51:24.983Z"}
{"msg":"since my machine is 32bit I'll run into this issue alot sooner :)","username":"wchang","ts":"2019-05-04T05:52:22.779Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=A9gqHDn2g778rsAps) @amundson I created an issue https://jira.hyperledger.org/browse/STL-1532","username":"artem.frantsiian","ts":"2019-05-04T07:59:13.709Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=A9gqHDn2g778rsAps","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=A9gqHDn2g778rsAps","remote":true,"fileId":null,"fileName":null}]}
{"msg":"@bobonana determinism in the TP. Your TP is expected to return same result, no matter when a transaction is executed.","username":"arsulegai","ts":"2019-05-04T08:45:47.244Z"}
{"msg":"Has joined the channel.","username":"robinbryce","ts":"2019-05-06T08:31:57.648Z","type":"uj"}
{"msg":"not - there is now a #transact channel for the new HL project that Sawtooth, Grid, and potentially others will eventually use for transaction processing","username":"amundson","ts":"2019-05-07T19:33:18.326Z"}
{"msg":"note - there is now a #transact channel for the new HL project that Sawtooth, Grid, and potentially others will eventually use for transaction processing","username":"amundson","ts":"2019-05-07T19:33:18.326Z"}
{"msg":"@arsulegai so why is it that when I switch back to sawtooth v1.0 and leave the TP untouched I don't get this error? I'll definitely look to see if we messed up the TP, but I would imagine if that were the issue then this error would manifest using v1.0 as well? ","username":"bobonana","ts":"2019-05-08T17:59:24.725Z"}
{"msg":"@bobonana it should be same in other versions. Do you've logs to know what's happening?","username":"arsulegai","ts":"2019-05-09T01:30:45.671Z"}
{"msg":"Yes, I am thinking of to not try outbound connections if peering request is rejected because the endpoint is already a peer. I don't know implications of this wrto losing connections though.","username":"arsulegai","ts":"2019-05-13T15:22:04.050Z"}
{"msg":"Any comments on this?","username":"arsulegai","ts":"2019-05-13T15:22:19.817Z"}
{"msg":"(This assumes a small correction in code needed, to not allow peering request pass through if an endpoint is already a peer)","username":"arsulegai","ts":"2019-05-13T15:36:00.224Z"}
{"msg":"I'm having trouble with your first sentence, could you please reword @arsulegai ","username":"Dan","ts":"2019-05-13T15:50:31.158Z"}
{"msg":"I am resuming discussion which happened long ago, this is regarding the multiple peering connection issue.","username":"arsulegai","ts":"2019-05-13T15:56:51.084Z"}
{"msg":"For example: https://github.com/hyperledger/sawtooth-core/blob/c209c6458aa9ee616d3a8c60a219f213d0915cb6/validator/sawtooth_validator/gossip/gossip.py#L231 adding extra check here can avoid duplicate peering connections to the same endpoint","username":"arsulegai","ts":"2019-05-13T15:57:33.967Z"}
{"msg":"I thought it's better to not establish a connection itself (do not retry as well) if a peering connection request is rejected because of above reason.","username":"arsulegai","ts":"2019-05-13T16:00:13.593Z"}
{"msg":"I would think that code should be updated to enforce that `endpoint` is unique in `_peers`. I don't know what you mean about rejected though. If the initiator is rejected does that code still add the connection on the initiator side?","username":"Dan","ts":"2019-05-13T16:13:09.108Z"}
{"msg":"Yes, I observed that behavior. I will run it again and confirm","username":"arsulegai","ts":"2019-05-13T16:18:47.636Z"}
{"msg":"That sounds like two bugs then. 1 to maintain a unique set of endpoints and 2 not to establish a 'half-open' connection.","username":"Dan","ts":"2019-05-13T16:33:42.372Z"}
{"msg":"Thanks for initiating the Proxy RFC.","username":"Dan","ts":"2019-05-13T16:34:03.652Z"}
{"msg":"Why would you call it half open connection? The old connection is removed and a new connection request is sent again","username":"arsulegai","ts":"2019-05-13T16:35:31.112Z"}
{"msg":"Would it impact if we stop retrying the new connection if peering connection couldn't be established with a specific reason?","username":"arsulegai","ts":"2019-05-13T18:27:17.583Z"}
{"msg":"The retry logic is here, maybe make it dynamically configurable via settings tp ? https://github.com/hyperledger/sawtooth-core/blob/4b6f63f3e2a0e9518c3f73c025fa2875422ee38b/validator/sawtooth_validator/gossip/gossip.py#L667","username":"arsulegai","ts":"2019-05-13T18:35:08.930Z"}
{"msg":"@amundson ^","username":"arsulegai","ts":"2019-05-15T06:34:29.959Z"}
{"msg":"Has joined the channel.","username":"GianlucaSchoefer","ts":"2019-05-16T07:22:18.129Z","type":"uj"}
{"msg":"","username":"Kirill_Vusik","ts":"2019-05-16T23:17:55.078Z","attachments":[{"type":"file","title":"Clipboard - May 17, 2019 2:17 AM","title_link":"/file-upload/8ezXRQYNtW5CpA7g9/Clipboard%20-%20May%2017,%202019%202:17%20AM","image_url":"/file-upload/8ezXRQYNtW5CpA7g9/Clipboard%20-%20May%2017,%202019%202:17%20AM","image_type":"image/png","image_size":387667,"url":"/file-upload/8ezXRQYNtW5CpA7g9/Clipboard%20-%20May%2017,%202019%202:17%20AM","remote":false,"fileId":"8ezXRQYNtW5CpA7g9","fileName":"Clipboard - May 17, 2019 2:17 AM"}]}
{"msg":"","username":"Kirill_Vusik","ts":"2019-05-16T23:17:55.078Z","attachments":[{"type":"file","title":"Clipboard - May 17, 2019 2:17 AM","title_link":"/file-upload/8ezXRQYNtW5CpA7g9/Clipboard%20-%20May%2017,%202019%202:17%20AM","image_url":"/file-upload/8ezXRQYNtW5CpA7g9/Clipboard%20-%20May%2017,%202019%202:17%20AM","image_type":"image/png","image_size":387667,"url":"/file-upload/8ezXRQYNtW5CpA7g9/Clipboard%20-%20May%2017,%202019%202:17%20AM","remote":false,"fileId":"8ezXRQYNtW5CpA7g9","fileName":"Clipboard - May 17, 2019 2:17 AM"}]}
{"msg":"","username":"Kirill_Vusik","ts":"2019-05-16T23:17:55.078Z","attachments":[{"type":"file","title":"Clipboard - May 17, 2019 2:17 AM","title_link":"/file-upload/8ezXRQYNtW5CpA7g9/Clipboard%20-%20May%2017,%202019%202:17%20AM","image_url":"/file-upload/8ezXRQYNtW5CpA7g9/Clipboard%20-%20May%2017,%202019%202:17%20AM","image_type":"image/png","image_size":387667,"url":"/file-upload/8ezXRQYNtW5CpA7g9/Clipboard%20-%20May%2017,%202019%202:17%20AM","remote":false,"fileId":"8ezXRQYNtW5CpA7g9","fileName":"Clipboard - May 17, 2019 2:17 AM"}]}
{"msg":"","username":"Kirill_Vusik","ts":"2019-05-16T23:17:55.078Z","attachments":[{"type":"file","title":"Clipboard - May 17, 2019 2:17 AM","title_link":"/file-upload/8ezXRQYNtW5CpA7g9/Clipboard%20-%20May%2017,%202019%202:17%20AM","image_url":"/file-upload/8ezXRQYNtW5CpA7g9/Clipboard%20-%20May%2017,%202019%202:17%20AM","image_type":"image/png","image_size":387667,"url":"/file-upload/8ezXRQYNtW5CpA7g9/Clipboard%20-%20May%2017,%202019%202:17%20AM","remote":false,"fileId":"8ezXRQYNtW5CpA7g9","fileName":"Clipboard - May 17, 2019 2:17 AM"}]}
{"msg":"@Kirill_Vusik According to the error message, it's a transient error due to a file update. Have you retried the install?","username":"danintel","ts":"2019-05-16T23:20:36.664Z"}
{"msg":"I have been trying to build the core for one hour. These logs are from `docker-compose build`","username":"Kirill_Vusik","ts":"2019-05-16T23:23:08.761Z"}
{"msg":"docker-compose build --no-cache resolved the issue, sorry for bothering ","username":"Kirill_Vusik","ts":"2019-05-16T23:58:47.744Z"}
{"msg":"@pschwarz @ltseeley @agunde @amundson Regarding the race condition observed with the patch to fix multiple peering connections, please let us know how do you wish to proceed. Do you have a proposal or shall I start working on it?","username":"arsulegai","ts":"2019-05-20T16:01:19.613Z"}
{"msg":"@arsulegai you're welcome to propose a solution. It'll probably involve some deterministic decision based some property of the connections that both of the nodes have knowledge of.","username":"ltseeley","ts":"2019-05-20T16:04:53.800Z"}
{"msg":"@arsulegai you're welcome to propose a solution. It'll probably involve some deterministic decision based on some property of the connections that both of the nodes have knowledge of.","username":"ltseeley","ts":"2019-05-20T16:04:53.800Z"}
{"msg":"Both nodes know their own endpoint and the other node's endpoint, for instance. We can't rely on timing or some information that's only known to the local validator (like a connection ID).","username":"ltseeley","ts":"2019-05-20T16:06:36.915Z"}
{"msg":"Thinking out loud here, didn't analyze implications in detail. How about sending clue about all connections between validators as part of acknowledgement, sorted wrto connection ids, in case of race condition remove all connections except first one.","username":"arsulegai","ts":"2019-05-20T16:12:09.806Z"}
{"msg":"Still a chance for a race condition; the two nodes could send the clues to each other and still decide on different connections.","username":"ltseeley","ts":"2019-05-20T16:19:40.453Z"}
{"msg":"The same connection can have different IDs on different nodes, I believe","username":"ltseeley","ts":"2019-05-20T16:20:11.143Z"}
{"msg":"Right! Then every node would require to know other node's connection id","username":"arsulegai","ts":"2019-05-20T16:48:39.346Z"}
{"msg":"They would also have to figure out which connection IDs match up","username":"ltseeley","ts":"2019-05-20T17:47:30.097Z"}
{"msg":"It may be useful to use the connecting validators public key. This would move this check after authorization. ","username":"agunde","ts":"2019-05-20T18:01:54.118Z"}
{"msg":"But provide a consistent id to check.","username":"agunde","ts":"2019-05-20T18:04:54.474Z"}
{"msg":"Is there a relatively convenient way to get the block_id from the block_num from the client side?","username":"kodonnel","ts":"2019-05-22T15:40:04.327Z"}
{"msg":"Is there a relatively convenient way to get to the block_id from the block_num from the client side?","username":"kodonnel","ts":"2019-05-22T15:40:04.327Z"}
{"msg":"Is there a relatively convenient way to get to the block_id from the block_num from the client side? I've been scanning the various repository and nothing jumps out at me.","username":"kodonnel","ts":"2019-05-22T15:40:04.327Z"}
{"msg":"@kodonnel in the rest api, you can do GET /blocks","username":"amundson","ts":"2019-05-22T21:11:20.868Z"}
{"msg":"I'll have a closer look.  I'm hoping for something where I don't have to maintain mapping/cache client side, and also avoid walking back from now to beginning of chain.  I'm looking to replay events from a point in the chain, block_num is a bit more convenient for that than the block_id.  (bearing in mind forks etc)","username":"kodonnel","ts":"2019-05-23T13:00:38.630Z"}
{"msg":"It's really all about the client_events_subscribe semantics.  If you are doing a catch-up subscription right now you need the last_known_block_ids -> implying that you need to persist that somewhere locally in an ordered or linked list, and then you need to accomodate for forks - or assume non-forking.  Might be much easier if you could catch-up via block height and then in a separate task detect forks.  Even better just be able to query block_id by block_num.  This may all be in the rest-api, if so question answered.","username":"kodonnel","ts":"2019-05-23T13:15:12.473Z"}
{"msg":"In grid, as well as other proof-of-concept apps, we store the (block id, block number) tuple in the db.  At every event, we check to see if we've seen the block height and perform some fork resolution on the other side.  This also doubles as a source of the last_known_block field.\n\nHere's a pretty simple example: https://github.com/peterschwarz/state-export-prototype\nLikewise, in Grid, here's the fork resolution step: https://github.com/hyperledger/grid/blob/master/daemon/src/event/block.rs#L81-L88","username":"pschwarz","ts":"2019-05-24T15:40:44.900Z"}
{"msg":"Reminder that the Hyperledger Sawtooth Contributor Meeting has been moved to tomorrow, Wednesday, May 29th at 10am CDT.\n\nThe meeting information can be found on the Hyperledger Community Meetings Calendar located here: https://wiki.hyperledger.org/display/HYP/Calendar+of+Public+Meetings\n\nWe are finalizing the agenda for this meeting. If you have an appropriate topic you would like to discuss and facilitate, please add it to the agenda, located in \nthe wiki here: https://wiki.hyperledger.org/pages/viewpage.action?pageId=13861698\n\nLooking forward to seeing everyone there!\n-Mark","username":"mfford","ts":"2019-05-28T17:51:04.044Z"}
{"msg":"Please use this number for the Hyperledger Sawtooth Contributor's Meeting:","username":"mfford","ts":"2019-05-29T14:54:38.909Z"}
{"msg":"https://zoom.us/j/332613493\n\nOne tap mobile\n+16468769923,,332613493# US (New York)\n+16699006833,,332613493# US (San Jose)\n\nDial by your location\n        +1 646 876 9923 US (New York)\n        +1 669 900 6833 US (San Jose)\n        +1 408 638 0968 US (San Jose)\nMeeting ID: 332 613 493\nFind your local number: https://zoom.us/u/acj8QRhsif","username":"mfford","ts":"2019-05-29T14:54:40.023Z"}
{"msg":"^ note, this is different than what was shared previously","username":"rbuysse","ts":"2019-05-29T14:58:05.407Z"}
{"msg":"Hi everyone, I would like to try fixing this issue: https://jira.hyperledger.org/browse/STL-1209. It is going to take some time for me to go through the contributing process for the first time, so I want to start with this task (fixing a integration test)","username":"Kirill_Vusik","ts":"2019-05-30T09:11:24.745Z"}
{"msg":"cool, thanks @Kirill_Vusik .  It looks like @benoit.razet may have already taken care of that https://github.com/hyperledger/sawtooth-core/commit/1246bcfd94aa3fe55be64a8bfc30da3c9eb9fa04\nAnd then that file seems to have subsequently been moved or removed. I haven't found the commit that moves the file but I no longer see it in master.","username":"Dan","ts":"2019-05-30T13:54:17.691Z"}
{"msg":"If you find that the issue is no longer relevant please note the commit that resolves it (possibly the one above) and close the ticket. That alone is a help to keep jira up to date.","username":"Dan","ts":"2019-05-30T13:54:56.868Z"}
{"msg":"Right, it has been resolved already, thank you. I was going to look into it later. I noticed that Need-Review is set, does this label indicate that there is a code review already?","username":"Kirill_Vusik","ts":"2019-05-30T14:02:25.201Z"}
{"msg":"@Kirill_Vusik the \"Needs-Review\" label indicates that the jira story itself needs to be reviewed to see if it still valid, needs more information, etc. It has been added to all stories that were in the backlog. It is a part of a planned backlog groom. ","username":"agunde","ts":"2019-05-30T14:06:10.727Z"}
{"msg":"@agunde, got it, thank you","username":"Kirill_Vusik","ts":"2019-05-30T14:08:06.942Z"}
{"msg":"I've marked the issue as \"Done\"","username":"pschwarz","ts":"2019-05-30T15:07:04.838Z"}
{"msg":"May I take this one (https://jira.hyperledger.org/browse/STL-998) then? It looks like the sawadm.py is here still","username":"Kirill_Vusik","ts":"2019-05-30T15:45:31.146Z"}
{"msg":"@Kirill_Vusik sure. it's hinted at there, but basically, we need to make sure we have ~100% compatibility between the python and rust sawadm CLIs first ( @rberg2 looked into this not too long ago and might remember the detail). There were a couple options that weren't in the rust one yet (--version,-V or something like that?). Then we need to figure out the packaging for how to include the sawadm ( @rbuysse had thoughts on this previously). ","username":"amundson","ts":"2019-05-30T15:57:24.229Z"}
{"msg":"@Kirill_Vusik if you are actively working on it, move the Status to \"In Progress\" which will make it show up on this board - https://jira.hyperledger.org/secure/RapidBoard.jspa?rapidView=232&quickFilter=620","username":"amundson","ts":"2019-05-30T15:59:11.877Z"}
{"msg":"Hello, I found that the rust version of `sawawd genesis` had no console output. and `-v` was missing. Otherwise it is drop in compatible with additional features.","username":"rberg2","ts":"2019-05-30T16:09:08.617Z"}
{"msg":"@amundson @rberg2 so removing of the python sawadm might be premature, right? I am looking for a small task (bug/improvement) to work on to understand the commit process","username":"Kirill_Vusik","ts":"2019-05-30T16:10:33.032Z"}
{"msg":"@Kirill_Vusik you could add -v to sawadm genesis (verbose flag) and try and get it to output closer to the python version","username":"amundson","ts":"2019-05-30T16:11:59.259Z"}
{"msg":"(to rust sawadm genesis)","username":"amundson","ts":"2019-05-30T16:12:12.131Z"}
{"msg":"This is more of a packaging than a code issue but it would be pretty simple. https://jira.hyperledger.org/browse/STL-1489","username":"rberg2","ts":"2019-05-30T16:12:59.459Z"}
{"msg":"working toward using the new sawadm is high-value","username":"amundson","ts":"2019-05-30T16:13:09.785Z"}
{"msg":"@amundson , @rberg2 thank you. @amundson , if you don't mind, I will take STL-1489 first and then I will start with STL-998 and the work related to  it (-v, console output)","username":"Kirill_Vusik","ts":"2019-05-30T16:17:29.501Z"}
{"msg":"@amundson , @rberg2 thank you. @amundson , if you don't mind, I will take STL-1489 first and then I will start with the STL-998 and the work related to it (-v, console output)","username":"Kirill_Vusik","ts":"2019-05-30T16:17:29.501Z"}
{"msg":"sounds great!!","username":"amundson","ts":"2019-05-30T16:18:01.124Z"}
{"msg":"I created this ticket about the command output. https://jira.hyperledger.org/browse/STL-1498","username":"rberg2","ts":"2019-05-30T16:26:04.174Z"}
{"msg":"@rberg2 @rbuysse in a recent discussion, @JonGeater brought up issues with docker-compose compatibility between sawtooth-core and sawtooth-seth. specifically, when you need to build the sawtooth-core and sawtooth-seth images and test them with together. we might want to apply a similar pattern as we are using with the consensus engines to it (where seth doesn't contain the validator images)","username":"amundson","ts":"2019-05-30T18:03:38.627Z"}
{"msg":"Has joined the channel.","username":"JonGeater","ts":"2019-05-30T18:03:39.710Z","type":"uj"}
{"msg":"yeah I think so","username":"rbuysse","ts":"2019-05-30T18:06:09.644Z"}
{"msg":"another thing we're gonna want to do is upgrade all the compose files to a current version","username":"rbuysse","ts":"2019-05-30T18:06:22.560Z"}
{"msg":"https://github.com/hyperledger/sawtooth-core/pull/2127 has been merged, which fixes the failing builds.  Rebase any outstanding PR's on master.","username":"pschwarz","ts":"2019-05-30T20:31:54.737Z"}
{"msg":"Outstanding sawtooth-core PR's, that is","username":"pschwarz","ts":"2019-05-30T20:32:17.449Z"}
{"msg":"Has joined the channel.","username":"Pradeep_Pentakota","ts":"2019-06-03T10:28:01.440Z","type":"uj"}
{"msg":"Hi guys,\nSorry for going quiet on this, got diverted into some customer action for a week. \n\nAnyway, on the point of the Docker-compose files, I'm trying to do a couple of things right now:\n - Support eth_call (mainly for compatibility with popular things like Go-Ethereum\n - Investigate some issues we're having with RAFT\n\nIn order to debug all of this I need to have locally-built bits of -seth, -raft and -core, and while any competent dev can contrive this and make it work I raised the question because this seems to be something we have to tackle with the looming 'pluggable everything' strategy driving through Hyperledger.  \n\nSean put the main issue much more concisely than I did, but the sort of issues I'm thinking need a holistic re-design are things like the validator definition in each of the files - which sometimes rebuilds all the rust on every invocation, and/or does it (partially) in --build', and/or re-creates the genesis block every time.  Consistency and reproducability would be good in this area.  There are also smaller things like strategy over shared/persistent volumes and network specifications  when mixing and matching built containers from different places.","username":"JonGeater","ts":"2019-06-09T23:12:13.897Z"}
{"msg":"I have some other questions too about being a good citizen in sawtooth contributions.  I've got eth_call working solidly now and discovered a couple of quite serious bugs in the utility code (incorrect exceptions being raised, incorrect treatment of data types leading to crashes).  Does the community prefer one big PR for \"implement eth_call\" or creating several tiny issues on Jira and submitting individual PRs for those, followed by the eth_call stuff?","username":"JonGeater","ts":"2019-06-09T23:16:54.837Z"}
{"msg":"And lastly: what's the strategy on rust vs python for things like the journal? I've been working on the python but is that going to be deprecated soon?  Is this the sort of thing the Wednesday morning (08:30 UK time) call addresses? ","username":"JonGeater","ts":"2019-06-09T23:18:18.732Z"}
{"msg":"wow, great list @JonGeater !  Did you know we also have PBFT now? I'm curious if you have some uses that drive more towards Raft? There's been some discussion here in the recent past about connection management. If that feels related to the issues you've seen I can say more there.\nI'm fine with a big PR so long as it has appropriately structured commits and clear commit messages. In particular I don't personally have a need for jira entries for those defects, again so long as the commit messages explain the 'why'.\nThe Wednesday meeting is @amolk 's. It tends to cover TP implementation for app devs more than core dev concepts. The short answer on the Journal is the center of the validator gets replaced by the new Hyperledger Transact project which is Rust. @ltseeley could say more on the existing journal code but I think even absent Transact the python was getting removed in favor of rust.\nThe core of your docker questions is out of my realm but @rbuysse spends a lot of his time there.","username":"Dan","ts":"2019-06-10T14:10:23.736Z"}
{"msg":"wow, great list @JonGeater !  Did you know we also have PBFT now? I'm curious if you have some uses that drive more towards Raft? There's been some discussion here in the recent past about connection management. If that feels related to the issues you've seen I can say more there.\nI'm fine with a big PR so long as it has appropriately structured commits and clear commit messages. In particular I don't personally have a need for jira entries for those defects, again so long as the commit messages explain the 'why'.\nThe Wednesday meeting is @amolk 's. It tends to cover TP implementation for app devs more than core dev concepts. The short answer on the Journal is the center of the validator gets replaced by the new Hyperledger Transact project which is Rust. @ltseeley could say more on the existing journal code but I think even absent Transact the python was getting removed in favor of rust.\nThe core of your docker questions is out of my realm but @rbuysse ","username":"Dan","ts":"2019-06-10T14:10:23.736Z"}
{"msg":"Thanks @Dan.  Yes I know PBFT is in now but one step at a time, we only just got this version stable!  We'll move a little later on.\nAlso confirms it's worth maintaining the python for a while so that's good.     What's less good is that the compatibility stuff I've implemented for the python version doesn't appear to be present in Rust so we will see a regression when the change happens...is there some overall ticket/issue I can be added to so I can see when this happens and work on the port when the time is right?  Maybe a question for @ltseeley ?\n\n\n","username":"JonGeater","ts":"2019-06-10T14:16:01.129Z"}
{"msg":"I also forgot the most important of my overarching project questions: the sawtooth-seth stuff depends on a change in sawtooth-core to work properly.  What's the strategy for dependency management in these intermingled projects?  And RTFM answer is fine, if you can just point me at the correct M. ","username":"JonGeater","ts":"2019-06-10T14:17:22.733Z"}
{"msg":"hahaha I think you might have to WTFM ;)\nI think what I've seen in the past is just referencing the core PR from the depending component PR.","username":"Dan","ts":"2019-06-10T14:20:12.053Z"}
{"msg":"@Dan it's not quite accurate that journal will be replaced by transact. journal will use transact (scheduler, executor, context manager, etc. will be replaced). but, generally speaking, everything in the validator will eventually be Rust.","username":"amundson","ts":"2019-06-10T14:23:48.434Z"}
{"msg":"@JonGeater bigger PRs mean longer review times. it can be a trade off. but like @Dan said, good commits is important","username":"amundson","ts":"2019-06-10T14:26:22.969Z"}
{"msg":"I worded it quite carefully, \"...the center of the validator...\" ;)","username":"Dan","ts":"2019-06-10T14:27:00.966Z"}
{"msg":"if there are small fixes you can get in that aren't part of your larger effort, you should definitely submit them earlier and not bundle unrelated things together","username":"amundson","ts":"2019-06-10T14:27:56.580Z"}
{"msg":"@JonGeater the docker stuff in Grid is where we are headed with Docker files for Sawtooth (they have a better approach for Rust code)","username":"amundson","ts":"2019-06-10T14:30:38.076Z"}
{"msg":"Does that include Track & Trace? Cuz last time I ran that it was .. expensive.","username":"Dan","ts":"2019-06-10T14:39:21.368Z"}
{"msg":"last time ~= 2 weeks ago maybe","username":"Dan","ts":"2019-06-10T14:39:47.204Z"}
{"msg":"compiling Rust is expensive (in terms of time). the differences in Grid's Dockerfiles allow for more caching during specific activities of the workflow. if you are just coming to the project having not worked on it recently, you are always going to have to compile the whole thing.","username":"amundson","ts":"2019-06-10T14:43:26.152Z"}
{"msg":"compiling Rust is expensive (in terms of time). the differences in Grid's Dockerfiles allow for more caching during specific activities of the dev workflow. if you are just coming to the project having not worked on it recently, you are always going to have to compile the whole thing.","username":"amundson","ts":"2019-06-10T14:43:26.152Z"}
{"msg":"Thanks @amundson so i'll push the little fixes ASAP","username":"JonGeater","ts":"2019-06-10T14:47:29.672Z"}
{"msg":"(To be clear and answer your wording precisely, they were found during my larger effort, and are essential to it being finished, but being changes to utility code they stand alone too and would benefit from broader testing/review)","username":"JonGeater","ts":"2019-06-10T15:14:14.606Z"}
{"msg":"We are likely to get Portuguese doc translations from the Brazil bootcamp. Anyone have thoughts of how we could manage those? Maybe a portugues-docs branch on core for starters. ","username":"Dan","ts":"2019-06-10T18:45:36.436Z"}
{"msg":"@Dan - This sounds very exciting!  I have thoughts.  But first, some questions. \n\n- Would this be just the docs?  \n\n- Would/could it include README.md and other  *.md files in the repos?  \n\n- Might it eventually include localization as well as translations for messages, strings, command prompts, and comments? (Note that code comments include, but are not limited to, the SDK doc comments used by javadoc, sphinx, rustdoc, etc.) Maybe even full-blown internationalization? (See the definition link below.)\n\nI don't know if a separate branch per language is the best approach, but am willing to believe that it could be pretty good. Perhaps someone knows how other projects and repos handle/organize their translations and localizations?\n\nP.S.  Definitions for internationalization (i18n) and localization (aka i10n): https://www.w3.org/International/questions/qa-i18n\n","username":"achenette","ts":"2019-06-10T21:50:50.096Z"}
{"msg":"@Dan - This sounds very exciting!  I have thoughts.  But first, some questions. \n\n* Would this be just the docs?  \n\n* Would/could it include README.md and other  *.md files in the repos?  \n\n* Might it eventually include localization as well as translations for messages, strings, command prompts, and comments? (Note that code comments include, but are not limited to, the SDK doc comments used by javadoc, sphinx, rustdoc, etc.) Maybe even full-blown internationalization? (See the definition link below.)\n\nI don't know if a separate branchs per language are the best approach, but am willing to believe that they could be pretty good. Perhaps someone knows how other projects and repos organized translations and localizations?\n\nP.S.  Definitions for internationalization (i18n) and localization (aka i10n): https://www.w3.org/International/questions/qa-i18n\n","username":"achenette","ts":"2019-06-10T21:50:50.096Z"}
{"msg":"@Dan - This sounds very exciting!  I have thoughts.  But first, some questions. \n\n- Would this be just the docs?  \n\n- Would/could it include README.md and other  *.md files in the repos?  \n\n- Might it eventually include localization as well as translations for messages, strings, command prompts, and comments? (Note that code comments include, but are not limited to, the SDK doc comments used by javadoc, sphinx, rustdoc, etc.) Maybe even full-blown internationalization? (See the definition link below.)\n\nI don't know if a separate branchs per language are the best approach, but am willing to believe that they could be pretty good. Perhaps someone knows how other projects and repos organized translations and localizations?\n\nP.S.  Definitions for internationalization (i18n) and localization (aka i10n): https://www.w3.org/International/questions/qa-i18n\n","username":"achenette","ts":"2019-06-10T21:50:50.096Z"}
{"msg":"@Dan - This sounds very exciting!  I have thoughts.  But first, some questions. \n\n- Would this be just the docs?  \n\n- Would/could it include README.md and other  *.md files in the repos?  \n\n- Might it eventually include localization as well as translations for messages, strings, command prompts, and comments? (Note that code comments include, but are not limited to, the SDK doc comments used by javadoc, sphinx, rustdoc, etc.) Maybe even full-blown internationalization? (See the definition link below.)\n\nI don't know if a separate branch per language is the best approach, but am willing to believe that it could be pretty good. Perhaps someone knows how other projects and repos organized translations and localizations?\n\nP.S.  Definitions for internationalization (i18n) and localization (aka i10n): https://www.w3.org/International/questions/qa-i18n\n","username":"achenette","ts":"2019-06-10T21:50:50.096Z"}
{"msg":"@Dan could start as a branch in someone's repo and once we have some content, we can play around with actual organization. My primary concern is how it would be maintained over time.","username":"amundson","ts":"2019-06-10T21:52:55.881Z"}
{"msg":":heavy_plus_sign: ","username":"achenette","ts":"2019-06-10T21:56:13.592Z"}
{"msg":"Ongoing translation of large doc sets is usually handled by a Content Management System backed by a content-control database. But that stuff is very expensive and time-consuming to implement. (It pays for itself in a large company that does lots of translations, but Open Source isn't like that.)","username":"achenette","ts":"2019-06-10T21:58:05.808Z"}
{"msg":"I've only done this w/gettext before, so that was just strings not larger docs.","username":"amundson","ts":"2019-06-10T21:59:04.709Z"}
{"msg":"There seems to be something called Poedit that works with gettext. Again, just strings, not full docs.  Documentation (aka human language) is complicated.\n\n","username":"achenette","ts":"2019-06-10T22:03:37.219Z"}
{"msg":"There seems to be something called Poedit that works with gettext. Again, just strings, not full docs.  Documentation (aka human language) is complicated.","username":"achenette","ts":"2019-06-10T22:03:37.219Z"}
{"msg":"https://poedit.net/","username":"achenette","ts":"2019-06-10T22:03:43.815Z"}
{"msg":"Poedit's docs are translated by human beans. :-) https://crowdin.com/project/poedit","username":"achenette","ts":"2019-06-10T22:04:47.678Z"}
{"msg":"Kubernetes has a nice guy on how they organize their doc/website translations: https://kubernetes.io/docs/contribute/localization/#translating-content\n\n(Putting this URL here so I don't forget it)","username":"achenette","ts":"2019-06-10T22:06:43.652Z"}
{"msg":"Kubernetes has a nice guide on how they organize their doc/website translations: https://kubernetes.io/docs/contribute/localization/#translating-content\n\n(Putting this URL here so I don't forget it)","username":"achenette","ts":"2019-06-10T22:06:43.652Z"}
{"msg":"It looks like Dan Mack hasn't made a commit to Sawtooth this year. He has a commit bit and no 2FA. Is he still active, or no?","username":"rjones","ts":"2019-06-11T18:43:12.230Z"}
{"msg":"It looks like Dan Mack hasn't made a commit to Sawtooth this year. He has a commit bit and no 2FA. Is he still active, or no? https://github.com/danmack","username":"rjones","ts":"2019-06-11T18:43:12.230Z"}
{"msg":"@rjones I'll DM you his email address if you want to try and reach out to him","username":"amundson","ts":"2019-06-11T18:46:13.271Z"}
{"msg":"thanks, that would be nice.","username":"rjones","ts":"2019-06-11T18:46:40.133Z"}
{"msg":"Hi all, I was away on personal leave and missed the recent Hyperledger Sawtooth contributor's meeting. Is there a MOM which I can read through?","username":"arsulegai","ts":"2019-06-13T08:48:43.033Z"}
{"msg":"@arsulegai For the 5/29 session, meeting notes were not posted, as the meeting itself was adjourned early due to low attendance (in part because of the US holiday reschedule). The next Hyperledger Sawtooth Contributor Meeting will be back to our regular schedule cadence on June 24th at 10am CDT.","username":"mfford","ts":"2019-06-13T14:01:59.467Z"}
{"msg":"Oh! Ok","username":"arsulegai","ts":"2019-06-13T14:24:53.226Z"}
{"msg":"when you weren't there no one else wanted to be there either ;D","username":"Dan","ts":"2019-06-13T15:01:34.397Z"}
{"msg":":sweat_smile: ","username":"arsulegai","ts":"2019-06-13T16:22:07.744Z"}
{"msg":"Has joined the channel.","username":"bryangross","ts":"2019-06-14T00:15:30.140Z","type":"uj"}
{"msg":"Has joined the channel.","username":"patelkishan","ts":"2019-06-17T19:47:30.714Z","type":"uj"}
{"msg":"Hello everyone, I am interested in benchmarking sawtooth-pbft using caliper so can someone guide me through the process?Thank you!","username":"patelkishan","ts":"2019-06-17T19:47:32.285Z"}
{"msg":"@danintel @dplumb @achenette There's some PRs growing stale in simple supply. Could you guys coordinate to get them resolved?","username":"Dan","ts":"2019-06-19T13:18:02.477Z"}
{"msg":"I commented on them a while ago, they didn't seem to be the right solution to me","username":"dplumb","ts":"2019-06-19T16:17:24.550Z"}
{"msg":"So the central issue seems to be the protoc built for repo.sawtooth.me? @danintel can you clarify further?","username":"Dan","ts":"2019-06-19T19:42:27.145Z"}
{"msg":"There may be a meta issue here around the navigability? of repo.sawtooth.me. It's hard to tell what's available. ","username":"Dan","ts":"2019-06-19T19:47:19.516Z"}
{"msg":"the repo isn't directly browsable, but you can see what packages the repository provides ","username":"rbuysse","ts":"2019-06-20T13:31:44.453Z"}
{"msg":"using bumper/stable as an example, if you have the repo in your /etc/apt/sources.list","username":"rbuysse","ts":"2019-06-20T13:33:28.515Z"}
{"msg":"navigate to /var/lib/apt/lists","username":"rbuysse","ts":"2019-06-20T13:33:34.783Z"}
{"msg":"the available packages are in an lz4 compressed file repo.sawtooth.me_ubuntu_bumper_stable_dists_xenial_universe_binary-amd64_Packages.lz4","username":"rbuysse","ts":"2019-06-20T13:34:25.746Z"}
{"msg":"you can use the lz4cat utility to view the contents","username":"rbuysse","ts":"2019-06-20T13:34:52.750Z"}
{"msg":"`lz4cat repo.sawtooth.me_ubuntu_bumper_stable_dists_xenial_universe_binary-amd64_Packages.lz4`","username":"rbuysse","ts":"2019-06-20T13:34:57.106Z"}
{"msg":"Basically, there is no acceptable solution for fixing Simple Supply Chain so it will work. The current source doesn't work and has never worked since code complete. It uses Sawtooth 1.0, which depends on the internal sawtooth.me repo, which is corrupt for Sawtooth 1.0. That is sawtooth.me for ST 1.0 has has a protoc and proto library that are mismatched and causes Simple Supply Chain to always fail. Working around it (the PR) is not acceptable. Upgrading to use ST 1.1 is not acceptable. Fixing sawtooth.me is not acceptable.  Nothing is acceptable :neutral_face: ","username":"danintel","ts":"2019-06-20T18:14:23.346Z"}
{"msg":"Hi @danintel , what are your goals with Simple Supply right now? Definitely not trying to be a blocker on anything. My concerns are that it doesn't seem ideal to update Simple Supply to 1.1, since the app was created to support the Sawtooth App Dev course which is still based on 1.0. Regarding the protobuf issue, it is not a good practice to manually edit the generated protos, so another solution would be ideal. Let me know what you think.","username":"dplumb","ts":"2019-06-20T18:56:24.743Z"}
{"msg":"it sounds like the resolution would be to correct the protoc in the 1.0 apt repo. I don't understand the problem though. Is it too new or too old or too something else?","username":"Dan","ts":"2019-06-20T18:59:38.385Z"}
{"msg":"The protoc compiler is newer than the library....which is not suppprted. The library can be newer bur not the compiler. So protoc generates stuff unknown to the library.","username":"danintel","ts":"2019-06-21T01:37:59.072Z"}
{"msg":"As far as 1.0 vs. 1.1 not much as changed from a API perspective... Just the internal implementation","username":"danintel","ts":"2019-06-21T01:39:12.735Z"}
{"msg":"REMINDER: The next Hyperledger Sawtooth Contributor Meeting is on Monday, June 24th at 10am CDT. \n\nThe meeting information can be found on the Hyperledger Community Meetings Calendar located here: https://wiki.hyperledger.org/display/HYP/Calendar+of+Public+Meetings\n\nWe are finalizing the agenda for this meeting. If you have an appropriate topic you would like to discuss and facilitate, please add it to the agenda, located in \nthe wiki here: https://wiki.hyperledger.org/pages/viewpage.action?pageId=13865440\n\nLooking forward to seeing everyone there!\n-Mark","username":"mfford","ts":"2019-06-21T13:57:54.562Z"}
{"msg":"@patelkishan most of us haven't used caliper, though I think some of its initial code was inspired by some of our workload generators from years ago. most of load testing is done with smallbank or intkey workload generators that are part of sawtooth. The code for that is in https://github.com/hyperledger/sawtooth-core/tree/master/perf . Setting up a cluster to test is usually best one on bare metal or in AWS. Docs for PBFT are here - https://sawtooth.hyperledger.org/docs/pbft/nightly/master/ Docs for installing Sawtooth (includes PBFT information) - https://sawtooth.hyperledger.org/docs/core/nightly/master/app_developers_guide/ubuntu_test_network.html","username":"amundson","ts":"2019-06-21T17:23:28.525Z"}
{"msg":"@patelkishan If you'll ping @rkrish82 about Caliper, he might be able to help. He uses Caliper regularly.","username":"amolk","ts":"2019-06-21T20:34:11.378Z"}
{"msg":"REMINDER: The Hyperledger Sawtooth Contributor Meeting is today, Monday, June 24th at 10am CDT.\n\nThe meeting information can be found on the Hyperledger Community Meetings Calendar located here: https://wiki.hyperledger.org/display/HYP/Calendar+of+Public+Meetings\n\nThe agenda for today's meeting is located in the wiki here: https://wiki.hyperledger.org/pages/viewpage.action?pageId=13865440","username":"mfford","ts":"2019-06-24T12:36:52.818Z"}
{"msg":"REMINDER: The Hyperledger Sawtooth Contributor Meeting is today, Monday, June 24th at 10am CDT.\n\nPLEASE USE THIS LINK FOR THE MEETING: Join Zoom Meeting\nhttps://zoom.us/j/438462056\n\nOne tap mobile\n+16468769923,,438462056# US (New York)\n+14086380968,,438462056# US (San Jose)\n\nDial by your location\n+1 646 876 9923 US (New York)\n+1 408 638 0968 US (San Jose)\n+1 669 900 6833 US (San Jose)\nMeeting ID: 438 462 056\nFind your local number: https://zoom.us/u/acj8QRhsif\n\nThe agenda for today's meeting is located in the wiki here: https://wiki.hyperledger.org/pages/viewpage.action?pageId=13865440","username":"mfford","ts":"2019-06-24T12:36:52.818Z"}
{"msg":"I see... a new meeting ID for this month","username":"danintel","ts":"2019-06-24T15:02:14.657Z"}
{"msg":"Yes, the calendar needs to be updated.  I got kicked off the call twice before I noticed this","username":"JonGeater","ts":"2019-06-24T19:32:54.377Z"}
{"msg":"The calendar was updated prior to the meeting this morning to fix the broken zoom. Should be good for future meetings. ","username":"mfford","ts":"2019-06-24T19:38:48.538Z"}
{"msg":"Has joined the channel.","username":"lucgerrits","ts":"2019-06-25T15:51:48.929Z","type":"uj"}
{"msg":"I am running a sawtooth network in docker containers. https://sawtooth.hyperledger.org/docs/core/nightly/master/sysadmin_guide/grafana_configuration.html gives instructions for Ubuntu environment. How can I use Grafana if I set up the environment using only the docker-compose file of sawtooth-pbft?","username":"patelkishan","ts":"2019-06-26T05:27:28.574Z"}
{"msg":"Isn't this a dead code or am I missing something here https://github.com/hyperledger/sawtooth-core/blob/1591798b766cdea03940f0d994d8614c5ec69b34/validator/src/journal/candidate_block.rs#L415 ?","username":"arsulegai","ts":"2019-06-27T06:27:59.001Z"}
{"msg":"Need help in another part of the code, could somebody please help me understand more about the comment here https://github.com/hyperledger/sawtooth-core/blob/bb481f279c5e48c7c4ecd2d06b3a093743fce365/validator/sawtooth_validator/execution/scheduler_parallel.py#L540 ?","username":"arsulegai","ts":"2019-06-27T19:09:34.117Z"}
{"msg":"@arsulegai I think that's just to prevent unscheduling all batches. This unschedule_incomplete_batches() thing won't get carried over into Transact. ","username":"amundson","ts":"2019-06-27T20:21:37.302Z"}
{"msg":"@arsulegai by dead code, do you mean never executed?","username":"amundson","ts":"2019-06-27T20:24:03.626Z"}
{"msg":"@amundson No, I meant that it's a local variable and because of return statement this assignment is not useful.","username":"arsulegai","ts":"2019-06-28T00:40:07.632Z"}
{"msg":"@amundson Could there be a corner case that this unschedule mechanism has left behind a batch which can never be completed, thus indefinitely delaying the candidate_block to complete the scheduled execution?","username":"arsulegai","ts":"2019-06-28T12:28:52.186Z"}
{"msg":"I see that before adding batches to the candidate_block itself, there are checks to not consider a batch before all its dependencies are added. So failed to prove above statement","username":"arsulegai","ts":"2019-06-28T12:29:55.841Z"}
{"msg":"The reason I went behind this path is because I consistently see unschedule happening when there's indefinite wait at validator","username":"arsulegai","ts":"2019-06-28T12:41:56.509Z"}
{"msg":"Any help here, please?","username":"arsulegai","ts":"2019-06-28T18:57:54.995Z"}
{"msg":"@arsulegai I think the only way that a batch would never be completed during execution would have to do with the Transaction Processor side of things","username":"pschwarz","ts":"2019-06-28T19:42:33.482Z"}
{"msg":"If a transaction processor never returns, but still responds to pings from the validator, the outstanding transaction won't set the value.","username":"pschwarz","ts":"2019-06-28T19:43:10.989Z"}
{"msg":"If it doesn't respond to pings, the connection will be closed and the transaction rescheduled","username":"pschwarz","ts":"2019-06-28T19:43:54.549Z"}
{"msg":"(Due to internal error)","username":"pschwarz","ts":"2019-06-28T19:44:04.622Z"}
{"msg":"The unscheduling  happens when the consensus engine tells the publisher to publish the block","username":"pschwarz","ts":"2019-06-28T19:45:25.186Z"}
{"msg":"The issue is seen with intkey workload or even the smallbank workload.. Consensus engine times out waiting for response to summarize_block call.","username":"arsulegai","ts":"2019-06-28T19:48:50.970Z"}
{"msg":"But I agree with you @pschwarz that there's no such corner case possible for indefinite wait here","username":"arsulegai","ts":"2019-06-28T19:53:14.840Z"}
{"msg":"There's another possible path for me to dig deeper, in all the error logs with me there's one more common pattern before this time out error","username":"arsulegai","ts":"2019-06-28T19:54:52.870Z"}
{"msg":"That is the node that fails to summarize and respond back, receives the block from another validator the same time when its own consensus engine finalizes the block","username":"arsulegai","ts":"2019-06-28T19:56:34.344Z"}
{"msg":"This sounds like a normal scenario and still i doubt if I'll get meaningful analysis by digging more in this path","username":"arsulegai","ts":"2019-06-28T19:58:17.554Z"}
{"msg":"Is this a possible bug that's fixed https://github.com/hyperledger/sawtooth-core/commit/358be02cb7f32d914b03e2bce3017a1c929cde41 ? @ltseeley ","username":"arsulegai","ts":"2019-07-01T05:02:37.291Z"}
{"msg":"I'm not sure I understand the question?","username":"ltseeley","ts":"2019-07-01T15:20:32.438Z"}
{"msg":"The git comment says it's to avoid adding duplicate batch to the candidate_block, I wanted to know if there were issues with it","username":"arsulegai","ts":"2019-07-01T15:29:43.111Z"}
{"msg":"Question: Is it required that the validator sends the duplicate block to the consensus engine (particularly a block which is already committed)?","username":"arsulegai","ts":"2019-07-03T05:08:17.267Z"}
{"msg":"The validator should not send duplicate blocks to consensus; it should only send each block to consensus once, and they should be in order.","username":"ltseeley","ts":"2019-07-08T13:56:53.476Z"}
{"msg":"How about in case of gossip network, when blocks are sent out?","username":"arsulegai","ts":"2019-07-08T14:21:32.512Z"}
{"msg":"I have a log where same block is received by the consensus engine at least twice","username":"arsulegai","ts":"2019-07-08T14:23:10.573Z"}
{"msg":"What version of the validator are you using? What's the scenario that produces that behavior?","username":"ltseeley","ts":"2019-07-08T15:10:14.417Z"}
{"msg":"Got it while testing PoET with Validator 1.2","username":"arsulegai","ts":"2019-07-08T15:53:12.661Z"}
{"msg":"It was LR setup where this scenario is observed","username":"arsulegai","ts":"2019-07-08T15:53:38.911Z"}
{"msg":"do you have snippets of the validator and consensus engine logs around that event?","username":"jsmitchell","ts":"2019-07-08T15:59:37.089Z"}
{"msg":"","username":"arsulegai","ts":"2019-07-08T16:24:28.082Z","attachments":[{"type":"file","title":"poet-engine-debug.log","title_link":"/file-upload/BxLZjvQQZd2MNzfaE/poet-engine-debug.log","url":"/file-upload/BxLZjvQQZd2MNzfaE/poet-engine-debug.log","remote":false,"fileId":"BxLZjvQQZd2MNzfaE","fileName":"poet-engine-debug.log"}]}
{"msg":"","username":"arsulegai","ts":"2019-07-08T16:24:50.152Z","attachments":[{"type":"file","title":"validator-debug.log","title_link":"/file-upload/xW2ar7Pd3rdXCYNMe/validator-debug.log","url":"/file-upload/xW2ar7Pd3rdXCYNMe/validator-debug.log","remote":false,"fileId":"xW2ar7Pd3rdXCYNMe","fileName":"validator-debug.log"}]}
{"msg":"Attached debug logs for PoET and Validator, you may consider the block 37e54461523b486fa8fe9b4e06da2c8cdbd8ebe3339478e4f0f051030c5b192f370551690206153241524062ae9e24d240c34f5055ec9cd53f40c71a10853f28 for example.","username":"arsulegai","ts":"2019-07-08T16:24:51.825Z"}
{"msg":"This duplicate arrival caused another issue in PoET for which a PR is raised on sawtooth-poet","username":"arsulegai","ts":"2019-07-08T16:25:13.009Z"}
{"msg":"Hmm, I have not seen that before. It looks like that block is getting validated twice, so my guess is that's a bug in the completer.","username":"ltseeley","ts":"2019-07-08T17:06:07.858Z"}
{"msg":"I am surprised that it's consistent in all PoET LRs","username":"arsulegai","ts":"2019-07-08T18:21:54.519Z"}
{"msg":"Added a new RFC for an Event Processor SDK API: https://github.com/hyperledger/sawtooth-rfcs/pull/48","username":"pschwarz","ts":"2019-07-09T14:52:37.078Z"}
{"msg":"Has left the channel.","username":"rjones","ts":"2019-07-09T17:02:12.871Z","type":"ul"}
{"msg":"@ltseeley Could it be that same block is scheduled twice for validation, without checking if it's already present in it?","username":"arsulegai","ts":"2019-07-10T14:01:21.912Z"}
{"msg":"Has joined the channel.","username":"AlexanderZhovnuvaty","ts":"2019-07-10T14:48:38.832Z","type":"uj"}
{"msg":"Any help here is useful, I would like to understand if there's behavior changes in Validator from 1.1, we see more forking in 1.2 candidate than 1.1 with same PoET binary","username":"arsulegai","ts":"2019-07-10T16:03:58.178Z"}
{"msg":"Based on a call I just had with @amolk I understand that master is not exhibiting the same forking? As in #sawtooth-release can you specify which build is exhibiting the forking?","username":"Dan","ts":"2019-07-10T17:00:51.764Z"}
{"msg":"It's possible, but I can't say for sure.","username":"ltseeley","ts":"2019-07-10T18:44:01.251Z"}
{"msg":"I haven't tracked the journal oxidation closely. Is the python completer still the active code? (That hasn't seen a change in nearly a year) or is there a rust replacement? I don't see an obvious one here: https://github.com/hyperledger/sawtooth-core/tree/master/validator/src/journal","username":"Dan","ts":"2019-07-10T19:24:42.615Z"}
{"msg":"Completer is still Python","username":"ltseeley","ts":"2019-07-10T20:58:32.762Z"}
{"msg":"Any information on why would validator take too long to process a block?","username":"arsulegai","ts":"2019-07-15T09:57:48.623Z"}
{"msg":"Example:\nt1: Adding block XYZ for processing\nt1 + 6 min: Block XYZ passed validation","username":"arsulegai","ts":"2019-07-15T09:58:20.728Z"}
{"msg":"How many transactions are in the block?","username":"ltseeley","ts":"2019-07-15T14:13:23.677Z"}
{"msg":"1 txn / 1 batch, max batches in a block set to 1000","username":"arsulegai","ts":"2019-07-15T14:14:19.074Z"}
{"msg":"Hmm, what's CPU usage look like while it's processing the block? Is the validator in question in-sync with the rest of the network?","username":"ltseeley","ts":"2019-07-15T14:24:26.248Z"}
{"msg":"Nodes are in sync, all the nodes seems to have slowed themselves down because of block validation time","username":"arsulegai","ts":"2019-07-15T14:31:39.587Z"}
{"msg":"There's no other activity happening except waiting for block validator be triggered. Because this is slow, all the nodes are trying to publish a block and more number of forks seen. Eventually making validators validate more blocks as time progresses","username":"arsulegai","ts":"2019-07-15T14:32:45.627Z"}
{"msg":"Does it wait on a thread to be released or an event? I couldn't make this out from code","username":"arsulegai","ts":"2019-07-15T14:35:10.176Z"}
{"msg":"Do the TP logs show anything interesting?","username":"ltseeley","ts":"2019-07-15T14:53:24.545Z"}
{"msg":"Nope :(","username":"arsulegai","ts":"2019-07-15T15:06:18.371Z"}
{"msg":"We then started playing with different configuration options, so that it can smooth with 10tps","username":"arsulegai","ts":"2019-07-15T15:07:17.394Z"}
{"msg":"Is there a possibility that validator is waiting on interconnect thread?","username":"arsulegai","ts":"2019-07-15T15:18:58.526Z"}
{"msg":"I see that one of the validator got disconnected and this one is printing too many \"unable to send NETWORK_ACK\" messages","username":"arsulegai","ts":"2019-07-15T15:19:32.334Z"}
{"msg":"@arsulegai Could you add a link to the master PR in your backport PR?","username":"pschwarz","ts":"2019-07-16T17:18:30.800Z"}
{"msg":"Ok","username":"arsulegai","ts":"2019-07-16T17:24:29.878Z"}
{"msg":"thanks","username":"pschwarz","ts":"2019-07-16T17:28:53.665Z"}
{"msg":"Makes it easier for mental correlation :)","username":"pschwarz","ts":"2019-07-16T17:29:03.673Z"}
{"msg":"Agree","username":"arsulegai","ts":"2019-07-16T17:46:51.542Z"}
{"msg":"Trying to find the valid meeting ID for now.  It is always changing!","username":"danintel","ts":"2019-07-22T15:01:29.228Z"}
{"msg":"https://zoom.us/j/438462056","username":"jsmitchell","ts":"2019-07-22T15:01:53.154Z"}
{"msg":"ty","username":"danintel","ts":"2019-07-22T15:02:13.162Z"}
{"msg":"@arsulegai let's pick that conversation up here","username":"jsmitchell","ts":"2019-07-22T16:02:21.009Z"}
{"msg":"what log messages are associated with the event where the block predecessor is determined to be missing and re-added to the pending queue?","username":"jsmitchell","ts":"2019-07-22T16:03:28.417Z"}
{"msg":"I was talking about the time interval between \"block XYZ added for processing\" and \"block XYZ validated\"","username":"arsulegai","ts":"2019-07-22T16:03:32.808Z"}
{"msg":"Oh! re-adding to pending queue is different issue","username":"arsulegai","ts":"2019-07-22T16:03:54.250Z"}
{"msg":"the re-adding to pending queue issue is the one you had up on your screen, right?","username":"jsmitchell","ts":"2019-07-22T16:05:43.192Z"}
{"msg":"Yes, then towards the end of the call I brought up the timing issue","username":"arsulegai","ts":"2019-07-22T16:06:19.788Z"}
{"msg":"Ok, let's pick up re-adding to pending queue first","username":"arsulegai","ts":"2019-07-22T16:06:30.598Z"}
{"msg":"do you have the raw log message line for when it decided that the already added block was missing?","username":"jsmitchell","ts":"2019-07-22T16:06:54.513Z"}
{"msg":"These traces were from the same log I posted few days ago","username":"arsulegai","ts":"2019-07-22T16:07:25.142Z"}
{"msg":"Here it is https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=Km7eKH4urMo8yKxYK","username":"arsulegai","ts":"2019-07-22T16:07:45.830Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=Km7eKH4urMo8yKxYK","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=Km7eKH4urMo8yKxYK","remote":true,"fileId":null,"fileName":null}]}
{"msg":"I just want that one message","username":"jsmitchell","ts":"2019-07-22T16:07:56.595Z"}
{"msg":"I didn't get you, how about if I point you out the log traces that I am referring to","username":"arsulegai","ts":"2019-07-22T16:09:36.679Z"}
{"msg":"Give me couple of minutes, let me pull them up from original log file","username":"arsulegai","ts":"2019-07-22T16:09:58.448Z"}
{"msg":"Is this the log message in question: https://github.com/hyperledger/sawtooth-core/blob/master/validator/src/journal/block_scheduler.rs#L127","username":"jsmitchell","ts":"2019-07-22T16:12:46.445Z"}
{"msg":"Yes","username":"arsulegai","ts":"2019-07-22T16:15:56.120Z"}
{"msg":"I didn't expect this trace when the previous block is in pending queue","username":"arsulegai","ts":"2019-07-22T16:16:30.174Z"}
{"msg":"@pschwarz looks like status can be https://github.com/hyperledger/sawtooth-core/blob/master/validator/src/journal/block_wrapper.rs#L25, but https://github.com/hyperledger/sawtooth-core/blob/master/validator/src/journal/block_scheduler.rs#L177 must be returning BlockStatus::Unknown","username":"jsmitchell","ts":"2019-07-22T16:16:48.718Z"}
{"msg":"Hmm","username":"pschwarz","ts":"2019-07-22T16:17:44.047Z"}
{"msg":"Before going there, can there be any intermittent state where block is not in pending or in processing?","username":"arsulegai","ts":"2019-07-22T16:18:02.111Z"}
{"msg":"it's not clear to me where stuff is inserted into the BlockStatusStore","username":"jsmitchell","ts":"2019-07-22T16:18:18.441Z"}
{"msg":"Missing != Unknown","username":"jsmitchell","ts":"2019-07-22T16:18:53.328Z"}
{"msg":"getting to that log message means that these checks must have failed: https://github.com/hyperledger/sawtooth-core/blob/master/validator/src/journal/block_scheduler.rs#L105 and 9 lines later","username":"jsmitchell","ts":"2019-07-22T16:23:50.470Z"}
{"msg":"Can this happen?\nZ -> A -> B -> C (is a fork) Z-> A -> D (is another fork)\n1. Block A is added to pending because Z is in process\n2. Block D arrives and then we see the trace you pointed (A's status is unknown). So A is added to processing. ---> I expected A to be in pending queue here\n3. Block A passed validation --> New Block Event triggered to consensus engine\n4. Chain head updated to A\n5. Again Block A passed validation --> New Block Event triggered to consensus engine","username":"arsulegai","ts":"2019-07-22T16:26:14.782Z"}
{"msg":"@pschwarz all access to the BlockSchedulerState is controlled by the BlockScheduler?","username":"jsmitchell","ts":"2019-07-22T16:28:06.808Z"}
{"msg":"because both of the methods that modify the state are managed by a mutex in BlockScheduler","username":"jsmitchell","ts":"2019-07-22T16:28:51.669Z"}
{"msg":"Looks like","username":"pschwarz","ts":"2019-07-22T16:32:47.767Z"}
{"msg":"","username":"arsulegai","ts":"2019-07-22T16:33:35.028Z","attachments":[{"type":"file","title":"ref-validator-debug.log","title_link":"/file-upload/BX7truyM2Qfgw9pSX/ref-validator-debug.log","url":"/file-upload/BX7truyM2Qfgw9pSX/ref-validator-debug.log","remote":false,"fileId":"BX7truyM2Qfgw9pSX","fileName":"ref-validator-debug.log"}]}
{"msg":"is this easily reproducible @arsulegai ?","username":"jsmitchell","ts":"2019-07-22T16:37:52.413Z"}
{"msg":"try adding a log line to https://github.com/hyperledger/sawtooth-core/blob/master/validator/src/journal/block_scheduler.rs#L195","username":"jsmitchell","ts":"2019-07-22T16:38:36.869Z"}
{"msg":"to see when the processing and pending queues are modified for the missing block","username":"jsmitchell","ts":"2019-07-22T16:39:28.145Z"}
{"msg":"Before the PoET patch, we could make out this happened seeing either the stalled network or KeyError issue. But now difficult to know for which block it happens, but yes it happens always","username":"arsulegai","ts":"2019-07-22T16:39:35.116Z"}
{"msg":"Quick question: https://github.com/hyperledger/sawtooth-core/blob/0e5f143fcfff7046d3647a042861b46b19ebc9b3/validator/src/journal/block_scheduler.rs#L197 what is in this list?","username":"arsulegai","ts":"2019-07-22T16:43:54.167Z"}
{"msg":"It's not obvious to me that this is the right place to log for the update to the block status store (the thing that's returning Unknown), but I think this is it: https://github.com/hyperledger/sawtooth-core/blob/master/validator/src/journal/block_validator.rs#L372","username":"jsmitchell","ts":"2019-07-22T16:46:00.390Z"}
{"msg":"it looks like a list of the immediate children of that block","username":"jsmitchell","ts":"2019-07-22T16:50:45.361Z"}
{"msg":"(in the case of forks, there could be multiple immediate children)","username":"jsmitchell","ts":"2019-07-22T16:50:58.808Z"}
{"msg":"that pending.remove doesn't seem right though....","username":"jsmitchell","ts":"2019-07-22T16:51:46.764Z"}
{"msg":"https://github.com/hyperledger/sawtooth-core/blob/0e5f143fcfff7046d3647a042861b46b19ebc9b3/validator/src/journal/block_scheduler.rs#L202","username":"jsmitchell","ts":"2019-07-22T16:51:56.048Z"}
{"msg":"it's returning the list of ready blocks","username":"jsmitchell","ts":"2019-07-22T16:53:30.111Z"}
{"msg":"which ends up here: https://github.com/hyperledger/sawtooth-core/blob/0e5f143fcfff7046d3647a042861b46b19ebc9b3/validator/src/journal/block_validator.rs#L341","username":"jsmitchell","ts":"2019-07-22T16:54:08.533Z"}
{"msg":"which goes over these channels","username":"jsmitchell","ts":"2019-07-22T16:56:30.298Z"}
{"msg":"Should they be added to processing before sent?","username":"arsulegai","ts":"2019-07-22T17:02:50.889Z"}
{"msg":"i'm not sure I understand the semantics of those different queues","username":"jsmitchell","ts":"2019-07-22T17:04:49.495Z"}
{"msg":"but, it does seem like the status of the dependent blocks is lost when done() is called and those dependent blocks are removed from pending","username":"jsmitchell","ts":"2019-07-22T17:06:08.264Z"}
{"msg":"at least while they are on these channels","username":"jsmitchell","ts":"2019-07-22T17:07:53.681Z"}
{"msg":"These channels are for block validation right?","username":"arsulegai","ts":"2019-07-22T17:09:38.562Z"}
{"msg":"Looking at those log traces and the code traces, I think the descendant blocks before sent for validation shall be added to processing queue","username":"arsulegai","ts":"2019-07-22T17:12:21.083Z"}
{"msg":"We remove blocks from pending -> consider them to be ready for processing -> miss out adding them to processing queue!","username":"arsulegai","ts":"2019-07-22T17:13:56.416Z"}
{"msg":"@pschwarz do you understand the intent behind this processing queue?","username":"jsmitchell","ts":"2019-07-22T17:14:08.227Z"}
{"msg":"@pschwarz do you understand the intent behind this processing ~queue~ list?","username":"jsmitchell","ts":"2019-07-22T17:14:08.227Z"}
{"msg":"Taking Z, A, B, C, D examples I posted earlier","username":"arsulegai","ts":"2019-07-22T17:22:32.565Z"}
{"msg":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=FoTKYXaz6EMjYLrcS","username":"arsulegai","ts":"2019-07-22T17:22:44.096Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=FoTKYXaz6EMjYLrcS","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=FoTKYXaz6EMjYLrcS","remote":true,"fileId":null,"fileName":null}]}
{"msg":"When Z is done processing and passes validation.. A is removed from the pending queue","username":"arsulegai","ts":"2019-07-22T17:23:06.007Z"}
{"msg":"D arrives, doesn't know A's status yet","username":"arsulegai","ts":"2019-07-22T17:23:16.736Z"}
{"msg":"Where as A was silently sent to validate earlier, now because of D the block A is again added to processing queue","username":"arsulegai","ts":"2019-07-22T17:25:53.656Z"}
{"msg":"Continuing this, if A completed validation process before the processing queue is processed further, the issue would have been masked","username":"arsulegai","ts":"2019-07-22T17:37:19.627Z"}
{"msg":"What we see is that block A was added to processing already (sent for validation) before that","username":"arsulegai","ts":"2019-07-22T17:38:16.570Z"}
{"msg":"@arsulegai we think we have a fix for this. @pschwarz is building/running tests and we'll probably try to get a build in an LR environment tomorrow.","username":"jsmitchell","ts":"2019-07-22T21:26:08.645Z"}
{"msg":"Cool! Could you please keep me in synch when the PR is ready?","username":"arsulegai","ts":"2019-07-22T23:22:52.900Z"}
{"msg":"Here's the PR: https://github.com/hyperledger/sawtooth-core/pull/2217","username":"pschwarz","ts":"2019-07-23T16:25:57.246Z"}
{"msg":"Is the scenario where processing queue already has that block taken care?","username":"arsulegai","ts":"2019-07-23T17:36:45.054Z"}
{"msg":"No, because it wouldn't be in the descendent block list","username":"pschwarz","ts":"2019-07-23T18:21:32.315Z"}
{"msg":"They can't be in processing if they have an ancestor that hasn't been processed yet","username":"pschwarz","ts":"2019-07-23T18:22:53.320Z"}
{"msg":"Right","username":"arsulegai","ts":"2019-07-24T02:27:26.928Z"}
{"msg":"@arsulegai do you have log examples of this delay in processing/notification you were talking about? Do they still happen on a build with PR 2217?","username":"jsmitchell","ts":"2019-07-24T14:26:21.072Z"}
{"msg":"We didn't disturb our earlier LR setup, it's going on for now way beyond LR7. I will see if we can squeeze in another setup to run a LR with PR 2217.","username":"arsulegai","ts":"2019-07-24T14:30:55.354Z"}
{"msg":"About the log example from earlier runs, let me check if I have one available to share","username":"arsulegai","ts":"2019-07-24T14:31:48.378Z"}
{"msg":"","username":"arsulegai","ts":"2019-07-24T14:59:05.815Z","attachments":[{"type":"file","title":"gaia-desktop-validator-debug.log","title_link":"/file-upload/Z8ci6NthFaATj86fx/gaia-desktop-validator-debug.log","url":"/file-upload/Z8ci6NthFaATj86fx/gaia-desktop-validator-debug.log","remote":false,"fileId":"Z8ci6NthFaATj86fx","fileName":"gaia-desktop-validator-debug.log"}]}
{"msg":"is there a timestamp in particular?","username":"jsmitchell","ts":"2019-07-24T15:02:30.226Z"}
{"msg":"Interesting timestamps: A block passed validation at 14:58:17.193 the next one was at 15:08:48.405","username":"arsulegai","ts":"2019-07-24T15:05:28.609Z"}
{"msg":"Another: a block passed validation at 15:16:38.865 and the next one was at 15:25:30.995","username":"arsulegai","ts":"2019-07-24T15:06:56.820Z"}
{"msg":"have you done any inspection of what the poet timers were in these cases?","username":"jsmitchell","ts":"2019-07-24T15:07:31.398Z"}
{"msg":"we've seen cases where all the nodes will get quite unlucky and you'll get 5+ minute inter block times ","username":"jsmitchell","ts":"2019-07-24T15:08:13.491Z"}
{"msg":"There was a case where one validator got away from rest of the network, it started producing longer wait times. This in SIM mode","username":"arsulegai","ts":"2019-07-24T15:08:36.973Z"}
{"msg":"Yes, I have seen cases of longer wait times","username":"arsulegai","ts":"2019-07-24T15:09:18.361Z"}
{"msg":"It's been a week or so since I last checked it, but there was a case where PoET completed the block creation process. It's now waiting for BLOCK NEW from the validator, it however didn't receive one for a long time (6~7 min)","username":"arsulegai","ts":"2019-07-24T15:10:45.984Z"}
{"msg":"ok, if you can find one of those instances, please point it out in the logs","username":"jsmitchell","ts":"2019-07-24T15:11:08.476Z"}
{"msg":"I don't recall which log file was that, but observation that time was I saw many validator-validator re-connection traces.","username":"arsulegai","ts":"2019-07-24T15:11:50.770Z"}
{"msg":"Did the team over there start a LR with this patch?","username":"arsulegai","ts":"2019-07-24T15:12:40.541Z"}
{"msg":"yeah","username":"jsmitchell","ts":"2019-07-24T15:13:50.616Z"}
{"msg":"no instances of rescheduling already scheduled blocks","username":"jsmitchell","ts":"2019-07-24T15:14:05.180Z"}
{"msg":"What are the config settings for PoET for the run?","username":"arsulegai","ts":"2019-07-24T15:16:47.982Z"}
{"msg":"10 nodes, 10 tps intkey, and I'm guessing 30 second target_wait_time and 300 second initial_wait_time","username":"jsmitchell","ts":"2019-07-24T15:17:30.129Z"}
{"msg":"That's great, the only reason we made it 10 second target_wait_time with 200 as max_batches_per_block was to avoid long gap between two block validations","username":"arsulegai","ts":"2019-07-24T15:18:33.877Z"}
{"msg":"BTW for the validator logs which I posted, here's the trace from PoET which shows that there's 5 min between block finalization and CONSENSUS NEW BLOCK event","username":"arsulegai","ts":"2019-07-24T15:19:15.463Z"}
{"msg":"[15:03:29.201 [MainThread] engine INFO] Published block 84eb268d69288fabd79e43ea2e183573178ab207e32b2ad959d37945c94fa74b5114720f233a626a68e71972a586937baa609f388d1777df68a5bbaa574604ce\n[15:08:49.421 [MainThread] engine DEBUG] Received message: CONSENSUS_NOTIFY_BLOCK_NEW","username":"arsulegai","ts":"2019-07-24T15:19:30.897Z"}
{"msg":"PoET wait timer value is reasonable. It's around 40~50 seconds for the blocks around this time.","username":"arsulegai","ts":"2019-07-24T15:20:33.524Z"}
{"msg":"it's a distribution","username":"jsmitchell","ts":"2019-07-24T15:21:07.265Z"}
{"msg":"A question, because I wasn't there earlier. How did we arrive at the time 30sec target_wait_time and 300sec initial_wait_time? Why not just any random time? Were there differences in the behavior with size of the network and time values?","username":"arsulegai","ts":"2019-07-24T15:25:57.314Z"}
{"msg":"math + experience","username":"jsmitchell","ts":"2019-07-24T15:47:55.907Z"}
{"msg":"10 second target wait time is going to cause a lot of forks","username":"jsmitchell","ts":"2019-07-24T15:48:06.637Z"}
{"msg":"you are shifting the random distribution such that it makes it highly likely that two or more validators will publish what they think are winning blocks within the block validation duration","username":"jsmitchell","ts":"2019-07-24T15:48:47.354Z"}
{"msg":"Hmm","username":"arsulegai","ts":"2019-07-24T15:50:19.226Z"}
{"msg":"@rberg2 @rbuysse I'm close to calling for FCP on https://github.com/hyperledger/sawtooth-rfcs/pull/45 but would like your reviews first.","username":"Dan","ts":"2019-07-24T15:57:23.258Z"}
{"msg":"Hello all,\n\nI was working on a tool and it helped me in analyzing logs faster.\nThe tool specifically is for the log analysis of those software that are state machine based.\n\n*For example:*\n1. To check if consensus engine is working as expected, if it is handling all the blocks gracefully, if all the responses from validator received at the consensus engine.\n2. The case which we just solved (sending duplicate blocks to the consensus engine). Identify which blocks are validated twice and sent to consensus engine, without peeping into huge log files.\n\nHere's  the GitHub link for the tool https://github.com/arsulegai/state-checker\nI welcome feedback from you","username":"arsulegai","ts":"2019-07-24T16:17:03.225Z"}
{"msg":"Also, I see @Dan has debug tools specifically designed for the PoET. It would be nice to have all such tools listed in a place. I request you to share your ways of debugging or the tools you have which can help to move things faster.","username":"arsulegai","ts":"2019-07-24T16:20:34.115Z"}
{"msg":"@dan I added some comments","username":"rbuysse","ts":"2019-07-24T16:32:41.964Z"}
{"msg":"@danintel looks like a couple minor things to update and then I can motion for FCP.","username":"Dan","ts":"2019-07-24T16:53:13.278Z"}
{"msg":"@arsulegai @Dan I think there might be an issue with poet-engine and timely evaluation of candidate blocks on a network where one node is trying to catch up","username":"jsmitchell","ts":"2019-07-24T16:57:16.844Z"}
{"msg":"it's something you should see if you can track down","username":"jsmitchell","ts":"2019-07-24T16:58:16.262Z"}
{"msg":"looking at the poet engine logs for a node that is about 10 blocks back, it seems to regularly attempt to build a competitive block and then win on lower wait timers vs the 'legitimate' blocks. Eventually aggregate local mean flips it back the other way. What I would expect to see is rapid evaluation of the sequence of legitimate blocks which would abort local publishing.","username":"jsmitchell","ts":"2019-07-24T17:00:33.842Z"}
{"msg":"@Dan OK. New suggestions keep on coming in","username":"danintel","ts":"2019-07-24T17:23:05.768Z"}
{"msg":"@jsmitchell Yes, I remember such sequence of events happening. Is the node catch-up causing block validation slow, and others are not publishing because they're either catching up or end up resolving forks?","username":"arsulegai","ts":"2019-07-24T17:24:33.738Z"}
{"msg":"The others are all in consensus and continue to publish blocks","username":"jsmitchell","ts":"2019-07-24T17:34:50.271Z"}
{"msg":"We think the 'validate before notify' requirement of poet are probably resulting in a cpu bottleneck in validation which is resulting in late notification to the engine","username":"jsmitchell","ts":"2019-07-24T17:36:12.223Z"}
{"msg":"and of course, the engine decides it should keep publishing, which exacerbates the issue","username":"jsmitchell","ts":"2019-07-24T17:36:29.675Z"}
{"msg":"@danintel yes, one of the tricks for us to work out with the RFC process is to compress the feedback cycle. I think the last time I checked I had something like 40 PRs to review (not sure how many of those were RFCs), so it can be tough for everyone to prioritize the same issue at the same time. It's probably a good practice for the RFC champion to pick the two or three most relevant reviewers and try to get their review early on. That way the most substantial changes are up front and the rest of the reviews are more stable. In this case I should have thought to ping the folks who have been most involved in the docker files earlier on in the process.","username":"Dan","ts":"2019-07-24T17:48:44.425Z"}
{"msg":"PoET 2 doesn't have such constraint as far as I know, what's that in PoET 1 which expects 'validate before notify'?","username":"arsulegai","ts":"2019-07-24T18:06:21.633Z"}
{"msg":"Consensus depends on state","username":"jsmitchell","ts":"2019-07-24T19:31:50.068Z"}
{"msg":"Settings, registry, etc.","username":"jsmitchell","ts":"2019-07-24T19:31:59.650Z"}
{"msg":"I'm pretty sure poet2 would be in the same situation","username":"jsmitchell","ts":"2019-07-24T19:38:06.454Z"}
{"msg":"@Dan The original review was on Google Docs, which worked well. The follow-on comments continued with the PR, which I did not expect. They were good comments, but I wish they were submitted early on in the process. Maybe if I guessed who I could ping, that would have worked better.","username":"danintel","ts":"2019-07-24T22:07:36.297Z"}
{"msg":"@jsmitchell that makes it register if need to block publish. Is that what you meant by validate before notify?\n\nUnless the block is committed, the state values wouldn't be updated right?","username":"arsulegai","ts":"2019-07-25T00:23:47.287Z"}
{"msg":"@jsmitchell I still failed to understand why a block needs to be validated before notify. It can still be done when consensus engine tells that block is valid.\n\nUnless the block is committed, the state values wouldn't be updated right? So consensus cannot depend on values set in current block.","username":"arsulegai","ts":"2019-07-25T00:23:47.287Z"}
{"msg":"At a minimum, the prior block needs to be evaluated and the new state root set so that the new block can be evaluated correctly. For example, a transaction in the prior block may register the signer of the new block in the validator registry, which allows the current block’s consensus payload to be evaluated correctly.","username":"jsmitchell","ts":"2019-07-25T00:42:39.512Z"}
{"msg":"Correct that will help in speeding up block validation without waiting for consensus engine. At consensus engine end the registration information is considered only after block commit (in PoET when VR TP writes the global state). Early validation helps in utilising free time at validator end. For example, if there are forks at same height then consensus engine becomes bottleneck because it'll serialise the way blocks are validated. But there's no strict mandate for early validation from consensus engine still.","username":"arsulegai","ts":"2019-07-25T01:49:07.340Z"}
{"msg":"hello all! i would like know whether any remote attestation happening in SGX POET consensus or not?!","username":"anandakumar.n","ts":"2019-07-25T06:41:18.609Z"}
{"msg":"remote attestation","username":"anandakumar.n","ts":"2019-07-25T06:42:35.517Z"}
{"msg":"Yes. Poet has 2 modes. 1 is simulated and makes no TEE calls. The other is an SGX implementation. You can see some of the sgx calls here: https://github.com/hyperledger/sawtooth-poet/blob/master/sgx/sawtooth_poet_sgx/libpoet_enclave/poet_enclave.cpp","username":"Dan","ts":"2019-07-25T15:17:55.096Z"}
{"msg":"and the calls to the attestation service here:\nhttps://github.com/hyperledger/sawtooth-poet/tree/master/ias_client","username":"Dan","ts":"2019-07-25T15:18:28.830Z"}
{"msg":"Can we have a nightly docker image pushed for 1-2 branch until it's released?","username":"arsulegai","ts":"2019-07-25T16:05:21.585Z"}
{"msg":"@arsulegai we could tag a new component release - which docker image?","username":"amundson","ts":"2019-07-25T21:49:29.246Z"}
{"msg":"The validator","username":"arsulegai","ts":"2019-07-26T00:19:20.480Z"}
{"msg":"there are chime tagged docker images for all components right now. ","username":"rbuysse","ts":"2019-07-26T14:31:23.231Z"}
{"msg":"I'll create a story for doing chime nightlies.","username":"rbuysse","ts":"2019-07-26T14:31:34.425Z"}
{"msg":"Thanks","username":"arsulegai","ts":"2019-07-26T14:49:44.050Z"}
{"msg":"Has joined the channel.","username":"SethiSaab","ts":"2019-07-29T14:07:57.730Z","type":"uj"}
{"msg":"Hi Team ,\n\ni am currently working on a Transaction Addressing scheme.\n\nAs per my understanding  we need to addressing and namespace technique for get and set data.\n\nNow say I have 10 attributes and i want to craete a query which give me result of same transaction ,doesnt matter which parameter i use.\n\nHow Should i Do that ?\n\nAnd how will this work in case i have an attribute of array type ","username":"SethiSaab","ts":"2019-07-29T14:11:48.092Z"}
{"msg":"Hi SethiSaab - your question is more targeted towards the general #sawtooth channel, which is a user channel.  This channel is for platform development.","username":"pschwarz","ts":"2019-07-29T15:18:04.114Z"}
{"msg":"Has joined the channel.","username":"jamesbarry","ts":"2019-07-31T16:24:10.111Z","type":"uj"}
{"msg":"Has joined the channel.","username":"ArpanNag","ts":"2019-08-05T14:16:49.508Z","type":"uj"}
{"msg":"@jsmitchell Could you please update status of PoET tests done from your end?","username":"arsulegai","ts":"2019-08-07T16:51:14.608Z"}
{"msg":"@jsmitchell Could you please update the status of PoET tests done from your end?","username":"arsulegai","ts":"2019-08-07T16:51:14.608Z"}
{"msg":"I would like to join the debug/analysis on this issue pointed out here https://chat.hyperledger.org/channel/sawtooth-governance?msg=H9wZ9eRj9QziZWu9w","username":"arsulegai","ts":"2019-08-08T04:53:10.425Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-governance?msg=H9wZ9eRj9QziZWu9w","url":"https://chat.hyperledger.org/channel/sawtooth-governance?msg=H9wZ9eRj9QziZWu9w","remote":true,"fileId":null,"fileName":null}]}
{"msg":"In our runs, PoET-SGX did not fork unlike PoET-SIM for the same settings. PoET-SIM too didn't fork much with changed config values. So, I am currently looking into generated wait time values and the functionality around it. This to make sure block creation is not blocked because of consensus engine.","username":"arsulegai","ts":"2019-08-08T04:56:59.281Z"}
{"msg":"initially, @rberg2 is running an additional set of LR tests to try and determine if it is a regression or not","username":"amundson","ts":"2019-08-08T14:30:04.605Z"}
{"msg":"one working theory suggests that the bug is not new, but the CPU pressure points have changed and we are seeing an existing issue manifest itself in a way that it did not previously; but, we are running the tests to first compare with 1.1 behavior with the same settings and environment","username":"amundson","ts":"2019-08-08T14:32:43.068Z"}
{"msg":"in particular, that the extra work the validator does during fork resolution (working on invalid forks) is at the heart of the problem","username":"amundson","ts":"2019-08-08T14:33:32.432Z"}
{"msg":"since PBFT doesn't use forking, we don't see the issue there at all","username":"amundson","ts":"2019-08-08T14:34:05.376Z"}
{"msg":"to fix that, we would have to make PoET a bit smarter so that it is nearly always working on the valid fork","username":"amundson","ts":"2019-08-08T14:35:50.702Z"}
{"msg":"the core issue there is that, during fork resolution, you need to have calculated the PoET settings for the previous block. so if we optimize for the fact that those settings rarely change, that should have a substantial impact on being able to select the right fork without always running through all the transactions for every block prior to fork resolution","username":"amundson","ts":"2019-08-08T14:39:01.630Z"}
{"msg":"that is one of many ideas","username":"amundson","ts":"2019-08-08T14:39:59.948Z"}
{"msg":"first we need to try and determine if we can cause the issue to reliably occur, so we can iterate on a fix","username":"amundson","ts":"2019-08-08T14:40:50.723Z"}
{"msg":"@arsulegai do you actually have PoET-SGX working with 1.2?","username":"amundson","ts":"2019-08-08T14:41:56.062Z"}
{"msg":"Yes, there's LR1 pass report. That was when we were trying with different config options for PoET-SIM before the duplicate block schedule fix in the validator.","username":"arsulegai","ts":"2019-08-08T15:27:39.230Z"}
{"msg":"The time spent by the Validator in validating blocks which could eventually end up in a fork that won't grow, can be reduced","username":"arsulegai","ts":"2019-08-11T14:01:51.474Z"}
{"msg":"Here's an idea - Currently the Validator executes/validates the block before sending to the consensus engine.\n1. The idea is that the Validator would send the block to the consensus engine as it receives. Do simultaneously send for processing if there's thread available.\n2. Consensus engine (PoET for example) does validate the consensus field in the block\n3. PoET then also applies a partial fork resolution (at least to rule out cases where a block has no chance of getting committed). Other consensus engines can do their respective validations as well.","username":"arsulegai","ts":"2019-08-11T14:06:10.315Z"}
{"msg":"Here's an idea - Currently the Validator executes/validates the block before sending to the consensus engine.\n1. The idea is that the Validator would send the block to the consensus engine as it receives. Do simultaneously send for processing if there's thread available.\n2. Consensus engine (PoET for example) does validate the consensus field in the block\n3. PoET then also applies a partial fork resolution (at least to rule out cases where a block has no chance of getting committed). Other consensus engines can do their respective validations as well.\n4. The Validator then can decide to either wait for the block to complete processing or remove it from the scheduler based on the response from consensus engine.\n5. If the block is valid, it's told to the consensus engine.\n6. Consensus engine then can proceed whether to commit or ignore the block. In case of PoET the actual fork resolution or remaining part of the fork resolution.","username":"arsulegai","ts":"2019-08-11T14:06:10.315Z"}
{"msg":"This may improve the performance, but has design change in both the Validator and the PoET","username":"arsulegai","ts":"2019-08-11T14:08:56.262Z"}
{"msg":"We can think of this post 1-2 release if not now","username":"arsulegai","ts":"2019-08-11T14:10:45.696Z"}
{"msg":"we are thinking roughly along those lines @arsulegai ","username":"jsmitchell","ts":"2019-08-12T15:17:45.142Z"}
{"msg":"poet consensus validation depends on state (settings and validator registry), so we can't blindly process payloads","username":"jsmitchell","ts":"2019-08-12T15:18:29.948Z"}
{"msg":"an optimization would be determining whether a given block contains a relevant consensus state-impacting transaction. If a chain of blocks for evaluation doesn't contain those, then the consensus payloads can be quickly evaluated with block validation occurring after the fact as a required async step. If a block didn't validate, that would require the consensus engine to pick a next best fork for evaluation. This should result in minimum effort for fork resolution.","username":"jsmitchell","ts":"2019-08-12T15:21:33.654Z"}
{"msg":"But that is a future step. First, we are going to change the block validation state model to notify consensus before the block is validated (as the design intends), which will give the consensus engine additional knowledge regarding the work outstanding. This will allow it _not to publish_ competitive blocks.","username":"jsmitchell","ts":"2019-08-12T15:23:38.400Z"}
{"msg":"That sounds ok to me, to start with I will consider the possible optimization in PoET2. If the testing goes well, will discuss about backporting it to current PoET.","username":"arsulegai","ts":"2019-08-12T15:30:01.027Z"}
{"msg":"Has joined the channel.","username":"Heena078","ts":"2019-08-19T12:18:09.355Z","type":"uj"}
{"msg":"Hi. In other news we have open sourced our DAML on Sawtooth implementation - https://github.com/blockchaintp/daml-on-sawtooth","username":"duncanjw","ts":"2019-08-20T11:00:47.471Z"}
{"msg":"It’s early days and we still have to formally create an RFC and see if the sawtooth community is interested in us contributing this to the upstream project","username":"duncanjw","ts":"2019-08-20T11:01:55.139Z"}
{"msg":"Please direct technical questions to @kodonnel ","username":"duncanjw","ts":"2019-08-20T11:04:48.760Z"}
{"msg":"@LeonardoCarvalho ^","username":"arsulegai","ts":"2019-08-20T12:42:16.613Z"}
{"msg":"Yeah, I'm restarting to develop my SDK flavor. :) ","username":"LeonardoCarvalho","ts":"2019-08-21T11:52:33.209Z"}
{"msg":"Good morning. I've noticed an odd little race that I can reproduce in the test_config_smoke test","username":"wkatsak","ts":"2019-08-22T14:59:47.446Z"}
{"msg":"Im debugging a patch that adds approximately 500ms to the validator's socket setup() function (a hostname query to determine if a host uses ipv6)","username":"wkatsak","ts":"2019-08-22T15:00:42.679Z"}
{"msg":"when this patch is in place, the test_config_smoke will hang","username":"wkatsak","ts":"2019-08-22T15:00:59.765Z"}
{"msg":"if i remove the line in question ,it passes","username":"wkatsak","ts":"2019-08-22T15:01:09.262Z"}
{"msg":"if i add a time.sleep(0.4), it also hangs","username":"wkatsak","ts":"2019-08-22T15:01:18.945Z"}
{"msg":"O'","username":"wkatsak","ts":"2019-08-22T15:01:22.401Z"}
{"msg":"I'm thinking this might be a docker-compose race, but im noticing that none of the devmode entries in the tests have any dependency listed","username":"wkatsak","ts":"2019-08-22T15:02:06.586Z"}
{"msg":"has anyone noticed this or thought about this?","username":"wkatsak","ts":"2019-08-22T15:02:16.317Z"}
{"msg":"If i add a sleep 2.0 to the devmode command line, it works fine.","username":"wkatsak","ts":"2019-08-22T15:08:40.903Z"}
{"msg":"Obviously, i can change the way my patch works to not slow down, but this seems like something that should be checked. It seems like if the consensus comes online too soon (before the validator is ready) something funky happens.","username":"wkatsak","ts":"2019-08-22T15:09:46.476Z"}
{"msg":"Are you using the published devmode or are you using devmode nightly?","username":"pschwarz","ts":"2019-08-22T15:32:12.992Z"}
{"msg":"nightly","username":"wkatsak","ts":"2019-08-22T15:35:31.410Z"}
{"msg":"im running the smoketest on master","username":"wkatsak","ts":"2019-08-22T15:35:39.955Z"}
{"msg":"You can see this if you look at my pull request for IPv6 (https://github.com/hyperledger/sawtooth-core/pull/2093), the current version was just rebased to master.","username":"wkatsak","ts":"2019-08-22T15:38:30.775Z"}
{"msg":"run `bin/run_docker_test test_config_smoke`","username":"wkatsak","ts":"2019-08-22T15:39:17.557Z"}
{"msg":"The odd thing is that I do see the validator output the line about registering the devmode","username":"wkatsak","ts":"2019-08-22T15:40:43.170Z"}
{"msg":"but it still freezes","username":"wkatsak","ts":"2019-08-22T15:40:55.996Z"}
{"msg":"if i go into the devmode container and start an instance manually, the test finishes","username":"wkatsak","ts":"2019-08-22T15:41:04.924Z"}
{"msg":"and if i add that sleep mentioned to compose, it also works fine","username":"wkatsak","ts":"2019-08-22T15:41:17.359Z"}
{"msg":"@wkatsak yeah, sounds like a bug. the desired behavior is that startup order of the processes doesn't matter. (except, tests run after everything is ready for the test)","username":"amundson","ts":"2019-08-22T16:23:38.241Z"}
{"msg":"That's why I asked about versions - there was a fix in devmode master/nightly that should fix that issue","username":"pschwarz","ts":"2019-08-22T16:25:14.234Z"}
{"msg":"recently?","username":"amundson","ts":"2019-08-22T16:26:48.690Z"}
{"msg":"Looks like it's using `hyperledger/sawtooth-devmode-engine-rust:nightly`","username":"pschwarz","ts":"2019-08-22T16:26:51.316Z"}
{"msg":"So, yes, it is a bug","username":"pschwarz","ts":"2019-08-22T16:26:56.414Z"}
{"msg":"(Unless a nightly for devmode hasn't been pushed out recently)","username":"pschwarz","ts":"2019-08-22T16:27:16.735Z"}
{"msg":"or @wkatsak has older images cached locally","username":"amundson","ts":"2019-08-22T16:27:47.060Z"}
{"msg":"Hmm. That could be. I’ll nuke my images and try again","username":"wkatsak","ts":"2019-08-22T17:08:49.505Z"}
{"msg":"@amundson @pschwarz This issue still appears with latest devmode nightly","username":"wkatsak","ts":"2019-08-23T13:49:03.161Z"}
{"msg":"I removed the reason my patch triggerd it, but the underlying issue is still there.","username":"wkatsak","ts":"2019-08-23T13:49:27.656Z"}
{"msg":"*triggered","username":"wkatsak","ts":"2019-08-23T13:49:32.570Z"}
{"msg":"@pschwarz the hyperledger/sawtooth-devmode-engine-rust:nightly image is 1.2.3-dev13 which is the latest build","username":"rbuysse","ts":"2019-08-23T14:35:39.565Z"}
{"msg":"REMINDER: The Hyperledger Sawtooth Contributor Meeting will be on Monday, August 26th at 10am CDT. \n\nThe meeting information can be found on the Hyperledger Community Meetings Calendar located here: https://wiki.hyperledger.org/display/HYP/Calendar+of+Public+Meetings\nHere is the direct zoom link: https://zoom.us/j/438462056\n\nThere is still time to add items to the agenda for this meeting. If you have an appropriate topic you would like to discuss and facilitate, please add it to the agenda, located in \nthe wiki here: https://wiki.hyperledger.org/pages/viewpage.action?pageId=16325305\n\nLooking forward to seeing everyone there!\n-Mark","username":"mfford","ts":"2019-08-24T21:28:17.090Z"}
{"msg":"Thanks for the update on root causing the 1.2 regression.  Sorry I lost signal just as you answered and wasn’t able to acknowledge but it was very encouraging to hear things are going better","username":"JonGeater","ts":"2019-08-26T15:26:43.648Z"}
{"msg":"It was fun to figure out","username":"jsmitchell","ts":"2019-08-26T16:10:31.317Z"}
{"msg":"\"fun\"","username":"jsmitchell","ts":"2019-08-26T16:10:41.196Z"}
{"msg":"Is there a spec for the test net nodes (in the form of a helm  chart or docker file or something)?  I may be able to add a node and some useful workload","username":"JonGeater","ts":"2019-08-26T16:11:01.386Z"}
{"msg":"I really agree with what was said about the depth of testing needed to get something from 'working' to 'good enough' to 'ready'","username":"JonGeater","ts":"2019-08-26T16:11:42.467Z"}
{"msg":"That's what I want to happen","username":"JonGeater","ts":"2019-08-26T16:12:20.137Z"}
{"msg":"@rberg2 @rbuysse ^","username":"jsmitchell","ts":"2019-08-26T16:13:04.070Z"}
{"msg":"The test net works are run on AWS nodes using the deb packages installed directly, no docker or helm involved.","username":"rberg2","ts":"2019-08-26T16:43:11.866Z"}
{"msg":"Thanks @rberg2.  Is there a script then, or some recipe to ensure the right configuration and ","username":"JonGeater","ts":"2019-08-26T16:55:02.943Z"}
{"msg":"Thanks @rberg2.  Is there a script then, or some recipe to ensure the right configuration and experiments are run in all places?  Sorry for the very elementary questions, just seeking whether it's feasible for me and my team to help here","username":"JonGeater","ts":"2019-08-26T16:55:02.943Z"}
{"msg":"We have some ansible plays that setup these networks, I will look into sharing those.","username":"rberg2","ts":"2019-08-26T17:50:47.823Z"}
{"msg":"Ah great, thanks.  That would work","username":"JonGeater","ts":"2019-08-26T22:24:52.443Z"}
{"msg":"Has joined the channel.","username":"sanket1211","ts":"2019-09-04T13:35:07.795Z","type":"uj"}
{"msg":"hey guys, do we got a mock validator in any language?","username":"LeonardoCarvalho","ts":"2019-09-25T11:42:44.885Z"}
{"msg":"Is it for the unit test cases?","username":"arsulegai","ts":"2019-09-25T13:49:48.969Z"}
{"msg":"yup","username":"LeonardoCarvalho","ts":"2019-09-25T20:53:18.846Z"}
{"msg":"Has joined the channel.","username":"MHBauer","ts":"2019-10-05T02:08:25.780Z","type":"uj"}
{"msg":"https://docs.google.com/document/d/12ce5XjmNdMF647mk2IyWdyz1mYPEA7MtCrfpKQw0t3c/edit#heading=h.2y5gwh60nerk","username":"jsmitchell","ts":"2019-10-09T17:40:55.419Z"}
{"msg":"working doc for options of aries DID/VCs as an identity source for sawtooth/transact ^","username":"jsmitchell","ts":"2019-10-09T17:41:21.681Z"}
{"msg":"@jsmitchell drinking Nathan's koolaide?","username":"amundson","ts":"2019-10-09T17:42:39.325Z"}
{"msg":"@jsmitchell drinking the koolaide?","username":"amundson","ts":"2019-10-09T17:42:39.325Z"}
{"msg":"heh","username":"jsmitchell","ts":"2019-10-09T17:42:54.653Z"}
{"msg":"I think that's very cool","username":"amundson","ts":"2019-10-09T17:43:21.528Z"}
{"msg":"hello all","username":"LeonardoCarvalho","ts":"2019-10-15T10:38:13.186Z"}
{"msg":"I am dealing with a embarrassingly simple problem, and could use some help","username":"LeonardoCarvalho","ts":"2019-10-15T10:38:56.506Z"}
{"msg":"my Java TP is sending the setState messages ok, I get the OK from the validator","username":"LeonardoCarvalho","ts":"2019-10-15T10:39:30.213Z"}
{"msg":"but the rust validator, in parallel mode, crashes hard after sending the first sequence of transations","username":"LeonardoCarvalho","ts":"2019-10-15T10:40:19.753Z"}
{"msg":"the pattern is, I send any number of INT TP transactions","username":"LeonardoCarvalho","ts":"2019-10-15T10:40:44.843Z"}
{"msg":"the got accepted","username":"LeonardoCarvalho","ts":"2019-10-15T10:40:51.567Z"}
{"msg":"I get `DEBUG    scheduler_parallel] Removed N incomplete batches from the schedule`","username":"LeonardoCarvalho","ts":"2019-10-15T10:41:15.843Z"}
{"msg":"and after that, a rust stack trace about timeout","username":"LeonardoCarvalho","ts":"2019-10-15T10:41:31.657Z"}
{"msg":"The image is sawtooth-devmode-engine-rust:1.2","username":"LeonardoCarvalho","ts":"2019-10-15T10:42:09.159Z"}
{"msg":"others are at 1.3 level","username":"LeonardoCarvalho","ts":"2019-10-15T10:42:15.081Z"}
{"msg":"any ideas on what can be missing ?","username":"LeonardoCarvalho","ts":"2019-10-15T10:42:24.360Z"}
{"msg":"Is the issue happening only in parallel scheduling mode?\nIf all the transactions are getting removed then there's probably mismatch in TP's name/version from what is sent by the client. @agunde has a pending PR to fix the TP timeout error. You could be facing the same issue.","username":"arsulegai","ts":"2019-10-15T12:28:28.137Z"}
{"msg":"I doubt, the python code works well, I think I simply forgot to send something back after the set operation...","username":"LeonardoCarvalho","ts":"2019-10-15T21:25:25.694Z"}
{"msg":"But I will take a look at the timeout ticket, thanks!","username":"LeonardoCarvalho","ts":"2019-10-15T21:25:39.116Z"}
{"msg":"nothing like a good sleep night. I was swallowing TP_PROCESS_RESPONSES on my flows. Duh.","username":"LeonardoCarvalho","ts":"2019-10-16T10:18:51.615Z"}
{"msg":"well, they are sent back, but no dice yet. Even in serial mode. I must be messing another part of the messages flow.","username":"LeonardoCarvalho","ts":"2019-10-16T10:50:55.093Z"}
{"msg":"Please update the `Sawtooth 1.1 has been released` banner on #sawtooth ","username":"danintel","ts":"2019-10-16T23:13:48.870Z"}
{"msg":"It's removed - you have to refresh for it to take effect","username":"pschwarz","ts":"2019-10-17T14:39:20.150Z"}
{"msg":".","username":"amundson","ts":"2019-10-17T15:32:14.416Z","type":"room_changed_announcement"}
{"msg":"","username":"amundson","ts":"2019-10-17T15:32:20.372Z","type":"room_changed_announcement"}
{"msg":"rocketchat is super buggy, maybe that will help?","username":"amundson","ts":"2019-10-17T15:32:31.794Z"}
{"msg":"Is there a plan to update hyperledger/blockchain-explorer to include HL Sawtooth?","username":"arsulegai","ts":"2019-10-22T10:37:27.585Z"}
{"msg":"not that I'm aware of. if someone does start working on more explorer work, we could dig up some ui mockups of some ideas.","username":"amundson","ts":"2019-10-22T17:18:13.408Z"}
{"msg":"This could've been a good Hyperledger internship project... I see support for other projects are being added by interns. Please consider this proposal for the next internship program.","username":"arsulegai","ts":"2019-10-22T17:44:32.770Z"}
{"msg":"@arsulegai take the lead on it, you would be a good mentor","username":"amundson","ts":"2019-10-22T17:58:14.349Z"}
{"msg":"sure","username":"pschwarz","ts":"2019-10-22T18:36:13.486Z"}
{"msg":"Has joined the channel.","username":"saanvijay","ts":"2019-10-24T10:14:39.402Z","type":"uj"}
{"msg":"Has joined the channel.","username":"tuckerg","ts":"2019-10-29T08:37:38.949Z","type":"uj"}
{"msg":"Has joined the channel.","username":"Alwii","ts":"2019-10-30T07:36:22.383Z","type":"uj"}
{"msg":"I suggest that sawtooth 2.0 be written as a splinter service (splinter providing networking, circuits, etc.). I'll eventually do an RFC for this but wanted to start the discussion prior. For those not familiar with splinter, it is here - https://github.com/cargill/splinter -- it uses transact and sabre in its scabbard component which demonstrates kind of were sawtooth would fit (as a peer of scabbard).","username":"amundson","ts":"2019-11-08T15:52:19.613Z"}
{"msg":"I suggest that sawtooth 2.0 be written as a splinter service (splinter providing networking, circuits, etc.). I'll eventually do an RFC for this but wanted to start the discussion prior. For those not familiar with splinter, it is here - https://github.com/cargill/splinter -- it uses transact and sabre in its scabbard component which demonstrates kind of where sawtooth would fit (as a peer of scabbard).","username":"amundson","ts":"2019-11-08T15:52:19.613Z"}
{"msg":"Splinter is now outside Hyperledger, would that be an issue?","username":"arsulegai","ts":"2019-11-09T08:12:38.849Z"}
{"msg":"wow, that's look extremely interesting!","username":"LeonardoCarvalho","ts":"2019-11-10T15:11:26.598Z"}
{"msg":"Has joined the channel.","username":"alexhq","ts":"2019-11-12T11:31:51.895Z","type":"uj"}
{"msg":"@arsulegai I don't think so, just another dependency. we can use libsplinter to construct the validator to run it separately too.","username":"amundson","ts":"2019-11-14T22:03:55.966Z"}
{"msg":"Has joined the channel.","username":"MarcoPasotti","ts":"2019-11-19T09:37:04.233Z","type":"uj"}
{"msg":"Do we have a call today?","username":"arsulegai","ts":"2019-11-25T14:01:56.246Z"}
{"msg":"We do not. That  meeting is cancelled.","username":"mfford","ts":"2019-11-25T14:28:04.613Z"}
{"msg":"I see, thanks","username":"arsulegai","ts":"2019-11-25T15:58:37.111Z"}
{"msg":"Has joined the channel.","username":"hidura","ts":"2019-11-28T01:39:37.150Z","type":"uj"}
{"msg":"Has joined the channel.","username":"DaveBuck","ts":"2019-12-03T18:33:13.912Z","type":"uj"}
{"msg":"@amundson I am just catching this idea of Sawtooth 2.0 being a splinter service.  Would that preclude Sawtooth 2.0 from being a standalone chain or simply a means to integrate with Spinter itself?  I see uses for Sawtooth beyond shaing between entities (companies) If Sawtooth is a peer to Scabbard, would it retain its own admin and API or subrogate it to Splinter?","username":"jamesbarry","ts":"2019-12-09T18:37:38.782Z"}
{"msg":"@jamesbarry splinter would become a core piece of what is necessary to run a sawtooth validator. but, that doesn't preclude compiling libsplinter into a sawtooth-validator and running it that way. it would be more of a customized splinter daemon than anything though.","username":"amundson","ts":"2019-12-09T19:41:39.561Z"}
{"msg":"sawtooth would still have its own API (scabbard also has its own API that isn't part of the core splinter daemon, it just happens too ship with splinter)","username":"amundson","ts":"2019-12-09T19:42:24.302Z"}
{"msg":"in terms of administration, I think that might depend on how we run it. if we are running a sawtooth-validator, that can be very sawtooth-specific in terms of configuration and administration; if we are running as a sawtooth service in a generic splinter daemon, then things have to be more run-time.","username":"amundson","ts":"2019-12-09T19:44:00.955Z"}
{"msg":"in general, I think we need to move more runtime-level anyway, and less static-config. in splinter, for example, we don't determine peers until we create circuits. so it doesn't make sense to configure peers on the command line of the daemon itself, because that's part of administering the node a runtime.","username":"amundson","ts":"2019-12-09T19:45:16.965Z"}
{"msg":"@amundson Thanks for the answer.  I am assuming Splinter will not become part of Hyperledger?  I will think through the runtime vs. static admin and post some questions back.  Do you need a separate #sawtooth-slinter discussion area?  I think that the 2.0 decision once understood will generate some levels of discussion.  ","username":"jamesbarry","ts":"2019-12-09T20:05:16.103Z"}
{"msg":"@amundson We currently depend on validated static admin for our first government customer build.  Runtime level would not work for the specific needs they have, and being the first cutomer they ditact the direction we are moving....","username":"jamesbarry","ts":"2019-12-09T20:05:34.783Z"}
{"msg":"this channel should be light enough traffic to handle the discussion. re:static vs. dynamic - this would be more a concern about how we design the future sawtooth-validator daemon than splinter per-se, though there is a circuity-creation step we will need to handle. (this is not necessarily difficult, but it doesn't exist in sawtooth today)","username":"amundson","ts":"2019-12-09T20:10:25.496Z"}
{"msg":"as far as Splinter becoming a HL project, maybe -- not sure whether it would be welcome or not, and it takes a substantial amount of energy to propose a HL project either way","username":"amundson","ts":"2019-12-09T21:39:04.572Z"}
{"msg":"for those interested in the future direction of transaction processors / transaction handlers and generally smart contract APIs, there is interesting work we are doing in Transact that we anticipate being the path forward for Sawtooth as well. one such aspect is separating out the idea of 'smart contract' from 'transaction handler' (and potentially, I think renaming transaction handler to smart contract engine'. also the simplified smart contract stuff going in should make it easier to write smart contracts (providing code to do addressing for example, and trickling that into the definition of smart contract).","username":"amundson","ts":"2020-01-03T17:47:55.389Z"}
{"msg":"Has joined the channel.","username":"MatthewRubino","ts":"2020-01-21T13:53:32.014Z","type":"uj"}
{"msg":"would someone be able to tell me what might cause this error to happen? https://github.com/hyperledger/sawtooth-core/blob/master/validator/src/journal/block_validator.rs#L703-L709","username":"MatthewRubino","ts":"2020-01-21T15:04:48.536Z"}
{"msg":"@MatthewRubino what is the full error string?","username":"amundson","ts":"2020-01-21T19:22:32.333Z"}
{"msg":"@amundson something like this ```WARNING | Dummy-13:(unknown file) | [src/journal/block_validator.rs: 284] Error during block validation: BlockValidationError(\"During validate_on_chain_rules, error creating settings view: NotFound(\\\"63add5c25ce6b279fb4c91aa9d63e6929474863ad4fbf7828412461c16590ecf\\\")\")``` where the node in question is trying to sync and the state root hash is some number of blocks AFTER the current block head","username":"MatthewRubino","ts":"2020-01-21T19:36:34.679Z"}
{"msg":"@amundson something like this ```WARNING | Dummy-13:(unknown file) | [src/journal/block_validator.rs: 284] Error during block validation: BlockValidationError(\"During validate_on_chain_rules, error creating settings view: NotFound(\\\"63add5c25ce6b279fb4c91aa9d63e6929474863ad4fbf7828412461c16590ecf\\\")\")``` where the node in question is trying to sync (~1000 blocks behind; ~60k total blocks) and the state root hash is some number of blocks AFTER the current block head (<10)","username":"MatthewRubino","ts":"2020-01-21T19:36:34.679Z"}
{"msg":"@MatthewRubino \"settings view\" internally returns settings for a specific state root hash; so when you create it, it takes that state root hash. the error \"NotFound\" indicates the underlying database (lmdb) couldn't find an entry for that state root hash. usually this would get created and stored as blocks are processed, so the error is a bit strange. is it possible that there were previously io-level errors were the lmdb database is stored (like disk full maybe)?","username":"amundson","ts":"2020-01-21T23:01:29.143Z"}
{"msg":"the disk is definitely not full. in the past we did reach some IOPS limits but i thought we addressed those. there was not any atypical load on the network anyways. would the remedy be to delete the data dir? or perhaps just certain lmdb files and have it sync from scratch?","username":"MatthewRubino","ts":"2020-01-22T14:11:11.197Z"}
{"msg":"the disk is definitely not full. in the past we did reach some IOPS limits but i thought we addressed those. there was not any atypical load on the network anyways. would the remedy be to delete the data dir? or perhaps just certain lmdb files and have it sync from scratch? or is there a potential race condition bug we may have come across?","username":"MatthewRubino","ts":"2020-01-22T14:11:11.197Z"}
{"msg":"@amundson so i moved the data dir and restarted the pod. it starts to sync but then runs into the same issue with a handful of different state hashes which it then never seems to be able to get past","username":"MatthewRubino","ts":"2020-01-22T15:50:17.961Z"}
{"msg":"Has joined the channel.","username":"dock","ts":"2020-01-22T16:07:47.857Z","type":"uj"}
{"msg":"@amundson for a little more context, the state root hash in question (that the broken node can't find) can be found on it's peer nodes 2 blocks beyond it's own furthest block.","username":"dock","ts":"2020-01-22T16:07:48.697Z"}
{"msg":"what version of Sawtooth are you running? does it have any customizations?","username":"amundson","ts":"2020-01-22T20:26:56.061Z"}
{"msg":"I'm wondering if this could be caused by non-deterministic TPs and the error we are seeing is a symptom but not the root cause","username":"amundson","ts":"2020-01-22T20:29:40.424Z"}
{"msg":"More generically, is there anything obvious about the TPs behavior that would be different than an Xo and Intkey","username":"amundson","ts":"2020-01-22T20:30:45.800Z"}
{"msg":"Has joined the channel.","username":"IWontDiscloseMyIdentity","ts":"2020-01-23T06:09:07.944Z","type":"uj"}
{"msg":"we are on 1.2 and yes we have two TPs of our own. i am fairly certain they are deterministic but we can do an audit. curious, if there was an issue like that wouldn't the node have a different state hash or be looking for a different one than given? trying to see if we could narrow the down to try and hone in on where things might have gone awry ","username":"MatthewRubino","ts":"2020-01-23T14:13:05.570Z"}
{"msg":"we are on 1.2 and yes we have two TPs of our own. i am fairly certain they are deterministic but we can do an audit. curious, if there was an issue like that wouldn't the node have a different state hash or be looking for a different one than the other chains have? trying to see if we could narrow the down to try and hone in on where things might have gone awry ","username":"MatthewRubino","ts":"2020-01-23T14:13:05.570Z"}
{"msg":"@MatthewRubino which dot release of 1.2?","username":"amundson","ts":"2020-01-23T15:35:02.196Z"}
{"msg":"you are correct that if there is indeterminism, we would expect a state hash mismatch and for the block to be discarded -- just looking for differences between what you are doing and what we've done in our testing","username":"amundson","ts":"2020-01-23T15:36:36.719Z"}
{"msg":"we dont specify a micro version so just the latest 1.2. the digest matches 1.2.3 (`03974b8bd0b9`)","username":"MatthewRubino","ts":"2020-01-23T15:51:02.704Z"}
{"msg":"you aren't using the pre-compiled stuff then?","username":"amundson","ts":"2020-01-23T15:56:24.393Z"}
{"msg":"what is your version of pbft?","username":"amundson","ts":"2020-01-23T15:57:41.441Z"}
{"msg":"(are you using pbft?)","username":"amundson","ts":"2020-01-23T15:57:49.545Z"}
{"msg":"we are using the docker image. and yes pbft. the set version is 1.0 and the digest matches 1.0.1 (`b49c0d01b827`)","username":"MatthewRubino","ts":"2020-01-23T16:06:09.587Z"}
{"msg":"we are using the docker images. and yes pbft. the set version is 1.0 and the digest matches 1.0.1 (`b49c0d01b827`)","username":"MatthewRubino","ts":"2020-01-23T16:06:09.587Z"}
{"msg":"Does that address exist in the other nodes?","username":"arsulegai","ts":"2020-01-23T16:49:19.194Z"}
{"msg":"Rephrasing my question: Is it a new node added?","username":"arsulegai","ts":"2020-01-23T16:49:19.194Z"}
{"msg":"Did the node in question parse the transaction that says it is part of the network now onwards? Or was it part of the network from beginning, just trying to catchup now with others?","username":"arsulegai","ts":"2020-01-23T16:57:06.350Z"}
{"msg":"@MatthewRubino sounds like versions are the same then","username":"amundson","ts":"2020-01-23T17:02:21.607Z"}
{"msg":"we have tried both. the node was part of a network (1 of 12). It randomly (possibly after a reboot) flatlined due to being unable to progress past that point. subsequent restarts didn't change anything. we have tried moving the data directory out to essentially start it as new node (with the same key pair) and it is unable to sync anything. it gets the same error though it cycles over ~3-4 different state hashes. ","username":"MatthewRubino","ts":"2020-01-23T17:28:53.663Z"}
{"msg":"we have ~60k blocks that have been running over 4-5 months. there havent been any code changes to sawtooth or our TPs in ~3months (maybe)","username":"MatthewRubino","ts":"2020-01-23T17:35:22.903Z"}
{"msg":"we have ~60k blocks that have been running over 4-5 months. there havent been any code changes to sawtooth or our TPs in \\~3months (maybe)","username":"MatthewRubino","ts":"2020-01-23T17:35:22.903Z"}
{"msg":"we have ~60k blocks that have been running over 4-5 months. there haven't been any code changes to sawtooth or our TPs in 3months (maybe)","username":"MatthewRubino","ts":"2020-01-23T17:35:22.903Z"}
{"msg":"this appears to have happened to a second node now. it is stuck 7 blocks behind the group. with the same sort of error. we have paused incoming batches. i am going to see if i can find anything useful.","username":"MatthewRubino","ts":"2020-01-24T14:34:12.879Z"}
{"msg":"@MatthewRubino if you come up with some way we could replicate it locally, please share. otherwise, sharing logs or whatever may be helpful.","username":"amundson","ts":"2020-01-24T16:49:36.294Z"}
{"msg":"That sounds like some kind of sequencing issue. Something is making an assumption about the presence of an uncommitted state root. We'd need to see the surrounding logs from both the consensus engine and the validator.","username":"jsmitchell","ts":"2020-01-24T16:59:30.502Z"}
{"msg":"working on that. will have to get back to you","username":"MatthewRubino","ts":"2020-01-24T17:30:29.848Z"}
{"msg":"is int-key and block-info safe in this sense? we use block-info injection and have int-key that inc/dec once every 15 minutes to act as a sort of ping. we then have two of our own TPs which, so far as I can tell, dont have any issues in terms of determinism ","username":"MatthewRubino","ts":"2020-01-24T18:22:54.262Z"}
{"msg":"is int-key and block-info safe in this sense? we use block-info injection and have an int-key that inc/dec once every 15 minutes to act as a sort of ping. we then have two of our own TPs which, so far as I can tell, dont have any issues in terms of determinism ","username":"MatthewRubino","ts":"2020-01-24T18:22:54.262Z"}
{"msg":"i did find this in the logs for the two nodes that are now failing: ```block-info-tp             | WARN  | block_info_tp::handl | Invalid Transaction: Timestamp must be less than local time. Expected 1579704304 in (1579704664-300, 1579704664+300)```","username":"MatthewRubino","ts":"2020-01-24T19:41:51.457Z"}
{"msg":"i did find this in the logs for the two nodes that are now failing (different times and such): ```block-info-tp             | WARN  | block_info_tp::handl | Invalid Transaction: Timestamp must be less than local time. Expected 1579704304 in (1579704664-300, 1579704664+300)```","username":"MatthewRubino","ts":"2020-01-24T19:41:51.457Z"}
{"msg":"thats like 2:45 vs 2:51, which is a rather extreme time difference. there was a reboot in the logs a few minutes before. is there some timing bit where it hasnt committed the block but then restarts and thus ends up with a very different time for validation?","username":"MatthewRubino","ts":"2020-01-24T19:44:37.972Z"}
{"msg":"thats like 2:45 vs 2:51+-300, which is a rather extreme time difference. there was a reboot in the logs a few minutes before. is there some timing bit where it hasnt committed the block but then restarts and thus ends up with a very different time for validation?","username":"MatthewRubino","ts":"2020-01-24T19:44:37.972Z"}
{"msg":"here is the first node that failed which we moved the data dir to try and get it to sync from scratch","username":"MatthewRubino","ts":"2020-01-24T19:49:57.091Z"}
{"msg":"```WARN | block_info_tp::handl | Invalid Transaction: Timestamp must be less than local time. Expected 1573080676 in (1579670414-300, 1579670414+300)`\n`1573080676` = November 6, 2019 10:51:16 PM\n`1579670414` =  January 22, 2020 5:20:14 AM\n```","username":"MatthewRubino","ts":"2020-01-24T19:50:12.100Z"}
{"msg":"```WARN | block_info_tp::handl | Invalid Transaction: Timestamp must be less than local time. Expected 1573080676 in (1579670414-300, 1579670414+300)```\n`1573080676` = November 6, 2019 10:51:16 PM\n`1579670414` =  January 22, 2020 5:20:14 AM","username":"MatthewRubino","ts":"2020-01-24T19:50:12.100Z"}
{"msg":"@amundson or @jsmitchell is block info expected to function in this manner? do we have something about it not setup correctly?","username":"MatthewRubino","ts":"2020-01-24T19:51:05.031Z"}
{"msg":"or is that just a red herring?","username":"MatthewRubino","ts":"2020-01-24T19:51:51.572Z"}
{"msg":"and we are on `hyperledger/sawtooth-block-info-tp:1.2.3`","username":"MatthewRubino","ts":"2020-01-24T19:58:18.259Z"}
{"msg":"and we are on `hyperledger/sawtooth-block-info-tp:1.2.3` i dont recall us having any issues like this on POET or perhaps block info 1.1.x. maybe we missed some setting adjustment","username":"MatthewRubino","ts":"2020-01-24T19:58:18.259Z"}
{"msg":"and we are on `hyperledger/sawtooth-block-info-tp:1.2.3` i dont recall us having any issues like this on POET or perhaps block info 1.1.x. we updated everything to 1.2.x to PBFT. maybe we missed some setting adjustment","username":"MatthewRubino","ts":"2020-01-24T19:58:18.259Z"}
{"msg":"```  'sawtooth.validator.batch_injectors': 'block_info',\n  'sawtooth.validator.block_validation_rules': 'NofX:1,block_info;XatY:block_info,0;local:0' }```","username":"MatthewRubino","ts":"2020-01-24T20:03:11.069Z"}
{"msg":"```  'sawtooth.validator.batch_injectors': 'block_info',\n  'sawtooth.validator.block_validation_rules': 'NofX:1,block_info;XatY:block_info,0;local:0'```","username":"MatthewRubino","ts":"2020-01-24T20:03:11.069Z"}
{"msg":"That _in range_ does not seem correct for historical timestamps","username":"jsmitchell","ts":"2020-01-24T20:14:24.683Z"}
{"msg":"right. so i havent tried to reproduce it locally, but if that is the issue it appears it would be easy to do","username":"MatthewRubino","ts":"2020-01-24T20:17:40.330Z"}
{"msg":"imo the check should be in range (prior block's block info timestamp, local clock+tolerance)","username":"jsmitchell","ts":"2020-01-24T20:19:51.593Z"}
{"msg":"where \"prior block's info timestamp\" is just the current state value timestamp","username":"jsmitchell","ts":"2020-01-24T20:21:47.430Z"}
{"msg":"```fn validate_timestamp(timestamp: u64, tolerance: u64) -> Result<(), ApplyError> {\n    let now = SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .expect(\"System time is before Unix epoch.\")\n        .as_secs();\n    if timestamp < (now - tolerance) || (now + tolerance) < timestamp {\n        let warning_string = format!(\n            \"Timestamp must be less than local time. Expected {0} in ({1}-{2}, {1}+{2})\",\n            timestamp, now, tolerance\n        );\n        warn!(\"Invalid Transaction: {}\", &warning_string);\n        return Err(ApplyError::InvalidTransaction(warning_string));\n    }\n\n    Ok(())\n}```","username":"amundson","ts":"2020-01-24T20:33:05.384Z"}
{"msg":"that's the logic in the rust version of batch_info (1.2.3 - not sure if that is rust, might be python, but probably same logic)","username":"amundson","ts":"2020-01-24T20:33:42.648Z"}
{"msg":"using block_info requires all the nodes to keep accurate time (using NTP probably) and be accurate at least to tolerance. If you had a node with bad time and it rebooted, when it came up it might have synced time with ntpdate (or similar) and now have a more accurate time.","username":"amundson","ts":"2020-01-24T20:36:18.670Z"}
{"msg":"though, based on your error, it looks like your local time went backwards","username":"amundson","ts":"2020-01-24T20:37:14.509Z"}
{"msg":"no, that's not the case (misread it)","username":"amundson","ts":"2020-01-24T20:39:46.389Z"}
{"msg":"so that one with the date from Nov is because it starting over from block 0 as opposed to keeping up. i think if they fall behind more than 5 minutes they cannot validate new blocks as they come in","username":"MatthewRubino","ts":"2020-01-24T20:43:42.784Z"}
{"msg":"this definitely worked before we did PBFT upgrade, no one on the team recalls us trying to sync from 0 with PBFT","username":"MatthewRubino","ts":"2020-01-24T20:44:39.263Z"}
{"msg":"that looks like a bug to me, should be \"if (now + tolerance) < timestamp\" to only check timestamp is less than the upper bound","username":"amundson","ts":"2020-01-24T20:44:43.771Z"}
{"msg":"did you go to a different version of 1.2.x to 1.2.3 at the same time?","username":"amundson","ts":"2020-01-24T20:45:00.199Z"}
{"msg":"before PBFT it was likely 1.1.x","username":"MatthewRubino","ts":"2020-01-24T20:45:19.132Z"}
{"msg":"let me look at that impl","username":"amundson","ts":"2020-01-24T20:45:45.727Z"}
{"msg":"```def validate_timestamp(timestamp, tolerance):\n    now = time.time()\n    if (timestamp - now) > tolerance:\n        raise InvalidTransaction(\n            \"Timestamp must be less than local time.\"\n            \" Expected {0} in ({1}-{2}, {1}+{2})\".format(\n                timestamp, now, tolerance))```","username":"amundson","ts":"2020-01-24T20:46:49.792Z"}
{"msg":"1.1.x was python, 1.2.x is rust. I think the bug existed in python at one time, got fixed there, probably got carried over to the rust impl before that.","username":"amundson","ts":"2020-01-24T20:47:21.208Z"}
{"msg":"this was the python fix - ```commit 5e7315a9f0e3c8863327034c036b28e70850112c\nAuthor: Peter Schwarz <pschwarz@bitwise.io>\nDate:   Tue Feb 6 15:31:12 2018 -0600\n\n    Correct timestamp check for catch up\n\n    The timecheck needs to ensure that the timestamp is only ahead of a\n    transaction processor's local time by the value of tolerance. The use of\n    absolute value enforeced that this time check is within tolerence of the\n    local time. This fails validation in the case where a node is catching\n    up on a chain the may contain blocks that were published more than\n    time-tolerence in the past.  Correcting this to ensure the the timestamp\n    is no more than tolerence in the future, ensures that the transaction\n    can still be validated during a catch up scenario.\n\n    Fixes STL-1048```","username":"amundson","ts":"2020-01-24T20:49:43.659Z"}
{"msg":"is there a python-tp we can or should use instead? would swapping the TP fix it or is our chain a bust?","username":"MatthewRubino","ts":"2020-01-24T20:51:48.434Z"}
{"msg":"is there a python-tp we can or should use instead? would swapping/fixing the TP fix it or is our chain a bust?","username":"MatthewRubino","ts":"2020-01-24T20:51:48.434Z"}
{"msg":"and is it valuable for me to try and reproduce this locally at this point?","username":"MatthewRubino","ts":"2020-01-24T20:53:39.355Z"}
{"msg":"probably best to fix up the rust one and then use that. since it will be less restrictive, should be fine.","username":"amundson","ts":"2020-01-24T20:53:43.821Z"}
{"msg":"not valuable to reproduce this specific bug, no","username":"amundson","ts":"2020-01-24T20:54:59.583Z"}
{"msg":"is that something I should make a PR for? and is it just to github.com?","username":"MatthewRubino","ts":"2020-01-24T20:57:54.730Z"}
{"msg":"@MatthewRubino I put up a PR - https://github.com/hyperledger/sawtooth-core/pull/2280 - do you have the ability there to test it?","username":"amundson","ts":"2020-01-24T21:05:08.333Z"}
{"msg":"that is against master, I will backport it to the 1-2 branch after it goes into master","username":"amundson","ts":"2020-01-24T21:06:07.449Z"}
{"msg":"thanks. we might be able to get it into AWS and see that it fixes our test environment. would that get pushed to a nightly or something? that would make it much easier as opposed to an ECR repo and such","username":"MatthewRubino","ts":"2020-01-24T21:16:16.888Z"}
{"msg":"thanks. we might be able to get it into AWS and see that it fixes our test environment. would that get pushed to a nightly or something? that would make it much easier as opposed to an ECR repo and such; though we could still figure something like that out. but probably not until monday. (we are all east coast)","username":"MatthewRubino","ts":"2020-01-24T21:16:16.888Z"}
{"msg":"Is there a contributors call today? Still on the calendar, but the zoom id is invalid.","username":"kodonnel","ts":"2020-01-27T16:02:46.212Z"}
{"msg":"That was previously cancelled in late 2019. I noticed it was added back to the calendar last week, and messaged for it to be removed","username":"mfford","ts":"2020-01-27T16:09:37.355Z"}
{"msg":"Cancelled just for Jan?","username":"kodonnel","ts":"2020-01-27T16:10:19.648Z"}
{"msg":"Cancelled just for Jan? And back in business Feb I assume?","username":"kodonnel","ts":"2020-01-27T16:10:19.648Z"}
{"msg":"no, the idea was to have the conversations here instead of a meeting, and have meetings on specific topics if we identify them here.","username":"amundson","ts":"2020-01-27T16:14:09.239Z"}
{"msg":"Then in case no one else has, I'd suggest that we revisit that decision after a while to see how well it is working. ","username":"kodonnel","ts":"2020-01-27T16:17:25.912Z"}
{"msg":"did you have a topic?","username":"amundson","ts":"2020-01-27T16:27:47.364Z"}
{"msg":"Not this round.  But it was a good way to touch base, and different people work and communicate differently.  It seems worth the effort to check in on that decision after a few months to see if it is still working well.  ","username":"kodonnel","ts":"2020-01-27T16:31:08.021Z"}
{"msg":"there was another splinter release - https://github.com/Cargill/splinter/blob/master/RELEASE_NOTES.md - of particular interest for Sawtooth is probably how we are working with experimental Rust features there - https://github.com/Cargill/splinter-docs/blob/master/docs/community/stable_feature_checklist.md","username":"amundson","ts":"2020-01-27T16:42:35.797Z"}
{"msg":"we should probably do the same thing w/Sawtooth going forward","username":"amundson","ts":"2020-01-27T16:42:51.632Z"}
{"msg":"FYI on common repo files across HL: https://wiki.hyperledger.org/x/QQR6AQ","username":"Dan","ts":"2020-01-27T17:11:46.804Z"}
{"msg":"I think the blocks never catching up should be a large issue to push this Jira STL-1510 up in priority and fixed. We are having the issue too. We are backing out our custom code so we can recreate the issue and demo it to others.  It is definitely an issue when a node gets disconnected or out of synch, that node will not catch up to the other nodes. Our only work around is to restart the entire blockchain, and that solves the issue until it happens again.  But we lose all of the intervening transactions.  It will take us a few days to have a spot that we can show it completely disconnected and reconnection does not synch.  I cannot get into to Jira to update the STL-1510.\n\nIn addition to us, Rajaram Kannan is in a thread on the Sawtooth email list.  @MicaelFerreira @MatthewRubino @wkatsak are all having it.  We thought is was our custom code causing the issues.  When we have a clean log showing the issue, is there a place to put it?","username":"jamesbarry","ts":"2020-01-29T21:21:27.716Z"}
{"msg":"Has joined the channel.","username":"MicaelFerreira","ts":"2020-01-29T21:21:27.779Z","type":"uj"}
{"msg":"We have a second issue around volume that we will try recreating so others can view.  It concerns having pending transactionscreated by a high volume node.  The queue does not replicate fast enough to catch up and thus we end up with either dropped transactions or transactions pending forewver.  Another one we qwill try to build and recreate.  This one seems to be connected to the node not catching up issue.  ","username":"jamesbarry","ts":"2020-01-29T21:24:17.129Z"}
{"msg":"is that the right JIRA? i wasnt able to find anything like this issue. can you link me when you get into jira?","username":"MatthewRubino","ts":"2020-01-29T22:17:35.764Z"}
{"msg":"@MatthewRubino You are correct in that that is another, though related issue. That was my mistake, working on too many things simultaneously. I apologize for any confusion. We are rebuilding a test suite without our custom code to demo in minikube so we can show the issue. Our test suite was testing higher volumes on the chain and then testing for disconnected nodes and reconnecting them as this is part of our products value proposition.If the node reconnected, we are having issues that the transactions never catch up. We also have an intermittent issue with the disconnected validator not reconnecting in. Our third issue have been the loss of \"pending\" transactions are dropping from the queue in high volume situations.  We need more detail so you all can see the exact issue.  I will not comment until our test cases are consistently showing the issues.","username":"jamesbarry","ts":"2020-01-29T22:41:45.587Z"}
{"msg":"have you guys setup infux and grafana? that usually shows the pending tx into back pressure build up if you are hitting things hard.","username":"MatthewRubino","ts":"2020-01-29T22:49:40.722Z"}
{"msg":"Few non-trivial long-term fixes for catch-up: 1) send txn receipts along with blocks, and apply these receipts efficiently without executing transactions (if you end up with the same state hash, this should be safe as long as you already know the block is the correct one, as we can accomplish with pbft) 2) use the txn receipts to solve non-determinism errors (similar to (1) but using txn receipts if you already trust the block is chosen and can't recreate state by running the txns); 3) Implement state checkpointing, which allows the transfer of state instead of blocks if the block store size exceeds the state store size. 4) expanding on (3), make it so you can do this as-you-go, so you can start processing blocks without having a complete copy of state.","username":"amundson","ts":"2020-01-29T22:50:15.415Z"}
{"msg":"thats not to say that recovering and such isnt still an issue. and that ticket does sound very related","username":"MatthewRubino","ts":"2020-01-29T22:50:17.936Z"}
{"msg":"@MatthewRubino We have set up Grafana. We keep tuning Sawtooth based on looking at the results we see through Grafana and logs.  As an FYI our test environment is 5 nodes and to stress it we started by running SOAK tests of grabbing 5 different weather reports, 1 per node per minute. Got it to the same set up at 1 weather report per node every 10 seconds and started stressing it out. Faster than every 10 seconds has not been successful yet. At a weather report per node every 10 seconds, disconnecting it and reconnecting it led to transactions on the disconnected node not catching up and sometimes nodes not reconnecting. Anyway we are three people with a lot on our plate and will try to demo it properly so all can look at the issue.","username":"jamesbarry","ts":"2020-01-29T23:04:21.562Z"}
{"msg":"Today i has the same pbft exception in a different node `InternalError: Couldn't find 2f commit messages in the message log for building a seal` , just had to restart the node validator to make it sync again, no need to restart all network","username":"MicaelFerreira","ts":"2020-01-30T12:36:18.769Z"}
{"msg":"Today i had the same pbft exception in a different node `InternalError: Couldn't find 2f commit messages in the message log for building a seal` , just had to restart the node validator to make it sync again, no need to restart all network","username":"MicaelFerreira","ts":"2020-01-30T12:36:18.769Z"}
{"msg":"Today i had the same pbft exception in a different node `InternalError: Couldn't find 2f commit messages in the message log for building a seal` , just had to restart the node validator to make it sync again, no need to restart the whole network","username":"MicaelFerreira","ts":"2020-01-30T12:36:18.769Z"}
{"msg":"I would like to propose a important validation in settings tp when applying the vote: if the setting to be changed is authorized_keys, check if the len of the future authorized_keys list is greater or equal than threshold and proceed if true, or reject if not. Actually as setting-tp is, we can remove a authorized key and have less keys to vote than the approval_threshold, which can cause the invalidity of any future settings changes","username":"MicaelFerreira","ts":"2020-01-30T12:46:34.650Z"}
{"msg":"I would like to propose an important validation in settings tp when applying the vote: if the setting to be changed is `authorized_keys`, check if the len of the future authorized_keys list is greater or equal than the approval_threshold and proceed if true, or reject if not. With the settings-tp as it is, we can remove an authorized key and have less keys to vote than the approval_threshold, which can cause the invalidity of any future settings changes","username":"MicaelFerreira","ts":"2020-01-30T12:46:34.650Z"}
{"msg":"HI Team , I am trying to get transaction id in response but getting\n\"link\": \"http://localhost:8008/batch_statuses?id=251339f1cb930dc1b5d4002de941e3fc6219a7d139fe3a8ce024c99e2bb9e383496ed83d9e888bcbd2eb2286c4a4962988f839d267ef35bc8fc316647234c8e2\"\n}\nbatch id\ncould someone please tell me how to get transaction Id instead of batch id\nit is showing tx id as output in return but on client side ... i am getting batch id\nsomeone please help on this","username":"IWontDiscloseMyIdentity","ts":"2020-01-30T14:01:10.693Z"}
{"msg":"getting this when i see the response in Transcation Processor\nresponse: 'Success',\nTxId:\n[ '1a4ecccf83e1357eefb8bdf1542850d66d8007d620e4050b5715dc83f4a921d36ce9ce' ]\ni want to get this TxID but not getting this on client side","username":"IWontDiscloseMyIdentity","ts":"2020-01-30T14:01:18.695Z"}
{"msg":"@amundson @jamesbarry @MatthewRubino  So we just managed to get our test chain (not docker, 5 physical geo-distributed nodes) into this state where transactions get stuck in PENDING. Essentially everything you submit gets stuck in pending (we have tried our app + intkey, all the same). All TPs are up.","username":"wkatsak","ts":"2020-01-30T18:16:01.830Z"}
{"msg":"validators dont even seem to be touch the the pbft service, as its timestamps are frozen","username":"wkatsak","ts":"2020-01-30T18:17:39.354Z"}
{"msg":"e.g. not producing any more output","username":"wkatsak","ts":"2020-01-30T18:17:46.944Z"}
{"msg":"For us, block 185 is the last block validated, and compare-chains shows all consistent","username":"wkatsak","ts":"2020-01-30T18:23:03.667Z"}
{"msg":"For us, block 188 is the last block validated, and compare-chains shows all consistent","username":"wkatsak","ts":"2020-01-30T18:23:03.667Z"}
{"msg":"Block 185 shows a serious of Faild block messages","username":"wkatsak","ts":"2020-01-30T18:33:17.105Z"}
{"msg":"An example from one node","username":"wkatsak","ts":"2020-01-30T18:33:22.978Z"}
{"msg":"```\n[17:21:17.005 [Dummy-5] (unknown file) INFO] [src/state/state_pruning_manager.rs: 134] Pruned 102 keys from the Global state Database\n[17:21:17.132 [ThreadPoolExecutor-1_7] responder DEBUG] Responding to batch requests 0ae2e61f57a600ae03b99ad5269727efdafa0fac0f94ac43360d3550ccdeba936153cec09232352d607d288f25de4941505c25f8e50b43ea4cd35b59600ac301\n[17:21:17.132 [ThreadPoolExecutor-1_7] responder DEBUG] Responding to batch requests 0ae2e61f57a600ae03b99ad5269727efdafa0fac0f94ac43360d3550ccdeba936153cec09232352d607d288f25de4941505c25f8e50b43ea4cd35b59600ac301\n[17:21:17.637 [ThreadPoolExecutor-7_0] ffi INFO] [src/journal/chain.rs: 578] Failed block Block(id: 051ccdc6b483173e8902c1fdd1f631be4ccfc2086d54d8af10c70d6b2b79c8684072af379a3aa8dfd15d770afcf83aeb54426f5a737ac2a3e3a7a6ffdd6ea7ba, block_num: 185, state_root_hash: dcb17471b755dc8ccafeacd1e9893eefdbdb73aa776f844caab0cdbb893dd85e, previous_block_id: 479902578e082bdb820a966d2faee9761147c332d1ead1ece351458e7ac271d754fe6d8fbf3b2f7fc13be6caa301eaf6afe6176311c7be2924ac35538fb78b14)\n[17:21:17.637 [ThreadPoolExecutor-7_0] ffi INFO] [src/journal/chain.rs: 578] Failed block Block(id: 051ccdc6b483173e8902c1fdd1f631be4ccfc2086d54d8af10c70d6b2b79c8684072af379a3aa8dfd15d770afcf83aeb54426f5a737ac2a3e3a7a6ffdd6ea7ba, block_num: 185, state_root_hash: dcb17471b755dc8ccafeacd1e9893eefdbdb73aa776f844caab0cdbb893dd85e, previous_block_id: 479902578e082bdb820a966d2faee9761147c332d1ead1ece351458e7ac271d754fe6d8fbf3b2f7fc13be6caa301eaf6afe6176311c7be2924ac35538fb78b14)\n[17:21:17.640 [ThreadPoolExecutor-7_1] ffi INFO] [src/journal/chain.rs: 578] Failed block Block(id: 128575c77b54816f48cd375f294542a149f11e6b300c6a31ac736642c17757380880d52231e5f20d64878b9f7ed6778d6319b1e87f8733a8a7ff81f8e7337248, block_num: 185, state_root_hash: 2cc8a12a1e18dcc9288984152546bd392d90e9848377110cba766cd98267bf37, previous_block_id: 479902578e082bdb820a966d2faee9761147c332d1ead1ece351458e7ac271d754fe6d8fbf3b2f7fc13be6caa301eaf6afe6176311c7be2924ac35538fb78b14)\n[17:21:17.640 [ThreadPoolExecutor-7_1] ffi INFO] [src/journal/chain.rs: 578] Failed block Block(id: 128575c77b54816f48cd375f294542a149f11e6b300c6a31ac736642c17757380880d52231e5f20d64878b9f7ed6778d6319b1e87f8733a8a7ff81f8e7337248, block_num: 185, state_root_hash: 2cc8a12a1e18dcc9288984152546bd392d90e9848377110cba766cd98267bf37, previous_block_id: 479902578e082bdb820a966d2faee9761147c332d1ead1ece351458e7ac271d754fe6d8fbf3b2f7fc13be6caa301eaf6afe6176311c7be2924ac35538fb78b14)\n[17:21:17.715 [ThreadPoolExecutor-7_1] ffi DEBUG] [src/journal/block_scheduler.rs: 166] Adding block eda8714eb9eae3c44d07b6fb5dce9fc7237e40af7fefe0bc0544d821b56cc6e07f783d1f236c296a2a8ff99e257f17b86f2be2bfa5876e2eb43d53ed281e7b6c for processing\n[17:21:17.715 [ThreadPoolExecutor-7_1] ffi DEBUG] [src/journal/block_scheduler.rs: 166] Adding block eda8714eb9eae3c44d07b6fb5dce9fc7237e40af7fefe0bc0544d821b56cc6e07f783d1f236c296a2a8ff99e257f17b86f2be2bfa5876e2eb43d53ed281e7b6c for processing\n[17:21:17.920 [Dummy-4] (unknown file) INFO] [src/journal/block_validator.rs: 265] Block eda8714eb9eae3c44d07b6fb5dce9fc7237e40af7fefe0bc0544d821b56cc6e07f783d1f236c296a2a8ff99e257f17b86f2be2bfa5876e2eb43d53ed281e7b6c passed validation\n[17:21:17.920 [Dummy-4] (unknown file) INFO] [src/journal/block_validator.rs: 265] Block eda8714eb9eae3c44d07b6fb5dce9fc7237e40af7fefe0bc0544d821b56cc6e07f783d1f236c296a2a8ff99e257f17b86f2be2bfa5876e2eb43d53ed281e7b6c passed validation\n[17:21:17.990 [Dummy-5] (unknown file) INFO] [src/journal/chain.rs: 206] Building fork resolution for chain head 'Block(id: cf74778ffc28b99d170cea524f3c124ffd105a439a604a17e7fe9d9921f8f2013ba061a7556de9349691a6fad3b44932238b02437e9ac08b43b6822b475c7303, block_num: 185, state_root_hash: 2cc8a12a1e18dcc9288984152546bd392d90e9848377110cba766cd98267bf37, previous_block_id: 479902578e082bdb820a966d2faee9761147c332d1ead1ece351458e7ac271d754fe6d8fbf3b2f7fc13be6caa301eaf6afe6176311c7be2924ac35538fb78b14)' against new block 'Block(id: c6af7c91d26c075d14b5408be396e1f43bf21dbe6ce58218a3f284e2881065a24ea54b1a6c258dadf94c567d1707bf3d1f393d9ac0c92188fc93d0c2460999dd, block_num: 186, state_root_hash: dcb17471b755dc8ccafeacd1e9893eefdbdb73aa776f844caab0cdbb893dd85e, previous_block_id: cf74778ffc28b99d170cea524f3c124ffd105a439a604a17e7fe9d9921f8f2013ba061a7556de9349691a6fad3b44932238b02437e9ac08b43b6822b475c7303)'\n\n``` ","username":"wkatsak","ts":"2020-01-30T18:44:38.187Z"}
{"msg":"Here  is that node's pbft log","username":"wkatsak","ts":"2020-01-30T19:00:33.225Z"}
{"msg":"","username":"wkatsak","ts":"2020-01-30T19:00:45.204Z","attachments":[{"type":"file","title":"wkatsak - Thu Jan 30 2020 14:00:39 GMT-0500 (Eastern Standard Time).txt","title_link":"/file-upload/RmNeKKkwcjtGQYFzQ/wkatsak%20-%20Thu%20Jan%2030%202020%2014:00:39%20GMT-0500%20(Eastern%20Standard%20Time).txt","url":"/file-upload/RmNeKKkwcjtGQYFzQ/wkatsak%20-%20Thu%20Jan%2030%202020%2014:00:39%20GMT-0500%20(Eastern%20Standard%20Time).txt","remote":false,"fileId":"RmNeKKkwcjtGQYFzQ","fileName":"wkatsak - Thu Jan 30 2020 14:00:39 GMT-0500 (Eastern Standard Time).txt"}]}
{"msg":"To me this looks ok, just like a block being resolved","username":"wkatsak","ts":"2020-01-30T19:05:43.666Z"}
{"msg":"@wkatsak hard to say for sure what happened around block 185, but it was able to handle it eventually.","username":"ltseeley","ts":"2020-01-30T19:05:48.185Z"}
{"msg":"@ltseeley thats my thought as well, as other blocks are committed afterwards, on all nodes","username":"wkatsak","ts":"2020-01-30T19:06:08.353Z"}
{"msg":"What stops it dead though seems to be one node losing connection and reconnecting","username":"wkatsak","ts":"2020-01-30T19:06:25.838Z"}
{"msg":"Do you have validator logs that indicate that?","username":"ltseeley","ts":"2020-01-30T19:07:56.881Z"}
{"msg":"I'm trying to collect now","username":"wkatsak","ts":"2020-01-30T19:08:45.581Z"}
{"msg":"this might have happened after the failure","username":"wkatsak","ts":"2020-01-30T19:08:53.510Z"}
{"msg":"checking","username":"wkatsak","ts":"2020-01-30T19:08:55.260Z"}
{"msg":"nm the disconnect happened 4 mins after the network seized","username":"wkatsak","ts":"2020-01-30T19:09:17.676Z"}
{"msg":"actually reconnect happened later","username":"wkatsak","ts":"2020-01-30T19:15:05.931Z"}
{"msg":"two of my nodes show a series of errors sending PING_RESPONSE and NETWORK_ACK. Like this:","username":"wkatsak","ts":"2020-01-30T19:15:45.014Z"}
{"msg":"`[17:21:17.099 [ThreadPoolExecutor-1_3] dispatch WARNING] Can't send message NETWORK_ACK back to 6e8569f0e8fa584304a9d314665b6a2931c5295936ef47b009e53c83490a28315f0260dc2d9bc1e761b8fe35c252d2439a18af9cb6c76d92764aeeccd0837f08 because connection OutboundConnectionThread-tcp://bc3.dcntral.net:8800 not in dispatcher`","username":"wkatsak","ts":"2020-01-30T19:15:46.565Z"}
{"msg":"this all lines up to 17:21, which is when the network locked","username":"wkatsak","ts":"2020-01-30T19:17:15.027Z"}
{"msg":"i can upload the entire logs if that helps","username":"wkatsak","ts":"2020-01-30T19:17:22.739Z"}
{"msg":"@ltseeley I restarted the bc4 and bc5, which were the ones with the comm errors, and the chain came back to life.","username":"wkatsak","ts":"2020-01-30T19:49:57.539Z"}
{"msg":"Ive been suspecting for some time that the peering/connection management has a bug, or some inconsistency","username":"wkatsak","ts":"2020-01-30T19:50:21.338Z"}
{"msg":"even now, its operating, but I see something like this `Can't send message PING_RESPONSE back to 0e904482b541c3615d021925377d35894c6964e117c6e972d0d5c1e7443c4b38a5126b72a9e61bfdaaf79a31bcd50f3657aa05a85ef08a2266c385840fc15e15 because connection OutboundConnectionThread-tcp://bc4.dcntral.net:8800 not in dispatcher`","username":"wkatsak","ts":"2020-01-30T19:50:41.132Z"}
{"msg":"another node, bc3, has some batches stuck in pending, and these wont unwedge","username":"wkatsak","ts":"2020-01-30T19:56:24.580Z"}
{"msg":"even submitting new ones from the same family","username":"wkatsak","ts":"2020-01-30T19:56:33.010Z"}
{"msg":"so possibly because of the network issues it thinks it shared it with the other nodes? thus if you reboot it they go away and are lost? otherwise they stay never being considered?","username":"MatthewRubino","ts":"2020-01-30T20:37:33.723Z"}
{"msg":"thats what it looks like. they are stuck in pending unless i restart the validator","username":"wkatsak","ts":"2020-01-30T21:07:54.555Z"}
{"msg":"i ended up having to restart everything to get the block heights to all agree","username":"wkatsak","ts":"2020-01-30T21:08:13.514Z"}
{"msg":"i dont know if the network issues are related at all","username":"wkatsak","ts":"2020-01-30T21:08:33.466Z"}
{"msg":"Has joined the channel.","username":"Tomomi.Yamano","ts":"2020-02-03T04:51:21.837Z","type":"uj"}
{"msg":"I use to have a lot of those ping response messages as well, but network still good so far","username":"MicaelFerreira","ts":"2020-02-03T10:05:42.997Z"}
{"msg":"Guys i have a question about pbft members: i removed one of my nodes from the network , removed it from pbft members list and removed all his data as well. After that, i joined the node to the network as a new node (without adding it to pbft members list). the node received all the blocks but the last (even with all the displayed errors that are shown at catching blocks). I did some transactions on other nodes and at the new node as well, and this new node keep getting the blocks but always one block behind. So, without adding the new node to pbft members looks like he can received / validate blocks and publish blocks.\nLooking at the `on_peer_message` https://github.com/hyperledger/sawtooth-pbft/blob/master/src/node.rs#L104, i see that if the node is not part of the network he do not send any kind of messages, but he does.. What is happening?","username":"MicaelFerreira","ts":"2020-02-03T10:26:06.508Z"}
{"msg":"Guys i have a question about pbft members: i removed one of my nodes from the network , removed it from pbft members list and removed all his data as well. After that, i joined the node to the network as a new node (without adding it to pbft members list). the node received all the blocks but the last (even with all the displayed errors that are shown at catching blocks). I did some transactions on other nodes and at the new node as well, and this new node keep getting the blocks but always one block behind. So, without adding the new node to pbft members looks like he can received / validate blocks and publish blocks.\nLooking at the `on_peer_message` https://github.com/hyperledger/sawtooth-pbft/blob/master/src/node.rs#L104, i see that if the node is not part of the network he do not send any kind of messages, but looks like it does.. All i see in the logs is the `InvalidMessage` WARN, but how he can receive and publish blocks? What is happening?","username":"MicaelFerreira","ts":"2020-02-03T10:26:06.508Z"}
{"msg":"Got this exception at the middle of the process of catching up the network with a new added node ( network have about 720 blocks, and this happened at 315 block +- )\n```\nFeb 03 10:37:07 svg-node pbft-engine[9612]: WARN  | pbft_engine::engine: | InvalidMessage: NewView failed verification - Error was: InvalidMessage: Node is on view 4008, but received NewView message for view 4008\nFeb 03 10:37:30 svg-node sawtooth-validator[9588]: thread 'ChainThread:CommitReceiver' panicked at 'No method cancel on python scheduler: PyErr { ptype: <class 'KeyError'>, pvalue: Some(KeyError('Value was not found',)), ptraceback: Some(<traceback object at 0x7bcdc43d2d88>) }', src/libcore/result.rs:1084:5\nFeb 03 10:37:30 svg-node sawtooth-validator[9588]: note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace.\nFeb 03 10:37:31 svg-node sawtooth-validator[9588]: thread 'ChainThread:ValidationResultReceiver' panicked at 'No lock holder should have poisoned the lock: \"PoisonError { inner: .. }\"', src/libcore/result.rs:1084:5\nFeb 03 10:37:31 svg-node sawtooth-validator[9588]: thread '<unnamed>' panicked at 'RwLock is poisoned: \"PoisonError { inner: .. }\"', src/libcore/result.rs:1084:5\nFeb 03 10:37:31 svg-node sawtooth-validator[9588]: fatal runtime error: failed to initiate panic, error 5\nFeb 03 10:37:31 svg-node pbft-engine[9612]: ERROR | pbft_engine::engine: | Disconnected from validator; stopping PBFT\nFeb 03 10:37:31 svg-node pbft-engine[9612]: ERROR | pbft_engine:108      | ReceiveError: Unexpected error while receiving: DisconnectedError\n\n```","username":"MicaelFerreira","ts":"2020-02-03T10:45:00.377Z"}
{"msg":"Got this exception at the middle of the process of catching up the network with a new added node ( network have about 720 blocks, and this happened at 315 block +- )\n```\nFeb 03 10:37:07 svg-node pbft-engine[9612]: WARN  | pbft_engine::engine: | InvalidMessage: NewView failed verification - Error was: InvalidMessage: Node is on view 4008, but received NewView message for view 4008\nFeb 03 10:37:30 node sawtooth-validator[9588]: thread 'ChainThread:CommitReceiver' panicked at 'No method cancel on python scheduler: PyErr { ptype: <class 'KeyError'>, pvalue: Some(KeyError('Value was not found',)), ptraceback: Some(<traceback object at 0x7bcdc43d2d88>) }', src/libcore/result.rs:1084:5\nFeb 03 10:37:30 node sawtooth-validator[9588]: note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace.\nFeb 03 10:37:31 node sawtooth-validator[9588]: thread 'ChainThread:ValidationResultReceiver' panicked at 'No lock holder should have poisoned the lock: \"PoisonError { inner: .. }\"', src/libcore/result.rs:1084:5\nFeb 03 10:37:31 node sawtooth-validator[9588]: thread '<unnamed>' panicked at 'RwLock is poisoned: \"PoisonError { inner: .. }\"', src/libcore/result.rs:1084:5\nFeb 03 10:37:31 node sawtooth-validator[9588]: fatal runtime error: failed to initiate panic, error 5\nFeb 03 10:37:31 node pbft-engine[9612]: ERROR | pbft_engine::engine: | Disconnected from validator; stopping PBFT\nFeb 03 10:37:31 node pbft-engine[9612]: ERROR | pbft_engine:108      | ReceiveError: Unexpected error while receiving: DisconnectedError\n\n```","username":"MicaelFerreira","ts":"2020-02-03T10:45:00.377Z"}
{"msg":"Got this exception at the middle of the process of catching up the network with a new added node ( network have about 720 blocks, and this happened at 315 block +- )\n```\nFeb 03 10:37:07 node pbft-engine[9612]: WARN  | pbft_engine::engine: | InvalidMessage: NewView failed verification - Error was: InvalidMessage: Node is on view 4008, but received NewView message for view 4008\nFeb 03 10:37:30 node sawtooth-validator[9588]: thread 'ChainThread:CommitReceiver' panicked at 'No method cancel on python scheduler: PyErr { ptype: <class 'KeyError'>, pvalue: Some(KeyError('Value was not found',)), ptraceback: Some(<traceback object at 0x7bcdc43d2d88>) }', src/libcore/result.rs:1084:5\nFeb 03 10:37:30 node sawtooth-validator[9588]: note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace.\nFeb 03 10:37:31 node sawtooth-validator[9588]: thread 'ChainThread:ValidationResultReceiver' panicked at 'No lock holder should have poisoned the lock: \"PoisonError { inner: .. }\"', src/libcore/result.rs:1084:5\nFeb 03 10:37:31 node sawtooth-validator[9588]: thread '<unnamed>' panicked at 'RwLock is poisoned: \"PoisonError { inner: .. }\"', src/libcore/result.rs:1084:5\nFeb 03 10:37:31 node sawtooth-validator[9588]: fatal runtime error: failed to initiate panic, error 5\nFeb 03 10:37:31 node pbft-engine[9612]: ERROR | pbft_engine::engine: | Disconnected from validator; stopping PBFT\nFeb 03 10:37:31 node pbft-engine[9612]: ERROR | pbft_engine:108      | ReceiveError: Unexpected error while receiving: DisconnectedError\n\n```","username":"MicaelFerreira","ts":"2020-02-03T10:45:00.377Z"}
{"msg":"Had to restart the node to successfully sync with the network","username":"MicaelFerreira","ts":"2020-02-03T10:50:34.027Z"}
{"msg":"Has joined the channel.","username":"cg223","ts":"2020-02-03T19:07:17.713Z","type":"uj"}
{"msg":"so with the block into tp changes I am able to get the network syncing again. however the behind nodes will only sync up to 1 block behind the head. they then stop and will not want to go further. i have restated the node numerous times to no avail.","username":"MatthewRubino","ts":"2020-02-03T19:53:50.449Z"}
{"msg":"so with the block info tp changes I am able to get the network syncing again. however the behind nodes will only sync up to 1 block behind the head. they then stop and will not want to go further. i have restated the node numerous times to no avail.","username":"MatthewRubino","ts":"2020-02-03T19:53:50.449Z"}
{"msg":"i am trying to get our network to a state where i can remove it and then commit transactions, to see if it will then catch up to N-1 still","username":"MatthewRubino","ts":"2020-02-03T19:59:17.324Z"}
{"msg":"i cannot get a new transaction to commit (I believe) as a result of this error: `ERROR | pbft_engine::engine: | InternalError: Couldn't find 2f commit messages in the message log for building a seal`","username":"MatthewRubino","ts":"2020-02-04T14:14:23.657Z"}
{"msg":"we had taken some snapshots and i spun up some early node states. i removed the node that had our max block 61500. I left the nodes that have the N-1 (61499). The snapshots were on various states around 58k-59k. they synced agains the 61499 nodes. they stopped at 61498... so there appears to be something broken with syncing in that they do not want to catch up to head.","username":"MatthewRubino","ts":"2020-02-04T16:04:20.639Z"}
{"msg":"@MatthewRubino what validator and PBFT versions are you using?","username":"ltseeley","ts":"2020-02-04T17:25:25.671Z"}
{"msg":"validator is 1.2.3 and pbft is 1.2.4","username":"MatthewRubino","ts":"2020-02-04T17:26:11.242Z"}
{"msg":"we have 12 nodes. so we figure out that our 2f+1 is 6 1/3. so we likely need 7 nodes for consensus. we only had 12","username":"MatthewRubino","ts":"2020-02-04T17:26:48.594Z"}
{"msg":"this is why we couldnt commit","username":"MatthewRubino","ts":"2020-02-04T17:26:52.812Z"}
{"msg":"but unsure ATM if that is related to not syncing to head (vs head - 1)","username":"MatthewRubino","ts":"2020-02-04T17:27:18.384Z"}
{"msg":"from the code: let f = ((config.members.len() - 1) / 3) as u64;","username":"MatthewRubino","ts":"2020-02-04T17:28:28.622Z"}
{"msg":"Are you running pbft 1.0.02  There is no 1.2.4 for PBFT","username":"jamesbarry","ts":"2020-02-04T18:26:29.139Z"}
{"msg":"ah right; 1.0.0 (`b49c0d01b827`)","username":"MatthewRubino","ts":"2020-02-04T18:47:10.523Z"}
{"msg":"ah right; 1.0.1 (`b49c0d01b827`)","username":"MatthewRubino","ts":"2020-02-04T18:47:10.523Z"}
{"msg":"ah right, sorry; 1.0.1 (`b49c0d01b827`)","username":"MatthewRubino","ts":"2020-02-04T18:47:10.523Z"}
{"msg":"ah right, sorry; PBFT is 1.0.1 (`b49c0d01b827`)","username":"MatthewRubino","ts":"2020-02-04T18:47:10.523Z"}
{"msg":"@amundson @arsulegai  Is there any documentation - other than in the code - for the node connection management internal to Sawtooth?  \n\nWe believe there is a network bug inside the validator.  We believe the code is internal because certain circumstances where where there is a network interruption between one or more nodes can cause the entire consensus to stop.  \n\nBill is traveling internationally and will continue to try to reproduce this so it can be shown when he lands.  In the meantime, let us know if there is anything other than code we can look though?","username":"jamesbarry","ts":"2020-02-04T18:58:30.815Z"}
{"msg":"@amundson @arsulegai @wkatsak  Is there any documentation - other than in the code - for the node connection management internal to Sawtooth?  \n\nWe believe there is a network bug inside the validator.  We believe the code is internal because certain circumstances where where there is a network interruption between one or more nodes can cause the entire consensus to stop.  \n\nBill is traveling internationally and will continue to try to reproduce this so it can be shown when he lands.  In the meantime, let us know if there is anything other than code we can look though?","username":"jamesbarry","ts":"2020-02-04T18:58:30.815Z"}
{"msg":"There's this networks section in the docs: https://sawtooth.hyperledger.org/docs/core/releases/latest/architecture/validator_network.html","username":"Dan","ts":"2020-02-04T20:32:33.312Z"}
{"msg":"Thanks for the link, we looked at it.  Bill (Our chief architect/programmer) was looking for some deeper docs on internal flows.  We don't have issues between node, but rather in nodes.  We are trying to get a demo assembled to show the issue and make it repeatable.","username":"jamesbarry","ts":"2020-02-04T21:52:14.662Z"}
{"msg":"@jamesbarry a bug like that could be in the validator or within the consensus engine (either side), if you get a sense for one or the other from the logs that would be helpful too. maybe try taking the consensus engine down and back up to make sure it reconnects and starts working again (it should).","username":"amundson","ts":"2020-02-04T23:06:45.192Z"}
{"msg":"@amundson @wkatsak Thank you for the suggestion.  We are in test have have brought the consensus down and up several times.  Just did our 3rd refresh complete from genesis and have the same issue.  I just posted the comment up, as several folks have issues that may have a similar origin. \n I won't post much more until we have a replication that will show you it happening consistently.  Haven't gotten a consistent reproduction yet, so I will be fairly quiet until we can reproduce the issue.  In the meantime we are on Sawtooth 1.2.4 with 1.0.2 for the PBFT.  We did have a five node AWS network that confirmed 85k transaction into the ledger in 30 hours, before it died.  Our old v1.1.x four node mixed hardware/software blockchain running a consistent set of transactions daily was up for five months and 750k + transactions, al with zero issues.  The 1.2.x version have given us trouble.  Not sure if its Sawtooth, or our custom code.  When we are sure, you'll see logs and a reproducer.  Thanks for yoru thoughts.","username":"jamesbarry","ts":"2020-02-04T23:16:57.357Z"}
{"msg":"is the network constantly busy, or does it have quiet periods?","username":"amundson","ts":"2020-02-04T23:56:29.678Z"}
{"msg":"On this test we have each node committing something every 10 seconds at minimum.  ","username":"wkatsak","ts":"2020-02-05T00:19:22.180Z"}
{"msg":"I thought I read someplace If you restart consensus you need to restart the validator. Is this not true anymore?","username":"wkatsak","ts":"2020-02-05T00:20:20.079Z"}
{"msg":"hmm, not 100% sure. that wasn't the original intent.","username":"amundson","ts":"2020-02-05T01:49:19.306Z"}
{"msg":"is there anything in pbft-engine that needs to be upgraded as a result of validator 1.2.4 (presumably the zmq heartbeat stuff)? I get disconnects and docker container terminations.","username":"MatthewRubino","ts":"2020-02-05T17:48:43.703Z"}
{"msg":"```pbft-engine-2      | ERROR | pbft_engine::engine: | Disconnected from validator; stopping PBFT\npbft-engine-2      | ERROR | pbft_engine:108      | ReceiveError: Received unexpected message type: PING_REQUEST\npbft-engine-2 exited with code 1\n```","username":"MatthewRubino","ts":"2020-02-05T17:56:45.152Z"}
{"msg":"```pbft-engine-1      | ERROR | pbft_engine::engine: | Disconnected from validator; stopping PBFT\npbft-engine-1      | DEBUG | sawtooth_sdk::messag | Disconnected outbound channel\npbft-engine-1      | DEBUG | sawtooth_sdk::messag | Exited stream\npbft-engine-1      | DEBUG | zmq:547              | socket dropped\npbft-engine-1      | DEBUG | zmq:547              | socket dropped\npbft-engine-1      | DEBUG | zmq:454              | context dropped\npbft-engine-1      | ERROR | pbft_engine:108      | ReceiveError: Received unexpected message type: PING_REQUEST\npbft-engine-1 exited with code 1\n```","username":"MatthewRubino","ts":"2020-02-05T17:56:45.152Z"}
{"msg":"```pbft-engine-1      | INFO  | pbft_engine:88       | Sawtooth PBFT Engine (1.0.1)\npbft-engine-1      | INFO  | pbft_engine::engine: | Startup state received from validator: StartupState { chain_head: Block(block_num: 0, block_id: [...], previous_id: [...], signer_id: [...], payload: 47656e65736973, summary: 9e32bb0045dc6e7008a5b57c34558aa0dc08fa657ca2d3d4063e22a39014a1fe), peers: [PeerInfo { peer_id: [...] }, PeerInfo { peer_id: [...] }, PeerInfo { peer_id: [...] }, PeerInfo { peer_id: [...] }], local_peer_info: PeerInfo { peer_id: [...] } }\npbft-engine-1      | DEBUG | pbft_engine::config: | Getting on-chain settings for config\npbft-engine-1      | INFO  | pbft_engine::engine: | PBFT config loaded: PbftConfig { members: [...], block_publishing_delay: 1s, update_recv_timeout: 10ms, exponential_retry_base: 100ms, exponential_retry_max: 60s, idle_timeout: 30s, commit_timeout: 10s, view_change_duration: 5s, forced_view_change_interval: 100, max_log_size: 10000, storage_location: \"memory\" }\npbft-engine-1      | INFO  | pbft_engine::engine: | PBFT state created: (PP, view 0, seq 1)\npbft-engine-1      | INFO  | pbft_engine::engine: | Received PeerConnected message with peer info: PeerInfo { peer_id: [...] }\npbft-engine-1      | INFO  | pbft_engine::engine: | Received PeerConnected message with peer info: PeerInfo { peer_id: [...] }\npbft-engine-1      | INFO  | pbft_engine::engine: | Received PeerConnected message with peer info: PeerInfo { peer_id: [...] }\npbft-engine-1      | INFO  | pbft_engine::engine: | Received PeerConnected message with peer info: PeerInfo { peer_id: [...] }\npbft-engine-1      | ERROR | pbft_engine::engine: | Disconnected from validator; stopping PBFT\npbft-engine-1      | ERROR | pbft_engine:108      | ReceiveError: Received unexpected message type: PING_REQUEST\npbft-engine-1      | DEBUG | sawtooth_sdk::messag | Disconnected outbound channel\npbft-engine-1      | DEBUG | sawtooth_sdk::messag | Exited stream\npbft-engine-1      | DEBUG | zmq:547              | socket dropped\npbft-engine-1      | DEBUG | zmq:547              | socket dropped\npbft-engine-1      | DEBUG | zmq:454              | context dropped\npbft-engine-1 exited with code 1\n```","username":"MatthewRubino","ts":"2020-02-05T17:56:45.152Z"}
{"msg":"@MatthewRubino I am looking into that error. Was PBFT registering when that error occurred?","username":"agunde","ts":"2020-02-05T18:10:03.810Z"}
{"msg":"Also what version of PBFT are you running?","username":"agunde","ts":"2020-02-05T18:11:41.475Z"}
{"msg":"it appears to be. edited the above to the full log with some data bits truncated","username":"MatthewRubino","ts":"2020-02-05T18:22:18.982Z"}
{"msg":"it appears to be. edited the above to the full log with some data bits truncated (`...`)","username":"MatthewRubino","ts":"2020-02-05T18:22:18.982Z"}
{"msg":"Okay looks like it completed registration. I think the issue is that 1.0.1 version of PBFT is built on top of Sawtooth SDK 0.2, but there was a fix that went in to Sawtooth SDK 0.3 to stop unexpected messages from causing the engine to stop. I think we will need a new release of PBFT to work with Sawtooth Validator 1.2.4.","username":"agunde","ts":"2020-02-05T18:30:57.334Z"}
{"msg":"would that sort of thing effect custom TPs too?","username":"MatthewRubino","ts":"2020-02-05T18:32:18.017Z"}
{"msg":"Yes, the transaction processor part of the rust sdk also had that issue and was fixed in 0.3. What language is your custom TP in? ","username":"agunde","ts":"2020-02-05T18:38:28.802Z"}
{"msg":"@MatthewRubino No, If the TP are using the sdks, they already handle the ping requests. The PingRequest messages where added a long time ago as a way for the validator to detect if a transaction processor went away. ","username":"agunde","ts":"2020-02-05T18:46:38.269Z"}
{"msg":"@agunde @MatthewRubino I think we might be having this issue as well, we just configured a test cluster with 1.2.4 and are having a hard time bringing it up","username":"wkatsak","ts":"2020-02-05T19:08:59.209Z"}
{"msg":"Could this issue cause any transient effects, or would it always be a termination?","username":"wkatsak","ts":"2020-02-05T19:09:53.709Z"}
{"msg":"i always saw the termination anyways. i was running 5 nodes locally and 4 of the pbft engines would terminate","username":"MatthewRubino","ts":"2020-02-05T20:30:07.981Z"}
{"msg":"Has joined the channel.","username":"gandhikim","ts":"2020-02-06T01:26:35.603Z","type":"uj"}
{"msg":"","username":"jamesbarry","ts":"2020-02-06T15:55:38.849Z","attachments":[{"type":"file","title":"Clipboard - February 6, 2020 8:55 AM","title_link":"/file-upload/PBCbWzAFoGZ92DxG4/Clipboard%20-%20February%206,%202020%208:55%20AM","image_url":"/file-upload/PBCbWzAFoGZ92DxG4/Clipboard%20-%20February%206,%202020%208:55%20AM","image_type":"image/png","image_size":304799,"url":"/file-upload/PBCbWzAFoGZ92DxG4/Clipboard%20-%20February%206,%202020%208:55%20AM","remote":false,"fileId":"PBCbWzAFoGZ92DxG4","fileName":"Clipboard - February 6, 2020 8:55 AM"}]}
{"msg":"@wkatsak @MatthewRubino @agunde @amundson Bill and I have seen the same thing as Mathew.  It sounds like we need a new release of PBFT?  We are working ona demo to show the issue.  I am attaching a snippet of our log file ","username":"jamesbarry","ts":"2020-02-06T15:55:45.673Z"}
{"msg":"there will be a release of PBFT today or tomorrow","username":"amundson","ts":"2020-02-06T16:04:54.750Z"}
{"msg":"(probably today)","username":"amundson","ts":"2020-02-06T16:05:36.416Z"}
{"msg":"@amundson  Perfect - Thank you!","username":"jamesbarry","ts":"2020-02-06T16:05:47.072Z"}
{"msg":"Has joined the channel.","username":"madhusudan.rao","ts":"2020-02-07T09:46:53.449Z","type":"uj"}
{"msg":"","username":"RajaramKannan","ts":"2020-02-07T09:50:14.502Z","attachments":[{"type":"file","title":"RajaramKannan - Mon Feb 03 2020 10_37_28 GMT+0530 (India Standard Time) (1).txt","title_link":"/file-upload/tHLrbYd6cofuewmCt/RajaramKannan%20-%20Mon%20Feb%2003%202020%2010_37_28%20GMT+0530%20(India%20Standard%20Time)%20(1).txt","url":"/file-upload/tHLrbYd6cofuewmCt/RajaramKannan%20-%20Mon%20Feb%2003%202020%2010_37_28%20GMT+0530%20(India%20Standard%20Time)%20(1).txt","remote":false,"fileId":"tHLrbYd6cofuewmCt","fileName":"RajaramKannan - Mon Feb 03 2020 10_37_28 GMT+0530 (India Standard Time) (1).txt"}]}
{"msg":"Has joined the channel.","username":"RajaramKannan","ts":"2020-02-07T09:56:06.939Z","type":"uj"}
{"msg":"Issue #2 is the one I posted yesterday where the consensus get issue was coming. On restarting the node, the validator would immediately exit with a keyerror. On further investigation, what we found was that we had about a 100 batches with transactions that did not cause any state change. So the blocks had the state root hash the same. it appears the validator will then start to fail (if it is up) or will exit (if you bring it down and back up).  the /state for the running node returned the \"Head Not Found\"  \"There is no block with the id specified in the 'head' query parameter.\"   ```\nOne of our engineers dug into the sawtooth code and it looks like it is trying to rebuild state from some block and our theory is that the \\blocks fetches by default only 100 blocks. The last state root hash change is at the 101 block from the current head.   (Just a theory - that it is causing the issue. We were able to consistently reprocude it in our lower environments a number of different times by running 100txns that cause no state change. The 101st then starts to see the consensus get keyerror message and on restart the validator exits.)\n``` ","username":"RajaramKannan","ts":"2020-02-07T09:56:07.874Z"}
{"msg":"we are using 1.1.5 validator with 1.01 PBFT","username":"RajaramKannan","ts":"2020-02-07T10:05:08.178Z"}
{"msg":"on the 1st issue and yes when we tried bringing up a node it was stalling in the catchup at that same block. The logs do look a little similar to what I think you hd posted (our versions are different though). Will the new PBFT proposed release fix that even if we continue with 1.1.5? ","username":"RajaramKannan","ts":"2020-02-07T10:55:25.320Z"}
{"msg":"on the 1st issue and yes when we tried bringing up a node it was stalling in the catchup at that same block. The logs do look a little similar to what I think you hd posted (our versions are different though). Will the new PBFT proposed release fix that even if we continue with 1.1.5? @jamesbarry @amundson ","username":"RajaramKannan","ts":"2020-02-07T10:55:25.320Z"}
{"msg":"@RajaramKannan  @agunde pasted this note\"Okay looks like it completed registration. I think the issue is that 1.0.1 version of PBFT is built on top of Sawtooth SDK 0.2, but there was a fix that went in to Sawtooth SDK 0.3 to stop unexpected messages from causing the engine to stop. I think we will need a new release of PBFT to work with Sawtooth Validator 1.2.4.\"\n\n","username":"jamesbarry","ts":"2020-02-07T19:12:43.509Z"}
{"msg":"We have seen your issue#1 with our test server.  We may have seen issue #2, as it is somewhat similar to what we have seen.  We intend to test the new PBFT and see if that fixes our issues, or write a gist to show problems we are having.  At this point we are ina waiting mode for the new PBFT. ","username":"jamesbarry","ts":"2020-02-07T19:16:09.686Z"}
{"msg":"fyi we are running with 1.2.4 for everything except validator on 1.2.3, or are you needing those ZMQ changes?","username":"MatthewRubino","ts":"2020-02-07T19:19:54.705Z"}
{"msg":"PBFT 1.0.2 has been released. You can read the release notes here: https://github.com/hyperledger/sawtooth-pbft/blob/v1.0.2/RELEASE_NOTES.md","username":"rbuysse","ts":"2020-02-07T20:03:37.257Z"}
{"msg":"@jamesbarry thanks, very much appreciated. On reading @agunde message once again, i think it might help fix the catchup issue. I presume the unexpected message is the one where in our case the invalid block 255 would not stall the pbft engine and it would potentially continue till it received the valid block?  What is still a mystery to me is why is bock 255 getting re-published every now and again (all nodes in the network show the head at 886)....","username":"RajaramKannan","ts":"2020-02-08T08:03:55.048Z"}
{"msg":"Has joined the channel.","username":"adityasingh177","ts":"2020-02-08T14:48:32.962Z","type":"uj"}
{"msg":"@RajaramKannan  We have the same issue as you are with your block 255.  We get an invalid block and it gets republished.  Luckily I am in constant test mode, no production yet.   We are trying to separate out our highly customized code, so we can post some active logs of straight Sawtooth and show a demo of where we get stuck.  So stay tuned.  We will be contributing code back, if we get it to work properly.  Otherwise we will be asking for smarter minds than us to help.","username":"jamesbarry","ts":"2020-02-09T16:30:18.026Z"}
{"msg":"@jamesbarry thanks once again. We will wait for your updates and root for your success in getting it to work properly. I guess the republishing itself is a validator issue. I presume then 1.0.2 PBFT will still help with ensuring atleast PBFT does not get stuck on the catchup? (It does work ok on the republishing itself today in 1.0.1 if it is already caught up...)","username":"RajaramKannan","ts":"2020-02-10T05:56:22.294Z"}
{"msg":"today the way we are getting over this is by transferring the entire _data files from a current node to the new node so that it doesnt need to catchup and that is working fine ..","username":"RajaramKannan","ts":"2020-02-10T05:57:33.614Z"}
{"msg":"My issue don't sync node1 and node2 but first block sync is succes.\nsawtooth-cli (Hyperledger Sawtooth) version 1.2.4\nubuntu 18.04\n\n1 step : node1 run\n2 step : set intkey five times\n3 step : node2 run\n\nsawtooth-validator log\nERROR    proxy] State from block 9e0ed232.... requested, but root hash 71da3e57.... was missing. Returning empty state.\npoet-engine log\nERROR    poet_block_verifier] Block 9e0ed232 rejected: Received block from an unregistered validator 025f88b8...311d7417","username":"gandhikim","ts":"2020-02-10T11:08:07.511Z"}
{"msg":"@gandhikim Question answered in #sawtooth ","username":"arsulegai","ts":"2020-02-10T11:50:08.117Z"}
{"msg":"From Shawn on what the PBFT release 1.02 should do to help our issues: \"amundson\nTechnical Ambassador - I think that the SDK update was necessary to handle heartbeat messages that the newer validator sends to keep the connection open when there is very low network activity (and a firewall that will timeout connections in betweeen).\"  My team will be installing this over the next couple of days in our test harness to see the results.  Unfortunately we can't get to it right away, but if anyone else has results, feel free to share them and we can see if the timeout issue disapate or disapear.","username":"jamesbarry","ts":"2020-02-10T15:16:38.461Z"}
{"msg":"Has joined the channel.","username":"AnthonyWhite","ts":"2020-02-11T10:24:25.130Z","type":"uj"}
{"msg":"@RajaramKannan @MatthewRubino @agunde @amundson @rejereggie We have installed the new PBFT v1.02 and have run 48k + transactions in 11 hours on our 5 node test network with no dropped connection issues.  I copied several folks who appear to have similar issues to ours. @wkatsak and I believe our dropped connection issue was resolved with the latest PBFT release.  We hope it also works for the rest of you.  ","username":"jamesbarry","ts":"2020-02-11T18:01:05.331Z"}
{"msg":"Has joined the channel.","username":"rejereggie","ts":"2020-02-11T18:01:05.382Z","type":"uj"}
{"msg":"Glad to hear!","username":"agunde","ts":"2020-02-11T18:01:33.659Z"}
{"msg":"jamesbarry thank you for the note.  I think I am starting to get a handle on my coding.","username":"rejereggie","ts":"2020-02-11T21:34:28.391Z"}
{"msg":"PR for rewriting the permission verifier in rust: https://github.com/hyperledger/sawtooth-core/pull/2251 (as well as a couple of changes that fix issues with permissions and forks)","username":"pschwarz","ts":"2020-02-11T22:50:41.192Z"}
{"msg":"PR for rewriting the permission verifier in rust: https://github.com/hyperledger/sawtooth-core/pull/2251 (as well as a couple of changes that fix issues with permissions and forks; block validation)","username":"pschwarz","ts":"2020-02-11T22:50:41.192Z"}
{"msg":"","username":"jamesbarry","ts":"2020-02-12T00:29:13.615Z","attachments":[{"type":"file","title":"jamesbarry - Tue Feb 11 2020 17:28:46 GMT-0700 (Mountain Standard Time).txt","title_link":"/file-upload/62BJjyPpCKrYbw2XH/jamesbarry%20-%20Tue%20Feb%2011%202020%2017:28:46%20GMT-0700%20(Mountain%20Standard%20Time).txt","url":"/file-upload/62BJjyPpCKrYbw2XH/jamesbarry%20-%20Tue%20Feb%2011%202020%2017:28:46%20GMT-0700%20(Mountain%20Standard%20Time).txt","remote":false,"fileId":"62BJjyPpCKrYbw2XH","fileName":"jamesbarry - Tue Feb 11 2020 17:28:46 GMT-0700 (Mountain Standard Time).txt"}]}
{"msg":"The file above is oiur timeout error occurred again at 61k transactions.  I am dropping in our logging from when it happened.  Timeouts again....  These transactions are a weather pulled from an API every 10 seconds in our test environment","username":"jamesbarry","ts":"2020-02-12T00:30:53.856Z"}
{"msg":"@jamesbarry thanks. We are still on 1.1.5 (will move to 1.2.x later this year - as we have consortium partners that all need to get past their internal IS/Compliance teams). So I am still not clear if it will solve our issue (my current understanding is that the PBFT engine is unable to handle certain messages from the 1.2.4/newer validator based on your note above). We will however in the next few days test and see if it has some welcome side effect with 1.1.5 to help with the catchup issue. ","username":"RajaramKannan","ts":"2020-02-12T04:02:29.903Z"}
{"msg":"","username":"jamesbarry","ts":"2020-02-13T15:04:38.068Z","attachments":[{"type":"file","title":"Clipboard - February 13, 2020 8:04 AM","title_link":"/file-upload/6c6fLj8XRuSZx66cA/Clipboard%20-%20February%2013,%202020%208:04%20AM","image_url":"/file-upload/6c6fLj8XRuSZx66cA/Clipboard%20-%20February%2013,%202020%208:04%20AM","image_type":"image/png","image_size":139863,"url":"/file-upload/6c6fLj8XRuSZx66cA/Clipboard%20-%20February%2013,%202020%208:04%20AM","remote":false,"fileId":"6c6fLj8XRuSZx66cA","fileName":"Clipboard - February 13, 2020 8:04 AM"}]}
{"msg":"@agunde @amundson More informationon our crash.  We set three completely seperate networks up.  We have been wanting to see if its IP4, IP6 or a mix of netowrks.  Network 1 was IP4 only, network 2 was IP6 only and network 3 was IP 6 running to our three developer houses and 2 AWS nodes.  Each had 5 nodes, with all five nodes pulling is a weather report from a differnet location every 10 seconds.  All of them experienced network issues.  When a single validator crashed because of a momentary loss of a network connection, sometimes the node was never able to automatically reconnect.  It appears the loss of 2 nodes or more would crash the system. One node only slows the system to a crawl.  Will see if anything interesting is in the log and post here.  But network fluxuations are causing disconnected nodes that cannot reconnect. ","username":"jamesbarry","ts":"2020-02-13T15:08:04.892Z"}
{"msg":"@ltseeley ^","username":"agunde","ts":"2020-02-13T16:08:02.086Z"}
{"msg":"2 nodes going down would halt the network due to there not being enough votes for PBFT to commit anything. Let us know what you find in the logs regarding the disconnections.","username":"ltseeley","ts":"2020-02-13T16:11:03.818Z"}
{"msg":"@Itseeley  Thank you for that- I should have know about 2 nodes.  We are re-running three new chains now.  One question I have is is there a way to limit the number of blocks being added from a backlog on a node that disconnects and tries to reconnect?  Or making it stream instead of submitting so many blaocks again. Out nodes are Ubuntu 18.04 on AWS Mediums with 4 gigs RAM.  Upon reconnecting the RAM &CPU max and the node crashes.  Hence never connecting back again.  We are running AWS large with 8 gIGS now, and we will see.  But I am wondering if the sudden rush of blocks behind causes issues in processing.  Thanks again.","username":"jamesbarry","ts":"2020-02-13T20:07:15.797Z"}
{"msg":"I thought I would echo this. we upgraded to PBFT 1.0.2 and that allowed us to use the validator 1.2.4. we have a 5 node network in test which was hitting the connection issues. those have stopped and it is running smoothly. our 12 node prod network is also continuing to run smoothly.","username":"MatthewRubino","ts":"2020-02-13T20:51:27.317Z"}
{"msg":"Hi, got this message ```sawtooth-validator[11736]: [2020-02-14 15:55:03.482 DEBUG    ffi] [src/journal/candidate_block.rs: 420] Batch 92c9a98e8b769a9485c85a19482b31abdaf9ee270f008a67f71be714b16f84832a70464e7f53f75e8284e709274c1e48a0fda9bbfb1e4cab99cf80e868823982 invalid, not added to block\npbft-engine[11772]: ERROR | pbft_engine::engine: | InternalError: Couldn't find 2f commit messages in the message log for building a seal\n```  \nwhen posting an Invalid batch. I'm already at pbft version 1.0.2","username":"MicaelFerreira","ts":"2020-02-14T16:21:28.620Z"}
{"msg":"is your config using poet or pbft?","username":"MatthewRubino","ts":"2020-02-14T17:31:53.742Z"}
{"msg":"and did you start on poet and switch? if so i think you need to keep the poet-tp","username":"MatthewRubino","ts":"2020-02-14T17:32:16.886Z"}
{"msg":"Why is that?","username":"arsulegai","ts":"2020-02-14T17:36:33.285Z"}
{"msg":"Is it a new node addition, or all the old nodes which have processed the transaction to switch to PBFT?","username":"arsulegai","ts":"2020-02-14T17:37:04.348Z"}
{"msg":"No consensus switch or node addition, I was testing an action that was invalid, and so the batch, and that specific node where I posted the batch start log that `2f commit` logs. This node was also ignored by all other 4 nodes, which required a restart to stay OK","username":"MicaelFerreira","ts":"2020-02-14T17:58:05.307Z"}
{"msg":"No consensus switch or node addition, I was testing an action that was invalid, and so the batch, and that specific node where I posted the batch start log that `2f commit` logs. This node was also ignored by all other 4 nodes, which required a restart to be accepted by the nodes again and be part of the network","username":"MicaelFerreira","ts":"2020-02-14T17:58:05.307Z"}
{"msg":"where is the `poet-engine` coming from? maybe its the container name (but its running pbft)... threw me off","username":"MatthewRubino","ts":"2020-02-14T18:28:10.553Z"}
{"msg":"Sorry but I must ask this, where do you see any poet-engine logs? I'm confused","username":"MicaelFerreira","ts":"2020-02-17T10:12:38.713Z"}
{"msg":"last line : `pbft-engine[11772]: ERROR | pbft_engine::engine:`","username":"MatthewRubino","ts":"2020-02-17T12:12:22.550Z"}
{"msg":"looking at now i don't :( i guess i just misread it repeatedly... sorry about that","username":"MatthewRubino","ts":"2020-02-17T12:13:10.721Z"}
{"msg":"Hello everyone, I'm working with @jamesbarry and we've been trying to debug some connection issues. I apologize for being out of the loop, I was doing some international travel.","username":"wkatsak","ts":"2020-02-17T17:24:02.930Z"}
{"msg":"Maybe james mentioned this already, but we've noticed an issue where if a node goes offline (for whatever reason) and comes back, if it has missed enough blocks, the validator will literally kill its host with OOM.","username":"wkatsak","ts":"2020-02-17T17:25:16.962Z"}
{"msg":"We've been running on AWS nodes with 4 GB of RAM, and can reliably cause a machine to run out of memory and lock up hard.","username":"wkatsak","ts":"2020-02-17T17:26:59.399Z"}
{"msg":"@amundson , @agunde you were tagged earlier, so I am pulling you in now.","username":"wkatsak","ts":"2020-02-17T17:29:50.567Z"}
{"msg":"One quick note, we have the same issue with 8 and 16 gig instances too, but have run over 4.5 million transactions over the weekend on various testnets, and every time we brought a single node offline, and reattached it, memory surges prior to re-attaching .  We are looking at a Jira to put in and would like some comments prior to writing it up.  Can we build in a limiter on RAM usage that can be set with the CLI.  That way, you do not have boundless RAM usage on re-attachment.  ","username":"jamesbarry","ts":"2020-02-17T18:08:18.693Z"}
{"msg":"so we had some issues like that before we got the block info fix. so what we experienced, if a node fell more than 5 minutes behind it would hit the block info bug (basically the timestamp was too old so the block was deemed invalid). in this case the node would be stuck at whatever block it left off at (or 0 if starting from scratch). the stuck node would attempt to sync forever and consume seemingly infinite resources. in our case kube would evict it over and over again.","username":"MatthewRubino","ts":"2020-02-17T19:10:22.233Z"}
{"msg":"i forget your setup, but if you are not using custom TPs or an old block info then it just sound similar but not the same issue. if you guys are not using block info it could be that your transaction processors are not deterministic. at some point they get to a block they cannot get past and get stuck","username":"MatthewRubino","ts":"2020-02-17T19:12:17.862Z"}
{"msg":"We were able to reproduce it with just `intkey`. We wanted to make sure that it wasn't something with our TP.","username":"wkatsak","ts":"2020-02-17T19:23:40.298Z"}
{"msg":"The only \"interesting\" thing that we are doing is submitting a series of `intkey` transactions, where each one has a dependency on the previous transaction.","username":"wkatsak","ts":"2020-02-17T19:24:42.733Z"}
{"msg":"Well to be clear, each node is running a process generating `intkey` transactions, and all submissions from each node are dependent on the previous transaction.","username":"wkatsak","ts":"2020-02-17T19:25:29.210Z"}
{"msg":"No dependency between nodes though.","username":"wkatsak","ts":"2020-02-17T19:25:51.473Z"}
{"msg":"When it goes down though, it really kills the AWS node. You can't even ssh into it. Our grafana shows the memory peak right before it craps out.","username":"wkatsak","ts":"2020-02-17T19:26:30.873Z"}
{"msg":"I remember this issue from the last year, but our tests were on containers so we could control the memory allocated. BTW, were you able to get to the OS error status? Check if IO peak caused because of node being down is able to handle. Memory overrun shouldn't kill the process/node unless there's a leak, peak in IO is expected instead. In our case the last year, it was because consensus engine's error.","username":"arsulegai","ts":"2020-02-18T04:36:32.385Z"}
{"msg":"I remember this issue from the last year, but our tests were on containers so we could control the memory allocated. BTW, were you able to get to the OS error status? Check if IO peak caused because of node down on memory is able to handle. Memory overrun shouldn't kill the process/node unless there's a leak, peak in IO is expected instead. In our case the last year, it was because consensus engine's error.","username":"arsulegai","ts":"2020-02-18T04:36:32.385Z"}
{"msg":"Has joined the channel.","username":"puria","ts":"2020-02-18T14:42:32.887Z","type":"uj"}
{"msg":"@arsulegai Thanks for this note.  @wkatsak and I are convinced that we need to put a limit on how many blocks can be processed at a time to catch up from a diconnected node.  We had a node that crashed every time that we tried to reconnect, because if dumped all blocks need to catch up in memory at the same time, thus getting us the out of memory error.  We are in the process of trying to recreate on Docker where we control the memory constraints much tighter to see if that helps the issue.  But our target market does not use containers. By the way we ran 4.5 million intkey transactions into our blockchain in 30 hours with 5 nodes, before we ran into this. Then the entire chain went down hard.  We want to get the correct logs to show why we beleive you need to moderate the number of blocks processed at a time for a node catching up.  Also, the network connection manager has issues prior to dropping the node.  We want to reproduce that too, for a total of 2 JIRAS. once we get the reproducability.","username":"jamesbarry","ts":"2020-02-18T18:52:49.745Z"}
{"msg":"@jamesbarry @arsulegai @amundson @agunde So, I have a bit of progress on the memory issue. I stood up a v1.2.4 compose environment with 5 validators and PBFT.     Validators were limited to 1GB of RAM in compose config. I left one validator offline, then did a few 100k `intkey` transactions. Sure enough, when I try to bring up the last validator the recovery process eats all available memory, and swaps over 2GB of additional data (seems like it requests all blocks at once).  If I try with swap disabled, the validator just crashes hard (which kind of makes sense).","username":"wkatsak","ts":"2020-02-19T14:53:57.076Z"}
{"msg":"Our AWS test machines didn't have swap enabled, so maybe this is the cause of our hard crashes. This seems like it should be carefully thought about, however. Does it really makes sense to try to load ALL behind blocks, then process them?","username":"wkatsak","ts":"2020-02-19T14:55:29.291Z"}
{"msg":"Incidentally, when I restarted the containers with an 8GB memory limit, it crashed anyway after a while, with this:\n```\nsawtooth-pbft-engine-default-4 | INFO  | pbft_engine::node:39 | (PP, view 1, seq 121): Received f + 1 ViewChange messages; starting early view change\nsawtooth-pbft-engine-default-4 | INFO  | pbft_engine::node:16 | (PP, view 1, seq 121): Starting change to view 59\nsawtooth-validator-default-4 | [2020-02-19 14:46:15.930 WARNING  (unknown file)] [src/journal/block_validator.rs: 284] Error during block validation: BlockValidationError(\"During validate_on_chain_rules, error creating settings view: NotFound(\\\"d5f20720b5c99592c3f2f649b7eb5b082bf952aaa3aea615f25c583823d214ce\\\")\")\nsawtooth-pbft-engine-default-4 | INFO  | pbft_engine::node:48 | (V(59), view 59, seq 121 *): Updated to view 59\nsawtooth-validator-default-4 | thread '<unnamed>' panicked at 'No lock holder should have poisoned the lock: \"PoisonError { inner: .. }\"', src/libcore/result.rs:1188:5\nsawtooth-validator-default-4 | fatal runtime error: failed to initiate panic, error 5\nsawtooth-pbft-engine-default-4 | INFO  | sawtooth_sdk::messag | Received Disconnect\nsawtooth-pbft-engine-default-4 | DEBUG | sawtooth_sdk::messag | Exited stream\nsawtooth-pbft-engine-default-4 | ERROR | pbft_engine::engine: | ServiceError: Couldn't initialize block after view change due to: ReceiveError: DisconnectedError\nsawtooth-pbft-engine-default-4 | DEBUG | zmq:489              | socket dropped\nsawtooth-pbft-engine-default-4 | DEBUG | zmq:489              | socket dropped\n``` ","username":"wkatsak","ts":"2020-02-19T14:56:14.185Z"}
{"msg":"This guy: `Error during block validation: BlockValidationError(\"During validate_on_chain_rules, error creating settings view: NotFound(\\\"d5f20720b5c99592c3f2f649b7eb5b082bf952aaa3aea615f25c583823d214ce\\\")\")` was occurring a lot up to the crash.","username":"wkatsak","ts":"2020-02-19T14:56:50.426Z"}
{"msg":"Not sure if this is an orthogonal issue, or what","username":"wkatsak","ts":"2020-02-19T14:57:02.406Z"}
{"msg":"@wkatsak that's a great finding, it should be noted in sawtooth-website or the document as a caution to the cluster administration.","username":"arsulegai","ts":"2020-02-19T15:06:15.916Z"}
{"msg":"One the prior question, there were requests for state checkpointing feature which avoids cycling through all the blocks from the genesis when a node comes up in between.","username":"arsulegai","ts":"2020-02-19T15:07:11.917Z"}
{"msg":"@arsulegai @wkatsak In the next several days we will update this feature request from 2/1/2018  Evidently this is an issue that has been around and needs resolution as it causes a crash that is hard to trace back.  More to come in this Jira going forward.  SawtoothSTL-972\n\"Reduce memory consumption on block catchup\"","username":"jamesbarry","ts":"2020-02-19T16:41:01.521Z"}
{"msg":"@wkatsak os metrics may be misleading because of aggressive caching that lmdb performs, so its important to be very specific about what metrics you are using (and ideally with graphs of the behavior, if you can get the data into that format)","username":"amundson","ts":"2020-02-19T17:12:17.261Z"}
{"msg":"before evaluating a block, the completer component within the validator will ensure that the validator has all the previous blocks required before sending teh block to the journal. it does this one block at a time (it does not have enough information to do otherwise with the current APIs between validators), and it is very inefficient for long chains. you will observe this as a period were the validator is doing a lot of block requests but not advancing the chain head.","username":"amundson","ts":"2020-02-19T17:17:27.916Z"}
{"msg":"however, IIRC, the blocks are persisted to disk during this process as part of the block manager changes between 1.1 and 1.2, but would have to spend some time diving into it again to verify that","username":"amundson","ts":"2020-02-19T17:22:01.492Z"}
{"msg":"that doesn't mean something else isn't eating up memory during that process (or that the use of block manager isn't helping for whatever reason), but there were definitely changes since STL-972 was filed that probably made this better than previously","username":"amundson","ts":"2020-02-19T17:25:44.356Z"}
{"msg":"@amundson I'd have to look into the details of how lmdb works (does it memory map the file or something? not sure) but this is definitely allocating and using a lot of memory. Like I said, if I disable swap, you can watch the validator process run up to the memory limit (on top), then crash when it cannot allocate any more memory.","username":"wkatsak","ts":"2020-02-19T18:27:15.893Z"}
{"msg":"@wkatsak yes, lmdb uses mmap. I'm not suggesting there isn't a problem, just sensitive to the difficulty in diagnosis/resolution. one of the guys that knows a lot in this area is back from vacation next week. we should be able to get quite a bit of data out of the process. it's a bit more difficult because of the mix of python and rust but its doable.","username":"amundson","ts":"2020-02-19T20:03:27.220Z"}
{"msg":"I've been looking at connection management code...the python/rust boundary is also painful there...","username":"wkatsak","ts":"2020-02-19T21:17:39.882Z"}
{"msg":"@jamesbarry @arsulegai @amundson Another interesting result. I've set up a similar network to the last example (docker compose, 5 nodes, pbft). In this case, I am running an additional 5 containers, each of them generating a stream of intkey transactions to a particular validator (with each transaction dependent on the previous one). Once this was running, I stopped and restarted a randomly chosen validator a couple times, and was able to get the network into a state where it wasn't taking any more transactions, with lots of messages like this:\n```\nsawtooth-validator-default-0 | [2020-02-19 22:09:52.818 DEBUG    ffi] [src/journal/candidate_block.rs: 165] Transaction rejected due to missing dependency, transaction 15f0e987b12fda21d15884f165c3d383f42a04c6ebb41f0cbac78e5a00fc4e711b57bb17073ff0808f8838b3191a2ae2d3c4f713e6fa723685bb2b68cbc7721f depends on 54409191748a82f0fd17254836502e974a61f5099119cab4417337500910817f7d7723cf032a6b0db430c1140e3fb1f40bd72175466d004ada273c85e4449fc3\n\n``` ","username":"wkatsak","ts":"2020-02-19T22:10:23.877Z"}
{"msg":"To try to automate, I brought in `https://github.com/alexei-led/pumba` to my compose config. This is a package to introduce random failures to docker configurations. I configured it to periodically pick a random validator, and pause the container for a bit, then let it resume.  This took a little longer, but the network eventually converted into a similar state.","username":"wkatsak","ts":"2020-02-19T22:12:18.398Z"}
{"msg":"The accept queues are all blocked up, and return 429s.","username":"wkatsak","ts":"2020-02-19T22:12:54.326Z"}
{"msg":"converged* not converted","username":"wkatsak","ts":"2020-02-19T22:13:06.902Z"}
{"msg":"lmdb uses linux fscache pages, which will not result in oom. Those pages will be the first to go when process memory needs to be allocated. The memory utilization on catchup is most likely due to the large number of blocks held in the completer. As @amundson mentioned, some block manager changes may have addressed portions of this, but it is likely that something is holding onto these references, instead of persisting them to disk and reloading later. The sawtooth catchup process could be substantially improved with the addition of two features: 1) a negotiation between the behind node and its peer on most recent common block height and then a protocol which sends those blocks sequentially as they are requested and applied by the behind node. 2) a state checkpointing/transfer mechanism.","username":"jsmitchell","ts":"2020-02-19T22:28:53.609Z"}
{"msg":"#1 should be fairly easy and should address the issue for reasonable catchups. It would at a minimum operate with known memory constraints. #2 is significantly more complex and would solve the issue for arbitrary depth catchups with node bring up times related to the size of the database checkpoint.","username":"jsmitchell","ts":"2020-02-19T22:31:50.467Z"}
{"msg":"Future more exotic possibilities involve partial state transfer with branch merkle hashes where the state is transferred incrementally as needed to validate incoming blocks or answer queries.","username":"jsmitchell","ts":"2020-02-19T22:32:48.953Z"}
{"msg":"@wkatsak that's correct. A solution was discussed for this issue where periodically the pending queue is cleared making space for new messages. It's interesting though, if its it's a random failure of upto 2 nodes then it should be able to process incoming transaction and expanding pending queue size. If you're failing validator much before it could catchup with others often then I do not know of a way to avoid 429. But in either case, you should see eventually 429 getting away?","username":"arsulegai","ts":"2020-02-20T00:46:55.104Z"}
{"msg":"@jsmitchell both system configuration and the application data are put in the same global state. Would that make it difficult to get towards proposal # 1 you mentioned?\n\nAre you suggesting that the new node query data from others as and when there's a request from user for that? Maybe the new node has broken links between the most recent block from where it is catching up to the current head. It'll never try to fill in the gap unless requested to do so?","username":"arsulegai","ts":"2020-02-20T00:57:49.455Z"}
{"msg":"@arsulegai no, it’s just a matter of changing the catchup protocol. State marches in concert with block application. If a node is 1000 blocks back, it needs a strategy for catchup — currently that process is recursive from the current head of the network. A better approach would be iteration in chunks based on shared most recent common block between nodes.","username":"jsmitchell","ts":"2020-02-20T01:27:21.723Z"}
{"msg":"The partial thing is a future exotic capability.","username":"jsmitchell","ts":"2020-02-20T01:28:05.277Z"}
{"msg":"How about that protocol negotiation take inference from the consensus engine attached to it?","username":"arsulegai","ts":"2020-02-20T01:36:26.949Z"}
{"msg":"For example, PBFT/RAFT would never fork. If majority of nodes have common block. Accept it blindly without a proof from the past. But global state sync is still a big problem to solve. ","username":"arsulegai","ts":"2020-02-20T01:38:04.485Z"}
{"msg":"Copying the global state from one of the current nodes to the new machine solves that concern? Don't know how good that is practically.","username":"arsulegai","ts":"2020-02-20T01:43:52.611Z"}
{"msg":"@arsulegai I believe and I have posted here and elsewhere a similar issue in catchup - this is with 1.1.5 and PBFT 1.0.1.  With just 886 blocks to catchup, the node was getting stuck at 255 (in other nodes, I could see an attempt to republish 255 every now and then even though the current head was at 886 blocks), so I presume that was part of the problem (and yet unexplained why it was happening).  (the node that was out of sync was part of PBFT and it is a small network so we were unable to publish any new blocks).  In any case, we were able to bring back the entire network up and running, by copying over the global state, blocks etc (the entire _data folder if you will) to the new node. Learnt a lot in the process because during our trial and error process we ended up bricking the network so we actually ended up doing this for all nodes in the network and bringing them up simultaneously.  We noticed that in this process we had to restart the validator/pbft a few times in each nodes since some of them were stalling - but with a few restarts (we were using the PBFT logs and the view numbers to guide us in ensuring all nodes were at the same view number eventually). So copying the global state over does work... Not ideal - we use generated custom events to catchup an external DB - but we now have a recovery utility that reads each block and resends the events manually! - but works.","username":"RajaramKannan","ts":"2020-02-20T05:05:13.552Z"}
{"msg":"Interesting and nice findings! Would it be possible to open source the utility for others benefit?","username":"arsulegai","ts":"2020-02-20T05:09:41.151Z"}
{"msg":"@arsulegai we are still working on the utility (we used an in progress version since it was an emergency), but happy to open source it once we have it fully working. Just in case I forget, you can hold me to it","username":"RajaramKannan","ts":"2020-02-20T05:26:42.931Z"}
{"msg":"question to the team - noticed but ignored this earlier, but once again today we noticed it. We have a PBFT setup with 4 nodes and setup with static peering in the respective validator.toml file.   Node 1, Node2 (peers: Node1 IP), Node3 (peers: Node 2, Node 3 IPs), Node 4 (peers:Node 2, 3, 4)```\nToday Node 3 went down (more accurately the containers within). When we brought Node 3 back up, it connected with Node 1 and Node 2 (checked using the /peers api call). But Node 3- Node 4 did not connect. We had to then restart Node4 to connect! (Validator version 1.1.5). Is this a known issue?\n``` ","username":"RajaramKannan","ts":"2020-02-20T08:09:17.823Z"}
{"msg":"How long did you wait for Node 4 when you found it's not listing Node 3? Node 4 has to initiate a connection to Node 3. In this case it has 1 failed connection, 2 successful connections active. Eventually it should have caught up with Node 3 as well. But you can also force minimum peer connectivity setting to 3 for the Node 4.","username":"arsulegai","ts":"2020-02-20T08:43:16.279Z"}
{"msg":"we do have minimum peer connectivity settings set to 3. We waited several minutes (say 10-15 - but I wasnt timing so cant be sure.). Would Node 4 try to reconnect?  How long would it typically take? (or perhaps, because The Node was down for an entire day, so I wonder if in the connection attempts there is some logic that escalates the timeout each time the attempt fails?)","username":"RajaramKannan","ts":"2020-02-20T08:51:18.953Z"}
{"msg":"Has joined the channel.","username":"Michael8086","ts":"2020-02-20T16:28:05.188Z","type":"uj"}
{"msg":"Has joined the channel.","username":"ParitoshPandey","ts":"2020-02-20T18:07:41.706Z","type":"uj"}
{"msg":"","username":"jamesbarry","ts":"2020-02-20T18:12:46.054Z","attachments":[{"type":"file","title":"Clipboard - February 20, 2020 11:12 AM","title_link":"/file-upload/ua6k55EKyfQ9RpFDF/Clipboard%20-%20February%2020,%202020%2011:12%20AM","image_url":"/file-upload/ua6k55EKyfQ9RpFDF/Clipboard%20-%20February%2020,%202020%2011:12%20AM","image_type":"image/png","image_size":163410,"url":"/file-upload/ua6k55EKyfQ9RpFDF/Clipboard%20-%20February%2020,%202020%2011:12%20AM","remote":false,"fileId":"ua6k55EKyfQ9RpFDF","fileName":"Clipboard - February 20, 2020 11:12 AM"}]}
{"msg":"@RajaramKannan We have a similar issue.  But when our node auto restarts, it floods transaction onto the node until it runs out of memory and the AWS instance reboots itself and tries to reconnect, where is gets the transactions and restarts yet again.  I am not sure if that is your problem or not.  It is simply no gate on the number of transactions to catch up on, and if the node has too many transactions it is behind and that number is greater than available memory, you will continually restart that node.  ","username":"jamesbarry","ts":"2020-02-20T18:12:51.026Z"}
{"msg":"@jamesbarry see my comment above","username":"jsmitchell","ts":"2020-02-20T18:32:12.871Z"}
{"msg":"Design discussions/PRs for tackling those feature additions would be very welcome","username":"jsmitchell","ts":"2020-02-20T18:33:41.493Z"}
{"msg":"I updated this old Sawtooth feature request in Jira as evidently this has been on the plate for a while.  We will update with a better plan to implement over the next few days.  \"STL-972 Reduce memory consumption on block catchup\"","username":"jamesbarry","ts":"2020-02-20T19:50:47.827Z"}
{"msg":"@jsmitchell @RajaramKannan I updated this old Sawtooth feature request in Jira as evidently this has been on the plate for a while.  We will update with a better plan to implement over the next few days.  \"STL-972 Reduce memory consumption on block catchup\"","username":"jamesbarry","ts":"2020-02-20T19:50:47.827Z"}
{"msg":"@jamesbarry we havent hit the memory issue yet, our deployments are via docker and typically we have used reasonbly sized EC2 instances.  Will keep a watch if see similar (we dont have the same number of transaction volumes yet that you have generated perhaps).","username":"RajaramKannan","ts":"2020-02-21T09:00:18.303Z"}
{"msg":"we are however seeing the catchup issue in general as my colleague @ParitoshPandey posted in the other channel","username":"RajaramKannan","ts":"2020-02-21T09:02:15.982Z"}
{"msg":"I posted Jira issue STL-1700  https://jira.hyperledger.org/browse/STL-1700 tonight.  The issue we have had on block's catching up in a validator is a memory-swap issue.  We detailed how to recreate the issue and why you don't see it in a memory swap enabled Docker.","username":"jamesbarry","ts":"2020-02-24T03:52:29.971Z"}
{"msg":"@jamesbarry as you point out we may be facing this issue as well as posted by @ParitoshPandey . However the node trying to catchup has just ~400 blocks. It is running on a partner's infrastructure so we dont have direct access to it making it harder to troubleshoot. They are using the docker compose files provided by us and we havent specifically setup any memory swap.  Just so we are able to check if it is related, when you mention above *_\"if the node has too many transactions it is behind and that number is greater than available memory, you will continually restart that node.\" _*, is there some way to work out an equation that shows the transaction size or number to the available memory that prevents the node from catching up? (I am making an assumption, probably incorrect, that it may not be just the number of transactions but perhaps also what it writes to the state/custom events etc?)","username":"RajaramKannan","ts":"2020-02-25T07:41:56.138Z"}
{"msg":"we definitely hit this issue. we are running ing EKS so with kube I do not think you can even define a swap. nodes would sync very slowly, get evicted, and restart","username":"MatthewRubino","ts":"2020-02-25T15:26:44.168Z"}
{"msg":"we definitely hit this issue. we are running in EKS so with kube I do not think you can even define a swap. nodes would sync very slowly, get evicted, and restart","username":"MatthewRubino","ts":"2020-02-25T15:26:44.168Z"}
{"msg":"Has joined the channel.","username":"mzins_dev","ts":"2020-02-25T20:55:38.099Z","type":"uj"}
{"msg":"@RajaramKannan @MatthewRubino Docker will usually utilize swap by itself if the node is configured for swapping. AWS Linux nodes are not by default, as it turns out.","username":"wkatsak","ts":"2020-02-26T00:58:11.408Z"}
{"msg":"I don't know about how much memory would exactly be required, you could probably extrapolate it by looking at the growth over time.","username":"wkatsak","ts":"2020-02-26T00:58:33.306Z"}
{"msg":"yes it will, however (my understanding is) kubernetes will still determine a process as a hog regardless of any swap configured and evict it.","username":"MatthewRubino","ts":"2020-02-26T01:12:39.393Z"}
{"msg":"This swap behavior is not desirable. A feature to improve the catchup protocol would allow the receiving node to decide how much it wanted to buffer as it was performing validations.","username":"jsmitchell","ts":"2020-02-26T01:21:18.745Z"}
{"msg":"@jsmitchell I don't think a special-case catch-up mode is necessary (or a good idea). So catch-up is probably the wrong word here, it's really about efficiently processing chain heads with a much greater block height than the current chain. If we were only handling consensus that had finality, then you could see this purely as a catch-up exercise, but with forking consensus it's not a special case, it's the norm, and the efficiency issue happens when the delta is large. (Point is, it's not a special mode.)","username":"amundson","ts":"2020-02-26T15:53:08.146Z"}
{"msg":"The recursive nature of the requests is (requesting blocks in reverse order until we have the complete set) is not super problematic, except that a) we seem to be holding onto too much in memory, which could be solved by making sure it gets offloaded to storage; b) for really long deltas, the amount of time to get all the blocks can be a problem because no work is getting done while we get all the blocks.","username":"amundson","ts":"2020-02-26T15:56:21.197Z"}
{"msg":"Solving for (b) is difficult for the forking consensus case, which is why we have the recursive approach we have now. Essentially, any efficient solution requires one validator to ask for blocks going forward from a point at which they both share history. The difficulty is in determining that historical shared point efficiently and then adding code to do that negotiation. Once that was solved, we could add a get_blocks(chain_head, starting_height, count) to incrementally get blocks in forward order.","username":"amundson","ts":"2020-02-26T16:00:19.391Z"}
{"msg":"However, we also would need to change our approach to handling off those blocks to the journal so that we don't just hold onto them in the completer. Today, when we get a block, we consider it a chain head, get the complete chain up to that point, then ask the journal to consider whether the chain head is better than what we have. Switching that to a more incremental approach requires a bit more journal+completer work. It also assumes that for any given chain head, at every block height, it is the preferred chain (which I'm pretty sure we said isn't a valid assumption in some cases of forking consensus, though that isn't clear).","username":"amundson","ts":"2020-02-26T16:04:04.007Z"}
{"msg":"I feel like we should be able to have a hint to the completer/journal that allows us to do the right thing when using consensus engines that have finality, because 90% of the complexity doesn't apply in those cases.","username":"amundson","ts":"2020-02-26T16:05:18.251Z"}
{"msg":"Solving (a) should be fairly straight-forward in comparison.","username":"amundson","ts":"2020-02-26T16:06:19.877Z"}
{"msg":"For example, when we have finality, we know the point of shared history (it will be the current chain head), and so we can immediately request the next block. It's also completely safe to immediately start applying that block (there is no ambiguity around correctness). The only thing that maybe would need to be done is to make sure that the journal intelligently orders its processing of work, so it's not confused by a fast influx of blocks in a forward manner. I don't recall if it's already smart about this or not, I know we discussed duplicate-work-avoidance previously.","username":"amundson","ts":"2020-02-26T16:11:25.706Z"}
{"msg":"@amundson @jsmitchell I agree that the swapping is not desired behavior. At the very least, it slows down the process. I only proposed this as a workaround until we can figure out what the right way forward is.","username":"wkatsak","ts":"2020-02-26T17:29:25.671Z"}
{"msg":"I haven't had time to dive into this code, but I've gleaned from discussions that what the system is supposed to do is get the blocks and put them into local storage, then do the validation. Is it possible that some code is simply not dropping the references to the blocks, and that is why they are staying in memory?","username":"wkatsak","ts":"2020-02-26T17:30:38.477Z"}
{"msg":"@amundson We have two forking consensus's today POET (elect new leaders causing the fork) and PBFT ( changing the primary node causing the fork) and one that is non-forking, RAFT.  If anyone is using the non-forking RAFT we should allow for non-forking consensus's to have a special path when selected, so that can be solved quickly.  We can keep the forking consensus with its own code that can be updated as additioanl consensus mechanisms are added to address different corporate workloads.  When adding consensus mechanisms they can go down the most efficient path. (Like Proof of Authority which is non forking) That might make it easier down the road as more consensus mechanisms are added.  ","username":"jamesbarry","ts":"2020-02-27T04:06:29.233Z"}
{"msg":"@jamesbarry just for my understanding when you say PBFT is forking, my understanding was that the final commit phase will always result in a non-forking behavior (no node will have in their state/blocks a fork). It is only during the earlier stages (and specifically when the primary node changes and therefore the next node proposes potentially a different block for processing), that there is forking that gets resolved before it gets committed. (Unlike in POET where it might commit the fork and resolve later?)","username":"RajaramKannan","ts":"2020-02-27T04:39:04.054Z"}
{"msg":"Has joined the channel.","username":"Ashish_ydv","ts":"2020-02-27T07:48:00.732Z","type":"uj"}
{"msg":"@jamesbarry It might be useful to first agree on what we mean by a fork -- in the context of Sawtooth, we mean that, for the same block height, different nodes have committed different blocks to the chain. This is a property of nakamoto-style consensus like PoW or PoET. This is because not every node in the network immediately sees all blocks, and so the decisions are not perfect. Eventually, the nodes will find adopt the winning block once they receive it, replacing the older block which was previously applied. We often call that process fork resolution. The result is that blocks can essentially end up uncommitted from the chain. This is very complex both from a journal perspective and from a client perspective (clients need some sense that state may completely shift, like using slowly changing dimensions in database materialization of state, etc.). This situation doesn't occur with PBFT or Raft.","username":"amundson","ts":"2020-02-27T14:44:57.872Z"}
{"msg":"@wkatsak seems possible, needs more investigation","username":"amundson","ts":"2020-02-27T14:47:32.389Z"}
{"msg":"@amundson Thank you for the clarification.  I was reading through the docs late last night, and got mixed up.  I agree that forking does not occur with PBFT or RAFT.  That being said, is it possible that upon loading PBFT, RAFT or any non-forking consensus mechanism's that there is a separate mechanism to solve (a) from above.  PoET itself seems to be in a standstill on development of a PoET 2.0.  Perhaps the path upon load could then keep PoET and other forking mechanisms on one way of merging in a new or returning node, while non-forking consensus would be handled another way.  I believe that having a pluggable consensus is a good idea, not all mechanisms can be handled the same way.  We can’t simply plug them in without taking into account various ways these mechanisms handle valid blocks. If we end up with a staking consensus, that is even more radical. It might mean that we need coarse grain segmentation-consensus paths upon load that will segment type of consensus properly.  I am not in favor of a one-size-fits-all approach to pluggable consensus, as we have seen, use cases can change approaches dramatically which makes coding even harder.   For a consensus to be sued, we might need a metadata definition header as the consensus is loaded to determine how blocks and nodes are handled. Just my quick thoughts.","username":"jamesbarry","ts":"2020-02-27T21:14:33.362Z"}
{"msg":"@amundson Thank you for the clarification.  I was reading through the docs late last night, and got mixed up.  I agree that forking does not occur with PBFT or RAFT.  That being said, is it possible that upon loading PBFT, RAFT or any non-forking consensus mechanism's that there is a separate mechanism (path) to solve (a) from above.  PoET itself seems to be in a standstill on development of a PoET 2.0.  Perhaps the path upon load could then keep PoET and other forking mechanisms on one way of merging in a new or returning node, while non-forking consensus would be handled another way.  While I believe that having a pluggable consensus is a good idea, not all mechanisms can be handled the same way.  We can’t simply plug them in without taking into account various ways these mechanisms handle valid blocks. For example, If we end up with a building for a staking consensus, that can be an even more radical design. It might mean that we need coarse grain segmentation-consensus paths upon load that will segment type of consensus properly.  I am not in favor of a one-size-fits-all approach to pluggable consensus, as we have seen, use cases can change approaches dramatically which makes coding even harder.   For a consensus to be used, we might need a metadata definition header as the consensus is loaded to determine how blocks and nodes are handled. Just my quick thoughts.","username":"jamesbarry","ts":"2020-02-27T21:14:33.362Z"}
{"msg":"Has joined the channel.","username":"UdayBollineni","ts":"2020-02-28T10:03:15.383Z","type":"uj"}
{"msg":"Hi all,\nI am facing an issue in the validator. I have created a jira ticket for that. \nhttps://jira.hyperledger.org/browse/STL-1701","username":"UdayBollineni","ts":"2020-02-28T10:03:16.274Z"}
{"msg":"@UdayBollineni Hi, can you provide more information about when the error happened. For example was this on start up? After it had been running for a while? Any other errors or events happen around it?","username":"agunde","ts":"2020-02-28T14:00:33.058Z"}
{"msg":"@UdayBollineni @agunde Please check your peer list. It is possible that you have an accidental empty string `''` listed as a peer. This can generate the ZMQ error specified.","username":"wkatsak","ts":"2020-02-28T15:51:50.349Z"}
{"msg":"Can you post your `validator.yaml`","username":"wkatsak","ts":"2020-02-28T15:56:44.711Z"}
{"msg":"I think there are a couple of things getting mixed up here @jamesbarry @wkatsak @amundson , and it would be helpful to keep them separate.","username":"jsmitchell","ts":"2020-02-28T16:00:51.990Z"}
{"msg":"@jamesbarry it sounds like you are talking about different consensus approaches and whether the existing interface or an enhanced interface would be capable of covering a spectrum of consensus models. We are very interested in that conversation, specifically regarding enhancements needed or detailed examples of difficulties with plugging novel consensus into such an interface. I propose we have this discussion on the #sawtooth-consensus-dev channel","username":"jsmitchell","ts":"2020-02-28T16:03:23.139Z"}
{"msg":"That is a separate issue from the catch up discussion. The concept of catchup being sensitive to forking/non-forking consensus was brought up - let me attempt to explain why that’s not the case.","username":"jsmitchell","ts":"2020-02-28T16:05:05.868Z"}
{"msg":"Currently, when a node makes a peer connection, it requests that peer’s chain head. The intent is the remote node shares the newest block it has determined is valid and has committed to its chain. When the node joining the network receives it, it determines if it has the required dependencies to validate it, which includes the parent block. It continues to request, parse, and request the parent blocks until it the dependencies are satisfied or until it reaches the first block in the chain (where the parent is a special null block identifier). This process has some significant drawbacks - it carries high latency since each request needs to go through the receive parse request loop, it delays the start of validation until the entire dependency chain is unzipped, and it requires an unbounded amount of storage (currently in ram) during operation. At the end of the day, however, this is just the simple transfer of a linked list of blocks between the “most recent shared common block” and the remote peer’s chain head. There are no fork blocks involved or transferred. While this lengthy process is happening, new blocks are being published and being received by the new node as well, and they go through this same completion process. Regardless of whether the consensus mechanism forks or not, those blocks will be received and their dependencies will be requested as above. This will likely have the effect of short branch like structures being added to the end of the linked block list that is being accumulated by the completer. If the remote peer’s chain head is on a discarded fork, the same thing will correct it - new blocks received from other nodes will be dependency resolved to a somewhat earlier point in the chain being requested.","username":"jsmitchell","ts":"2020-02-28T16:17:11.051Z"}
{"msg":"Currently, when a node makes a peer connection, it requests that peer’s chain head. The intent is the remote node shares the newest block it has determined is valid and has committed to its chain. When the node joining the network receives it, it determines if it has the required dependencies to validate it, which includes the parent block. It continues to request, parse, and request the parent blocks until either the dependencies are satisfied or until it reaches the first block in the chain (where the parent is a special null block identifier). This process has some significant drawbacks - it carries high latency since each request needs to go through the receive parse request loop, it delays the start of validation until the entire dependency chain is unzipped, and it requires an unbounded amount of storage (currently in ram) during operation. At the end of the day, however, this is just the simple transfer of a linked list of blocks between the “most recent shared common block” and the remote peer’s chain head. There are no fork blocks involved or transferred. While this lengthy process is happening, new blocks are being published and being received by the new node as well, and they go through this same completion process. Regardless of whether the consensus mechanism forks or not, those blocks will be received and their dependencies will be requested as above. This will likely have the effect of short branch like structures being added to the end of the linked block list that is being accumulated by the completer. If the remote peer’s chain head is on a discarded fork, the same thing will correct it - new blocks received from other nodes will be dependency resolved to a somewhat earlier point in the chain being requested.","username":"jsmitchell","ts":"2020-02-28T16:17:11.051Z"}
{"msg":"Currently, when a node makes a peer connection, it requests that peer’s chain head. The intent is the remote node shares the newest block it has determined is valid and has committed to its chain. When the node joining the network receives it, it determines if it has the required dependencies to validate it, which includes the parent block. It continues to request, parse, and request the parent blocks until either the dependencies are satisfied or until it reaches the first block in the chain (where the parent is a special null block identifier). This process has some significant drawbacks - it carries high latency since each request needs to go through the receive parse request loop, it delays the start of validation until the entire dependency chain is unzipped, and it requires an unbounded amount of storage (currently in ram) during operation. At the end of the day, however, this is just the simple transfer of a linked list of blocks between the “most recent shared common block” and the remote peer’s chain head. There are no fork blocks involved or transferred. While this lengthy process is happening, new blocks are being published and being received by the new node as well, and they go through this same completion process. Regardless of whether the consensus mechanism forks or not, those blocks will be received and their dependencies will be requested as above. This will likely have the effect of short branch like structures being added to the end of the linked block list that is being accumulated by the completer. If the remote peer’s chain head is on a discarded fork, the same thing will correct it - new blocks received from other nodes will be dependency resolved to a somewhat earlier point in the chain being requested.","username":"jsmitchell","ts":"2020-02-28T16:17:11.051Z"}
{"msg":"Currently, when a node makes a peer connection, it requests that peer’s chain head. The intent is the remote node shares the newest block it has determined is valid and has committed to its chain. When the node joining the network receives it, it determines if it has the required dependencies to validate it, which includes the parent block. It continues to request, parse, and request the parent blocks until either the dependencies are satisfied or until it reaches the first block in the chain (where the parent is a special null block identifier). This process has some significant drawbacks - it carries high latency since each request needs to go through the receive parse request loop, it delays the start of validation until the entire dependency chain is unzipped, and it requires an unbounded amount of storage (currently in ram) during operation. At the end of the day, however, this is just the simple transfer of a linked list of blocks between the “most recent shared common block” and the remote peer’s chain head. There are no fork blocks involved or transferred. While this lengthy process is happening, new blocks are being published and being received by the new node as well, and they go through this same completion process. Regardless of whether the consensus mechanism forks or not, those blocks will be received and their dependencies will be requested as above. This will likely have the effect of short branch like structures being added to the end of the linked block list that is being accumulated by the completer. If the remote peer’s chain head is on a discarded fork, the same thing will correct it - new blocks received from other nodes will be dependency resolved to a somewhat earlier point in the chain being requested.","username":"jsmitchell","ts":"2020-02-28T16:17:11.051Z"}
{"msg":"So, none of this is a “mode” and none of it is relevant to how the consensus algorithm considers forks. My proposal above was to enhance the block transfer request process to allow negotiation for “most recent common shared block” to some arbitrary future block in an ordered list (likely the remote node’s chain head). This would allow the blocks to be transferred in order avoiding the latency of the recursive request parse request loop, and allowing the first blocks to begin validation immediately upon receipt. The existing completer functionality would remain intact. The slow existing process would begin requesting dependencies backward from newly received blocks, while the enhanced transfer process would be racing from the beginning. At some point (probably fairly close to the original chain head) they would “meet up” and the completer could stop recursively requesting parents.","username":"jsmitchell","ts":"2020-02-28T16:23:06.168Z"}
{"msg":"@jsmitchell This sounds like a good solution to the issue. Is there anything that we can do to help make it happen?","username":"wkatsak","ts":"2020-02-28T17:00:44.734Z"}
{"msg":"submit a PR :)","username":"jsmitchell","ts":"2020-02-28T17:00:55.493Z"}
{"msg":"(as an aside, I also think it would be a good idea to make the completer's behavior bounded for memory usage with a backing store)","username":"jsmitchell","ts":"2020-02-28T17:01:53.887Z"}
{"msg":"@jsmitchell the difference is that, when you have finality, you can very easily immediately request the blocks in a forward order without negotiating the information about a common ancestor -- block height is enough","username":"amundson","ts":"2020-02-28T20:25:56.496Z"}
{"msg":"@jamesbarry the current approach is to let consensus \"drive\" -- which means, it is telling journal (chain controller really) what to do and when to do it. this greatly reduces the need for journal to know anything about consensus. this is actually a great approach and it works really well architecturally; but, if we extend that idea to allow for pluggable chain controllers, we can implement chain controllers that have less features (which is why its interesting to me) and we can implement chain controllers that don't necessarily have to have a single chain (also interesting). splinter's scabbard implementation could mostly be thought of a chain controller with no chain (ok, we need to rename chain controller probably).","username":"amundson","ts":"2020-02-28T20:35:11.169Z"}
{"msg":"@amundson sure, but I don't think a binary search on a set of block signatures is onerous. It's going to be a list of length log2 of the search space","username":"jsmitchell","ts":"2020-02-28T20:36:28.679Z"}
{"msg":"it's a lot of network traffic and async opportunity for error between the nodes","username":"amundson","ts":"2020-02-28T20:37:11.308Z"}
{"msg":"In the usual case, the most recent block the connecting client will have is either a block in the peer's history or the null block identifier (starting from scratch)","username":"jsmitchell","ts":"2020-02-28T20:37:42.866Z"}
{"msg":"it's way way less network traffic than what's currently happening","username":"jsmitchell","ts":"2020-02-28T20:38:10.300Z"}
{"msg":"yeah, my point is that its only strictly necessary to do anything of that sort when you have forking consensus, so it should only happen if you are using forking consensus","username":"amundson","ts":"2020-02-28T20:39:04.011Z"}
{"msg":"could noop when you have finality","username":"amundson","ts":"2020-02-28T20:39:19.492Z"}
{"msg":"right, but that can fall out of the protocol - the existence check would be O(1) with a finality based consensus (assuming you were connecting to a network with shared history)","username":"jsmitchell","ts":"2020-02-28T20:39:48.581Z"}
{"msg":"GetBlocks(head, start_height, count) -- where you know start_height automatically when you have finality, and when you don't, you use the negotiation protocol to determine start_height between the nodes.","username":"amundson","ts":"2020-02-28T20:40:26.006Z"}
{"msg":"something which unravels your history to genesis block should probably be an error to the admin","username":"jsmitchell","ts":"2020-02-28T20:40:40.258Z"}
{"msg":"if you have history","username":"jsmitchell","ts":"2020-02-28T20:40:49.503Z"}
{"msg":"because it means that the network is completely different than the one you were previously attached to","username":"jsmitchell","ts":"2020-02-28T20:41:06.106Z"}
{"msg":"@jsmitchell I agree that we should tske this over to the #sawtooth-consensus-dev channel.  @wkatsak and I would like to see where we can help, as we are not that familiar with the core code & structure.  The less the plugged in consensus needs to know about the block storage the better.  But in the end there are differnt approaches to broad paths of consensus, unless the validator node only confirms a transaction and discards memory of that transaction once a full node has committed to the chain.  Hedera Hashgraph thinks that is the answer, as it keeps zero history except for mirror nodes that have the chain database.  Perhaps we discuss in the consensus channel.  ","username":"jamesbarry","ts":"2020-02-28T20:45:19.114Z"}
{"msg":"@jsmitchell I agree that we should tske this over to the #sawtooth-consensus-dev channel.  @wkatsak and I would like to see where we can help, as we are not that familiar with the core code & structure.  The less the plugged in consensus needs to know about the block storage the better.  But in the end there are different approaches to broad paths of consensus, unless the validator node only confirms a transaction and discards memory of that transaction once a full node has committed to the chain.  Hedera Hashgraph thinks that is the answer, as it keeps zero history except for mirror nodes that have the chain database.  Perhaps we discuss in the consensus channel.  ","username":"jamesbarry","ts":"2020-02-28T20:45:19.114Z"}
{"msg":"@agunde .This error happened after a while. No other errors are there with it.","username":"UdayBollineni","ts":"2020-03-03T09:34:59.383Z"}
{"msg":"Validator files are attached in the ticket. I am also attaching validator yaml file below.","username":"UdayBollineni","ts":"2020-03-03T09:36:16.821Z"}
{"msg":"apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    deployment.kubernetes.io/revision: \"7\"\n  creationTimestamp: \"2019-12-11T12:15:20Z\"\n  generation: 15\n  labels:\n    name: sawtooth-0\n  name: sawtooth-0\n  namespace: default\n  resourceVersion: \"36438859\"\n  selfLink: /apis/apps/v1/namespaces/default/deployments/sawtooth-0\n  uid: e685b828-1c0f-11ea-a58d-42010a8a0160\nspec:\n  progressDeadlineSeconds: 2147483647\n  replicas: 1\n  revisionHistoryLimit: 2147483647\n  selector:\n    matchLabels:\n      name: sawtooth-0\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 1\n    type: RollingUpdate\n  template:\n    metadata:\n      creationTimestamp: null\n      labels:\n        name: sawtooth-0\n    spec:\n      containers:\n      - args:\n        - -c\n        - pbft-engine -vv --connect tcp://sawtooth-0:5050\n        command:\n        - bash\n        image: gcr.io/beriblock-219722/sawtooth-pbft-engine:nightly\n        imagePullPolicy: IfNotPresent\n        name: sawtooth-pbft-engine\n        resources: {}\n        terminationMessagePath: /dev/termination-log\n        terminationMessagePolicy: File\n      - args:\n        - -c\n        - transaction-processor -v --connect tcp://sawtooth-0:4004\n        command:\n        - bash\n        envFrom:\n        - secretRef:\n            name: tp-secret\n        image: gcr.io/beriblock-219722/processor:upgrade-v0.5\n        imagePullPolicy: IfNotPresent\n        name: sawtooth-transaction-processor\n        resources: {}\n        terminationMessagePath: /dev/termination-log\n        terminationMessagePolicy: File\n        volumeMounts:\n        - mountPath: /project/sawtooth-tuna\n          name: tp-pvc-claim0\n      - args:\n        - -c\n        - |\n          if [ ! -f /var/lib/sawtooth/block-00.lmdb ]; then\n            echo Running validator startup script\n            echo $pbft0priv > /etc/sawtooth/keys/validator.priv\n            echo $pbft0pub > /etc/sawtooth/keys/validator.pub\n            sawtooth keygen my_key\n            sawset genesis -k /root/.sawtooth/keys/my_key.priv -o config-genesis.batch\n            sleep 30\n            echo sawtooth.consensus.pbft.members=[\"\\\"$pbft0pub\\\",\\\"$pbft1pub\\\",\\\"$pbft2pub\\\",\\\"$pbft3pub\\\"\"]\n            sawset proposal create \\\n              -k /root/.sawtooth/keys/my_key.priv \\\n              sawtooth.consensus.algorithm.name=pbft \\\n              sawtooth.consensus.algorithm.version=1.0\\\n              sawtooth.consensus.pbft.members=[\"\\\"$pbft0pub\\\",\\\"$pbft1pub\\\",\\\"$pbft2pub\\\",\\\"$pbft3pub\\\"\"] \\\n              sawtooth.publisher.max_batches_per_block=1200 \\\n              sawtooth.identity.allowed_keys=$(cat /etc/sawtooth/keys/validator.pub) \\\n              -o config.batch\n            sawadm genesis config-genesis.batch config.batch\n          fi &&\n          sawtooth-validator -vv \\\n            --endpoint tcp://34.82.73.240:8800 \\\n            --bind component:tcp://eth0:4004 \\\n            --bind consensus:tcp://eth0:5050 \\\n            --bind network:tcp://eth0:8800 \\\n            --scheduler parallel \\\n            --peering static \\\n            --maximum-peer-connectivity 10000\n        command:\n        - bash\n        envFrom:\n        - configMapRef:\n            name: keys-config\n        - secretRef:\n            name: keys-secrets\n        image: gcr.io/beriblock-219722/sawtooth-validator:chime\n        imagePullPolicy: IfNotPresent\n        name: sawtooth-validator\n        ports:\n        - containerPort: 4004\n          name: tp\n          protocol: TCP\n        - containerPort: 5050\n          name: consensus\n          protocol: TCP\n        - containerPort: 8800\n          name: validators\n          protocol: TCP\n        resources: {}\n        terminationMessagePath: /dev/termination-log\n        terminationMessagePolicy: File\n        volumeMounts:\n        - mountPath: /etc/sawtooth/keys\n          name: validator-claim0\n        - mountPath: /var/lib/sawtooth\n          name: validator-claim1\n      dnsPolicy: ClusterFirst\n      restartPolicy: Always\n      schedulerName: default-scheduler\n      securityContext: {}\n      terminationGracePeriodSeconds: 30\n      volumes:\n      - name: validator-claim0\n        persistentVolumeClaim:\n          claimName: validator-claim0\n      - name: validator-claim1\n        persistentVolumeClaim:\n          claimName: validator-claim1\n      - name: tp-pvc-claim0\n        persistentVolumeClaim:\n          claimName: tp-pvc-claim0\nstatus:\n  availableReplicas: 1\n  conditions:\n  - lastTransitionTime: \"2019-12-11T12:15:20Z\"\n    lastUpdateTime: \"2019-12-11T12:15:20Z\"\n    message: Deployment has minimum availability.\n    reason: MinimumReplicasAvailable\n    status: \"True\"\n    type: Available\n  observedGeneration: 15\n  readyReplicas: 1\n  replicas: 1\n  updatedReplicas: 1","username":"UdayBollineni","ts":"2020-03-03T09:37:34.003Z"}
{"msg":"apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    deployment.kubernetes.io/revision: \"4\"\n  creationTimestamp: \"2019-12-11T12:15:20Z\"\n  generation: 8\n  labels:\n    name: sawtooth-1\n  name: sawtooth-1\n  namespace: default\n  resourceVersion: \"36439162\"\n  selfLink: /apis/apps/v1/namespaces/default/deployments/sawtooth-1\n  uid: e6b4b962-1c0f-11ea-a58d-42010a8a0160\nspec:\n  progressDeadlineSeconds: 2147483647\n  replicas: 1\n  revisionHistoryLimit: 2147483647\n  selector:\n    matchLabels:\n      name: sawtooth-1\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 1\n    type: RollingUpdate\n  template:\n    metadata:\n      creationTimestamp: null\n      labels:\n        name: sawtooth-1\n    spec:\n      containers:\n      - args:\n        - -c\n        - pbft-engine -vv --connect tcp://sawtooth-1:5050\n        command:\n        - bash\n        image: gcr.io/beriblock-219722/sawtooth-pbft-engine:nightly\n        imagePullPolicy: IfNotPresent\n        name: sawtooth-pbft-engine\n        resources: {}\n        terminationMessagePath: /dev/termination-log\n        terminationMessagePolicy: File\n      - args:\n        - -c\n        - transaction-processor -v --connect tcp://sawtooth-1:4004\n        command:\n        - bash\n        envFrom:\n        - secretRef:\n            name: tp-secret\n        image: gcr.io/beriblock-219722/processor:upgrade-v0.5\n        imagePullPolicy: IfNotPresent\n        name: sawtooth-transaction-processor\n        resources: {}\n        terminationMessagePath: /dev/termination-log\n        terminationMessagePolicy: File\n        volumeMounts:\n        - mountPath: /project/sawtooth-tuna\n          name: tp-pvc-claim1\n      - args:\n        - -c\n        - |\n          if [ ! -e /etc/sawtooth/keys/validator.priv ]; then\n            echo $pbft1priv > /etc/sawtooth/keys/validator.priv\n            echo $pbft1pub > /etc/sawtooth/keys/validator.pub\n          fi &&\n          sawtooth keygen my_key &&\n          sawtooth-validator -vv \\\n            --endpoint tcp://35.203.133.49:8800 \\\n            --bind component:tcp://eth0:4004 \\\n            --bind consensus:tcp://eth0:5050 \\\n            --bind network:tcp://eth0:8800 \\\n            --scheduler parallel \\\n            --peering static \\\n            --maximum-peer-connectivity 10000 \\\n            --peers tcp://34.82.73.240:8800\n        command:\n        - bash\n        envFrom:\n        - configMapRef:\n            name: keys-config\n        - secretRef:\n            name: keys-secrets\n        image: gcr.io/beriblock-219722/sawtooth-validator:chime\n        imagePullPolicy: IfNotPresent\n        name: sawtooth-validator\n        ports:\n        - containerPort: 4004\n          name: tp\n          protocol: TCP\n        - containerPort: 5050\n          name: consensus\n          protocol: TCP\n        - containerPort: 8800\n          name: validators\n          protocol: TCP\n        resources: {}\n        terminationMessagePath: /dev/termination-log\n        terminationMessagePolicy: File\n        volumeMounts:\n        - mountPath: /etc/sawtooth/keys\n          name: validator-claim2\n        - mountPath: /var/lib/sawtooth\n          name: validator-claim3\n      dnsPolicy: ClusterFirst\n      restartPolicy: Always\n      schedulerName: default-scheduler\n      securityContext: {}\n      terminationGracePeriodSeconds: 30\n      volumes:\n      - name: validator-claim2\n        persistentVolumeClaim:\n          claimName: validator-claim2\n      - name: validator-claim3\n        persistentVolumeClaim:\n          claimName: validator-claim3\n      - name: tp-pvc-claim1\n        persistentVolumeClaim:\n          claimName: tp-pvc-claim1\nstatus:\n  availableReplicas: 1\n  conditions:\n  - lastTransitionTime: \"2019-12-11T12:15:20Z\"\n    lastUpdateTime: \"2019-12-11T12:15:20Z\"\n    message: Deployment has minimum availability.\n    reason: MinimumReplicasAvailable\n    status: \"True\"\n    type: Available\n  observedGeneration: 8\n  readyReplicas: 1\n  replicas: 1\n  updatedReplicas: 1","username":"UdayBollineni","ts":"2020-03-03T09:39:28.415Z"}
{"msg":"These configuration files are for two validators.","username":"UdayBollineni","ts":"2020-03-03T09:40:22.784Z"}
{"msg":"Tracy just mentioned .. I think .. that moderators can get access to the chat bot here and we can have it respond to FAQs.","username":"Dan","ts":"2020-03-04T22:12:07.109Z"}
{"msg":"","username":"Dan","ts":"2020-03-04T22:15:49.938Z","attachments":[{"url":null,"remote":true,"fileId":null,"fileName":null}],"type":"message_pinned"}
{"msg":"Hi All, if anyone can provide more information on the Backpressure logic will be great. Specifically, we hit issues today when we sent about 30 batches in about 10 seconds, we saw a few of them fail with the Queue Full (429).  The sawtooth rest API FAQ says \"The number of batches that validator can accept is based on a multiplier, QUEUE_MULTIPLIER (currently 10, formerly 2), times a rolling average of the number of published batches.\"      Specifically, 1. how is the \"rolling average\" computed? What is it averaged over? 2. Are there ways to bump up that rolling average or other settings that can potentially reduce the current batch queue  (I know the QUEUE_MULTIPLIER is hardcoded to 10, so no way to change it via settings currently or bump it up unless we build a custom validator). ","username":"RajaramKannan","ts":"2020-03-05T14:17:56.752Z"}
{"msg":"Hi All, if anyone can provide more information on the Backpressure logic will be great. Specifically, we hit issues today when we sent about 30 batches in about 10 seconds, we saw a few of them fail with the Queue Full (429).  The sawtooth rest API FAQ says \"The number of batches that validator can accept is based on a multiplier, QUEUE_MULTIPLIER (currently 10, formerly 2), times a rolling average of the number of published batches.\"      Specifically, 1. how is the \"rolling average\" computed? What is it averaged over? 2. Are there ways to bump up that rolling average or other settings that can potentially reduce the current batch queue  (I know the QUEUE_MULTIPLIER is hardcoded to 10, so no way to change it via settings currently or bump it up unless we build a custom validator). ```\n2020-03-04 22:01:21.875 INFO     back_pressure_handlers] Ending back pressure on client submitted batches: current depth: 8, limit: 10\n[2020-03-04 22:01:22.497 INFO     back_pressure_handlers] Applying back pressure on client submitted batches: current depth: 10, limit: 10\n[2020-03-04 22:01:22.757 INFO     back_pressure_handlers] Ending back pressure on client submitted batches: current depth: 8, limit: 10\n[2020-03-04 22:01:23.295 INFO     back_pressure_handlers] Applying back pressure on client submitted batches: current depth: 10, limit: 10\n[2020-03-04 22:01:23.776 INFO     back_pressure_handlers] Ending back pressure on client submitted batches: current depth: 8, limit: 10\n[2020-03-04 22:01:24.418 INFO     back_pressure_handlers] Applying back pressure on client submitted batches: current depth: 10, limit: 10\n[2020-03-04 22:01:25.017 INFO     back_pressure_handlers] Ending back pressure on client submitted batches: current depth: 8, limit: 10\n[2020-03-05 08:24:06.223 INFO     back_pressure_handlers] Applying back pressure on client submitted batches: current depth: 12, limit: 10\n[2020-03-05 08:26:51.639 INFO     back_pressure_handlers] Ending back pressure on client submitted batches: current depth: 0, limit: 10\n[2020-03-05 08:26:52.159 INFO     back_pressure_handlers] Applying back pressure on client submitted batches: current depth: 10, limit: 10\n[2020-03-05 09:13:43.768 INFO     back_pressure_handlers] Ending back pressure on client submitted batches: current depth: 0, limit: 10\n[2020-03-05 09:13:44.007 INFO     back_pressure_handlers] Applying back pressure on client submitted batches: current depth: 10, limit: 10\n[2020-03-05 09:21:00.693 INFO     back_pressure_handlers] Ending back pressure on client submitted batches: current depth: 0, limit: 10\n[2020-03-05 09:21:01.166 INFO     back_pressure_handlers] Applying back pressure on client submitted batches: current depth: 10, limit: 10\n[2020-03-05 09:21:03.861 INFO     back_pressure_handlers] Ending back pressure on client submitted batches: current depth: 6, limit: 10\n[2020-03-05 09:21:03.990 INFO     back_pressure_handlers] Applying back pressure on client submitted batches: current depth: 10, limit: 10\n[2020-03-05 11:29:00.381 INFO     back_pressure_handlers] Ending back pressure on client submitted batches: current depth: 0, limit: 10\n``` ","username":"RajaramKannan","ts":"2020-03-05T14:17:56.752Z"}
{"msg":"@RajaramKannan the correct client behavior is to resubmit the batch(es) if that happens. 429 must be interpreted as \"try again\". the current algorithm is pretty good at ramping up quickly to find the right amount of back pressure, you probably shouldn't try and tune anything in the validator.","username":"amundson","ts":"2020-03-05T15:20:14.755Z"}
{"msg":"https://github.com/hyperledger/sawtooth-devmode/pull/18 was blocked on CI whitelist but is clean now. Needs another review.","username":"Dan","ts":"2020-03-05T17:14:15.137Z"}
{"msg":"@Dan done, merged","username":"amundson","ts":"2020-03-05T19:52:02.881Z"}
{"msg":"Gracias","username":"Dan","ts":"2020-03-05T20:08:35.847Z"}
{"msg":"Has left the channel.","username":"lucgerrits","ts":"2020-03-06T13:51:35.751Z","type":"ul"}
{"msg":"@jamesbarry Please share the link to the SDK repositories you have in Go","username":"arsulegai","ts":"2020-03-08T20:03:33.090Z"}
{"msg":"@amundson  thanks for that, we have already started to build a re-submit logic in our app when a 429 occurs (for the moment we are planning to attempt a couple of times with some gap in the retries). Would you be able to outline the current logic. my fear is that if we have a little burst, there will be a lot of 429s, i am happy to consider for example sending a few hearbeat type transactions if I knew the backpressure rampup logic to be able to keep the rolling average high enough. Ideally, I would like to be able to submit a 100 batches in bursts if required","username":"RajaramKannan","ts":"2020-03-09T04:29:26.922Z"}
{"msg":"@RajaramKannan basically, each validator independently attempts to figure out the rate at which the network has been operating over the last few blocks. Locally, it sets its pending queue to twice (I believe) that number. If the pending queue fills up, you will get 429s. The pending queue is the batch queue which is used when building new blocks, so each block you would expect it to divide by half under load. When the network is not fully loaded, it will drain the pending queue faster (blocks will be larger than 1/2 the pending queue). When the network is idle, the average rate at which it can process blocks is thus very low; there is a minimum  estimate, but I don't recall the specific figure. However, it ramps up very quickly (but is constrained by block publishing speed, as that's the rate of recalculation).","username":"amundson","ts":"2020-03-09T14:31:17.358Z"}
{"msg":"Was there some pylint update that might cause some build failures? I noticed @rberg2 's doc change failing for example.\nhttps://build.sawtooth.me/job/Sawtooth-Hyperledger/job/sawtooth-poet/job/PR-32/4/console\n```\n09:47:19  \u001b[36mlint_1    |\u001b[0m ************* Module sawtooth_poet_engine.engine\n09:47:19  \u001b[36mlint_1    |\u001b[0m engine/sawtooth_poet_engine/engine.py:48:4: W0236: Method 'name' was expected to be 'property', found it instead as 'method' (invalid-overridden-method)\n09:47:19  \u001b[36mlint_1    |\u001b[0m engine/sawtooth_poet_engine/engine.py:51:4: W0236: Method 'version' was expected to be 'property', found it instead as 'method' (invalid-overridden-method)\n09:47:19  \u001b[36mlint_1    |\u001b[0m ************* Module sawtooth_poet_engine.oracle\n09:47:19  \u001b[36mlint_1    |\u001b[0m engine/sawtooth_poet_engine/oracle.py:278:0: R1721: Unnecessary use of a comprehension (unnecessary-comprehension)\n```","username":"Dan","ts":"2020-03-09T18:29:59.550Z"}
{"msg":"That one is an @rbuysse PR :)","username":"rberg2","ts":"2020-03-09T20:35:36.046Z"}
{"msg":"Thanks, I believe the number is now 10. we will try and observe how this changes when more batches are published to see how it ramps up.","username":"RajaramKannan","ts":"2020-03-10T06:38:21.523Z"}
{"msg":"@rberg2 according to autocomplete you two are the same person. I'm sorry I have to be the one to tell you that. I assume there's some common law about property ownership and you guys can work out those details.\nMeanwhile I think there's still a pylint version thing that might be affecting multiple PRs. Is anyone already aware of that? If not I might be able to look further this afternoon.","username":"Dan","ts":"2020-03-10T13:12:19.711Z"}
{"msg":"Hi, I was testing stop and start of my tp from one node only and that node validator crashed, when it restarted, it started log the 2f messages. I'll add the log file here, if you want to take a look","username":"MicaelFerreira","ts":"2020-03-16T11:26:04.937Z"}
{"msg":"Hi, I was testing stop and start of my tp from one node only and that node validator crashed, after restarting, it started log the 2f messages. I'll add the log file here, if you want to take a look","username":"MicaelFerreira","ts":"2020-03-16T11:26:04.937Z"}
{"msg":"","username":"MicaelFerreira","ts":"2020-03-16T11:26:17.711Z","attachments":[{"type":"file","title":"pbft-logs-2f-messages.txt","title_link":"/file-upload/BSdT9JYwKTGwew57Z/pbft-logs-2f-messages.txt","url":"/file-upload/BSdT9JYwKTGwew57Z/pbft-logs-2f-messages.txt","remote":false,"fileId":"BSdT9JYwKTGwew57Z","fileName":"pbft-logs-2f-messages.txt"}]}
{"msg":"I'm using pbft 1.0.2","username":"MicaelFerreira","ts":"2020-03-16T11:30:05.914Z"}
{"msg":"I have a question for the core contributors of the hyperledger sawtooth framework regarding the read and write permissions of each TP on each namespace.\nI build a quick TP to test this out by changing the `sawtooth.settings.vote.authorized_keys` and I did it with no issue whatsoever. After that I also tested using other reserved namespaces and the result was the same.\nI also tried to add an already used namespace on my TP handler and that is also possible without any issues or warnings. \nIs that supposed to be possible?  ","username":"AnthonyWhite","ts":"2020-03-17T10:04:22.942Z"}
{"msg":"Hi all,\nThe validator in one of our  nodes is down \nHere is the error I see .\nAny help would be appreciated","username":"ParitoshPandey","ts":"2020-03-17T12:20:51.671Z"}
{"msg":"","username":"ParitoshPandey","ts":"2020-03-17T12:21:12.311Z","attachments":[{"type":"file","title":"IMG_1856.PNG","title_link":"/file-upload/P884zFeaT5KEhCeRc/IMG_1856.PNG","image_url":"/file-upload/P884zFeaT5KEhCeRc/IMG_1856.PNG","image_type":"image/jpeg","image_size":255145,"url":"/file-upload/P884zFeaT5KEhCeRc/IMG_1856.PNG","remote":false,"fileId":"P884zFeaT5KEhCeRc","fileName":"IMG_1856.PNG"}]}
{"msg":"@AnthonyWhite there's misunderstanding here. The setting key you pasted isn't for what you want. In your case of restricting the TP writes and reads, you could use namespace restrictions. That would be enabled if you use allowed transaction processors key.","username":"arsulegai","ts":"2020-03-17T19:31:25.075Z"}
{"msg":"@ParitoshPandey Which version are you on? Do you have the scenario, more logs?","username":"arsulegai","ts":"2020-03-17T19:32:09.993Z"}
{"msg":"@arsulegai we are on Validator v 1.1.5 and PBFT v 1.0.1.  The logs might be huge, but is there anything we should look for in it? @ParitoshPandey if we still have the logs pls post maybe a few hours of it.  But overall, we noticed some alerts based on monitoring we had setup for errors and for docker exit statuses. There wasnt much activity at that time, no specific scenario as such....","username":"RajaramKannan","ts":"2020-03-18T04:59:44.890Z"}
{"msg":"I am attaching the logs here","username":"ParitoshPandey","ts":"2020-03-18T05:38:16.234Z"}
{"msg":"","username":"ParitoshPandey","ts":"2020-03-18T05:39:25.282Z","attachments":[{"type":"file","title":"validator-error.log","title_link":"/file-upload/r3irMxb6mBym8ya75/validator-error.log","url":"/file-upload/r3irMxb6mBym8ya75/validator-error.log","remote":false,"fileId":"r3irMxb6mBym8ya75","fileName":"validator-error.log"}]}
{"msg":"I just gave that key as an example. I was worried that someone with a malicious TP could override the settings of the network or another TP's state.","username":"AnthonyWhite","ts":"2020-03-18T10:30:36.647Z"}
{"msg":"I just gave that key as an example. I was worried that someone with a malicious TP could override the settings of the network or another TP's state.\nThanks @arsulegai ","username":"AnthonyWhite","ts":"2020-03-18T10:30:36.647Z"}
{"msg":"Sure, yes in production you would set namespace restriction for TPs","username":"arsulegai","ts":"2020-03-18T11:34:52.357Z"}
{"msg":"TP cannot be malicious because it has to be installed on multiple or all the validators depending on the consensus algorithm","username":"arsulegai","ts":"2020-03-18T11:35:46.521Z"}
{"msg":"There can be a wrongfully implemented TP though","username":"arsulegai","ts":"2020-03-18T11:36:11.936Z"}
{"msg":"Yes, but there is always a chance there can be some purposely hidden code for malicious ends","username":"AnthonyWhite","ts":"2020-03-18T11:37:29.257Z"}
{"msg":"You could make sure that a TP has isolation from its namespace, if it's must to share the namespace then there shall be careful checks","username":"arsulegai","ts":"2020-03-18T11:42:04.336Z"}
{"msg":"* careful code reviews before agreeing to deploy the TP to the validator","username":"arsulegai","ts":"2020-03-18T11:42:33.539Z"}
{"msg":"Interesting execution error and correction: A few days back, we noticed some error logs in our TP. Note: it wasnt a sawtooth error, but an error example \"asset doesnt exist\" that the TP itself validates while processing the txn. In these scenarios we log the transaction as failed in our state and send an event back.  Interestingly in this case in our 5 node setup, only one node reported this error. All nodes have the same state and same version of TP at the time this occured. However a second later, the transaction again executed (in the TP) and this time it went through fine in this node.  I dont have the logs to share (couldnt grab it in a way that I can obscure some of the more sensitive execution information). But just wanted to check if anyone has seen this scenario and under what circumstances it could occur?  There were no issues in the end outcome because all nodes ended up with the same state and hence same events sent out that synced up our external DB. ","username":"RajaramKannan","ts":"2020-03-22T07:25:30.176Z"}
{"msg":"I don't know if I've seen that specific issue, but usually if one node responds differently it's because there's some tiny non-determinism hiding in the TP.","username":"Dan","ts":"2020-03-22T15:28:26.266Z"}
{"msg":"@RajaramKannan @dan We are seeing this happen on a consistent , but non regular basis in our load testing.  We are testing the Sextant stable code base, which is a rev of 1.1x with PBFT.  What we believe to be happening after looking at the logs, is somehow a transaction got messed up , possible bad network connection etc. When a valid transaction comes in the bad transaction is disregarded and the node gets back into sync.  We use AWS USWest-2 Zone, and sometimes the traffic between nodes is flaky.  We believe that is the issue.  Both us and Blockchain Technology Partners are looking at this issue.   When we work out kinks with the AWS only testing we are going to have a mixed node set and run 3 nodes out of our houses around the USA, and 2 nodes on AWS.  That may be more telling in what is happening.  We should take this discussion on email discussion forum, as its easier to search and find there than Rocketchat.","username":"jamesbarry","ts":"2020-03-22T20:23:09.589Z"}
{"msg":"thanks @jamesbarry - this is the first time we are seeing it, but atleast we know now it is not out of the ordinary and overall integrity is not compromised","username":"RajaramKannan","ts":"2020-03-23T04:57:40.393Z"}
{"msg":"When does a pending transaction dissappear from the queue? We had a situation today where someone sent a batch while other nodes were down. I believe the nodes were being restarted at this point including this node. Now this batch is in Pending status in that node, but in \"unknown\" in all other nodes. Meanwhile, new transactions were submitted and they went through/got committed. ","username":"RajaramKannan","ts":"2020-03-23T14:05:29.242Z"}
{"msg":"@jamesbarry @Dan - I was thinking about it and to clarify, we did not submit the transaction again. The TP logs showed that it got re-executed a second time a second later with the right results and got committed!","username":"RajaramKannan","ts":"2020-03-23T14:08:07.122Z"}
{"msg":"Has joined the channel.","username":"dushanchain1","ts":"2020-03-27T06:46:46.267Z","type":"uj"}
{"msg":"hi, i'm new to sawtooth and i tried to create and submit a transaction to sawtooth. I'm using XO transaction family. I submitted a transaction to intkey and i worked successfully. But when i submit my transaction using XO family, it gives me \"Invalid payload serialization\" message. What am i doing wrong? I even asked this from stackoverflow. But noone answered me. Can someone please help me. \n\nMy payload is -> \nconst payload = {\n    Name: 'new-game',\n    Action: 'create',\n    Space: '',\n}\n\nand my payloadbyes is ->\n\nconst payloadBytes = cbor.encode(payload)\n\nand my payloadSha512 is ->\n\npayloadSha512: createHash('sha512').update(payloadBytes).digest('hex')\n","username":"dushanchain1","ts":"2020-03-27T06:46:46.763Z"}
{"msg":"hi, i'm new to sawtooth and i tried to create and submit a transaction to sawtooth. I'm using XO transaction family. I submitted a transaction to intkey and i worked successfully. But when i submit my transaction using XO family, it gives me \"Invalid payload serialization\" message. What am i doing wrong? I even asked this from stackoverflow. But noone answered me. Can someone please help me. \n\nMy payload is -> \nconst payload = {\n    Name: 'new-game',\n    Action: 'create',\n    Space: '',\n}\n\nand my payloadbyes is ->\n\nconst payloadBytes = cbor.encode(payload)\n\nand my payloadSha512 is ->\n\npayloadSha512: createHash('sha512').update(payloadBytes).digest('hex')\n\nmy stackoverflow question -> https://stackoverflow.com/questions/60864191/sawtooth-xo-transaction-family-transaction-submission","username":"dushanchain1","ts":"2020-03-27T06:46:46.763Z"}
{"msg":"@dushanchain1 Verify that you are using cbor at your TP for decode aswell","username":"MicaelFerreira","ts":"2020-03-27T09:13:42.761Z"}
{"msg":"@dushanchain1 Verify that you are also using cbor at your TP for decode","username":"MicaelFerreira","ts":"2020-03-27T09:13:42.761Z"}
{"msg":"pbft","username":"LeonardoCarvalho","ts":"2020-03-28T12:11:19.562Z"}
{"msg":"Hi All - any ideas on this? I am still seeing that batch in pending status in the node. All other nodes show the status as unknown. ","username":"RajaramKannan","ts":"2020-03-30T10:03:17.093Z"}
{"msg":"@RajaramKannan This node would broadcast the transaction to other nodes. But since you're saying other nodes were down at that time, the transaction is only with this validator.","username":"arsulegai","ts":"2020-03-30T11:09:25.648Z"}
{"msg":"If this validator becomes a leader (based on consensus algorithm you're following) that's the only possibility of the node to send to other validators.","username":"arsulegai","ts":"2020-03-30T11:10:07.352Z"}
{"msg":"Or rather resend to other validators.","username":"arsulegai","ts":"2020-03-30T11:10:25.447Z"}
{"msg":"@arsulegai we are using PBFT - 5 node network ... The other nodes were down for maybe 10 -15 minutes for an upgrade ...  so ideally it should have sent it across at somepoint once they were back up?","username":"RajaramKannan","ts":"2020-03-30T11:11:14.468Z"}
{"msg":"BTW, one way to solve it could be if your client can resend the transaction. The validator which has the transaction already would mark it duplicate but other validators receive the transaction and they can process it.","username":"arsulegai","ts":"2020-03-30T11:11:24.036Z"}
{"msg":"Pending batches are not resent after initial attempt to broadcast, unless there's a request from other validators","username":"arsulegai","ts":"2020-03-30T11:12:16.094Z"}
{"msg":"Ah got it","username":"RajaramKannan","ts":"2020-03-30T11:12:23.202Z"}
{"msg":"is there anyway instead to clear out the pending batch? I presume it will continue to stay in the validator queue forever otherwise?","username":"RajaramKannan","ts":"2020-03-30T11:12:49.293Z"}
{"msg":"Pending batch queue is in memory, if the service is restarted it's cleared","username":"arsulegai","ts":"2020-03-30T11:13:24.461Z"}
{"msg":"Since we are using containers, if we restarted the validator container It should clear the pending queue I suppose","username":"RajaramKannan","ts":"2020-03-30T11:14:24.809Z"}
{"msg":"thanks so much, always good to know so that we can troubleshoot/document this behavior","username":"RajaramKannan","ts":"2020-03-30T11:14:47.948Z"}
{"msg":"Happy to help","username":"arsulegai","ts":"2020-03-30T11:15:15.538Z"}
{"msg":"in our case we are retrying if we get a 429, we are also logging all submitted transactions (so if they are pending or lost say because the entire network was brought down and back up after accepting and before commiting it) - we can track.  At that point we maynot want to resubmit the transaction because another transaction may supercede it. (We have a job to go and mark that transaction then as Failed externally)","username":"RajaramKannan","ts":"2020-03-30T11:17:09.042Z"}
{"msg":"thanks again - ","username":"RajaramKannan","ts":"2020-03-30T11:17:17.361Z"}
{"msg":"Has joined the channel.","username":"CodeReaper","ts":"2020-03-30T13:32:02.965Z","type":"uj"}
{"msg":"Hi everyone, I see that there are quite a few open issues in Jira for Sawtooth that have been lying there for a while now. Are these in progress or have been rejected? Any information on them? Like STL-1655 specifically?","username":"CodeReaper","ts":"2020-03-30T13:33:16.897Z"}
{"msg":"@CodeReaper many of us are aren't working directly off of jira, so there is a lot of grooming to do there","username":"amundson","ts":"2020-03-31T16:58:45.171Z"}
{"msg":"Has joined the channel.","username":"jarvis569","ts":"2020-04-06T18:21:37.001Z","type":"uj"}
{"msg":"I appreciate all the efforts the team has put down for the project, and I find the protocol to be better fit for a lot of use-cases than others, but issue tracking is something required as an evidence to propose any project onto it. This also doesn't give us any visibility of how serious are the current issues on Sawtooth.  Please let me know if I'm overlooking anything.","username":"CodeReaper","ts":"2020-04-07T08:37:28.185Z"}
{"msg":"@CodeReaper how about starting email thread for discussion or using this platform for identified issues. If it's about the design in question or deciding on right or wrong, we will get answers. We should be able to fix some of these working together.","username":"arsulegai","ts":"2020-04-07T18:25:40.464Z"}
{"msg":"Thanks @arsulegai  , we will get in touch with you for the support. Thanks very much. Currently we face block syncing issues with our networks with the latest sawtooth images. Is this a a known issue? We can recreate it and share you the access to it. ","username":"CodeReaper","ts":"2020-04-08T10:20:40.715Z"}
{"msg":"No, it should not occur. Are you on the latest PoET and 1.2 version of the Sawtooth?","username":"arsulegai","ts":"2020-04-08T10:58:42.783Z"}
{"msg":"Yes, the images don't seem to have been updated for 2 months and we were utilizing the latest.","username":"CodeReaper","ts":"2020-04-08T18:32:11.923Z"}
{"msg":"Is it a Z test failure?","username":"arsulegai","ts":"2020-04-08T18:53:20.716Z"}
{"msg":"Haven't yet seen any specific error to it. We are using these parameters so it shall not be the problem, sawtooth.poet.target_wait_time=5 sawtooth.poet.initial_wait_time=25 sawtooth.publisher.max_batches_per_block=100 sawtooth.poet.block_claim_delay=1 sawtooth.poet.key_block_claim_limit=100000 sawtooth.poet.ztest_minimum_win_count=999999999.","username":"CodeReaper","ts":"2020-04-11T17:39:39.604Z"}
{"msg":"@jamesbarry ^","username":"arsulegai","ts":"2020-04-11T17:59:32.177Z"}
{"msg":"Hi team, I was thinking to try out the latest stable release of sawtooth as I was not able to have any of my transactions committed for my own TP, so I decided to trying the steps from https://sawtooth.hyperledger.org/docs/core/releases/latest/app_developers_guide/docker_test_network.html for poet based setup to confirm there is an issue with the latest stable release itself. I did the exact setup as documented without any customisation. The setup doesn't seem to be giving any issue in itself but no transactions are being committed to the ledger. As the document states in the step to perform the intkey or settings tp transaction, i found out, all remain pending. Is this an known issue that documented steps on the latest stable release don't work? ","username":"CodeReaper","ts":"2020-04-12T14:11:39.898Z"}
{"msg":"Hi team, I was thinking to try out the latest stable release of sawtooth as I was not able to have any of my transactions committed for my own TP, so I decided to try out the steps from https://sawtooth.hyperledger.org/docs/core/releases/latest/app_developers_guide/docker_test_network.html for poet based setup to confirm there is an issue with the latest stable release itself. I did the exact setup as documented without any customisation. The setup doesn't seem to be giving any issue in itself but no transactions are being committed to the ledger. As the document states in the step to perform the intkey or settings tp transaction, i found out, all remain pending. Is this an known issue that documented steps on the latest stable release don't work? ","username":"CodeReaper","ts":"2020-04-12T14:11:39.898Z"}
{"msg":"@CodeReaper Try this if you're facing this issue https://sawtooth.hyperledger.org/faq/docker/#why-doesn-t-sawtooth-default-poet-yaml-start-the-network-successfully-on-subsequent-runs","username":"arsulegai","ts":"2020-04-12T14:33:43.935Z"}
{"msg":"Yes that's it thanks a lot. ","username":"CodeReaper","ts":"2020-04-12T14:43:43.220Z"}
{"msg":"@CodeReaper  One suggestion is what my team did, and that is use the version from Blockchain Technology Partners. https://hub.docker.com/r/blockchaintp/sawtooth-pbft-engine  They are back revved at 1.15, but its stable.  This version saved a lot of headaches we were having.  I am trying to get them to upstream some of their patches that make this more a stable version.  Going to try to put a call on this together this week to talk through some of their patches and push to get them tested and upstreamed.  In the meantime, this version (PBFT only) is pretty stable that we have seen.","username":"jamesbarry","ts":"2020-04-12T22:44:34.563Z"}
{"msg":"@jamesbarry is the source for that somewhere? if not, let's not reward poor community behavior by making such claims here.","username":"amundson","ts":"2020-04-13T17:20:26.056Z"}
{"msg":"Appreciate the point out @jamesbarry . I'll try to set it up for stability test runs to check its stability.","username":"CodeReaper","ts":"2020-04-14T08:50:20.622Z"}
{"msg":"@jamesbarry @amundson we ran some tests with the PBFT engine that btp put up and still find the same catchup issues I have posted elsewhere....  I am in broad agreement with @amundson in general, as it is unclear what license those are made available or if they are under commercial license with the usage of sextant","username":"RajaramKannan","ts":"2020-04-14T09:36:04.789Z"}
{"msg":"The source for all of our open source work in hyperledger and elsewhere is always available on our github organization dedicated for such things.  In particular sawtooth-pbft-engine which you main find here https://github.com/blockchaintp/sawtooth-pbft.  Any variation which we are happy with but which vary from upstream are tagged with a \"p\" level attached to the most relevant upstream version. ","username":"kodonnel","ts":"2020-04-14T18:22:03.479Z"}
{"msg":"So I'd love to dig into the catch up issues you have had, in our experience those can have less to do with the consensus engine than with some idiosyncrasies with the timedcaches in the validator.  \nAs for license, there is no separate from the Apache licenses of those image license for those docker images, and as I say above the source is available on our forks. ","username":"kodonnel","ts":"2020-04-14T18:24:45.118Z"}
{"msg":"Finally for the record, any variants we do make on the code are intended to ultimately be contributed back upstream unless they are backports of items already upstream but for which backports were declined.","username":"kodonnel","ts":"2020-04-14T18:25:52.576Z"}
{"msg":"The version of pbft we are currently putting up there on dockerhub is tagged v1.0.1p5.  ","username":"kodonnel","ts":"2020-04-14T18:36:40.766Z"}
{"msg":"@amundson to reiterate what @kodonnel said and for the benefit of everyone on this channel here is our official position -\n\nWe provide two things -\n1. BTP Sawtooth - our distribution of Sawtooth\n2. BTP Sextant - our management platform that simplifies its deployment and management on Kubernetes\n\nWe follow the Red Hat model where we provide customers with long term support for our distribution so we are currently on 1.1.5. We will move to 1.2.x once we think it is stable. However, in the meantime we have significantly improved both the validator and PBFT engine addressing range of issues while carrying out extensive testing with the Tel Aviv Stock Exchange amongst others.\n\nBTP Sextant is only available as licensed product which includes support for BTP Sawtooth backed by serious SLAs\n\n*However BTP Sawtooth is freely available.*\n\nCode is on Github - https://github.com/blockchaintp\nArtifacts are on DockerHub - https://hub.docker.com/orgs/blockchaintp\n\nAs @kodonnel notes we are committed to contributing all improvements upstream but clearly customers take priority and get fixes as soon as these are available. Also in one specific case we backported a 1.2 fix not applied to 1.1 branch by the community.\n","username":"duncanjw","ts":"2020-04-14T20:48:09.603Z"}
{"msg":"@RajaramKannan hopefully we've cleared up the license point - you only had to ask! Like @kodonnel I'm sorry you hit some issues. Looking back the email/slack trail went cold at the end of January and we didn't get any feedback on your catch up test. That said just cherry picking pbft-engine from our dockerhub might not have been the most sensible thing to do as we've also made some changes to the validator too particularly wrt to catch up.","username":"duncanjw","ts":"2020-04-14T20:58:44.265Z"}
{"msg":"The other thing worth pointing out is that we run all our tests on kubernetes so we are always interested in feedback if folk deploy Sawtooth some other way ...","username":"duncanjw","ts":"2020-04-14T21:00:29.794Z"}
{"msg":"@amundson hi. With the Sawtooth report due shortly - delayed due to cancelled TSC last week AFAICT? - is there an update on the discussion from a while back between @jamesbarry and yourself about the future direction of Sawtooth and the potential role of Splinter? Ditto whether there are plans to contribute Splinter to HL? Thanks in advance","username":"duncanjw","ts":"2020-04-14T23:10:39.097Z"}
{"msg":"@duncanjw @kodonnel thanks for the clarifications and apologies for the confusion.  Regarding the catchup tests in Jan, I moved over all the conversations to this chat channel and ultimately we were able to chart over a recovery path by copying over the LMDB files. (for scenarios when the catchup is for several 100s of blocks). But our recent tests show that sometimes the catchup may fail for even a few blocks (it is not very predictable).","username":"RajaramKannan","ts":"2020-04-15T03:19:02.701Z"}
{"msg":"@kodonnel I will ping you on the consensus channel where I posted the catchup issue and logs from PBFT yesterday...","username":"RajaramKannan","ts":"2020-04-15T03:20:24.262Z"}
{"msg":"@duncanjw @kodonnel - we did trials with both the btp validator as well as the pbft together and see the same results i.e the catchup is inconsistent (roughly works 50% of the time).","username":"RajaramKannan","ts":"2020-04-15T08:46:13.221Z"}
{"msg":"@duncanjw nothing has changed, it is the plan to use splinter for the networking layer. if you are familiar with splinter, I could dive into the details. but basically, I see two ways of running Sawtooth in the future. one looks like it does now, where we still have a Sawtooth validator process; the other is to run Sawtooth as a splinter service. in both cases, we use splinter's library code in the lower layers.","username":"amundson","ts":"2020-04-15T13:10:11.133Z"}
{"msg":"more fundamentally from a Sawtooth perspective, my plan is to push toward a model where we shift the majority of Sawtooth's implementation to libsawtooth and organize the code in a manner that we can use the pieces as building blocks. this should pick up in the next few weeks.","username":"amundson","ts":"2020-04-15T13:14:09.412Z"}
{"msg":"Has joined the channel.","username":"SamParks","ts":"2020-04-15T15:12:12.435Z","type":"uj"}
{"msg":"@amundson when you say the plan/my plan is there an RFC we can review. You mentioned this late last year https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=5Qd23TJwFBD9v6GgE","username":"duncanjw","ts":"2020-04-15T18:35:48.774Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=5Qd23TJwFBD9v6GgE","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=5Qd23TJwFBD9v6GgE","remote":true,"fileId":null,"fileName":null}]}
{"msg":"But unless I am looking in the wrong place I don't see a corresponding https://github.com/hyperledger/sawtooth-rfcs/pulls","username":"duncanjw","ts":"2020-04-15T18:36:26.222Z"}
{"msg":"But unless I am looking in the wrong place I don't see a corresponding pull request https://github.com/hyperledger/sawtooth-rfcs/pulls","username":"duncanjw","ts":"2020-04-15T18:36:26.222Z"}
{"msg":"@duncanjw not sure what you are driving at","username":"amundson","ts":"2020-04-15T20:28:00.065Z"}
{"msg":"@duncanjw I think you're right @amundson maybe still in the early stage of discussion and getting opinion here.. Next step is surely RFC once the open items/path is discussed","username":"arsulegai","ts":"2020-04-16T09:38:20.074Z"}
{"msg":":)","username":"arsulegai","ts":"2020-04-16T09:38:24.676Z"}
{"msg":"There could be actionable items first to convert remaining Python modules to Rust, put them to libsawtooth. Do you think having a call to kick start all these discussions is good?","username":"arsulegai","ts":"2020-04-16T09:43:20.003Z"}
{"msg":"@arsulegai that's exactly what I was driving at","username":"duncanjw","ts":"2020-04-16T12:33:23.656Z"}
{"msg":"Has left the channel.","username":"MHBauer","ts":"2020-04-16T21:18:30.153Z","type":"ul"}
{"msg":"what do you guys like for making svgs for documentation? ","username":"Dan","ts":"2020-04-24T19:56:17.974Z"}
{"msg":"omnigraffle","username":"amundson","ts":"2020-04-24T20:33:01.456Z"}
{"msg":"libredraw is ok too","username":"amundson","ts":"2020-04-24T20:33:35.893Z"}
{"msg":"thanks ","username":"Dan","ts":"2020-04-24T20:34:05.445Z"}
{"msg":"Has joined the channel.","username":"YadhuPhilip","ts":"2020-04-28T06:05:28.923Z","type":"uj"}
{"msg":"Has joined the channel.","username":"S.GOPINATH","ts":"2020-04-29T07:09:38.262Z","type":"uj"}
{"msg":"hi","username":"S.GOPINATH","ts":"2020-04-29T07:09:40.180Z"}
{"msg":"I have a hyperledger sawtooth test setup 4 nodes - pbft consensus engine and each node runs on Ubuntu","username":"S.GOPINATH","ts":"2020-04-29T07:10:39.233Z"}
{"msg":"Initially my test application's apply method was called whenever I submit the transactions and blocks were generated","username":"S.GOPINATH","ts":"2020-04-29T07:11:37.952Z"}
{"msg":"When I repeat the transaction during testing, 3 of the nodes I find 3 blocks are generated and the one node has only 2 blocks","username":"S.GOPINATH","ts":"2020-04-29T07:12:23.252Z"}
{"msg":"how to debug the issue ?","username":"S.GOPINATH","ts":"2020-04-29T07:12:35.206Z"}
{"msg":"Now, my apply method is not called when I submit the transaction ( although the same program is used)","username":"S.GOPINATH","ts":"2020-04-29T07:13:18.975Z"}
{"msg":"I could see from the log that rest-api server submits the transaction to the local validator","username":"S.GOPINATH","ts":"2020-04-29T07:13:42.286Z"}
{"msg":"sawtooth peer list .. I could see 3 peers in each of the nodes","username":"S.GOPINATH","ts":"2020-04-29T07:14:02.812Z"}
{"msg":"which means that I got a mesh of validator network in my setup.","username":"S.GOPINATH","ts":"2020-04-29T07:14:30.111Z"}
{"msg":"Please help","username":"S.GOPINATH","ts":"2020-04-29T07:14:33.087Z"}
{"msg":"Following up on the note I posted April 14 we have formally announced BTP Paralos today - https://medium.com/blockchaintp/btp-delivers-first-long-term-support-lts-release-of-its-hyperledger-sawtooth-distribution-73c7bcf38bf1","username":"duncanjw","ts":"2020-04-29T16:38:45.544Z"}
{"msg":"Please note *CTA #1* — If you are working with Hyperledger Sawtooth already then please give our images a try — use tag BTP2.0 to pull the latest stable version of BTP Paralos ...","username":"duncanjw","ts":"2020-04-29T16:48:03.305Z"}
{"msg":"Please note\n>*CTA #1* — If you are working with Hyperledger Sawtooth already then please give our images a try — use tag BTP2.0 to pull the latest stable version of BTP Paralos ...","username":"duncanjw","ts":"2020-04-29T16:48:03.305Z"}
{"msg":"Has joined the channel.","username":"DavidSetyanugraha","ts":"2020-05-05T03:39:39.869Z","type":"uj"}
{"msg":"Has joined the channel.","username":"sawtooth","ts":"2020-05-12T18:37:15.761Z","type":"uj"}
{"msg":"Hi guys, me and @AnthonyWhite are upgrading sawtooth batch injector feature to also allow block_end events. However we are facing some trouble reading the setting \"sawtooth.validator.block_validation_rules\" at \"journal -> state -> settings_view.rs\". \n\nThe settigns we are trying to read are: `sawtooth.validator.block_validation_rules='NofX:1,injector_A;XatY:injector_A,0;NofX:1,injector_B;XatY:injector_B,-1;local:0,-1'`\nAnd the error we face is the following:\n`thread 'PublisherThread' panicked at 'Unable to get setting: EncodingError(WireError(UnexpectedWireType(WireTypeEndGroup)))', src/journal/validation_rule_enforcer.rs:50:17`\n\nWhile running tests locally it works, reading the settings from state does not.\nAny clue why it it failing to read the rules byte array?","username":"MicaelFerreira","ts":"2020-05-13T15:38:15.927Z"}
{"msg":"Has joined the channel.","username":"Will_Gluwa","ts":"2020-05-14T15:33:21.106Z","type":"uj"}
{"msg":"Has joined the channel.","username":"yashar.nesvaderani","ts":"2020-05-14T20:38:40.253Z","type":"uj"}
{"msg":"@MicaelFerreira that line here looks like a simple return statement","username":"amundson","ts":"2020-05-16T03:14:12.601Z"}
{"msg":"Looks like a protobuf deserialization error","username":"amundson","ts":"2020-05-16T03:19:18.407Z"}
{"msg":"Yes it is a protobuf deserialization error. I tried to shorten the rule and at some point it works, looks like it fails to read when the rules is bigger than a certain length but this doesn't makes sense. ","username":"MicaelFerreira","ts":"2020-05-16T11:42:29.576Z"}
{"msg":"Yes it is a protobuf deserialization error. I tried to shorten the rule and at some point it works, looks like it fails to read when the rule is bigger than a certain length but this doesn't makes sense. ","username":"MicaelFerreira","ts":"2020-05-16T11:42:29.576Z"}
{"msg":"Has joined the channel.","username":"Moolkothari","ts":"2020-05-23T09:57:51.630Z","type":"uj"}
{"msg":"Hi .. I need a help in understand Sawtooth implementation of Radix Merkle Trie","username":"S.GOPINATH","ts":"2020-05-24T17:50:22.733Z"}
{"msg":"I'm using address 000001 00000000000000000000000000001","username":"S.GOPINATH","ts":"2020-05-24T17:50:55.500Z"}
{"msg":"thats is family is 1 and address under that family also 1.","username":"S.GOPINATH","ts":"2020-05-24T17:51:16.648Z"}
{"msg":"How do the trie looks like ?. Can any one help me in drawing in a piece of paper and pencil and show here","username":"S.GOPINATH","ts":"2020-05-24T17:51:49.304Z"}
{"msg":"@S.GOPINATH the documentation explains it well. Starting from the root node each child node is represented with an address using 1 byte appended to parent's address. So each node has 00 to FF addressed child nodes. In your case `Root Node` -> `Child with address 00` -> `Child with address 00 00` -> `Child with address 00 00 01` -> and so on until you reach the complete address leaf node.","username":"arsulegai","ts":"2020-05-25T04:48:31.644Z"}
{"msg":"Thanks again Arun. The docs I refer is https://sawtooth.hyperledger.org/docs/core/releases/1.2.4/architecture/global_state.html#merkle-radix-tree-overview .  It is not clear as you explained. Also, in that I could not find which hash algorithm is used. I dont know whether I have to search further. ","username":"S.GOPINATH","ts":"2020-05-25T06:19:51.353Z"}
{"msg":"Hi...in my application I use only one address 000001 00000000000000000000000000001. I want to calculate the State root Hash , given the hash of the payload which is stored in the address. this is for my academic interest.","username":"S.GOPINATH","ts":"2020-05-25T12:13:29.261Z"}
{"msg":"https://github.com/hidura/sawtooth-blockmed\nHello friends, this is the 1.0 version of a Sawtooth health care blockchain, based on the wonderful work of @AlexanderZhovnuvaty , I intend to use it to provide for my country DR a healthcare blockchain to track the information of all the patients and the serial diseases that happen every year, mainly to help on those poor communities on the country.","username":"hidura","ts":"2020-06-03T22:34:04.795Z"}
{"msg":"Has joined the channel.","username":"rajesh_kumar_p","ts":"2020-06-04T13:47:48.491Z","type":"uj"}
{"msg":"All - we are planning on having a series of zoom calls as we do Sawtooth 2 planning/design/architecture. If you have topics you would like to discuss (especially if you have features you re planning to implement), please let me know. I'll post links to the zoom calls here.","username":"amundson","ts":"2020-06-05T17:32:44.180Z"}
{"msg":"We are planning for the first session to be on Monday morning at 9am US/Central","username":"amundson","ts":"2020-06-05T21:35:07.187Z"}
{"msg":"Topic: Sawtooth Core Working Session\nTime: Jun 8, 2020 09:00 AM Central Time (US and Canada)\n\nJoin Zoom Meeting\nhttps://us02web.zoom.us/j/89262216179\n\nMeeting ID: 892 6221 6179\nOne tap mobile\n+13126266799,,89262216179# US (Chicago)\n+19292056099,,89262216179# US (New York)\n\nDial by your location\n        +1 312 626 6799 US (Chicago)\n        +1 929 205 6099 US (New York)\n        +1 301 715 8592 US (Germantown)\n        +1 346 248 7799 US (Houston)\n        +1 669 900 6833 US (San Jose)\n        +1 253 215 8782 US (Tacoma)\nMeeting ID: 892 6221 6179\nFind your local number: https://us02web.zoom.us/u/kbfpTnIXUY","username":"amundson","ts":"2020-06-05T21:35:43.195Z"}
{"msg":"Initial topics will include moving libsawtooth to its own repo, a sawtotoh splinter service, creating consensus library, pluggable journal, etc. but we will limit the meeting to 2 hours.","username":"amundson","ts":"2020-06-05T21:37:03.425Z"}
{"msg":"Initial topics will include moving libsawtooth to its own repo, a sawtooth splinter service, creating consensus library, pluggable journal, etc. but we will limit the meeting to 2 hours.","username":"amundson","ts":"2020-06-05T21:37:03.425Z"}
{"msg":"@MicaelFerreira @jamesbarry @duncanjw ^","username":"arsulegai","ts":"2020-06-06T13:31:04.093Z"}
{"msg":"@MicaelFerreira @jamesbarry @duncanjw @S.GOPINATH ^","username":"arsulegai","ts":"2020-06-06T13:31:04.093Z"}
{"msg":"@arsulegai thanks // @KevinODonnell ","username":"duncanjw","ts":"2020-06-06T13:42:48.763Z"}
{"msg":"Here is a link to a working doc for the meeting - https://docs.google.com/document/d/1WlF8UfoKAEydJobHWDvz-tMpWqQSTlChoFv50fHX1tM/edit?usp=sharing","username":"amundson","ts":"2020-06-08T13:58:14.894Z"}
{"msg":"thanks to everyone who participated in the meeting!","username":"amundson","ts":"2020-06-08T16:46:26.695Z"}
{"msg":"We will do another working session on Wednesday 10:00 AM US/Central -- topic will be constrained to identifying what components to move from the validator to libsawtooth prior to splitting it off to its own repo","username":"amundson","ts":"2020-06-08T23:18:06.437Z"}
{"msg":"Zoom meeting info is the same as above","username":"amundson","ts":"2020-06-08T23:18:32.861Z"}
{"msg":"Intent is that we are literally going to sit on the call and go through code, making a list as a group","username":"amundson","ts":"2020-06-08T23:20:23.435Z"}
{"msg":"@kodonnel @S.GOPINATH @MicaelFerreira @jamesbarry @wkatsak ^","username":"arsulegai","ts":"2020-06-09T06:37:01.507Z"}
{"msg":"Hi coming up in about an hour and half is our first guest speaker for the DCI-WG. If you are available at noon central / 10 pacific / 8:30 Bangalore you are welcome:\nhttps://wiki.hyperledger.org/x/kw7cAQ\nhttps://zoom.us/my/hyperledger.community.backup","username":"Dan","ts":"2020-06-10T15:21:27.390Z"}
{"msg":"","username":"amundson","ts":"2020-06-10T16:19:13.753Z","attachments":[{"type":"file","title":"Clipboard - June 10, 2020 11:19 AM","title_link":"/file-upload/WcuApA4eoCWTRkuXx/Clipboard%20-%20June%2010,%202020%2011:19%20AM","image_url":"/file-upload/WcuApA4eoCWTRkuXx/Clipboard%20-%20June%2010,%202020%2011:19%20AM","image_type":"image/png","image_size":1087458,"url":"/file-upload/WcuApA4eoCWTRkuXx/Clipboard%20-%20June%2010,%202020%2011:19%20AM","remote":false,"fileId":"WcuApA4eoCWTRkuXx","fileName":"Clipboard - June 10, 2020 11:19 AM"}]}
{"msg":"^ this is the partial dependency diagram that was used in the working session","username":"amundson","ts":"2020-06-10T16:19:34.799Z"}
{"msg":"","username":"amundson","ts":"2020-06-10T17:25:14.383Z","attachments":[{"type":"file","title":"Clipboard - June 10, 2020 12:25 PM","title_link":"/file-upload/wbDfaMiNZa7d7Gfk3/Clipboard%20-%20June%2010,%202020%2012:25%20PM","image_url":"/file-upload/wbDfaMiNZa7d7Gfk3/Clipboard%20-%20June%2010,%202020%2012:25%20PM","image_type":"image/png","image_size":1088014,"url":"/file-upload/wbDfaMiNZa7d7Gfk3/Clipboard%20-%20June%2010,%202020%2012:25%20PM","remote":false,"fileId":"wbDfaMiNZa7d7Gfk3","fileName":"Clipboard - June 10, 2020 12:25 PM"}]}
{"msg":"that was the resulting diagram at the end","username":"amundson","ts":"2020-06-10T17:25:26.806Z"}
{"msg":"No meeting today; next one will be in a week on Friday","username":"amundson","ts":"2020-06-12T14:08:36.020Z"}
{"msg":"Greetings, me and my college @MicaelFerreira have forked the sawtooth project so that we could develop the block injector's features especially the `Block End`.\nWe realized that when we set the setting `sawtooth.validator.block_validation_rules` the serialization of the value gets 2 extra bytes in the beginning of the byte array and because of it the validator fails to parse it and crashes the validator in one of the network nodes (This only happens when the string value is at least bigger than 67 chars).\nWe've debugged the validator and everything is working as it should until it tries to parse the byte array in the function `get_setting` implementation for the `SettingsView`.\n\nWe've made a Spike project mimicking the sawtooth flow from creating the `SettingProposal` and the `SettingsPayload` encoded data like in the `Sawset CLI`, decoded and parsed it into an `Entry` array inside the message `Setting` and decoded it to get the `key` `value` of the setting and everything went smoothly.\nBut when we do the same thing in the validator, it always fails to parse it, so we tried hardcoding the byte array in case the key is equal to `sawtooth.validator.block_validation_rules`, and it worked.\nCurrently I believe the problem might be coming from the `StateReader` but I'm still unsure.\n\nAny help from someone who is familiar with the source code would be greatly appreciated! \nThank you in advance.","username":"AnthonyWhite","ts":"2020-06-16T12:06:52.029Z"}
{"msg":"Did you create a jira ticket for it?","username":"pschwarz","ts":"2020-06-16T16:44:55.522Z"}
{"msg":"How are you setting the value?","username":"pschwarz","ts":"2020-06-16T16:45:24.925Z"}
{"msg":"No, I haven't. Could you point me in the right direction to do so?\nAlso, would you maybe be available to help us out or just a quick call to discuss a bit of the codebase you helped develop?\nRegarding the value it's something like `NofX:1,block_info;XatY:block_info,0;XatY:example_info,-1;local:0,-1`","username":"AnthonyWhite","ts":"2020-06-16T16:50:31.377Z"}
{"msg":"No, I haven't. Could you point me in the right direction to do so?\nAlso, would you maybe be available to help us out or just a quick call to discuss a bit of the codebase you helped develop?\nRegarding the value it's something like `NofX:1,block_info;XatY:block_info,0;NofX:1,example_info;XatY:example_info,-1;local:0,-1`","username":"AnthonyWhite","ts":"2020-06-16T16:50:31.377Z"}
{"msg":"https://sawtooth.hyperledger.org/community/contributing/","username":"pschwarz","ts":"2020-06-16T16:54:04.285Z"}
{"msg":"This is a good start","username":"pschwarz","ts":"2020-06-16T16:54:10.258Z"}
{"msg":"I'd need some more details on the issue","username":"pschwarz","ts":"2020-06-16T16:54:20.024Z"}
{"msg":"Are you looking at the python implementation or the rust implementation?","username":"pschwarz","ts":"2020-06-16T16:55:10.128Z"}
{"msg":"We have reason to believe the problem is in parsing the bytes in the `Merkle.rs` file. If I parse the settings data that I get from the Sawtooth Rest API, it's valid, but for some reason the validator receives a byte array with some extra data that can't be parsed and we have no ideia what it contains.","username":"AnthonyWhite","ts":"2020-06-16T16:59:21.188Z"}
{"msg":"We have reason to believe the problem is in parsing the bytes in the `Merkle.rs` file in the Rust implementation. If I parse the settings data that I get from the Sawtooth Rest API, it's valid, but for some reason the validator receives a byte array with some extra data that can't be parsed and we have no ideia what it contains.","username":"AnthonyWhite","ts":"2020-06-16T16:59:21.188Z"}
{"msg":"We have reason to believe the problem is in parsing the bytes in the `Merkle.rs` file in the Rust implementation. If I parse the settings data that I get from the Sawtooth Rest API, it's valid, but for some reason the validator receives a byte array with some extra data that can't be parsed and we have no ideia what it contains.\nBy the way, this is all theory, we're still unsure where the problem comes from","username":"AnthonyWhite","ts":"2020-06-16T16:59:21.188Z"}
{"msg":"We have reason to believe the problem is in parsing the bytes in the `Merkle.rs` file in the Rust implementation. If I parse the settings data that I get from the Sawtooth Rest API, it's valid, but for some reason the validator receives a byte array with some extra data that can't be parsed and we have no ideia what it contains.\nBy the way, this is all theory, we're still unsure where the problem comes from, but it seems to be from there.","username":"AnthonyWhite","ts":"2020-06-16T16:59:21.188Z"}
{"msg":"Has joined the channel.","username":"jmbarry","ts":"2020-06-16T17:17:08.801Z","type":"uj"}
{"msg":"Back to my earlier question: how are you setting the value?","username":"pschwarz","ts":"2020-06-16T18:31:28.464Z"}
{"msg":"Is it custom code on your end, or are you using the sawtooth commands for this?","username":"pschwarz","ts":"2020-06-16T18:32:16.646Z"}
{"msg":"I've set it using the Sawset CLI and when that didn't work I managed to get it working by harcoding the byte array  in `SettingsView.get_setting` like this:\n```\nlet setting_opt = if let Some(bytes) = bytes_opt {\n            if key != \"sawtooth.validator.block_validation_rules\" {\n                Some(protobuf::parse_from_bytes::<Setting>(&bytes)?)\n            } else {\n                Some(protobuf::parse_from_bytes::<Setting>(&custom_byte_array)?)\n            }\n        } else {\n            None\n        };\n```","username":"AnthonyWhite","ts":"2020-06-16T21:24:18.134Z"}
{"msg":"Do you have the same parsing problem with other settings?","username":"pschwarz","ts":"2020-06-16T21:26:03.679Z"}
{"msg":"@pschwarz no, other settings works great, but the setting `block_validation_rules` was not meant to work with multiple rules as we are trying to do now. At least there're no tests for multiple rules.","username":"MicaelFerreira","ts":"2020-06-17T08:43:48.869Z"}
{"msg":"That can explain why this issue wasn't noticed before","username":"MicaelFerreira","ts":"2020-06-17T08:49:58.869Z"}
{"msg":"Just wanted to leave a quick note here, this documentation https://sawtooth.hyperledger.org/docs/core/nightly/1-1/architecture/injecting_batches_block_validation_rules.html is misleading in the following lines:\n\" A validation rule consists of a name followed by a colon and a comma-separated list of arguments: rulename:arg,arg,...,arg \" <- it's not how it's implemented (only the local rule works this way)\nand\n\"The last transaction in the block has index -1. If abs(Y) is larger than the number of transactions per block, then there would not be a transaction of type X at Y and the block would be invalid.\" <- isn't currently implemented.\nBecause the latter wasn't implemented, we had to do it for the block_end batch injection event","username":"MicaelFerreira","ts":"2020-06-17T10:51:23.641Z"}
{"msg":"Admittedly, the feature was implemented to the degree that we could support the needs of seth.  Hence, why the other modes aren't implemented, nor is there a way to dynamically load batch injectors","username":"pschwarz","ts":"2020-06-17T14:10:54.098Z"}
{"msg":"I'd have to look, but I wouldn't be surprised to see some Jira stories for some of the remaining work","username":"pschwarz","ts":"2020-06-17T14:11:36.386Z"}
{"msg":"It sounds like there are two issues - one setting the block validation setting is producing some invalid content.  My guess is that it has more to do with sawset, rather than the validator (all other settings would have the same issue, since they are all written via the same transaction processor).  The other issue is the lack of features for block injection.","username":"pschwarz","ts":"2020-06-17T14:14:40.234Z"}
{"msg":"It sounds like there are two issues - the first being setting the block validation setting is producing some invalid content.  My guess is that it has more to do with sawset, rather than the validator (all other settings would have the same issue, since they are all written via the same transaction processor).  The other issue is the lack of features for block injection.","username":"pschwarz","ts":"2020-06-17T14:14:40.234Z"}
{"msg":"Yeah, that was almost certainly text pulled from the original design doc","username":"amundson","ts":"2020-06-17T14:19:26.616Z"}
{"msg":"@pschwarz Would you be available to talk with us?\nRegarding the issue coming from Sawset, we've tested it and it doesn't seem to be it.\nWe've debugged from the serialization of the `SettingProposal` and the `SettingsPayload` in Sawset, to the deserialization and serialization of the `Entry` array inside the `Settings` message  in the `settingsTP` and it seems to be ok. But when it tries to parse the byte array using protobuf inside the `get_setting` implementation for the `SettingsView` it panics. We've tried to deserialize the bytes on our Spike but to no avail.\nIf we try to deserialize the `sawtooth.validator.block_validation_rules` from the state using the Sawtooth Rest API then we are able to deserialize it using Protobuf. \nMy current guess is with a problem of the deserialization using CBOR on the validator because the Rest API can get the data with no issues, meaning, it's probably not a problem with the serialization but with deserialization. Next we are going to check how the validator processes the data before sending it to the Rest API.\nDo you know anything related to that?","username":"AnthonyWhite","ts":"2020-06-17T15:14:59.815Z"}
{"msg":"Could you send me the exact sawset command you are using?","username":"pschwarz","ts":"2020-06-17T15:32:37.812Z"}
{"msg":"(paste it here)","username":"pschwarz","ts":"2020-06-17T15:32:43.946Z"}
{"msg":"We are doing it at genesis creation\n```    sawset proposal create \\\n        -k /etc/sawtooth/keys/validator.priv \\\n        sawtooth.consensus.algorithm.name=pbft \\\n        sawtooth.consensus.algorithm.version=1.0 \\\n        sawtooth.validator.batch_injectors='block_info,svg_fee_info' \\\n        sawtooth.validator.block_validation_rules='NofX:1,block_info;XatY:block_info,0;XatY:svg_fee_info,-1;local:0,-1' \\\n        -o config.batch ```","username":"MicaelFerreira","ts":"2020-06-17T15:36:45.909Z"}
{"msg":"We are doing it at genesis creation\n```    sawset proposal create \\\n        -k /etc/sawtooth/keys/validator.priv \\\n        sawtooth.consensus.algorithm.name=pbft \\\n        sawtooth.consensus.algorithm.version=1.0 \\\n        sawtooth.validator.batch_injectors='block_info,svg_fee_info' \\\n        sawtooth.validator.block_validation_rules='NofX:1,block_info;XatY:block_info,0;NofX:1,svg_fee_info;XatY:svg_fee_info,-1;local:0,-1' \\\n        -o config.batch ```","username":"MicaelFerreira","ts":"2020-06-17T15:36:45.909Z"}
{"msg":"This does not work: `'NofX:1,block_info;XatY:block_info,0;NofX:1,svg_fee_info;XatY:svg_fee_info,-1;local:0,-1'`\nThis works `'NofX:1,block_info;XatY:block_info,0;XatY:svg_fee_info,-1;local:0,-1'`","username":"MicaelFerreira","ts":"2020-06-17T15:38:49.853Z"}
{"msg":"This does not work: `'NofX:1,block_info;XatY:block_info,0;NofX:1,svg_fee_info;XatY:svg_fee_info,-1;local:0,-1'`\nThis works `'NofX:1,block_info;XatY:block_info,0;XatY:svg_fee_info,-1;local:0,-1'`  (without the rule \"NofX:1,svg_fee_info\")","username":"MicaelFerreira","ts":"2020-06-17T15:38:49.853Z"}
{"msg":"It looks to me like the only place EncodingError is generated is in the From impl; you could instrument that to log the bytes it is trying to decode, so you have more information (is it the same bytes that are in state, for example)","username":"amundson","ts":"2020-06-17T15:44:00.537Z"}
{"msg":"well, actually, that's just converting the error","username":"amundson","ts":"2020-06-17T15:44:43.045Z"}
{"msg":"but, you could instrument get_setting","username":"amundson","ts":"2020-06-17T15:45:07.899Z"}
{"msg":"you should set RUST_BACKTRACE=1 so you get the full backtrace","username":"amundson","ts":"2020-06-17T15:46:25.011Z"}
{"msg":"in settings_view.rs, around line 122 you will see \n\nlet setting_opt = if let Some(bytes) = bytes_opt {\n            Some(protobuf::parse_from_bytes::<Setting>(&bytes)?)\n\nyou want to know what bytes are there before parse_from_bytes","username":"amundson","ts":"2020-06-17T15:49:28.038Z"}
{"msg":"That's exactly there where it fails to parse, we are already logging that bytes array","username":"MicaelFerreira","ts":"2020-06-17T15:50:27.474Z"}
{"msg":"https://developers.google.com/protocol-buffers/docs/encoding","username":"amundson","ts":"2020-06-17T15:50:46.109Z"}
{"msg":"and we've tried to hardcoded the byte array with a valid one, and it successfully parses it","username":"MicaelFerreira","ts":"2020-06-17T15:51:34.319Z"}
{"msg":"so the byte array is already wrong at that point","username":"MicaelFerreira","ts":"2020-06-17T15:51:57.392Z"}
{"msg":"so, what is the value there that it doesn't like?","username":"amundson","ts":"2020-06-17T15:52:02.762Z"}
{"msg":"this is the bad byte array : \n``` [88, 135, 10, 132, 1, 10, 41, 115, 97, 119, 116, 111, 111, 116, 104, 46, 118, 97, 108, 105, 100, 97, 116, 111, 114, 46, 98, 108, 111, 99, 107, 95, 118, 97, 108, 105, 100, 97, 116, 105, 111, 110, 95, 114, 117, 108, 101, 115, 18, 87, 78, 111, 102, 88, 58, 49, 44, 98, 108, 111, 99, 107, 95, 105, 110, 102, 111, 59, 88, 97, 116, 89, 58, 98, 108, 111, 99, 107, 95, 105, 110, 102, 111, 44, 48, 59, 78, 111, 102, 88, 58, 49, 44, 115, 118, 103, 95, 102, 101, 101, 95, 105, 110, 102, 111, 59, 88, 97, 116, 89, 58, 115, 118, 103, 95, 102, 101, 101, 95, 105, 110, 102, 111, 44, 45, 49, 59, 108, 111, 99, 97, 108, 58, 48, 44, 45, 49]\n```","username":"MicaelFerreira","ts":"2020-06-17T15:53:05.334Z"}
{"msg":"the only difference to the good array are the first 2 bytes (i'm trying to find it here in our tests..)","username":"MicaelFerreira","ts":"2020-06-17T15:54:18.106Z"}
{"msg":"what statement in the code are you using to output that?","username":"amundson","ts":"2020-06-17T15:55:00.140Z"}
{"msg":"`info!({:?})`","username":"MicaelFerreira","ts":"2020-06-17T15:55:48.389Z"}
{"msg":"`info!({:?}, byte_array)`","username":"MicaelFerreira","ts":"2020-06-17T15:55:48.389Z"}
{"msg":"`info!(\"{:?}\", byte_array)`","username":"MicaelFerreira","ts":"2020-06-17T15:55:48.389Z"}
{"msg":"Another question: which build of the settings transaction family are you using?  Is it still the python one, or the rust one?","username":"pschwarz","ts":"2020-06-17T15:56:33.825Z"}
{"msg":"rust","username":"MicaelFerreira","ts":"2020-06-17T15:57:14.311Z"}
{"msg":"```58  87  0a  84  01  0a  29  73  61  77  74  6f  6f  74  68  2e  76  61  6c  69  64  61  74  6f  72  2e  62  6c  6f  63  6b  5f  76  61  6c  69  64  61  74  69  6f  6e  5f  72  75  6c  65  73  12  57  4e  6f  66  58  3a  31  2c  62  6c  6f  63  6b  5f  69  6e  66  6f  3b  58  61  74  59  3a  62  6c  6f  63  6b  5f  69  6e  66  6f  2c  30  3b  4e  6f  66  58  3a  31  2c  73  76  67  5f  66  65  65  5f  69  6e  66  6f  3b  58  61  74  59  3a  73  76  67  5f  66  65  65  5f  69  6e  66  6f  2c  2d  31  3b  6c  6f  63  61  6c  3a  30  2c  2d  31```","username":"amundson","ts":"2020-06-17T16:01:04.605Z"}
{"msg":"what is an example of some valid bytes at that point?","username":"amundson","ts":"2020-06-17T16:01:38.792Z"}
{"msg":"Well i found it, the difference from the bad byte array to the good one, are the 2 first bytes that are not there:\n``` [10, 132, 1, 10, 41, 115, 97, 119, 116, 111, 111, 116, 104, 46, 118, 97, 108, 105, 100, 97, 116, 111, 114, 46, 98, 108, 111, 99, 107, 95, 118, 97, 108, 105, 100, 97, 116, 105, 111, 110, 95, 114, 117, 108, 101, 115, 18, 87, 78, 111, 102, 88, 58, 49, 44, 98, 108, 111, 99, 107, 95, 105, 110, 102, 111, 59, 88, 97, 116, 89, 58, 98, 108, 111, 99, 107, 95, 105, 110, 102, 111, 44, 48, 59, 78, 111, 102, 88, 58, 49, 44, 115, 118, 103, 95, 102, 101, 101, 95, 105, 110, 102, 111, 59, 88, 97, 116, 89, 58, 115, 118, 103, 95, 102, 101, 101, 95, 105, 110, 102, 111, 44, 45, 49, 59, 108, 111, 99, 97, 108, 58, 48, 44, 45, 49]\n```","username":"MicaelFerreira","ts":"2020-06-17T16:02:55.835Z"}
{"msg":"```0a  84  01  0a  29  73  61  77  74  6f  6f  74  68  2e  76  61  6c  69  64  61  74  6f  72  2e  62  6c  6f  63  6b  5f  76  61  6c  69  64  61  74  69  6f  6e  5f  72  75  6c  65  73  12  57  4e  6f  66  58  3a  31  2c  62  6c  6f  63  6b  5f  69  6e  66  6f  3b  58  61  74  59  3a  62  6c  6f  63  6b  5f  69  6e  66  6f  2c  30  3b  4e  6f  66  58  3a  31  2c  73  76  67  5f  66  65  65  5f  69  6e  66  6f  3b  58  61  74  59  3a  73  76  67  5f  66  65  65  5f  69  6e  66  6f  2c  2d  31  3b  6c  6f  63  61  6c  3a  30  2c  2d  31```","username":"amundson","ts":"2020-06-17T16:04:09.882Z"}
{"msg":"the one starting with 58 87 looks like valid cbor","username":"jsmitchell","ts":"2020-06-17T16:28:06.896Z"}
{"msg":"decodes to \"\\n\\x84\\x01\\n)sawtooth.validator.block_validation_rules\\x12WNofX:1,block_info;XatY:block_info,0;NofX:1,svg_fee_info;XatY:svg_fee_info,-1;local:0,-1\"","username":"jsmitchell","ts":"2020-06-17T16:28:57.755Z"}
{"msg":"so, 10/0a there is basically field_number=1, wire_type=2 and the next byte (132) would be the length","username":"amundson","ts":"2020-06-17T16:29:40.978Z"}
{"msg":"What bytes are printed with the shorter string?","username":"pschwarz","ts":"2020-06-17T16:30:19.042Z"}
{"msg":"actually, the next two bytes (132, 1) are the length of 132","username":"amundson","ts":"2020-06-17T16:33:25.817Z"}
{"msg":"the spurious bytes at the beginning are the cbor byte array wrapping","username":"jsmitchell","ts":"2020-06-17T16:34:23.297Z"}
{"msg":"@amundson , I've here the log when it panics, `thread 'PublisherThread' panicked at 'Unable to get setting: EncodingError(WireError(UnexpectedWireType(WireTypeEndGroup)))', src/journal/validation_rule_enforcer.rs:50:17`","username":"MicaelFerreira","ts":"2020-06-17T16:34:30.529Z"}
{"msg":"```58 87                                   # bytes(135)\n   0A84010A29736177746F6F74682E76616C696461746F722E626C6F636B5F76616C69646174696F6E5F72756C657312574E6F66583A312C626C6F636B5F696E666F3B586174593A626C6F636B5F696E666F2C303B4E6F66583A312C7376675F6665655F696E666F3B586174593A7376675F6665655F696E666F2C2D313B6C6F63616C3A302C2D31 # \"\\n\\x84\\x01\\n)sawtooth.validator.block_validation_rules\\x12WNofX:1,block_info;XatY:block_info,0;NofX:1,svg_fee_info;XatY:svg_fee_info,-1;local:0,-1\"\n```","username":"jsmitchell","ts":"2020-06-17T16:34:36.700Z"}
{"msg":"@pschwarz the shorted setting that works normally: ```[10, 132, 1, 10, 41, 115, 97, 119, 116, 111, 111, 116, 104, 46, 118, 97, 108, 105, 100, 97, 116, 111, 114, 46, 98, 108, 111, 99, 107, 95, 118, 97, 108, 105, 100, 97, 116, 105, 111, 110, 95, 114, 117, 108, 101, 115, 18, 87, 78, 111, 102, 88, 58, 49, 44, 98, 108, 111, 99, 107, 95, 105, 110, 102, 111, 59, 88, 97, 116, 89, 58, 98, 108, 111, 99, 107, 95, 105, 110, 102, 111, 44, 48, 59, 78, 111, 102, 88, 58, 49, 44, 115, 118, 103, 95, 102, 101, 101, 95, 105, 110, 102, 111, 59, 88, 97, 116, 89, 58, 115, 118, 103, 95, 102, 101, 101, 95, 105, 110, 102, 111, 44, 45, 49, 59, 108, 111, 99, 97, 108, 58, 48, 44, 45, 49]\n```","username":"MicaelFerreira","ts":"2020-06-17T16:35:32.508Z"}
{"msg":"double-cbor'd somewhere?","username":"amundson","ts":"2020-06-17T16:36:43.365Z"}
{"msg":"","username":"amundson","ts":"2020-06-17T16:41:59.813Z","attachments":[{"type":"file","title":"Clipboard - June 17, 2020 11:41 AM","title_link":"/file-upload/DwdvHXhkz8C9BbFAX/Clipboard%20-%20June%2017,%202020%2011:41%20AM","image_url":"/file-upload/DwdvHXhkz8C9BbFAX/Clipboard%20-%20June%2017,%202020%2011:41%20AM","image_type":"image/png","image_size":38102,"url":"/file-upload/DwdvHXhkz8C9BbFAX/Clipboard%20-%20June%2017,%202020%2011:41%20AM","remote":false,"fileId":"DwdvHXhkz8C9BbFAX","fileName":"Clipboard - June 17, 2020 11:41 AM"}]}
{"msg":"seems like even the short string above would be >0.17","username":"amundson","ts":"2020-06-17T16:42:43.804Z"}
{"msg":"seems like even the short string above would be >0x17","username":"amundson","ts":"2020-06-17T16:42:43.804Z"}
{"msg":"I think this issue is fixed in this commit: https://github.com/hyperledger/sawtooth-core/pull/2251/commits/20d7b4f8592e9d31ac75527d8f0b93380712a21c","username":"pschwarz","ts":"2020-06-17T16:43:24.283Z"}
{"msg":"(cbor is truly wild)","username":"amundson","ts":"2020-06-17T16:43:26.372Z"}
{"msg":"Which hasn't yet been merged","username":"pschwarz","ts":"2020-06-17T16:43:29.629Z"}
{"msg":"Hmm it could be","username":"MicaelFerreira","ts":"2020-06-17T16:46:49.006Z"}
{"msg":"that doesn't explain why different lengths would matter","username":"amundson","ts":"2020-06-17T16:46:50.528Z"}
{"msg":"@MicaelFerreira you gave the same string, one without the cbor prefix, one without. I'm still not sure how you captured those and whether the different-lengths thing is accurate.","username":"amundson","ts":"2020-06-17T16:51:01.962Z"}
{"msg":"@pschwarz kind of surprised anything works if that patch is accurate (which it probably is)","username":"amundson","ts":"2020-06-17T16:53:56.005Z"}
{"msg":"Very true.  Though, the only rust code that currently reads state is the settings view, and most of those values are short","username":"pschwarz","ts":"2020-06-17T16:56:46.622Z"}
{"msg":"So if there's some reason that the cbor encoder isn't writing that leading tag, then it probably just works by accident","username":"pschwarz","ts":"2020-06-17T16:57:27.720Z"}
{"msg":"maybe the cbor encoding for some things would accidentally valid protobuf that would just result in it getting thrown away, but it seems unlikely","username":"amundson","ts":"2020-06-17T16:57:50.381Z"}
{"msg":"Clearly, came across this issue in Sept of last year while testing the permissions stuff","username":"pschwarz","ts":"2020-06-17T16:58:04.712Z"}
{"msg":"I would have expected to see this probably crop up in poet testing","username":"amundson","ts":"2020-06-17T16:58:40.215Z"}
{"msg":"True","username":"pschwarz","ts":"2020-06-17T16:58:46.106Z"}
{"msg":"well","username":"amundson","ts":"2020-06-17T16:59:01.863Z"}
{"msg":"@pschwarz We are going to try it with the changes from your pull request tomorrow and get back to you","username":"AnthonyWhite","ts":"2020-06-17T16:59:06.323Z"}
{"msg":"I'll pull that commit out into its own PR","username":"pschwarz","ts":"2020-06-17T16:59:20.646Z"}
{"msg":"we are probably looking at master and not the 1.2 branch, am I right?","username":"amundson","ts":"2020-06-17T16:59:23.849Z"}
{"msg":"Yes, in this case","username":"pschwarz","ts":"2020-06-17T16:59:37.050Z"}
{"msg":"wonder if this patch applies to 1.2 then","username":"amundson","ts":"2020-06-17T17:00:29.834Z"}
{"msg":"(seems likely)","username":"amundson","ts":"2020-06-17T17:00:52.486Z"}
{"msg":"Probably","username":"pschwarz","ts":"2020-06-17T17:01:00.165Z"}
{"msg":"@AnthonyWhite @MicaelFerreira good luck, let us know how it goes","username":"amundson","ts":"2020-06-17T17:02:10.360Z"}
{"msg":"@amundson The one with cbor prefix we got it from settings view from the output of the state_reader; The one without cbor prefix was from our rust spike using protobuf","username":"MicaelFerreira","ts":"2020-06-17T17:03:31.950Z"}
{"msg":"Will do @amundson  @pschwarz  Thank you for the help","username":"AnthonyWhite","ts":"2020-06-17T17:03:45.881Z"}
{"msg":"We are using the branch 1.2, not the master","username":"MicaelFerreira","ts":"2020-06-17T17:04:06.609Z"}
{"msg":"it would be good to run a shorter string through and capture it and see what the encoding is (in the environment that the longer one breaks) if we continue to believe length matters","username":"amundson","ts":"2020-06-17T17:05:22.876Z"}
{"msg":"@amundson We'll prepare those and the rust stack trace and post it here tomorrow","username":"AnthonyWhite","ts":"2020-06-17T17:06:28.028Z"}
{"msg":"@amundson We'll prepare those and the rust stack trace and post it here","username":"AnthonyWhite","ts":"2020-06-17T17:06:28.028Z"}
{"msg":"rust stack traces probably less important now that we have a reasonable theory","username":"amundson","ts":"2020-06-17T17:07:36.762Z"}
{"msg":"the shorter setting which works: ```[88, 114, 10, 112, 10, 41, 115, 97, 119, 116, 111, 111, 116, 104, 46, 118, 97, 108, 105, 100, 97, 116, 111, 114, 46, 98, 108, 111, 99, 107, 95, 118, 97, 108, 105, 100, 97, 116, 105, 111, 110, 95, 114, 117, 108, 101, 115, 18, 67, 78, 111, 102, 88, 58, 49, 44, 98, 108, 111, 99, 107, 95, 105, 110, 102, 111, 59, 88, 97, 116, 89, 58, 98, 108, 111, 99, 107, 95, 105, 110, 102, 111, 44, 48, 59, 88, 97, 116, 89, 58, 115, 118, 103, 95, 102, 101, 101, 95, 105, 110, 102, 111, 44, 45, 49, 59, 108, 111, 99, 97, 108, 58, 48, 44, 45, 49]\n```","username":"MicaelFerreira","ts":"2020-06-17T17:08:28.732Z"}
{"msg":"ok, give me a sec and I'll try to see what 88,114 means to protobuf","username":"amundson","ts":"2020-06-17T17:10:24.121Z"}
{"msg":"(clearly its cbor, but what I want to know is how protobuf will interpret it)","username":"amundson","ts":"2020-06-17T17:11:10.912Z"}
{"msg":"Just to make it clear, that byte array is the result from state_reader at get_setting() implementation from SettingsView","username":"MicaelFerreira","ts":"2020-06-17T17:12:59.542Z"}
{"msg":"that byte array doesn't parse as cbor","username":"jsmitchell","ts":"2020-06-17T17:13:20.792Z"}
{"msg":"88,114 would be string of length 114 right?","username":"amundson","ts":"2020-06-17T17:14:04.474Z"}
{"msg":"its length 116, so it seems like it should be valid","username":"amundson","ts":"2020-06-17T17:15:07.435Z"}
{"msg":"the difference between 88,132 and 88,114 is that in protobuf 114 is a one-byte value and 132 will pull in another byte because the highest bit is set","username":"amundson","ts":"2020-06-17T17:16:37.565Z"}
{"msg":"i lied, it does parse","username":"jsmitchell","ts":"2020-06-17T17:20:44.226Z"}
{"msg":"```>>> cbor.loads(bytes(foo))\nb'\\np\\n)sawtooth.validator.block_validation_rules\\x12CNofX:1,block_info;XatY:block_info,0;XatY:svg_fee_info,-1;local:0,-1'\n```","username":"jsmitchell","ts":"2020-06-17T17:20:47.263Z"}
{"msg":"88 has the meaning field_type = varint, field = 11. so indeed, that appears to be valid protobuf (stuffing the length of the cbor into field 11)","username":"amundson","ts":"2020-06-17T17:21:26.329Z"}
{"msg":"ya it should, because that setting works :)","username":"MicaelFerreira","ts":"2020-06-17T17:21:32.843Z"}
{"msg":"which, for most protobuf, will work because we don't have many field 11s","username":"amundson","ts":"2020-06-17T17:21:45.332Z"}
{"msg":"crazy","username":"jsmitchell","ts":"2020-06-17T17:21:53.326Z"}
{"msg":"this seems well-understood to me at this point, I don't think we need the extra work tomorrow beyond testing @pschwarz's fix","username":"amundson","ts":"2020-06-17T17:23:40.590Z"}
{"msg":"@pschwarz should they be testing the entire branch or just that one commit? what would we backport?","username":"amundson","ts":"2020-06-17T17:25:15.004Z"}
{"msg":"Interesting, so protobuf deserialization happened on cbor? Shouldn't this fail?","username":"arsulegai","ts":"2020-06-17T18:24:38.852Z"}
{"msg":"Understood","username":"arsulegai","ts":"2020-06-17T18:45:26.574Z"}
{"msg":"I think just testing that one commit would be fine","username":"pschwarz","ts":"2020-06-17T19:16:44.202Z"}
{"msg":"https://github.com/hyperledger/sawtooth-core/pull/2304","username":"pschwarz","ts":"2020-06-17T22:12:51.199Z"}
{"msg":"@pschwarz your commit definitely fixed the issue. It's working great now","username":"MicaelFerreira","ts":"2020-06-18T10:00:36.046Z"}
{"msg":"We must thank you guys for the support yesterday, @amundson @pschwarz @jsmitchell","username":"MicaelFerreira","ts":"2020-06-18T10:03:14.466Z"}
{"msg":"Reminder: The next Sawtooth Core Working Session meeting is Friday at 10am US/Central","username":"amundson","ts":"2020-06-18T14:22:11.310Z"}
{"msg":"Time: Jun 19, 2020 10:00 AM Central Time (US and Canada)\n\nJoin Zoom Meeting\nhttps://us02web.zoom.us/j/89262216179\n\nMeeting ID: 892 6221 6179\nOne tap mobile\n+13126266799,,89262216179# US (Chicago)\n+19292056099,,89262216179# US (New York)\n\nDial by your location\n        +1 312 626 6799 US (Chicago)\n        +1 929 205 6099 US (New York)\n        +1 301 715 8592 US (Germantown)\n        +1 346 248 7799 US (Houston)\n        +1 669 900 6833 US (San Jose)\n        +1 253 215 8782 US (Tacoma)\nMeeting ID: 892 6221 6179\nFind your local number: https://us02web.zoom.us/u/kbfpTnIXUY","username":"amundson","ts":"2020-06-18T14:22:45.646Z"}
{"msg":"The working doc for the meeting is: https://docs.google.com/document/d/1WlF8UfoKAEydJobHWDvz-tMpWqQSTlChoFv50fHX1tM/edit#","username":"amundson","ts":"2020-06-18T20:51:21.568Z"}
{"msg":"Agenda: next 1.2.x release; 1-3 branch; builds in master; sawtooth library status; sawtooth library RFC","username":"amundson","ts":"2020-06-18T20:51:59.969Z"}
{"msg":"note that a draft version of the RFC is in that working doc, at the end, if you want to read it prior to the meeting","username":"amundson","ts":"2020-06-18T20:52:40.244Z"}
{"msg":"Has joined the channel.","username":"mrausnadian","ts":"2020-06-19T09:53:43.684Z","type":"uj"}
{"msg":"@arsulegai @ltseeley should we move forward with https://github.com/hyperledger/sawtooth-core/pull/2312/files and then build upon it, or are we going to iterate on that PR itself?","username":"amundson","ts":"2020-06-24T16:33:18.754Z"}
{"msg":"My take on the PR: It's not serving the purpose of abstracting away Py impl dependency from the place where it is used. However, it does put up a skeleton trait for Rust impl.","username":"arsulegai","ts":"2020-06-24T16:36:33.008Z"}
{"msg":"I don't have a strong preference","username":"ltseeley","ts":"2020-06-24T16:40:10.054Z"}
{"msg":"I don't either. @arsulegai you decide","username":"amundson","ts":"2020-06-24T16:49:04.504Z"}
{"msg":"Same here, no hard preferences","username":"arsulegai","ts":"2020-06-24T16:52:32.352Z"}
{"msg":"Ok, I'll merge it, because I think it will make the future related PRs less verbose and more focused.","username":"amundson","ts":"2020-06-24T16:54:35.974Z"}
{"msg":"I was too slow, now it has conflicts","username":"amundson","ts":"2020-06-24T16:54:58.102Z"}
{"msg":"Resolved, but build will take 1:30 hours","username":"arsulegai","ts":"2020-06-24T17:19:41.358Z"}
{"msg":"@ltseeley is investigating https://docs.rs/metrics/0.12.1/metrics/","username":"amundson","ts":"2020-06-25T15:40:43.400Z"}
{"msg":"Here's a PR to use that metrics crate in the validator: https://github.com/hyperledger/sawtooth-core/pull/2319 Still working on testing it out properly","username":"ltseeley","ts":"2020-06-25T16:48:12.359Z"}
{"msg":"Any update on https://github.com/hyperledger/sawtooth-core/pull/1994 / https://jira.hyperledger.org/browse/STL-1477? This is causing lots of problems with our attempted migration from 1.0.5 to 1.2","username":"Will_Gluwa","ts":"2020-06-26T18:02:12.098Z"}
{"msg":"Has joined the channel.","username":"shantanhunt","ts":"2020-06-28T19:28:17.602Z","type":"uj"}
{"msg":"@Will_Gluwa I think the PR is abandoned; there was a lot of discussion that didn't get summarized in the PR about it and alternative fixes (none of which were implemented); long story short it is not necessarily the right fix to the problem.","username":"amundson","ts":"2020-06-30T14:21:27.241Z"}
{"msg":"It seems like a pretty large issue to keep unpatched for so long, no? Are others not impacted by the problem?","username":"Will_Gluwa","ts":"2020-07-01T04:54:40.759Z"}
{"msg":"I opened up a PR with a bunch of backports to 1-2. They looked safe to me, found by comparing branches. Could use multiple eyes on this for sure, and testing if folks have the capacity --  https://github.com/hyperledger/sawtooth-core/pull/2324","username":"amundson","ts":"2020-07-06T17:38:18.316Z"}
{"msg":"I think we should make the 1-3 branch point cd283d14954066af08a3b09aa85708c8cc226e3c, right before we added libsawtooth, then cherry-pick non-libsawtooth things to it","username":"amundson","ts":"2020-07-06T17:55:22.269Z"}
{"msg":"PR for moving modules from validator to libsawtooth https://github.com/hyperledger/sawtooth-core/pull/2323","username":"arsulegai","ts":"2020-07-07T10:46:06.442Z"}
{"msg":"Moving sawtooth-core rust code into the sawtooth crate is done, so we are moving forward with populating the sawtooth-lib repo and purging sawtooth-core's master of that code. The plan is to create \"master\" and \"0-3\" branches in sawtooth-lib and point the validator at the \"0-3\" for now (master becoming 0.4.","username":"amundson","ts":"2020-07-07T17:02:25.547Z"}
{"msg":"The next Sawtooth working session will be on Friday 10am US/Central (same zoom URL as posted previously)","username":"amundson","ts":"2020-07-07T17:03:44.184Z"}
{"msg":"Agenda will roughly be: review progress toward sawtooth-lib; immediate next steps (protocol layer, adopt Transact)","username":"amundson","ts":"2020-07-07T17:05:09.326Z"}
{"msg":"and 1-3/master branch updates/status for sawtooth-core as well","username":"amundson","ts":"2020-07-07T17:06:28.940Z"}
{"msg":"We are actively seeking assistance rewriting the REST API and CLIs in Rust short-term, because it will be necessary soon in order to rewrite the integration tests, because we want to do full-stack tests within a single process","username":"amundson","ts":"2020-07-07T17:10:11.428Z"}
{"msg":"so, if anyone is looking for a way to help... :)","username":"amundson","ts":"2020-07-07T17:10:30.059Z"}
{"msg":"What is rust?","username":"Dan","ts":"2020-07-07T17:10:42.540Z"}
{"msg":"its like python","username":"amundson","ts":"2020-07-07T17:10:58.826Z"}
{"msg":"lol","username":"Dan","ts":"2020-07-07T17:11:08.904Z"}
{"msg":"if someone wants a more technical challenge, adding a backward-compatible transaction processor backend to Transact would be good, otherwise we likely loose that compatibility short-term","username":"amundson","ts":"2020-07-07T17:13:15.470Z"}
{"msg":"ok, I fixed the python code.. just added `__declspec(rust)` before each function. I think that's it.","username":"Dan","ts":"2020-07-07T17:13:59.614Z"}
{"msg":"we are planning to compile in all Sawtooth-provided smart contracts into the validator, so we will not have separate processes for them","username":"amundson","ts":"2020-07-07T17:14:30.557Z"}
{"msg":"you mean like settings, identity, etc.?","username":"Dan","ts":"2020-07-07T17:15:29.772Z"}
{"msg":"yes - settings, identity, sabre, xo, intkey, etc.","username":"amundson","ts":"2020-07-07T17:15:49.023Z"}
{"msg":"does that have any deployment/upgrade implications? Like if I want to deploy intkey v2 then I need to restart the validator instead of pushing live?","username":"Dan","ts":"2020-07-07T17:16:42.461Z"}
{"msg":"yes, which is why apps should use sabre or another on-chain smart contract engine","username":"amundson","ts":"2020-07-07T17:17:23.528Z"}
{"msg":"another interesting thing to do for backward compatibility would be to figure out how to run existing python smart contracts inside sabre with minimal modifications","username":"amundson","ts":"2020-07-07T17:19:43.761Z"}
{"msg":"Hi guys,\nI have a question regarding the block validation rules related to this pull request https://github.com/hyperledger/sawtooth-core/pull/2314.\nFor some reason you are enforcing the validation rules every time a batch is added by calling the `validation_rule_enforcer::enforce_validation_rules` method, that leads to duplicate validations on some batches.\nIn case of rules set using negative values that reference the end of the block (`XatY`) or rules that have a maximum amount of transactions of a certain family (`NofX`), not all validations can be done every time a batch is added or are unnecessary to do so from my point of view.\nIs it necessary for some special reason or could all the validations be done just before finalizing the block?","username":"AnthonyWhite","ts":"2020-07-08T15:00:58.582Z"}
{"msg":"@AnthonyWhite can you please explain duplicate validations?","username":"arsulegai","ts":"2020-07-08T18:41:41.991Z"}
{"msg":"Is there a working doc for Friday's meeting?","username":"Will_Gluwa","ts":"2020-07-08T23:00:41.512Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=chLykj5oaF75nGpuG) @Will_Gluwa here it is","username":"arsulegai","ts":"2020-07-09T03:25:44.057Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=chLykj5oaF75nGpuG","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=chLykj5oaF75nGpuG","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Thanks @arsulegai !","username":"Will_Gluwa","ts":"2020-07-09T03:26:10.102Z"}
{"msg":"Basically, every time a batch is added it validates all the pending batches in the line https://github.com/hyperledger/sawtooth-core/blob/1-2/validator/src/journal/candidate_block.rs#L273","username":"AnthonyWhite","ts":"2020-07-09T08:50:05.008Z"}
{"msg":"Isn't it batches to be added only?","username":"arsulegai","ts":"2020-07-09T17:42:25.564Z"}
{"msg":"Reminder, the URL for Today's 10am (US/Central) working session is https://us02web.zoom.us/j/89262216179","username":"amundson","ts":"2020-07-10T14:41:33.269Z"}
{"msg":"The working session doc is - https://docs.google.com/document/d/1WlF8UfoKAEydJobHWDvz-tMpWqQSTlChoFv50fHX1tM/edit#","username":"amundson","ts":"2020-07-10T14:41:56.445Z"}
{"msg":"moving over to here https://chat.hyperledger.org/channel/transact?msg=uQDGq3NxPfuz5PpHR","username":"kodonnel","ts":"2020-07-10T16:58:54.394Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/transact?msg=uQDGq3NxPfuz5PpHR","url":"https://chat.hyperledger.org/channel/transact?msg=uQDGq3NxPfuz5PpHR","remote":true,"fileId":null,"fileName":null}]}
{"msg":"Actually, looking through transact.  Is it just a matter of having an alternate implementation of something like `libtransact/src/sawtooth.rs` the remotes the calls?","username":"kodonnel","ts":"2020-07-10T17:00:19.463Z"}
{"msg":"probably more generically than sawtooth though would be good","username":"kodonnel","ts":"2020-07-10T17:03:18.465Z"}
{"msg":"Has joined the channel.","username":"kenty","ts":"2020-07-11T01:43:34.352Z","type":"uj"}
{"msg":"I don't see a search box in the splinter website.  I think we should keep one for sawtooth v2.0 docs.  I use it quite a lot for CHSA.","username":"kenty","ts":"2020-07-11T01:46:09.014Z"}
{"msg":"Sounds good option","username":"arsulegai","ts":"2020-07-11T09:18:25.347Z"}
{"msg":"several projects including the linux kernel are adopting more inclusive terminology to replace master/slave and blacklist/whitelist. I've audited our project and there is very little to be fixed.\nThere's some poet documentation, the jenkins whitelist check, and then 3rd party files like pylint.\nI think we should address our files but not modify the 3rd party files.\nI've created one PR just to get feedback before tackling the jenkins files. Please take a look and provide feedback:\nhttps://github.com/hyperledger/sawtooth-poet/pull/48","username":"Dan","ts":"2020-07-13T16:38:57.852Z"}
{"msg":"I am in the LMWG meeting and was wondering if we can get any analytics on sawtooth documentation usage, eg. which versions were most accessed.  At the moment, I can only see this for sawtooth: https://lfanalytics.io/projects/hyperledger%2Fsawtooth/dashboard","username":"kenty","ts":"2020-07-13T17:32:59.352Z"}
{"msg":"@kenty I don't have access to any analytics. This is the main docs page though which has links to each version. https://sawtooth.hyperledger.org/docs/","username":"Dan","ts":"2020-07-13T17:45:01.233Z"}
{"msg":"@ryanbeck I'm looking at renaming whitelist as above. It looks like each repo has the same whitelist bin script. Would it make sense to remove that from all repos and just have it local to jenkins? It looks like jenkins already relies on a centralized auth list to feed to that script.","username":"Dan","ts":"2020-07-13T17:46:20.966Z"}
{"msg":"or maybe the right handle is @rbuysse","username":"Dan","ts":"2020-07-13T17:50:36.272Z"}
{"msg":"@Dan  thanks, I am thinking about how to revamp the existing docs site and prepare for v2.0","username":"kenty","ts":"2020-07-13T17:50:57.535Z"}
{"msg":"I don't think it should get removed","username":"rbuysse","ts":"2020-07-13T17:51:25.072Z"}
{"msg":"rename is fine though","username":"rbuysse","ts":"2020-07-13T17:51:38.919Z"}
{"msg":"I was thinking it might be more secure to have that file out of possible attacker control. Is there a benefit to having the script in each repo rather than local to the jenkins server?","username":"Dan","ts":"2020-07-13T17:54:45.446Z"}
{"msg":"portability and transparency is the main thing","username":"rbuysse","ts":"2020-07-13T17:59:31.251Z"}
{"msg":"we do readTrusted on that file so it's not an attack vector https://www.jenkins.io/doc/pipeline/steps/workflow-multibranch/#readtrusted-read-trusted-file-from-scm","username":"rbuysse","ts":"2020-07-13T17:59:48.269Z"}
{"msg":"Yes, I'll rephrase, every time a batch is added to the vector `batches_to_add` the `validation_rule_enforcer::enforce_validation_rules` is called with all the previously added batches (`pending_batches`) and if it passes the new batch is added to the `pending_batches`","username":"AnthonyWhite","ts":"2020-07-14T08:26:13.844Z"}
{"msg":"Yes, I'll rephrase, every time the `add_batch` method is called the batch is added to the vector `batches_to_add` the `validation_rule_enforcer::enforce_validation_rules` is called with all the previously added batches (`pending_batches`) and if it passes, the new batch is added to the `pending_batches`","username":"AnthonyWhite","ts":"2020-07-14T08:26:13.844Z"}
{"msg":"Please refrain from using threading on conversations here. We don't have the time or patience to click on every thread separately.","username":"amundson","ts":"2020-07-24T14:13:45.418Z"}
{"msg":"Next working session will be Friday, Aug 7 at 10am","username":"amundson","ts":"2020-07-24T14:18:54.519Z"}
{"msg":"","username":"amundson","ts":"2020-07-27T20:39:18.114Z","attachments":[{"type":"file","title":"Sawtooth code dependencies (between components)","title_link":"/file-upload/RM2tZK9bFuuhsC7dj/Sawtooth%20code%20dependencies%20(between%20components)","image_url":"/file-upload/RM2tZK9bFuuhsC7dj/Sawtooth%20code%20dependencies%20(between%20components)","image_type":"image/png","image_size":4183993,"url":"/file-upload/RM2tZK9bFuuhsC7dj/Sawtooth%20code%20dependencies%20(between%20components)","remote":false,"fileId":"RM2tZK9bFuuhsC7dj","fileName":"Sawtooth code dependencies (between components)"}]}
{"msg":"Reminder, the Zoom for the 10am (US/Central) meeting tomorrow is: https://us02web.zoom.us/j/89262216179","username":"amundson","ts":"2020-08-06T22:09:25.450Z"}
{"msg":"the working doc for the meeting is - https://docs.google.com/document/d/1WlF8UfoKAEydJobHWDvz-tMpWqQSTlChoFv50fHX1tM/edit#","username":"amundson","ts":"2020-08-06T22:55:24.047Z"}
{"msg":"We merged the whitelist->authlist change in core a few weeks ago. That same commit is rippled to the other repos. Really easy PR reviews: https://github.com/search?q=org%3Ahyperledger+Revise+jenkins+scripts+for+inclusive+terminology&type=Issues","username":"Dan","ts":"2020-08-07T13:05:09.706Z"}
{"msg":"Anyone have a summary of the CI change? ```Remove existing build/ci infrastructure\nPut new build/ci infrastructure in place (borrowing from Splinter and Grid work)\n``` Not sure if I can make the 10 am call.","username":"Dan","ts":"2020-08-07T13:10:02.480Z"}
{"msg":"@Dan its not actual CI stuff (Jenkins, whatever) - it's the docker images and how they build the site","username":"amundson","ts":"2020-08-07T14:56:54.062Z"}
{"msg":"cool. thanks.","username":"Dan","ts":"2020-08-07T14:57:14.559Z"}
{"msg":"it is present currently in the grid-docs refresh branch","username":"amundson","ts":"2020-08-07T14:57:38.944Z"}
{"msg":"you can clone it and do 'just run' to get the site up quickly. good stuff.","username":"amundson","ts":"2020-08-07T14:57:57.820Z"}
{"msg":"@rbuysse @rberg2 We committed a change to sawtooth-core for inclusive wording with the jenkins scripts. I've got replicas of that PR for the other repos. If you or others want to approve those, we can get uniformity across the repos: https://github.com/search?q=org%3Ahyperledger+sawtooth+inclusive&type=Issues","username":"Dan","ts":"2020-08-24T17:21:32.944Z"}
{"msg":"Is there any reason to believe that using FQDN instead of IPV4 addresses with Sawtooth will cause performance issues?","username":"Will_Gluwa","ts":"2020-08-26T03:43:25.249Z"}
{"msg":"Hi there, i'm trying to run docker composer run-lint at branch 1-3 of the sawtooth-core but i'm facing alot of issues accessing to the repositories, any ideas?","username":"MicaelFerreira","ts":"2020-08-26T16:27:56.544Z"}
{"msg":"","username":"MicaelFerreira","ts":"2020-08-26T16:28:00.388Z","attachments":[{"type":"file","title":"Clipboard - August 26, 2020 5:27 PM","title_link":"/file-upload/uQKepoBb7kAZHX3ch/Clipboard%20-%20August%2026,%202020%205:27%20PM","image_url":"/file-upload/uQKepoBb7kAZHX3ch/Clipboard%20-%20August%2026,%202020%205:27%20PM","image_type":"image/png","image_size":190187,"url":"/file-upload/uQKepoBb7kAZHX3ch/Clipboard%20-%20August%2026,%202020%205:27%20PM","remote":false,"fileId":"uQKepoBb7kAZHX3ch","fileName":"Clipboard - August 26, 2020 5:27 PM"}]}
{"msg":"The cmd i ran `docker-compose -f docker/compose/run-lint.yaml up --abort-on-container-exit --exit-code-from lint-validator lint-validator`","username":"MicaelFerreira","ts":"2020-08-26T16:28:32.256Z"}
{"msg":"are you behind a proxy and if so do you have environment variables like https_proxy, HTTPS_PROXY, etc set?","username":"Dan","ts":"2020-08-26T17:37:12.058Z"}
{"msg":"wonder if adding --build there would help. I think maybe that could be a docker caching problem if not a proxy problem","username":"amundson","ts":"2020-08-26T18:53:59.412Z"}
{"msg":"i'm not behind a proxy, i can run docker compose for sawtooth-core build, so it access the repositories of the services to download the images with no problems (e.g. Step 4 of the BUILD.md)","username":"MicaelFerreira","ts":"2020-08-27T08:29:51.928Z"}
{"msg":"I figured out the problem, i removed the proxy args from the run-lint.yaml docker compose file","username":"MicaelFerreira","ts":"2020-08-27T08:47:45.672Z"}
{"msg":"I'm facing another issue now, after updating to sawtooth branch 1-3 I'm not able to do any transaction to the validator, it looks like transactions are getting ignored completely. I'm using latest version on all services, pbft-engine starts with version 1.0.3 and validator with version 1.3.1.dev1. At the rest-api the transactions POST's are successfull with an OK status. I have validator verbosity at max and I'm testing doing transaction with the intkey-tp, but there are no output, it's failing silently. Any help?","username":"MicaelFerreira","ts":"2020-08-27T13:44:36.008Z"}
{"msg":"The date for the next contributor working session is Sept 4, not tomorrow. I had the date incorrect in the working doc; sorry for any confusion.","username":"amundson","ts":"2020-08-27T14:21:59.782Z"}
{"msg":"Nevermind this, it was my fault","username":"MicaelFerreira","ts":"2020-08-28T08:35:50.978Z"}
{"msg":"Has joined the channel.","username":"Patrick-Erichsen1","ts":"2020-08-31T21:35:17.602Z","type":"uj"}
{"msg":"Reminder, the URL for tomorrow's 10am (US/Central) contributor meeting is https://us02web.zoom.us/j/89262216179","username":"amundson","ts":"2020-09-03T17:30:05.585Z"}
{"msg":"The working doc for the meeting is - https://docs.google.com/document/d/1WlF8UfoKAEydJobHWDvz-tMpWqQSTlChoFv50fHX1tM/edit","username":"amundson","ts":"2020-09-04T14:58:37.355Z"}
{"msg":"Has joined the channel.","username":"Glenn_Gluwa","ts":"2020-09-08T23:03:04.023Z","type":"uj"}
{"msg":"Has joined the channel.","username":"infrared","ts":"2020-09-10T17:45:51.953Z","type":"uj"}
{"msg":"Hi guys, I'm been having some weird issues regarding the lost of peers from the validator when for some reason there's an invalid transaction, the validator is ignored by the others (it still has the peers) and so it stops posting batches. It doesn't look like this should be the right behaviour, is it? (I'm sorry in advance i had not the time to check in the source code for this)","username":"MicaelFerreira","ts":"2020-09-11T08:55:52.740Z"}
{"msg":"Btw, i'm using branch 1-3, with pbft as consensus and a 5 node network","username":"MicaelFerreira","ts":"2020-09-11T08:56:41.935Z"}
{"msg":"Hi, I need one more reviewer on these (thanks Ryan for being the first) https://github.com/search?q=org:hyperledger+sawtooth+inclusive&type=Issues; the gist is replicating the same inclusive wording change we made in core to the other repos so they are all consistent.","username":"Dan","ts":"2020-09-11T19:19:28.781Z"}
{"msg":"No thoughts about it? Thank you","username":"MicaelFerreira","ts":"2020-09-14T15:29:19.147Z"}
{"msg":"I have another question i would like to know the implications of it, sometimes i have to update dozens to some hundreds of addresses at once in a single transaction. Is there a correct way to do such thing? Because with around 50 addresses to set, the block takes a minute or 2 to get committed, i wonder what would be the behaviour with about some hundreds of addresses to set...","username":"MicaelFerreira","ts":"2020-09-14T15:38:37.635Z"}
{"msg":"Is this even feasible at all? Setting all these addresses at once?","username":"MicaelFerreira","ts":"2020-09-14T15:39:32.229Z"}
{"msg":"you can update multiple locations in state with a single call; which SDK?","username":"amundson","ts":"2020-09-14T17:04:07.098Z"}
{"msg":"python","username":"MicaelFerreira","ts":"2020-09-14T17:15:30.262Z"}
{"msg":"that's actually a very good point that i completely forgot, thanks for the reminder!","username":"MicaelFerreira","ts":"2020-09-14T17:19:16.528Z"}
{"msg":"Actually i'm already doing that, i send an array with all the key-value into set_state()","username":"MicaelFerreira","ts":"2020-09-14T17:19:16.528Z"}
{"msg":"@MicaelFerreira PR 2331 passes linting if if it's rebased on 1-3. There were some lint fixes merged a while ago.","username":"rbuysse","ts":"2020-09-14T19:50:53.168Z"}
{"msg":"the block injector test is failing, however.","username":"rbuysse","ts":"2020-09-14T19:51:13.502Z"}
{"msg":"`validator_1                 | thread '<unnamed>' panicked at 'BatchInjectorFactory has no method 'create_injectors': PyErr { ptype: <class 'ModuleNotF\noundError'>, pvalue: Some(ModuleNotFoundError(\"No module named 'sawtooth_validator.journal.injectors'\",)), ptraceback: Some(<traceback object at 0x7f6\n55f3f6588>) }', src/journal/publisher.rs:214:14\nvalidator_1                 | note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\nvalidator_1                 | fatal runtime error: failed to initiate panic, error 5`","username":"rbuysse","ts":"2020-09-14T19:51:29.304Z"}
{"msg":"```\nvalidator_1                 | thread '<unnamed>' panicked at 'BatchInjectorFactory has no method 'create_injectors': PyErr { ptype: <class 'ModuleNotF\noundError'>, pvalue: Some(ModuleNotFoundError(\"No module named 'sawtooth_validator.journal.injectors'\",)), ptraceback: Some(<traceback object at 0x7f6\n55f3f6588>) }', src/journal/publisher.rs:214:14\nvalidator_1                 | note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\nvalidator_1                 | fatal runtime error: failed to initiate panic, error 5\n```","username":"rbuysse","ts":"2020-09-14T19:51:29.304Z"}
{"msg":"when I add an __init__.py file to `validator/sawtooth_validator/journal/injectors/`, it fails with this:","username":"rbuysse","ts":"2020-09-14T19:52:35.376Z"}
{"msg":"when I add an __init__.py file to `validator/sawtooth_validator/journal/injectors/`, devmode fails with this:","username":"rbuysse","ts":"2020-09-14T19:52:35.376Z"}
{"msg":"```\nvalidator_1                 | writing file: /etc/sawtooth/keys/validator.priv\nvalidator_1                 | writing file: /etc/sawtooth/keys/validator.pub\ndevmode_1                   | INFO  | devmode_engine_rust: | Wait time: 0\nvalidator_1                 | Generated config-genesis.batch\nsettings-tp_1               | INFO  | settings_tp:95       | Console logging level: DEBUG\nvalidator_1                 | Processing config-genesis.batch...\nvalidator_1                 | Processing config.batch...\nvalidator_1                 | Generating /var/lib/sawtooth/genesis.batch\nsettings-tp_1               | INFO  | sawtooth_sdk::proces | connecting to endpoint: tcp://validator:4004\nsettings-tp_1               | INFO  | sawtooth_sdk::proces | sending TpRegisterRequest: sawtooth_settings 1.0\nvalidator_1                 | [2020-09-14 19:34:10.127 WARNING  (unknown file)] [src/pylogger.rs: 40] Started logger at level INFO\nsettings-tp_1               | INFO  | sawtooth_sdk::proces | Message: d7a02186b57c4d00a5ce6719dd9a602a\ndevmode_1                   | INFO  | sawtooth_sdk::messag | Received Disconnect\nsettings-tp_1               | INFO  | settings_tp::handler | Setting \"sawtooth.settings.vote.authorized_keys\" changed to \"03d59fb117cf1c6d8653c27c7b09ffe5a6b08855683f4ce35bd53d6fdafe73a870\"\ndevmode_1                   | thread 'main' panicked at 'Failed to initialize: ReceiveError(\"DisconnectedError\")', src/engine.rs:72:14\ndevmode_1                   | note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\nblock-info-tp_1             | INFO  | block_info_tp:97     | Console logging level: DEBUG\nblock-info-tp_1             | INFO  | sawtooth_sdk::proces | connecting to endpoint: tcp://validator:4004\nvalidator_1                 | [2020-09-14 19:34:10.454 INFO     path] Skipping path loading from non-existent config file: /etc/sawtooth/path.toml\nsettings-tp_1               | INFO  | sawtooth_sdk::proces | TP_PROCESS_REQUEST sending TpProcessResponse: OK\nblock-info-tp_1             | INFO  | sawtooth_sdk::proces | sending TpRegisterRequest: block_info 1.0\nsettings-tp_1               | INFO  | sawtooth_sdk::proces | Message: daf132c5a0eb4459adda18660ef9b9ee\nintkey-tp-python_1          | [2020-09-14 19:34:10.516 INFO     core] register attempt: OK\nvalidator_1                 | [2020-09-14 19:34:10.455 INFO     validator] Skipping validator config loading from non-existent config file: /etc/sawtooth/validator.toml\nblock-info-tp_1             | INFO  | sawtooth_sdk::messag | Received Disconnect\nblock-info-tp_1             | DEBUG | sawtooth_sdk::messag | Exited stream\nblock-info-tp_1             | INFO  | sawtooth_sdk::proces | Trying to Reconnect\nblock-info-tp_1             | INFO  | sawtooth_sdk::proces | connecting to endpoint: tcp://validator:4004\nblock-info-tp_1             | DEBUG | zmq:489              | socket dropped\nblock-info-tp_1             | INFO  | sawtooth_sdk::proces | sending TpRegisterRequest: block_info 1.0\nvalidator_1                 | [2020-09-14 19:34:10.455 INFO     keys] Loading signing key: /etc/sawtooth/keys/validator.priv\nlatest_devmode_1 exited with code 101\n```","username":"rbuysse","ts":"2020-09-14T19:53:14.995Z"}
{"msg":"Has joined the channel.","username":"jorgeRodriguez","ts":"2020-09-15T02:10:59.404Z","type":"uj"}
{"msg":"Thanks @rbuysse for your help, PR is now ready to be reviewed. I would like some reviews now, please take a look https://github.com/hyperledger/sawtooth-core/pull/2331 reviewers","username":"MicaelFerreira","ts":"2020-09-16T13:31:49.162Z"}
{"msg":"@ltseeley it looks like raft build has been broken for the last month. Something to do with test dynamic membership\nhttps://build.sawtooth.me/job/Sawtooth-Hyperledger/job/sawtooth-raft/view/default/builds\nhttps://build.sawtooth.me/job/Sawtooth-Hyperledger/job/sawtooth-raft/job/master/563/execution/node/52/log/\nI'm sure you have bigger fish to fry, but thought I'd point it out. I have a PR blocked on this and thought I'd look for quick fixes but the membership test is not a quick read for me.","username":"Dan","ts":"2020-09-16T18:26:02.212Z"}
{"msg":"Just a question to the code owners, there are some modules in python that are not used any more right? For example the module at /journal/validation_rule_enforcer.py, i wonder what is this code doing here, because the same is implemented in rust and is actually the one being used. Please correct me if i'm wrong","username":"MicaelFerreira","ts":"2020-09-17T10:15:29.566Z"}
{"msg":"in sequence, if my previous statement is correct, the validator/tests/test_validator_rule_enforcer is testing something that is not used","username":"MicaelFerreira","ts":"2020-09-17T10:39:40.792Z"}
{"msg":"@MicaelFerreira that's correct. The components you mentioned were recently re-written in Rust. It's an ongoing effort to convert everything from Python -> Rust.","username":"ltseeley","ts":"2020-09-17T14:05:55.750Z"}
{"msg":"@Dan I'll add that to my backlog :slightly_smiling_face:","username":"ltseeley","ts":"2020-09-17T14:06:59.932Z"}
{"msg":"Great, I just mentioned this because the sawtooth-core architecture is not easy to read and when someone is not entirely into the architecture (like me) we start to confuse things up =)","username":"MicaelFerreira","ts":"2020-09-17T14:34:13.868Z"}
{"msg":"That's definitely something we're working on improving!","username":"ltseeley","ts":"2020-09-17T14:37:59.149Z"}
{"msg":"Can someone just clarify me something about the integration tests: I have only one test being done, and after run pose it shows \"Ran 1 test in 0.465s  ok\", but the coverage is not 100%, it has \"135 Stmts and 36 Miss\", what are those?","username":"MicaelFerreira","ts":"2020-09-18T13:31:41.593Z"}
{"msg":"https://github.com/hyperledger/sawtooth-core/pull/2331 re-pushed with integration tests, reviewers please take a look","username":"MicaelFerreira","ts":"2020-09-21T13:10:31.522Z"}
{"msg":"Got this error at the rest-api:\n```[2020-09-22 17:24:00.064 DEBUG    route_handlers] Sending CLIENT_BATCH_STATUS_REQUEST request to validator\n[2020-09-22 17:24:02.227 DEBUG    state_delta_subscription_handler] Received event a23ebb2a: 3 changes\n[2020-09-22 17:24:02.229 DEBUG    state_delta_subscription_handler] Updating 3 subscribers\n[2020-09-22 17:24:02.230 WARNING  selector_events] socket.send() raised exception.\n[2020-09-22 17:24:02.246 DEBUG    route_handlers] Received CLIENT_BATCH_STATUS_RESPONSE response from validator with status OK\n[2020-09-22 17:24:02.256 INFO     helpers] GET /batch_statuses?id=4c9d375a7a189e1c97fea09ddcb59c4a8e7b6aadec57a488da65e8664037ccf013e6da00cb7482f9219055aec7b7033020e612dbea972d71e73e0637694093e2&wait=3 HTTP/1.1: 200 status, 610 size, in 2.192721 s\n[2020-09-22 17:24:12.978 ERROR    web_protocol] Error handling request\nTraceback (most recent call last):\n  File \"/usr/lib/python3/dist-packages/aiohttp/web_protocol.py\", line 231, in data_received\n    messages, upgraded, tail = self._request_parser.feed_data(data)\n  File \"aiohttp/_http_parser.pyx\", line 295, in aiohttp._http_parser.HttpParser.feed_data\naiohttp.http_exceptions.BadStatusLine: invalid HTTP method\n```","username":"MicaelFerreira","ts":"2020-09-22T17:26:37.956Z"}
{"msg":"rest-api recovered","username":"MicaelFerreira","ts":"2020-09-22T17:30:02.625Z"}
{"msg":"rest-api recovered by itself","username":"MicaelFerreira","ts":"2020-09-22T17:30:02.625Z"}
{"msg":"^ This is a pending ask from the community to port the Rest API component to the Rust language. @MicaelFerreira","username":"arsulegai","ts":"2020-09-27T12:21:09.692Z"}
{"msg":"Need more reviews on this PR, https://github.com/hyperledger/sawtooth-core/pull/2331, please take a look","username":"MicaelFerreira","ts":"2020-09-28T09:10:15.830Z"}
{"msg":"Hey reviewers, i had to fix a test running twice pointed out by agunde on the PR https://github.com/hyperledger/sawtooth-core/pull/2331, please re-check it","username":"MicaelFerreira","ts":"2020-09-30T16:57:21.094Z"}
{"msg":"Hey reviewers, i had to fix a test running twice pointed out by @agunde on the PR https://github.com/hyperledger/sawtooth-core/pull/2331, please re-check it","username":"MicaelFerreira","ts":"2020-09-30T16:57:21.094Z"}
{"msg":"Reminder, the contributor meeting is at 10am US/Central - in about 45 minutes -- the zoom URL is https://us02web.zoom.us/j/89262216179?pwd=UzFyK2t6MmxGTkxwR2dydnBkaUtDQT09 and agenda is at https://docs.google.com/document/d/1WlF8UfoKAEydJobHWDvz-tMpWqQSTlChoFv50fHX1tM/edit","username":"amundson","ts":"2020-10-02T14:16:10.002Z"}
{"msg":"Hey, @amundson I’ve been in the waiting room for a while now","username":"wkatsak","ts":"2020-10-02T14:26:44.509Z"}
{"msg":"Is the meeting going on?","username":"wkatsak","ts":"2020-10-02T14:26:49.523Z"}
{"msg":"Ack, never mind. Timezone difference","username":"wkatsak","ts":"2020-10-02T14:27:12.759Z"}
{"msg":"Meeting invite is updated in the Hyperledger's public calendar https://us02web.zoom.us/j/89262216179?pwd=UzFyK2t6MmxGTkxwR2dydnBkaUtDQT09","username":"arsulegai","ts":"2020-10-02T15:19:16.761Z"}
{"msg":"Hi, what is this warning at the catching up process? Non-deterministic issue?\n```[2020-10-06 16:34:17.199 WARNING  (unknown file)] [src/journal/block_validator.rs: 284] Error during block validation: BlockValidationError(\"During validate_on_chain_rules, error creating settings view: NotFound(\\\"be3c5582f7bad9229c0809a202ecdff72d7142e00a5201c44ce5ade0ad34684c\\\")\")\n[2020-10-06 16:34:17.365 WARNING  (unknown file)] [src/journal/block_validator.rs: 284] Error during block validation: BlockValidationError(\"During validate_on_chain_rules, error creating settings view: NotFound(\\\"9a4d1201b6373887c04e2d251856180cd8e153378f4dc3d28d3478c925030b72\\\")\")\n```","username":"MicaelFerreira","ts":"2020-10-06T16:35:36.759Z"}
{"msg":"Has left the channel.","username":"danintel","ts":"2020-10-06T18:53:49.809Z","type":"ul"}
{"msg":"@MicaelFerreira could this be the same issue that was discussed few days ago?","username":"arsulegai","ts":"2020-10-12T17:03:36.826Z"}
{"msg":"Has joined the channel.","username":"csunitha","ts":"2020-10-22T10:05:29.662Z","type":"uj"}
{"msg":"Hello everyone, my name is Kent!  Arun has asked me to markdown something from the FAQ folder and I have chosen consensus.rst as my starting point.  I am also coordinating with Mr Jin in China and I will translate some/all the docs into Chinese.","username":"kenty","ts":"2020-10-29T07:49:59.777Z"}
{"msg":"Hello everyone, my name is Kent!  Arun has asked me to markdown something from the FAQ folder and I have chosen consensus.rst as my starting point.  I am also coordinating with Mr Jin in China and I will translate some/all the docs into Chinese.\nhttps://github.com/hyperledger/sawtooth-docs/blob/refresh/faq/consensus.rst","username":"kenty","ts":"2020-10-29T07:49:59.777Z"}
{"msg":"Hello everyone, my name is Kent!  Arun has asked me to markdown something from the FAQ folder and I have chosen consensus.rst as my starting point.  I am also coordinating with Mr Jin in China and I will translate some/all of the docs into Chinese.\nhttps://github.com/hyperledger/sawtooth-docs/blob/refresh/faq/consensus.rst","username":"kenty","ts":"2020-10-29T07:49:59.777Z"}
{"msg":"Reminder, there is a contributor meeting tomorrow at 10am US/Central -- the zoom is https://us02web.zoom.us/j/89262216179?pwd=UzFyK2t6MmxGTkxwR2dydnBkaUtDQT09 and agenda is at https://docs.google.com/document/d/1WlF8UfoKAEydJobHWDvz-tMpWqQSTlChoFv50fHX1tM/edit","username":"amundson","ts":"2020-10-29T19:27:03.061Z"}
{"msg":"Has joined the channel.","username":"SimonCritchley","ts":"2020-10-31T12:19:54.863Z","type":"uj"}
{"msg":"@amundson having a separate branch for language translation makes sense to start with. Let's have @kenty and Mr Jin raise the current translation they have to the branch.\n\nAlternate could be to have a hyperledger-labs project and I am happy to sponsor it. Including help in technical matters if any for build and test. Note that other projects have followed this approach.","username":"arsulegai","ts":"2020-11-01T15:01:02.853Z"}
{"msg":"Has joined the channel.","username":"crypto_beep","ts":"2020-11-04T17:02:37.643Z","type":"uj"}
{"msg":"Has joined the channel.","username":"omerporze","ts":"2020-11-09T19:38:24.686Z","type":"uj"}
{"msg":"Has joined the channel.","username":"Vikash2601","ts":"2020-11-10T04:44:03.017Z","type":"uj"}
{"msg":"the  validator on one of the nodes crashed today (after being up for ~140 days), the only thing we can see is an exception a few seconds before it crashed \"Exception in callback _AsyncSocket._handle_send()\nhandle: <Handle _AsyncSocket._handle_send()>\nTraceback (most recent call last):\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/future.py\", line 280, in _handle_send\n    f.set_result(result)\n  File \"/usr/lib/python3.5/asyncio/futures.py\", line 332, in set_result\n    self._schedule_callbacks()\n  File \"/usr/lib/python3.5/asyncio/futures.py\", line 236, in _schedule_callbacks\n    callbacks = self._callbacks[:]\nAttributeError: 'Future' object has no attribute '_callbacks'\".    It crashed a couple of seconds after, any ideas on why this might have happened? we are on 1.1.15","username":"RajaramKannan","ts":"2020-11-18T03:15:20.198Z"}
{"msg":"Hi Greetings, I didn't find any Commands to list all Validators Nodes and list all Genesis Nodes in doc or wiki how to Hyperledger Sawtooth v1.2.4 in Docker approach. could you guys please help me out on this.Thanks!","username":"crypto_beep","ts":"2020-11-18T15:44:21.864Z"}
{"msg":"Anyone here that can help me setup Seth with more than 1 validator?","username":"omerporze","ts":"2020-11-19T20:53:45.797Z"}
{"msg":"Hi, is there anyone here that can help me setup Seth with more than 1 validator?","username":"omerporze","ts":"2020-11-19T20:53:45.797Z"}
{"msg":"Do we have Sawtooth Core Working Session call today?","username":"arsulegai","ts":"2020-11-27T16:01:21.956Z"}
{"msg":"Hi, i had an error at the rest-api that i never saw before, restarting the network solved, but i wonder what could cause it\n```[2020-12-04 14:38:33.072 DEBUG    route_handlers] Sending CLIENT_BLOCK_LIST_REQUEST request to validator\n[2020-12-04 14:38:33.462 ERROR    state_delta_subscription_handler] Unable to fetch latest block id\n[2020-12-04 14:38:33.462 DEBUG    route_handlers] Received CLIENT_BLOCK_LIST_RESPONSE response from validator with status NOT_READY\n[2020-12-04 14:38:33.463 INFO     helpers] GET /blocks?limit=1 HTTP/1.1: 503 status, 385 size, in 0.391587 s\n[2020-12-04 14:38:33.464 DEBUG    state_delta_subscription_handler] Starting subscriber from \n[2020-12-04 14:38:33.465 ERROR    state_delta_subscription_handler] unable to subscribe!\n[2020-12-04 14:38:33.465 DEBUG    state_delta_subscription_handler] Sending initial most recent event to new subscriber\n[2020-12-04 14:38:33.465 DEBUG    state_delta_subscription_handler] Subscribing to state delta events\n[2020-12-04 14:38:58.215 DEBUG    state_delta_subscription_handler] Sending initial most recent event to new subscriber\n```","username":"MicaelFerreira","ts":"2020-12-04T15:17:41.408Z"}
{"msg":"Hello everyone. We at Taekion have discovered a failure mode in Sawtooth/PBFT that persists to the latest release (1.2.6). The application that we are developing has a pattern of a stream of transactions. Each of many particular contexts will each have their own stream. Within a stream of transactions, each transaction will be explicitly declared as dependent on the transaction before it.  What happens in our testing is that eventually, the cluster will lock up hard, where a transaction will get stuck in PENDING, and all subsequent transactions will either stay pending or get explicitly rejected as missing a dependency. The cluster can be restarted, but anything that was in pending will be lost, and we will have to resubmit them. The big issue is that we can make this happen quite reliably with our application. We have been chasing this for about a month internally.","username":"wkatsak","ts":"2020-12-14T18:53:38.866Z"}
{"msg":"When it is stuck, we cannot even resubmit the stuck transaction, because it still shows as PENDING, and thus the system will not take it as a resubmit.","username":"wkatsak","ts":"2020-12-14T18:54:20.027Z"}
{"msg":"I've managed to build a tester that replicates the issue WITHOUT any of our proprietary app. My tester constructs a series of intkey transactions, with dependencies between each, and submits them in batchlists, with one transactions per batch.","username":"wkatsak","ts":"2020-12-14T18:55:38.197Z"}
{"msg":"I've just verified that I can replicate the issue as I said, with v1.2.6. My testing environment is a docker-compose environment on my workstation with 5 validators.","username":"wkatsak","ts":"2020-12-14T18:56:21.530Z"}
{"msg":"The testing code is at https://github.com/taekion-org/Sawtooth-intkey-stress-test. You will want to run this tool in \"sync\" mode.","username":"wkatsak","ts":"2020-12-14T18:57:40.943Z"}
{"msg":"I also have a docker published at https://hub.docker.com/repository/docker/taekion/intkey-stress-test","username":"wkatsak","ts":"2020-12-14T18:57:54.358Z"}
{"msg":"@amundson @jamesbarry @kodonnel","username":"wkatsak","ts":"2020-12-14T18:58:50.920Z"}
{"msg":"Just a followup. On my workstation, I run the test as follows: `intkey-stress-test sync --max_submit 250 --max_pending 1000`.","username":"wkatsak","ts":"2020-12-14T21:14:47.696Z"}
{"msg":"","username":"wkatsak","ts":"2020-12-14T21:15:36.886Z","attachments":[{"type":"file","title":"wkatsak - Mon Dec 14 2020 16:15:26 GMT-0500 (Eastern Standard Time).txt","title_link":"/file-upload/tKFcmsHWFYHjzxvEA/wkatsak%20-%20Mon%20Dec%2014%202020%2016:15:26%20GMT-0500%20(Eastern%20Standard%20Time).txt","url":"/file-upload/tKFcmsHWFYHjzxvEA/wkatsak%20-%20Mon%20Dec%2014%202020%2016:15:26%20GMT-0500%20(Eastern%20Standard%20Time).txt","remote":false,"fileId":"tKFcmsHWFYHjzxvEA","fileName":"wkatsak - Mon Dec 14 2020 16:15:26 GMT-0500 (Eastern Standard Time).txt"}]}
{"msg":"","username":"wkatsak","ts":"2020-12-14T21:15:36.886Z","attachments":[{"type":"file","title":"wkatsak - Mon Dec 14 2020 16:15:26 GMT-0500 (Eastern Standard Time).txt","title_link":"/file-upload/tKFcmsHWFYHjzxvEA/wkatsak%20-%20Mon%20Dec%2014%202020%2016:15:26%20GMT-0500%20(Eastern%20Standard%20Time).txt","url":"/file-upload/tKFcmsHWFYHjzxvEA/wkatsak%20-%20Mon%20Dec%2014%202020%2016:15:26%20GMT-0500%20(Eastern%20Standard%20Time).txt","remote":false,"fileId":"tKFcmsHWFYHjzxvEA","fileName":"wkatsak - Mon Dec 14 2020 16:15:26 GMT-0500 (Eastern Standard Time).txt"}]}
{"msg":"@wkatsak cool that you have it reduced to a repeatable test case. how long do you need to run the tool to get the error condition?","username":"amundson","ts":"2020-12-15T17:31:20.472Z"}
{"msg":"@amundson It varies. Usually within a few hours it will get stuck.  Sometimes, it is a matter of minutes.","username":"wkatsak","ts":"2020-12-15T17:59:42.361Z"}
{"msg":"You can recover the cluster by restarting it, but it seems to get stuck faster after its been stuck once.","username":"wkatsak","ts":"2020-12-15T18:00:00.857Z"}
{"msg":"That part is only an impression though, I don't have hard data.","username":"wkatsak","ts":"2020-12-15T18:00:14.752Z"}
{"msg":"When it is stuck, the throttling mechanism will be triggered, and no batches can come in.","username":"wkatsak","ts":"2020-12-15T18:01:05.785Z"}
{"msg":"At least on the validator that I am submitting through.","username":"wkatsak","ts":"2020-12-15T18:01:45.848Z"}
{"msg":"I am getting some fun reading the Sawtooth LMDB files in Java, where can I get a description of the data transformation to/from lmdb.rs layer?","username":"LeonardoCarvalho","ts":"2020-12-26T19:03:49.100Z"}
{"msg":"Has joined the channel.","username":"erivlis","ts":"2021-01-13T00:17:57.561Z","type":"uj"}
{"msg":"Hi reminder that the next Sawtooth Contributor Session is tomorrow at 10am US/Central. The zoom link is https://us02web.zoom.us/j/89262216179?pwd=UzFyK2t6MmxGTkxwR2dydnBkaUtDQT09 and the agenda/working doc is at https://docs.google.com/document/d/1WlF8UfoKAEydJobHWDvz-tMpWqQSTlChoFv50fHX1tM/edit#","username":"amundson","ts":"2021-01-21T18:02:34.170Z"}
{"msg":"@kenty please join this call. We can discuss over the PR you raised.","username":"arsulegai","ts":"2021-01-21T18:43:35.902Z"}
{"msg":"Thanks Arun, I have received some feedback on my markdown conversion and will be cleaning my code ASAP.  Catch you all at the meeting :)","username":"kenty","ts":"2021-01-22T11:42:06.621Z"}
{"msg":"@jsmitchell I didn't understand the topic of determinism in the meeting. Maybe it was me having sleepy eyes on a Friday night. Can you please give me a reference to it on other projects?","username":"arsulegai","ts":"2021-01-22T17:27:45.799Z"}
{"msg":"basically, if you are running inside the wasm container, it is fairly easy to get some level of determinism because you are naturally limited by what you can do. you can't do non-deterministic things like access external resources. however, to be fully deterministic, you need to solve the halting problem as well -- which means you have to guarantee that the execution of the smart contract will end. ethereum's approach to this is to limit the number instructions that can be executed based on gas (each instruction takes some gas, there is a limit to the amount of gas available).","username":"amundson","ts":"2021-01-22T17:55:36.733Z"}
{"msg":"if you ignore the halting problem, sabre already does a pretty good job in this area when compared to TPs because TPs can \"do anything\" including accessing external resources (that might change) or random number generation.","username":"amundson","ts":"2021-01-22T17:56:56.377Z"}
{"msg":"Got it. Thanks for the clarification.","username":"arsulegai","ts":"2021-01-22T18:02:53.119Z"}
{"msg":"Reminder that the next Sawtooth Contributor Session is tomorrow at 10am US/Central. The zoom link is https://us02web.zoom.us/j/89262216179?pwd=UzFyK2t6MmxGTkxwR2dydnBkaUtDQT09 and the agenda/working doc is at https://docs.google.com/document/d/1WlF8UfoKAEydJobHWDvz-tMpWqQSTlChoFv50fHX1tM/edit# -- feel free to add agenda items if you have them","username":"amundson","ts":"2021-02-18T16:44:35.168Z"}
{"msg":"Thanks @amundson I'll be on the call.   We have been running around like crazy here with product work, but we are still chasing the Sawtooth bug that I reported a month or two ago.","username":"wkatsak","ts":"2021-02-18T23:22:16.996Z"}
{"msg":"Just to notate it before the discussion tomorrow, it usually gets triggered when the system is presented with a high volume of DEPENDENT transactions, e.g. a collection of transaction chains where each transaction has an explicit dependency on the transaction before.","username":"wkatsak","ts":"2021-02-18T23:23:34.366Z"}
{"msg":"We see it running PBFT. When it happens, usually it is preceded by the validator returning an error to a call from PBFT, at which point PBFT drifts off the rails.","username":"wkatsak","ts":"2021-02-18T23:25:00.130Z"}
{"msg":"The end result is that transactions stop.","username":"wkatsak","ts":"2021-02-18T23:25:09.165Z"}
{"msg":"Has joined the channel.","username":"romanmoz","ts":"2021-02-18T23:38:35.864Z","type":"uj"}
{"msg":"@wkatsak is the client re-submitting transactions if they get dropped?","username":"amundson","ts":"2021-02-19T14:36:18.384Z"}
{"msg":"Waiting for the host to start meeting","username":"arsulegai","ts":"2021-02-19T15:11:31.725Z"}
{"msg":"@arsulegai the meeting is not for another hour","username":"agunde","ts":"2021-02-19T15:12:30.534Z"}
{"msg":"Oops! Right, with daylight savings it'll be at this time","username":"arsulegai","ts":"2021-02-19T15:13:28.424Z"}
{"msg":"For mentorship program, submit proposals here https://wiki.hyperledger.org/display/INTERN/Cactus-samples+-+Business+Logic+Plugins+for+Hyperledger+Cactus","username":"arsulegai","ts":"2021-02-19T17:15:45.020Z"}
{"msg":"If you are interested in giving a talk on Sawtooth for the Hyperledger Global Forum, I have set up a Slack Forum off of our Slack. Please send james@taekion.com your email and I will add you.  Thanks!","username":"jmbarry","ts":"2021-02-19T17:28:19.942Z"}
{"msg":"can't we keep that discussion here?","username":"amundson","ts":"2021-02-19T17:29:39.645Z"}
{"msg":"Sure if you would like to we certainly can.","username":"jmbarry","ts":"2021-02-19T17:30:28.018Z"}
{"msg":"I think there should be a Topic on Sawtooth 1.2 - how to use, Sawtooth Roadmap, Kent and his Sawtooth on the Raspberry Pi, Perhaps some commercial uses, Transact, Grid and others?","username":"jmbarry","ts":"2021-02-19T17:31:48.123Z"}
{"msg":"I guess there should be talks like \"Setup your first Sawtooth app in 5 steps\", \"Top 5 concepts that stands out Sawtooth from the rest\", \"Cool projects built on Sawtooth\", \"Best of design patterns for Sawtooth\" etc.","username":"arsulegai","ts":"2021-02-19T17:37:25.177Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=CoP9JaaGmsCejRZct) This could be an avenue for experimentation, in addition to getting things built from scratch in labs. I like the idea Shawn proposed, we should put it in.","username":"arsulegai","ts":"2021-02-19T17:42:31.711Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=CoP9JaaGmsCejRZct","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=CoP9JaaGmsCejRZct","remote":true,"fileId":null,"fileName":null}]}
{"msg":"I am interested in replace the Validator Interconnect with a Java component, where can I find documentation or code on the communication with the other components?","username":"LeonardoCarvalho","ts":"2021-02-20T12:28:17.550Z"}
{"msg":"If you are re-implementing 1.x, then the code/protobuf in the 1-2 or 1-3 branches. if you are targeting 2.x compat. then libsplinter's transport module.","username":"amundson","ts":"2021-02-22T18:07:22.776Z"}
{"msg":"cool!","username":"LeonardoCarvalho","ts":"2021-02-23T10:54:18.493Z"}
{"msg":"Has joined the channel.","username":"gilescope","ts":"2021-02-25T17:27:04.566Z","type":"uj"}
{"msg":"@jmbarry re:HGF do you know if there is still a fee this year like past years? I just remembered why we've never presented there.","username":"amundson","ts":"2021-02-26T18:07:15.715Z"}
{"msg":"@amundson fee is for attending. This year it shows to be $50 per attendee. Speakers, program committee, sponsors (limited seats) are given free coupon codes.","username":"arsulegai","ts":"2021-02-27T07:27:24.802Z"}
{"msg":"I am getting this message on the rust validator devmode  0.1 : \"Removed 5 incomplete batches from the schedule\", how can I track the cause for that? My TP got the TP_STATE_SET_RESPONSE for the 5 SET operations, but the message appears anyway","username":"LeonardoCarvalho","ts":"2021-03-01T11:28:27.590Z"}
{"msg":"docker images from 1.2.6","username":"LeonardoCarvalho","ts":"2021-03-01T11:31:22.176Z"}
{"msg":"I assume that message is printing at the time of creating candidate block. Incomplete batches for that ask by consensus engine (that round of consensus) is removed. Maybe consensus engine asked to finalize the blocks before these were executed. Nothing to worry about, do you see log traces that indicate this flow?","username":"arsulegai","ts":"2021-03-01T14:56:04.566Z"}
{"msg":"I assume that message is printed at the time of creating candidate block. Incomplete batches for that ask by consensus engine (that round of consensus) is removed. Maybe consensus engine asked to finalize the block before these batches were executed. Nothing to worry about, do you see log traces that indicate this flow?","username":"arsulegai","ts":"2021-03-01T14:56:04.566Z"}
{"msg":"* printing -> printed","username":"arsulegai","ts":"2021-03-01T14:56:26.967Z"}
{"msg":"Today I tried again, and:\nst-validator_1_2_6 | [2021-03-03 11:30:24.679 DEBUG    scheduler_serial] Removed 5 incomplete batches from the schedule\n<....>\n5 minutes later\n<...>\nst-devmode-engine-rust_1_2_4 | thread 'main' panicked at 'Failed to summarize block: ReceiveError(\"TimeoutError\")', src/engine.rs:87:23\nst-devmode-engine-rust_1_2_4 | stack backtrace:\nst-devmode-engine-rust_1_2_4 |    0:     0x557c338f3205 - <unknown>\nst-devmode-engine-rust_1_2_4 |    1:     0x557c339135ec - <unknown>\nst-devmode-engine-rust_1_2_4 |    2:     0x557c338f0a13 - <unknown>\nst-devmode-engine-rust_1_2_4 |    3:     0x557c338f5980 - <unknown>\nst-devmode-engine-rust_1_2_4 |    4:     0x557c338f56cc - <unknown>\nst-devmode-engine-rust_1_2_4 |    5:     0x557c338f5fb7 - <unknown>\nst-devmode-engine-rust_1_2_4 |    6:     0x557c338f5bbb - <unknown>\nst-devmode-engine-rust_1_2_4 |    7:     0x557c339129f1 - <unknown>\nst-devmode-engine-rust_1_2_4 |    8:     0x557c33912813 - <unknown>\nst-devmode-engine-rust_1_2_4 |    9:     0x557c33817d2f - <unknown>\nst-devmode-engine-rust_1_2_4 |   10:     0x557c3381dc2b - <unknown>\nst-devmode-engine-rust_1_2_4 |   11:     0x557c3382b2e6 - <unknown>\nst-devmode-engine-rust_1_2_4 |   12:     0x557c3381cda3 - <unknown>\nst-devmode-engine-rust_1_2_4 |   13:     0x557c338f6388 - <unknown>\nst-devmode-engine-rust_1_2_4 |   14:     0x557c3382b7c2 - <unknown>\nst-devmode-engine-rust_1_2_4 |   15:     0x7f109f5f9b97 - __libc_start_main\nst-devmode-engine-rust_1_2_4 |   16:     0x557c3381223a - <unknown>\nst-devmode-engine-rust_1_2_4 |   17:                0x0 - <unknown>\nst-devmode-engine-rust_1_2_4 exited with code 101","username":"LeonardoCarvalho","ts":"2021-03-03T11:37:49.847Z"}
{"msg":"even with  RUST_BACKTRACE=full, no extra information","username":"LeonardoCarvalho","ts":"2021-03-03T11:38:43.835Z"}
{"msg":"I have only one node of each type, can be that an issue?","username":"LeonardoCarvalho","ts":"2021-03-03T11:40:08.556Z"}
{"msg":"@LeonardoCarvalho try building in non-release mode (remove --release from cargo) to get a better backtrace","username":"amundson","ts":"2021-03-05T14:34:19.757Z"}
{"msg":"","username":"LeonardoCarvalho","ts":"2021-03-09T10:19:57.944Z","attachments":[{"type":"file","title":"Clipboard - March 9, 2021 7:19 AM","title_link":"/file-upload/yMRJT2Wi7z76BQSET/Clipboard%20-%20March%209,%202021%207:19%20AM","image_url":"/file-upload/yMRJT2Wi7z76BQSET/Clipboard%20-%20March%209,%202021%207:19%20AM","image_type":"image/png","image_size":22404,"url":"/file-upload/yMRJT2Wi7z76BQSET/Clipboard%20-%20March%209,%202021%207:19%20AM","remote":false,"fileId":"yMRJT2Wi7z76BQSET","fileName":"Clipboard - March 9, 2021 7:19 AM"}]}
{"msg":"I've tried, but I am getting this failure:","username":"LeonardoCarvalho","ts":"2021-03-09T10:20:02.415Z"}
{"msg":"@jmbarry @amundson we will have to submit abstract by 12th","username":"arsulegai","ts":"2021-03-09T12:27:43.471Z"}
{"msg":"@LeonardoCarvalho I think that's the error when protobuf is missing (required in build.rs)","username":"amundson","ts":"2021-03-09T14:55:55.697Z"}
{"msg":"hm, ok, so how do I build that ?","username":"LeonardoCarvalho","ts":"2021-03-10T11:29:53.294Z"}
{"msg":"I really miss a manual or howto...","username":"LeonardoCarvalho","ts":"2021-03-10T11:29:59.499Z"}
{"msg":"Allas, as a constructive criticism, I think that the creation of language-agnostic documentation would help a lot Sawtooth's adoption in some companies.","username":"LeonardoCarvalho","ts":"2021-03-10T12:02:19.042Z"}
{"msg":"Has joined the channel.","username":"Helen_Garneau","ts":"2021-03-10T14:56:10.319Z","type":"uj"}
{"msg":"Hello Sawtooth Developers! Reminder to please join the DevRel Marketing Committee call at 9am PT today. Take a look at the agenda and add items if you'd like here: https://wiki.hyperledger.org/x/Nqx6Ag (note new Zoom info)","username":"Helen_Garneau","ts":"2021-03-10T14:56:45.547Z"}
{"msg":"Has anyone submitted sessions for Sawtooth?  ANything that we can chain together for a \"Sawtooth Track?\"  My company is two of us coding at this point in time, and we have been stymied at getting any topics that make sense for this conference.","username":"jmbarry","ts":"2021-03-12T21:40:46.577Z"}
{"msg":"@arsulegai had put a lot of suggestions for topics for the Hyperledger Global Forum https://www.hyperledger.org/event/hyperledger-global-forum-2021 Topic on\n*  Sawtooth 1.2 - how to use\n* Sawtooth Roadmap, Kent and his team \n* Sawtooth on the Raspberry Pi\n* Sawtooth commercial uses\n* Transact, \n* Grid\n* Setup your first Sawtooth app in 5 steps\n* Top 5 concepts that stands out Sawtooth from the rest\n* Transaction processor use cases\n* Cool projects built on Sawtooth\n* Best of design patterns for Sawtooth\n* Real life use case of setting up the Tel Aviv Stock exchange on Sawtooth. Duncan from Blockchain Technology Partners","username":"jmbarry","ts":"2021-03-12T21:43:08.139Z"}
{"msg":"@amundson is Bitwise going to propose any sessions with an abstract?","username":"jmbarry","ts":"2021-03-12T21:43:50.696Z"}
{"msg":"Cargill is planning to submit a talk on Grid","username":"amundson","ts":"2021-03-12T21:52:21.932Z"}
{"msg":"OK any others?  You guys have the real Sawtooth expertise....","username":"jmbarry","ts":"2021-03-12T21:55:59.202Z"}
{"msg":"I think the Grid one will be good to showcase Sawtooth/Transact/Splinter tech but through more of a business lens.","username":"amundson","ts":"2021-03-12T22:00:30.895Z"}
{"msg":"I was considering a Sawtooth 2 one but I haven't had an opportunity to write up a submission and not even enough time to successfully track down the template, etc.","username":"amundson","ts":"2021-03-12T22:01:48.873Z"}
{"msg":"@amundson the templlate is here https://events.linuxfoundation.org/hyperledger-global-forum/program/cfp/","username":"jmbarry","ts":"2021-03-12T22:16:44.048Z"}
{"msg":"am curious why cpython was chosen over pyo3? was that because it was simpler and python won't be in the picture long term?","username":"gilescope","ts":"2021-03-15T18:19:23.173Z"}
{"msg":"At the time, pyo3 only compiled on Rust nightly, and we have set a rule that Sawtooth must compile on stable","username":"pschwarz","ts":"2021-03-15T19:11:44.598Z"}
{"msg":"ah ok. took a little work to get things working on stable but they got there last year. Am amazed how much progress they achieved last year to be honest.","username":"gilescope","ts":"2021-03-16T10:50:45.995Z"}
{"msg":"I am guessing you're not after a pyo3 switchover pr.","username":"gilescope","ts":"2021-03-16T10:52:08.836Z"}
{"msg":"ok, after some painful tcpdumping and debugging, I figured out that a couple merges I've entangled the context ids for the messages. Shouldn't the Validator valdiate context ids and send back a error message?","username":"LeonardoCarvalho","ts":"2021-03-18T11:13:27.956Z"}
{"msg":"[ ](https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=rLZSoT6ru8Q68Rjyg) I was away from RocketChat for a while, saw this now. Tomorrow is the last day for submission. Did you submit a talk?","username":"arsulegai","ts":"2021-03-18T14:28:11.859Z","attachments":[{"message_link":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=rLZSoT6ru8Q68Rjyg","url":"https://chat.hyperledger.org/channel/sawtooth-core-dev?msg=rLZSoT6ru8Q68Rjyg","remote":true,"fileId":null,"fileName":null}]}
{"msg":"I have not submitted one, I'm not sure about others. TBH, simply too stressful for me to present in a semi-public forum. Happy to support others that are more comfortable, including on content development.","username":"amundson","ts":"2021-03-18T14:36:09.426Z"}
{"msg":"Reminder that the next Sawtooth Contributor Session is tomorrow at 10am US/Central. The zoom link is https://us02web.zoom.us/j/89262216179?pwd=UzFyK2t6MmxGTkxwR2dydnBkaUtDQT09 and the agenda/working doc is at https://docs.google.com/document/d/1WlF8UfoKAEydJobHWDvz-tMpWqQSTlChoFv50fHX1tM/edit# -- feel free to add agenda items if you have them","username":"amundson","ts":"2021-03-18T20:46:45.014Z"}
{"msg":"ok, managed to get a fully functional and stable transaction processor, now I will apply the Saint Exupéry Refactoring to remove the noise from going in and out of the coding... :)","username":"LeonardoCarvalho","ts":"2021-03-31T11:44:15.202Z"}
{"msg":"Reminder that the next Sawtooth Contributor Session is tomorrow at 10am US/Central. The zoom link is https://us02web.zoom.us/j/89262216179?pwd=UzFyK2t6MmxGTkxwR2dydnBkaUtDQT09 and the agenda/working doc is at https://docs.google.com/document/d/1WlF8UfoKAEydJobHWDvz-tMpWqQSTlChoFv50fHX1tM/edit# -- feel free to add agenda items if you have them","username":"amundson","ts":"2021-04-15T13:57:11.136Z"}
{"msg":"Thanks all for the conversation - this is the book I referenced - https://www.springer.com/gp/book/9783642152597","username":"amundson","ts":"2021-04-16T16:00:16.835Z"}
{"msg":"^ @jmbarry @wkatsak Shawn did a walkthrough of consensus library proposal.","username":"arsulegai","ts":"2021-04-16T16:01:50.605Z"}
{"msg":"I was looking over the validator rust code in main. Is it fair to say that at the moment that everything has a rust interface but that that interface calls over to the python module? (I didn't see any gossip or zmq related depenencies in Cargo.toml that got me wondering).","username":"gilescope","ts":"2021-04-22T16:59:27.802Z"}
{"msg":"@gilescope the general direction we are taking is to move all the functionality to libsawtooth, libtransact, libsplinter, etc. and the validator will just pull all of that together. python is there for components we haven't worked through yet. so for example, since libsplinter will provide the networking layer but isn't currently being used, the network stuff is largely still in python at the moment","username":"amundson","ts":"2021-04-30T17:45:14.661Z"}
{"msg":"Has joined the channel.","username":"lucgerrits","ts":"2021-05-05T08:05:27.454Z","type":"uj"}
{"msg":"Has joined the channel.","username":"pushkarb","ts":"2021-05-26T07:48:06.537Z","type":"uj"}
{"msg":"anyone have a positive or negative experience with grpc auth features? https://grpc.io/docs/guides/auth/","username":"Dan","ts":"2021-05-26T14:37:18.134Z"}
{"msg":"I need to modify the intkey transaction family for specific purpose. But I am unable to find the code for intkey in the sawtooth-core repository on github.","username":"pushkarb","ts":"2021-05-30T15:39:27.572Z"}
{"msg":"@Dan no, but grpc generally we found performed exceptionally poorly in python, which is why it wasn't used initially","username":"amundson","ts":"2021-06-01T16:17:22.102Z"}
{"msg":"Hello everyone, I need some help. I am trying to make changes to the intkey transaction family. I have cloned the sawtooth python sdk. The problem I am facing is that if I make changes to the intkey code present in `\\sawtooth-sdk-python\\sawtooth-sdk-python-main\\examples\\intkey_python\\sawtooth_intkey\\client_cli`, the changes aren't reflecting in the binaries that I am building using docker. What am I missing?","username":"pushkarb","ts":"2021-06-11T11:09:20.940Z"}
{"msg":"Has left the channel.","username":"nage","ts":"2021-06-21T17:29:53.165Z","type":"ul"}
{"msg":"Has joined the channel.","username":"AbhijeetBH 2","ts":"2021-07-03T12:51:32.296Z","type":"uj"}
{"msg":"Hello. Need help.\nOur Production Node stopped working with following error on 4 out of 10 nodes\n`[2021-07-03 12:15:34.266 INFO (unknown file)] [src/journal/block_validator.rs: 265] Block ea5fcd1fdd38365b47881c2511c325d6690adca26d4ba63ffad35a6a7b61bdff27d74c7d77716112d38ffa2fba6fbf9984f81d36721f05aa79ce99bfcb753c33 passed validation\n[2021-07-03 12:15:34.289 INFO ffi] [src/journal/chain.rs: 557] Failed block Block(id: ea5fcd1fdd38365b47881c2511c325d6690adca26d4ba63ffad35a6a7b61bdff27d74c7d77716112d38ffa2fba6fbf9984f81d36721f05aa79ce99bfcb753c33, block_num: 30710, state_root_hash: fa7631f2dfb7f674ec361e379a205c9909fb00ee919c11c65b5c0c30015ff5e9, previous_block_id: 33e03d392caa491a51a8262124ac2eb0ce340742cf63950a80905108b46ab6a16d6a84d7aba4aacd9ee17fbd0f30fa3a41ec2ddc26bfbf5f7848214fd62b42`\n\nThese 4 nodes are on 30686 while rest of the 6 are on 30710.\nNow blockchain has stopped altogether.","username":"AbhijeetBH 2","ts":"2021-07-03T13:02:05.644Z"}
{"msg":"cc: @pschwarz @amundson","username":"arsulegai","ts":"2021-07-04T05:25:12.254Z"}
{"msg":"@arsulegai After copying lmdb files from a node which was ahead, to the nodes which were failing validation, the bllockchain is again working now. But I think monitoring is required. We have lost 90% of transactions submitted as either failed block or unknown status","username":"AbhijeetBH 2","ts":"2021-07-04T06:32:04.940Z"}
{"msg":"Guys, once an invalid transaction is submitted to blockchain, it takes around 15 minutes and keeps retrying that invalid transaction. During this time if any new valid transaction is submitted, it stays in pending state. This is a worrisome situation since availability takes a hit just because of a single invalid transaction.","username":"AbhijeetBH 2","ts":"2021-07-05T05:36:55.778Z"}
{"msg":"Guys, once an invalid transaction is submitted to blockchain, it takes around 15 minutes and keeps retrying that invalid transaction. During this time if any new valid transaction is submitted, it stays in pending state. This is a worrisome situation since availability takes a hit just because of a single invalid transaction. \n\nWhat is a recommended way of suppressing this behaviour ?","username":"AbhijeetBH 2","ts":"2021-07-05T05:36:55.778Z"}
{"msg":"Abhijeet, you have 2 in your name. I am unable to tag you. Validator node will not block itself from receiving new requests. It will keep at least on transaction, but if it the only transaction then you see this error. Your validator should still receive newer transactions. One of the solution I have come across so far is to not fail a transaction but rather model your contract to know it is invalid by storing the status on chain. Another solution is to refresh the validator's runtime memory by restarting it.\n\nNote: A better solution to this, i.e. syncing the failed transaction status is added as a feature in Transact. Most probably in next version, you can expect a feature around this","username":"arsulegai","ts":"2021-07-05T18:43:34.403Z"}
{"msg":"@arsulegai I am unable to change my name. \n\nI have been using the second solution so far i.e. restarting the all the validators. But I like the first solution i.e. storing the status. Still any runtime errors in Python contract still results invalid transaction.","username":"AbhijeetBH 2","ts":"2021-07-06T05:51:12.023Z"}
{"msg":"PBFT has been breaking regularly now on Production. A few nodes are always left behind. While a few keep adding blocks. I have no clue what's going on. Then after sometime, the node which is behind starts failing the blocks","username":"AbhijeetBH 2","ts":"2021-07-08T16:38:36.640Z"}
{"msg":"out of 10 nodes, 9 nodes have already committed the blocks, while one nodes keeps giving error.","username":"AbhijeetBH 2","ts":"2021-07-08T16:40:04.840Z"}
{"msg":"","username":"AbhijeetBH 2","ts":"2021-07-08T16:40:41.855Z","attachments":[{"type":"file","title":"sawtooth-8689d6799c-2bqx5-pbftengine.txt","title_link":"/file-upload/Nvtf79wP6skFf5Gai/sawtooth-8689d6799c-2bqx5-pbftengine.txt","url":"/file-upload/Nvtf79wP6skFf5Gai/sawtooth-8689d6799c-2bqx5-pbftengine.txt","remote":false,"fileId":"Nvtf79wP6skFf5Gai","fileName":"sawtooth-8689d6799c-2bqx5-pbftengine.txt"}]}
{"msg":"These are the logs. @pschwarz @amundson","username":"AbhijeetBH 2","ts":"2021-07-08T16:41:36.051Z"}
{"msg":"Reminder that the next Sawtooth Contributor Session is tomorrow at 10am US/Central. The zoom link is https://us02web.zoom.us/j/89262216179?pwd=UzFyK2t6MmxGTkxwR2dydnBkaUtDQT09 and the agenda/working doc is at https://docs.google.com/document/d/1WlF8UfoKAEydJobHWDvz-tMpWqQSTlChoFv50fHX1tM/edit# -- feel free to add agenda items if you have them","username":"amundson","ts":"2021-07-08T21:09:20.845Z"}
{"msg":"Hello Sawtooth Developers! Reminder to please join the DevRel Marketing Committee call at 9am PT tomorrow- 7/14. Take a look at the agenda and add items if you'd like here: https://wiki.hyperledger.org/x/sANCAw","username":"Helen_Garneau","ts":"2021-07-13T13:27:56.969Z"}
{"msg":"Has joined the channel.","username":"rafaelmelo","ts":"2021-07-29T18:27:59.811Z","type":"uj"}
{"msg":"Reminder that the next Sawtooth Contributor Session is tomorrow at 10am US/Central. The zoom link is https://us02web.zoom.us/j/88191563969?pwd=NkloR1VhQ2JLU1RQZW0vY2hHS1VOQT09 (different than normal link) and the agenda/working doc is at https://docs.google.com/document/d/1WlF8UfoKAEydJobHWDvz-tMpWqQSTlChoFv50fHX1tM/edit# -- feel free to add agenda items if you have them","username":"agunde","ts":"2021-08-05T19:13:39.238Z"}
{"msg":"Hi all !!\nAfter struggling with solving this issue on production and taking a few measures, I am coming back to the forum in hope of getting help on following ticket. https://lists.hyperledger.org/g/sawtooth/message/852\nI am also facing a similar issue with 2 out of 7 Nodes on production and this has brought the complete blockchain to halt. following is a detailed backtrace:\n\n`at src/libstd/sys_common/backtrace.rs:71\n2: 0x7f62860e0d36 - std::panicking::default_hook::{{closure}}::he20974adbefcc046\nat src/libstd/sys_common/backtrace.rs:59\nat src/libstd/panicking.rs:197\n3: 0x7f62860e0ac9 - std::panicking::default_hook::he4af6af4ac7fef7b\nat src/libstd/panicking.rs:211\n4: 0x7f62860e143f - std::panicking::rust_panic_with_hook::h057ff03eb4c8000f\nat src/libstd/panicking.rs:474\n5: 0x7f62860e0fc1 - std::panicking::continue_panic_fmt::ha6d6ae144369025b\nat src/libstd/panicking.rs:381\n6: 0x7f62860e0ea5 - rust_begin_unwind\nat src/libstd/panicking.rs:308\n7: 0x7f628610a03c - core::panicking::panic_fmt::hc4f83bfed80aeabd\nat src/libcore/panicking.rs:85\n8: 0x7f6285d508ed - core::result::unwrap_failed::h4e6021f3814dea74\n9: 0x7f6285f18a10 - core::ops::function::impls::<impl core::ops::function::FnOnce<A> for &mut F>::call_once::h57b1d53639052476\n10: 0x7f6285d56067 - <&mut I as core::iter::traits::iterator::Iterator>::next::ha31cc21dc9369295\n11: 0x7f6285cadd8a - <alloc::vec::Vec<T> as alloc::vec::SpecExtend<T,I>>::from_iter::had44e8f5062869bc\n12: 0x7f6285f3b0ca - <sawtooth_validator::scheduler::py_scheduler::PyScheduler as sawtooth_validator::scheduler::Scheduler>::complete::he4a2710d77656596\n13: 0x7f6285d8fc70 - sawtooth_validator::journal::block_validator::BlockValidationProcessor<SBV>::validate_block::h42228c67dd79a36a\n14: 0x7f6285f11084 - std::sys_common::backtrace::__rust_begin_short_backtrace::ha5884d17750b97f3\n15: 0x7f6285f182ef - std::panicking::try::do_call::hd3adc0ff8af40e20\n16: 0x7f62860f2409 - __rust_maybe_catch_panic\nat src/libpanic_unwind/lib.rs:85\n17: 0x7f6285d6c976 - core::ops::function::FnOnce::call_once{{vtable.shim}}::heba166d4acd621f0\n18: 0x7f62860c364e - <alloc::boxed::Box<F> as core::ops::function::FnOnce<A>>::call_once::h805c3cc89d534c05\nat /rustc/a53f9df32fbb0b5f4382caaad8f1a46f36ea887c/src/liballoc/boxed.rs:704\n19: 0x7f62860f10bf - std::sys::unix::thread::Thread::new::thread_start::h6f10b78f26c98dc6\nat /rustc/a53f9df32fbb0b5f4382caaad8f1a46f36ea887c/src/liballoc/boxed.rs:704\nat src/libstd/sys_common/thread.rs:13\nat src/libstd/sys/unix/thread.rs:79\n20: 0x7f628a9ee6da - start_thread\n21: 0x7f628a4ff88e - __clone\n22: 0x0 - <unknown>`","username":"AbhijeetBH 2","ts":"2021-08-25T08:09:30.919Z"}
{"msg":"Hi all !!\nAfter struggling with solving this issue on production and taking a few measures, I am coming back to the forum in hope of getting help on following ticket. https://lists.hyperledger.org/g/sawtooth/message/852\nI am also facing a similar issue with 2 out of 7 Nodes on production and this has brought the complete blockchain to halt. following is a detailed backtrace:\n\n\n`[2021-08-25 08:07:56.942 ERROR ffi] [src/state/merkle_ffi.rs: 423] Address 10373e83d96f8ef69fe93be62180bee3e0b4fa49d1294b0c27c46f5671bed181, in deletions, was not found.\nthread '<unnamed>' panicked at 'No method get_batch_execution_result on python scheduler: PyErr { ptype: <class 'KeyError'>, pvalue: Some(KeyError('Value was not found',)), ptraceback: Some(<traceback object at 0x7f62831d6108>) }', src/libcore/result.rs:999:5\nstack backtrace:\n0: 0x7f62860e4b03 - std::sys::unix::backtrace::tracing::imp::unwind_backtrace::h6485381528590a55\nat src/libstd/sys/unix/backtrace/tracing/gcc_s.rs:39\n1: 0x7f62860dc7ab - std::sys_common::backtrace::_print::h49a82ae9552e35c7\nat src/libstd/sys_common/backtrace.rs:71\n2: 0x7f62860e0d36 - std::panicking::default_hook::{{closure}}::he20974adbefcc046\nat src/libstd/sys_common/backtrace.rs:59\nat src/libstd/panicking.rs:197\n3: 0x7f62860e0ac9 - std::panicking::default_hook::he4af6af4ac7fef7b\nat src/libstd/panicking.rs:211\n4: 0x7f62860e143f - std::panicking::rust_panic_with_hook::h057ff03eb4c8000f\nat src/libstd/panicking.rs:474\n5: 0x7f62860e0fc1 - std::panicking::continue_panic_fmt::ha6d6ae144369025b\nat src/libstd/panicking.rs:381\n6: 0x7f62860e0ea5 - rust_begin_unwind\nat src/libstd/panicking.rs:308\n7: 0x7f628610a03c - core::panicking::panic_fmt::hc4f83bfed80aeabd\nat src/libcore/panicking.rs:85\n8: 0x7f6285d508ed - core::result::unwrap_failed::h4e6021f3814dea74\n9: 0x7f6285f18a10 - core::ops::function::impls::<impl core::ops::function::FnOnce<A> for &mut F>::call_once::h57b1d53639052476\n10: 0x7f6285d56067 - <&mut I as core::iter::traits::iterator::Iterator>::next::ha31cc21dc9369295\n11: 0x7f6285cadd8a - <alloc::vec::Vec<T> as alloc::vec::SpecExtend<T,I>>::from_iter::had44e8f5062869bc\n12: 0x7f6285f3b0ca - <sawtooth_validator::scheduler::py_scheduler::PyScheduler as sawtooth_validator::scheduler::Scheduler>::complete::he4a2710d77656596\n13: 0x7f6285d8fc70 - sawtooth_validator::journal::block_validator::BlockValidationProcessor<SBV>::validate_block::h42228c67dd79a36a\n14: 0x7f6285f11084 - std::sys_common::backtrace::__rust_begin_short_backtrace::ha5884d17750b97f3\n15: 0x7f6285f182ef - std::panicking::try::do_call::hd3adc0ff8af40e20\n16: 0x7f62860f2409 - __rust_maybe_catch_panic\nat src/libpanic_unwind/lib.rs:85\n17: 0x7f6285d6c976 - core::ops::function::FnOnce::call_once{{vtable.shim}}::heba166d4acd621f0\n18: 0x7f62860c364e - <alloc::boxed::Box<F> as core::ops::function::FnOnce<A>>::call_once::h805c3cc89d534c05\nat /rustc/a53f9df32fbb0b5f4382caaad8f1a46f36ea887c/src/liballoc/boxed.rs:704\n19: 0x7f62860f10bf - std::sys::unix::thread::Thread::new::thread_start::h6f10b78f26c98dc6\nat /rustc/a53f9df32fbb0b5f4382caaad8f1a46f36ea887c/src/liballoc/boxed.rs:704\nat src/libstd/sys_common/thread.rs:13\nat src/libstd/sys/unix/thread.rs:79\n20: 0x7f628a9ee6da - start_thread\n21: 0x7f628a4ff88e - __clone\n22: 0x0 - <unknown>`","username":"AbhijeetBH 2","ts":"2021-08-25T08:09:30.919Z"}
{"msg":"@AbhijeetBH 2 which version of Sawtooth are you running?","username":"arsulegai","ts":"2021-08-26T14:04:56.945Z"}
{"msg":"Check why does it say deletions entries are not found.","username":"arsulegai","ts":"2021-08-26T14:05:18.660Z"}
{"msg":"I am running hyperledger/sawtooth-validator:chime\n\nHow can I check that ? What are troubleshooting steps ?","username":"AbhijeetBH 2","ts":"2021-08-30T04:10:11.844Z"}
{"msg":"","username":"AbhijeetBH 2","ts":"2021-08-31T05:21:38.256Z","attachments":[{"type":"file","title":"Screenshot from 2021-08-31 10-48-00.png","title_link":"/file-upload/eCaEWxfWajkTFnedY/Screenshot%20from%202021-08-31%2010-48-00.png","image_url":"/file-upload/eCaEWxfWajkTFnedY/Screenshot%20from%202021-08-31%2010-48-00.png","image_type":"image/png","image_size":40591,"url":"/file-upload/eCaEWxfWajkTFnedY/Screenshot%20from%202021-08-31%2010-48-00.png","remote":false,"fileId":"eCaEWxfWajkTFnedY","fileName":"Screenshot from 2021-08-31 10-48-00.png"}]}
{"msg":"Reminder that the next Sawtooth Contributor Session is today at 10am US/Central. The zoom link is https://us02web.zoom.us/j/89262216179?pwd=UzFyK2t6MmxGTkxwR2dydnBkaUtDQT09 and the agenda/working doc is at https://docs.google.com/document/d/1WlF8UfoKAEydJobHWDvz-tMpWqQSTlChoFv50fHX1tM/edit# -- feel free to add agenda items if you have them","username":"agunde","ts":"2021-09-03T13:02:55.390Z"}
{"msg":"Has joined the channel.","username":"isabeltomb","ts":"2021-09-03T15:01:42.012Z","type":"uj"}
{"msg":"is there anywhere I can read about rationale for moving docs to its own repo? I don't have an issue with it, just curious about the rationale.","username":"Dan","ts":"2021-09-16T17:55:05.075Z"}
{"msg":"@Dan The rationale is essentially that assembling the docs from a bunch of separate repos is a failed experiment, and that treating documentation as a separate component completely (the website), it is easier to get good results.","username":"amundson","ts":"2021-09-27T15:56:37.084Z"}
{"msg":"Hi @AbhijeetBH 2 did you get a resolution or a workaround to this? We are on 1.1.5 though and the error is similar althought not the same. Whenever we send a transaction the validator crashes....","username":"RajaramKannan","ts":"2021-10-18T18:11:07.625Z"}
{"msg":"We are seeing all of a sudden a crash in the validators in our UAT environment (we are still on 1.1.5). We have narrowed down to the fact that when a single batch comes in, it works fine and doesnt crash. But when multiple batches come in (not even that many - say even 5-10), the validator crashes!","username":"RajaramKannan","ts":"2021-10-19T05:50:45.140Z"}
{"msg":"stack trace - hread '<unnamed>' panicked at 'No method complete on python scheduler: PyErr { ptype: <class 'KeyError'>, pvalue: Some(KeyError('Value was not found',)), ptraceback: Some(<tracebackobject at 0x7f2f383b0b88>) }', src/libcore/result.rs:997:5\nstack backtrace:\n   0: std::sys::unix::backtrace::tracing::imp::unwind_backtrace\n             at src/libstd/sys/unix/backtrace/tracing/gcc_s.rs:39\n   1: std::sys_common::backtrace::_print\n             at src/libstd/sys_common/backtrace.rs:70\n   2: std::panicking::default_hook::{{closure}}\n             at src/libstd/sys_common/backtrace.rs:58\n             at src/libstd/panicking.rs:200\n   3: std::panicking::default_hook\n             at src/libstd/panicking.rs:215\n   4: std::panicking::rust_panic_with_hook\n             at src/libstd/panicking.rs:478\n   5: std::panicking::continue_panic_fmt\n             at src/libstd/panicking.rs:385\n   6: rust_begin_unwind\n             at src/libstd/panicking.rs:312\n   7: core::panicking::panic_fmt\n             at src/libcore/panicking.rs:85\n   8: core::result::unwrap_failed\n   9: <sawtooth_validator::scheduler::py_scheduler::PyScheduler as sawtooth_validator::scheduler::Scheduler>::complete\n  10: sawtooth_validator::journal::candidate_block::CandidateBlock::summarize\n  11: sawtooth_validator::journal::publisher::BlockPublisher::summarize_block\n  12: block_publisher_summarize_block\n  13: ffi_call_unix64\n  14: ffi_call\n  15: _ctypes_callproc\n  16: <unknown>\n  17: PyObject_Call\n  18: PyEval_EvalFrameEx\n  19: <unknown>\n  20: PyEval_EvalCodeEx\n  21: <unknown>\n  22: PyObject_Call\n  23: PyEval_EvalFrameEx\n  24: <unknown>\n  25: PyEval_EvalFrameEx\n  26: <unknown>\n  27: PyEval_EvalFrameEx\n  28: PyEval_EvalFrameEx\n  29: PyEval_EvalFrameEx\n  30: PyEval_EvalFrameEx\n  31: <unknown>\n  32: PyEval_EvalCodeEx\n  33: <unknown>\n  34: PyObject_Call\n  35: PyEval_EvalFrameEx\n  36: <unknown>\n  37: PyEval_EvalCodeEx\n  38: <unknown>\n  39: PyObject_Call\n  40: PyEval_EvalFrameEx\n  41: PyEval_EvalFrameEx\n  42: <unknown>\n  43: PyEval_EvalCodeEx\n  44: <unknown>\n  45: PyObject_Call\n  46: PyEval_EvalFrameEx\n  47: PyEval_EvalFrameEx\n  48: PyEval_EvalFrameEx\n  49: <unknown>\n  50: PyEval_EvalCodeEx\n  51: <unknown>\n  52: PyObject_Call\n  53: <unknown>\n  54: PyObject_Call\n  55: PyEval_CallObjectWithKeywords\n  56: <unknown>\n  57: start_thread\n  58: clone\nfatal runtime error: failed to initiate panic, error 5","username":"RajaramKannan","ts":"2021-10-19T05:51:02.533Z"}
{"msg":"any troubleshooting tips/workarounds/tips will be much appreciated","username":"RajaramKannan","ts":"2021-10-19T05:51:27.037Z"}
{"msg":"Note we saw a different error when it was in parallel scheduling setup, this is for serial - but I think the root cause is the same. Except we dont know the root cause","username":"RajaramKannan","ts":"2021-10-19T05:52:09.883Z"}
{"msg":"Docker exit status is 139 i.e SigSEGV","username":"RajaramKannan","ts":"2021-10-19T05:57:37.652Z"}
{"msg":"@RajaramKannan quick question: do you have both the add and delete operations in your smart contract as part of any transaction","username":"arsulegai","ts":"2021-10-19T10:10:13.492Z"}
{"msg":"@RajaramKannan quick question: do you have both the add and delete operations in your smart contract as part of any transaction?","username":"arsulegai","ts":"2021-10-19T10:10:13.492Z"}
{"msg":"@RajaramKannan quick question: do you have both the add and delete state operations in your smart contract as part of any transaction?","username":"arsulegai","ts":"2021-10-19T10:10:13.492Z"}
{"msg":"Other things you can confirm, see which address does it claim is not found (is it pre-existing state or a new state). Is any of your batch/transaction trying to do something with it.","username":"arsulegai","ts":"2021-10-19T10:15:36.424Z"}
{"msg":"I suspect we do, I'll check. We are narrowing down on if any specific transaction is causing it, but if you have anything we can check as a hypothesis, it will be helpful","username":"RajaramKannan","ts":"2021-10-19T10:15:48.546Z"}
{"msg":"Since you're on older branch, there was an issue back then ~ it was to do with delete and add state operations happening in one go. Maybe you can draw up a tree structure, see if what you're adding is in the tree path what is getting deleted.","username":"arsulegai","ts":"2021-10-19T10:17:52.329Z"}
{"msg":"Since you're on older branch, there was an issue back then ~ it was to do with delete and add state operations happening in one go. Maybe you can draw up a tree structure, see if what you're adding is in the tree path of what is getting deleted.","username":"arsulegai","ts":"2021-10-19T10:17:52.329Z"}
{"msg":"The error log that I see here is different from what was observed earlier though. This is occurring at summarize block step? (a forking issue maybe?) which consensus algorithm are you on?","username":"arsulegai","ts":"2021-10-19T10:19:42.171Z"}
{"msg":"We are on PBFT ...","username":"RajaramKannan","ts":"2021-10-19T10:19:55.902Z"}
{"msg":"The above was after changing it to serial yesterday. When we had it as parallel we were seeing thread '<unnamed>' panicked at 'No method get_batch_execution_result on python scheduler: PyErr { ptype: <class 'KeyError'>, pvalue: Some(KeyError('Value was not found',)), ptraceback: Some(<traceback object at 0x7eba7ffdad48>) }', src/libcore/result.rs:997:5\nnote: Run with RUST_BACKTRACE=1 environment variable to display a backtrace.\nfatal runtime error: failed to initiate panic, error 5","username":"RajaramKannan","ts":"2021-10-19T10:20:49.263Z"}
{"msg":"but I did not have the backtrace on at that point","username":"RajaramKannan","ts":"2021-10-19T10:20:59.462Z"}
{"msg":"Unfortunately it was not showing which Key... (If that was an address for example)","username":"RajaramKannan","ts":"2021-10-19T10:22:09.343Z"}
{"msg":"Need some logs before the crash, to understand what was the scenario. It appears to be like `summarize_block` is trying to get a state that is missing. Maybe prior log traces (including block IDs for reference) would help to know what's happening there","username":"arsulegai","ts":"2021-10-19T10:38:47.804Z"}
{"msg":"@amundson @pschwarz @agunde have you seen this error before?","username":"arsulegai","ts":"2021-10-19T10:40:29.482Z"}
{"msg":"There doesnt seem to be much useful in the log, let me get them in any case... We actually are also seeing this sometimes for only 1 transaction/batch apparently. I will post it shortly...","username":"RajaramKannan","ts":"2021-10-19T10:47:10.213Z"}
{"msg":"","username":"RajaramKannan","ts":"2021-10-19T11:16:23.029Z","attachments":[{"type":"file","title":"crash-19-10-2021-1 copy.docx","title_link":"/file-upload/jmSHWQ4R7BZbSA73C/crash-19-10-2021-1%20copy.docx","url":"/file-upload/jmSHWQ4R7BZbSA73C/crash-19-10-2021-1%20copy.docx","remote":false,"fileId":"jmSHWQ4R7BZbSA73C","fileName":"crash-19-10-2021-1 copy.docx"}]}
{"msg":"","username":"RajaramKannan","ts":"2021-10-19T11:50:06.499Z","attachments":[{"type":"file","title":"crash-19-10-2021-1 copy.docx","title_link":"/file-upload/sBjD6o5FWc96dXhWr/crash-19-10-2021-1%20copy.docx","url":"/file-upload/sBjD6o5FWc96dXhWr/crash-19-10-2021-1%20copy.docx","remote":false,"fileId":"sBjD6o5FWc96dXhWr","fileName":"crash-19-10-2021-1 copy.docx"}]}
{"msg":"\"No method\" means it tried to call that function on the python object and it wasn't there","username":"amundson","ts":"2021-10-19T13:22:09.211Z"}
{"msg":"Has anything about the environment changed recently? (How you start things up, etc?)","username":"amundson","ts":"2021-10-19T13:23:15.162Z"}
{"msg":"Hi @amud","username":"RajaramKannan","ts":"2021-10-19T14:03:43.571Z"}
{"msg":"@amundson we did change it to auto restart if the container goes down, but nothing else. Also this issue happens even if the container is not auto - restarted.","username":"RajaramKannan","ts":"2021-10-19T14:07:21.015Z"}
{"msg":"We noticed it seems to happen for a transaction where we are setting an address. Interestingly other transactions in the past should have already set that address and have not (not because the  previous transactions did not try, but there was no failure and neither were the values set.). This is however circumstantial although we are able to currently isolate and replicate this behvaior, but the logs as you can see do not show any further details...","username":"RajaramKannan","ts":"2021-10-19T14:09:51.979Z"}
{"msg":"FYI - the sawtooth meeting this morning is canceled. See you next time.","username":"amundson","ts":"2021-10-29T13:09:08.515Z"}
{"msg":"@amundson @arsulegai just following up on our issue on the crash. Background, we have an account based model, where account holdings for each account are in a particular address in the tree. This is in the form of a simple JSON of the form {[\"USD\":3000]} for example. We have a number of transactions that primarily update the holdings and send out a custom event. None of the transactions delete state at any address, they either set if not previously set or else update. We went backwards and reviewed all our daily LMDB backups as well as the logs prior to the crash. Interestingly, that particular address did have the data/state set up until the transaction that crashed. In the logs of the transaction where it crashed, we print the current data in the state and it was blank! And then it crashed.  The transaction just prior to that was the same type of transaction and it got data from the state fine and went through... It almost feels like one specific address in LMDB suddenly got corrupted (not sure what the right term is!) and anytime any operation (maybe a set or update) on it is done now it crashes the validator in all nodes.   Any ideas? We havent seen it yet in prod, but we need to figure out why it happened in our UAT environment so that we can try to avoid it in prod.","username":"RajaramKannan","ts":"2021-10-29T13:32:31.381Z"}
{"msg":"Does for some reason you are sending payloads which has exact same hash signatures ? Ususally `nonce` field is used to variate hash signature between each transaction.","username":"AbhijeetBH 2","ts":"2021-11-01T04:09:02.631Z"}
{"msg":"We do generate a unique nonce, but I dont think this is the issue. This has happened after running maybe 100K txns overall and atleast several 100 that has set or updated that specific address location with no issues so far until it crashed for the first time. Any new transactions after that to that address location ends up crashing the validator. (And the TP logs show that there is no data there either, when it was there prior to the crash)","username":"RajaramKannan","ts":"2021-11-01T05:11:50.154Z"}
{"msg":"So this is a new sort of error it seems. Since the issue I faced tends to get solved once I restart all the validator nodes and retry the transaction with a new nonce","username":"AbhijeetBH 2","ts":"2021-11-02T03:49:49.110Z"}
{"msg":"yes, first time we are seeing this and it has been up for 2 years continuously now!","username":"RajaramKannan","ts":"2021-11-02T07:14:46.861Z"}
{"msg":"Has joined the channel.","username":"Aljone","ts":"2021-11-09T16:04:34.022Z","type":"uj"}
{"msg":"`const DEFAULT_BATCH_POOL_SAMPLE_SIZE: usize = 5;\nconst DEFAULT_BATCH_POOL_INITIAL_SAMPLE_VALUE: usize = 30;\nconst BATCH_POOL_MULTIPLIER: usize = 10;`","username":"Aljone","ts":"2021-11-09T16:05:12.241Z"}
{"msg":"Hi Team, I have a question regarding the pending batch pool's limit.\n\n`\nconst DEFAULT_BATCH_POOL_SAMPLE_SIZE: usize = 5;\nconst DEFAULT_BATCH_POOL_INITIAL_SAMPLE_VALUE: usize = 30;\nconst BATCH_POOL_MULTIPLIER: usize = 10;\n`\n\nIs there a way to configure the DEFAULT_BATCH_POOL_INITIAL_SAMPLE_VALUE \nin /sawtooth-lib/libsawtooth/src/journal/publisher/batch_pool.rs\n\nThe validator sometimes returns HTTP/1.1: 429 status when there's a heavy request.\nSo, I want to test by increasing it a little bit.\n\nPlease help.","username":"Aljone","ts":"2021-11-09T16:08:07.062Z"}
{"msg":"@amundson @arsulegai One more instance of a crash that seems to be related to data in an address in LMDB going bad( not sure what to call it - maybe corrupted?). Same sequence, a transaction was sent that basically gets from that address and then updates the values and sets to that address. The next transaction for the same address when it does a get it sees [] instead of the values previously set and then all the nodes crash (from prior logs on block summarizing). The txn seems quite innocuous just does a get/set on that address.  I have copied down the LMDB file to see what is going in there and done an mdb_dump, but obviously cant make out what is going on inside :-). I want to see what the actual value stored in there is now if any in that address. 1. Any further hypothesis on what may be going wrong? 2. Any recommendations on how I can read the LMDB file to see what is there in that address now ?","username":"RajaramKannan","ts":"2021-12-03T02:49:08.023Z"}
{"msg":"@RajaramKannan you can also get state out of the REST API https://sawtooth.hyperledger.org/docs/core/releases/1.2/rest_api/endpoint_specs.html - GET /state/{address}","username":"amundson","ts":"2021-12-14T14:29:32.411Z"}
{"msg":"@amundson thanks, we already did that and it shows []. The state previously (we backup LMDB daily) had values and was never deleted but just set/updated to new values. Between that and the fact that any operation on that state is causing all our nodes to crash, prompted me to see if we can explore the LMDB file externally as well...","username":"RajaramKannan","ts":"2021-12-15T04:23:27.232Z"}
{"msg":"@RajaramKannan at a high-level, the lmdb database is key,value where key is the hash of a node of a tree and the value is a cbor-encoded struct of the data at that node of the tree. if you decoded the cbor-encoded value, one of the values of the struct will be the bytes set by the smart contract. if you wanted to read the database, you have to start at the root of the tree and work your way down; to do that you use the state root hash stored within a block.","username":"amundson","ts":"2021-12-21T15:23:59.550Z"}
{"msg":"thanks @amundson Will let you know if we find anything.","username":"RajaramKannan","ts":"2021-12-22T05:16:17.043Z"}
{"msg":"can we get some reviews on: https://github.com/hyperledger/sawtooth-sdk-python/pull/30","username":"Dan","ts":"2022-02-03T15:00:11.749Z"}
{"msg":"Thanks @Dan PR has been merged.","username":"agunde","ts":"2022-02-03T16:32:10.087Z"}
{"msg":"muchas gracias :)","username":"Dan","ts":"2022-02-03T16:33:06.026Z"}
{"msg":"Has joined the channel.","username":"saheli_c","ts":"2022-02-07T07:34:51.189Z","type":"uj"}
{"msg":"In Sawtooth core we are planning to implement some modifications to the parallel scheduler implementation. The original scheduler has been developed in python. \n\nBut we are observing that in the newer versions of the Sawtooth core, all the modules are being implemented in Rust. So will it be better to implement the modifications to the scheduler in Rust and invoking the Rust modules from python or to develop these modules in python itself? Any advice on this is really appreciated.","username":"saheli_c","ts":"2022-02-07T07:34:51.712Z"}
{"msg":"Sawtooth is being rewritten in Rust and in Sawtooth 2.0 the scheduler implementation will come from Transact (There is not currently a finished parallel scheduler in Transact). However 2.0 is still a ways out. So if you are planning to use sawtooth 1.2 your modifications should be written in Python.","username":"agunde","ts":"2022-02-07T15:01:31.205Z"}
{"msg":"Reminder that the next Sawtooth Contributor Session is Friday at 10:30am US/Central. The zoom link is https://us02web.zoom.us/j/89262216179?pwd=UzFyK2t6MmxGTkxwR2dydnBkaUtDQT09   and the agenda/working doc is at https://docs.google.com/document/d/1WlF8UfoKAEydJobHWDvz-tMpWqQSTlChoFv50fHX1tM/edit# -- feel free to add agenda items if you have them","username":"agunde","ts":"2022-03-15T17:33:26.975Z"}
{"msg":"Reminder has also been posted in the new discord \"sawtooth-contributors\" channel","username":"agunde","ts":"2022-03-15T17:34:11.928Z"}
{"msg":"Reminder has also been posted in the new Hyperledger discord \"sawtooth-contributors\" channel","username":"agunde","ts":"2022-03-15T17:34:11.928Z"}
{"msg":"","username":"rjones","ts":"2022-03-23T17:35:56.089Z","type":"room_changed_topic"}
{"msg":"","username":"rjones","ts":"2022-03-23T17:35:56.098Z","type":"room_changed_description"}
